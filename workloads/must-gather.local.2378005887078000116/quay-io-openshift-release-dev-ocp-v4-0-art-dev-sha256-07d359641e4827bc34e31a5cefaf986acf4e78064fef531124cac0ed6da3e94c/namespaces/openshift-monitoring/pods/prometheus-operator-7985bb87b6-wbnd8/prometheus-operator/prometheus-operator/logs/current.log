2023-01-09T04:47:06.298383138Z level=info ts=2023-01-09T04:47:06.298300268Z caller=main.go:220 msg="Starting Prometheus Operator" version="(version=0.60.1, branch=rhaos-4.12-rhel-8, revision=a59cc50)"
2023-01-09T04:47:06.298521355Z level=info ts=2023-01-09T04:47:06.298495291Z caller=main.go:221 build_context="(go=go1.19.4, user=root, date=20230105-00:50:47)"
2023-01-09T04:47:06.309961242Z level=warn ts=2023-01-09T04:47:06.309895591Z caller=operator.go:328 component=prometheusoperator msg="failed to check if the API supports the endpointslice resources" err="converting (v1.APIGroup) to (v1.APIResourceList): unknown conversion"
2023-01-09T04:47:06.309961242Z level=info ts=2023-01-09T04:47:06.309929873Z caller=operator.go:330 component=prometheusoperator msg="Kubernetes API capabilities" endpointslices=false
2023-01-09T04:47:06.311826218Z level=info ts=2023-01-09T04:47:06.311762792Z caller=main.go:103 msg="Starting insecure server on 127.0.0.1:8080"
2023-01-09T04:47:06.313404316Z level=info ts=2023-01-09T04:47:06.31337105Z caller=operator.go:457 component=alertmanageroperator msg="connection established" cluster-version=v1.25.4+77bec7a
2023-01-09T04:47:06.313425519Z level=info ts=2023-01-09T04:47:06.313400917Z caller=operator.go:466 component=alertmanageroperator msg="CRD API endpoints ready"
2023-01-09T04:47:06.313599300Z level=info ts=2023-01-09T04:47:06.313556072Z caller=operator.go:440 component=prometheusoperator msg="connection established" cluster-version=v1.25.4+77bec7a
2023-01-09T04:47:06.313659333Z level=info ts=2023-01-09T04:47:06.313635852Z caller=operator.go:449 component=prometheusoperator msg="CRD API endpoints ready"
2023-01-09T04:47:06.313785987Z level=info ts=2023-01-09T04:47:06.313760189Z caller=operator.go:311 component=thanosoperator msg="connection established" cluster-version=v1.25.4+77bec7a
2023-01-09T04:47:06.313844687Z level=info ts=2023-01-09T04:47:06.313822088Z caller=operator.go:320 component=thanosoperator msg="CRD API endpoints ready"
2023-01-09T04:47:06.413995538Z level=info ts=2023-01-09T04:47:06.413944794Z caller=operator.go:369 component=prometheusoperator msg="successfully synced all caches"
2023-01-09T04:47:06.414105580Z level=info ts=2023-01-09T04:47:06.414074205Z caller=operator.go:263 component=thanosoperator msg="successfully synced all caches"
2023-01-09T04:47:06.714463233Z level=info ts=2023-01-09T04:47:06.714413227Z caller=operator.go:289 component=alertmanageroperator msg="successfully synced all caches"
2023-01-09T04:47:15.844165146Z level=info ts=2023-01-09T04:47:15.844111706Z caller=operator.go:754 component=alertmanageroperator key=openshift-monitoring/main msg="sync alertmanager"
2023-01-09T04:47:16.008356985Z level=info ts=2023-01-09T04:47:16.008304254Z caller=operator.go:754 component=alertmanageroperator key=openshift-monitoring/main msg="sync alertmanager"
2023-01-09T04:47:16.095628764Z level=info ts=2023-01-09T04:47:16.095571794Z caller=operator.go:754 component=alertmanageroperator key=openshift-monitoring/main msg="sync alertmanager"
2023-01-09T04:47:16.185414681Z level=info ts=2023-01-09T04:47:16.185368001Z caller=operator.go:754 component=alertmanageroperator key=openshift-monitoring/main msg="sync alertmanager"
2023-01-09T04:47:20.290337390Z level=info ts=2023-01-09T04:47:20.290289917Z caller=operator.go:754 component=alertmanageroperator key=openshift-monitoring/main msg="sync alertmanager"
2023-01-09T04:47:20.313519023Z level=info ts=2023-01-09T04:47:20.313474574Z caller=operator.go:1390 component=prometheusoperator key=openshift-monitoring/k8s msg="sync prometheus"
2023-01-09T04:47:20.518608898Z level=info ts=2023-01-09T04:47:20.518545612Z caller=operator.go:754 component=alertmanageroperator key=openshift-monitoring/main msg="sync alertmanager"
2023-01-09T04:47:20.577953466Z level=info ts=2023-01-09T04:47:20.577888477Z caller=operator.go:1390 component=prometheusoperator key=openshift-monitoring/k8s msg="sync prometheus"
2023-01-09T04:47:20.578024871Z level=info ts=2023-01-09T04:47:20.577987955Z caller=operator.go:1559 component=prometheusoperator key=openshift-monitoring/k8s msg="update prometheus status"
2023-01-09T04:47:20.578069415Z level=info ts=2023-01-09T04:47:20.578022222Z caller=operator.go:1581 component=prometheusoperator key=openshift-monitoring/k8s statefulset=openshift-monitoring/prometheus-k8s shard=0 msg="not found"
2023-01-09T04:47:20.587822059Z level=info ts=2023-01-09T04:47:20.58776656Z caller=operator.go:754 component=alertmanageroperator key=openshift-monitoring/main msg="sync alertmanager"
2023-01-09T04:47:20.676298163Z level=info ts=2023-01-09T04:47:20.676252862Z caller=operator.go:1559 component=prometheusoperator key=openshift-monitoring/k8s msg="update prometheus status"
2023-01-09T04:47:20.825184337Z level=info ts=2023-01-09T04:47:20.825123262Z caller=operator.go:1390 component=prometheusoperator key=openshift-monitoring/k8s msg="sync prometheus"
2023-01-09T04:47:20.825228327Z level=info ts=2023-01-09T04:47:20.825193547Z caller=operator.go:1559 component=prometheusoperator key=openshift-monitoring/k8s msg="update prometheus status"
2023-01-09T04:47:21.047145052Z level=info ts=2023-01-09T04:47:21.047098961Z caller=operator.go:1390 component=prometheusoperator key=openshift-monitoring/k8s msg="sync prometheus"
2023-01-09T04:47:21.047223406Z level=info ts=2023-01-09T04:47:21.047180398Z caller=operator.go:1559 component=prometheusoperator key=openshift-monitoring/k8s msg="update prometheus status"
2023-01-09T04:47:21.290687446Z level=info ts=2023-01-09T04:47:21.29062946Z caller=operator.go:1390 component=prometheusoperator key=openshift-monitoring/k8s msg="sync prometheus"
2023-01-09T04:47:21.290850329Z level=info ts=2023-01-09T04:47:21.290789163Z caller=operator.go:1559 component=prometheusoperator key=openshift-monitoring/k8s msg="update prometheus status"
2023-01-09T04:47:21.521549171Z level=info ts=2023-01-09T04:47:21.521499933Z caller=operator.go:754 component=alertmanageroperator key=openshift-monitoring/main msg="sync alertmanager"
2023-01-09T04:47:21.565608385Z level=info ts=2023-01-09T04:47:21.565556609Z caller=operator.go:1390 component=prometheusoperator key=openshift-monitoring/k8s msg="sync prometheus"
2023-01-09T04:47:21.565688330Z level=info ts=2023-01-09T04:47:21.565644217Z caller=operator.go:1559 component=prometheusoperator key=openshift-monitoring/k8s msg="update prometheus status"
2023-01-09T04:47:21.787915094Z level=info ts=2023-01-09T04:47:21.787858806Z caller=operator.go:1559 component=prometheusoperator key=openshift-monitoring/k8s msg="update prometheus status"
2023-01-09T04:47:32.952346101Z level=info ts=2023-01-09T04:47:32.952294562Z caller=operator.go:1390 component=prometheusoperator key=openshift-monitoring/k8s msg="sync prometheus"
2023-01-09T04:47:33.129212081Z level=info ts=2023-01-09T04:47:33.129166074Z caller=operator.go:754 component=alertmanageroperator key=openshift-monitoring/main msg="sync alertmanager"
2023-01-09T04:47:33.471832452Z level=info ts=2023-01-09T04:47:33.471741586Z caller=operator.go:754 component=alertmanageroperator key=openshift-monitoring/main msg="sync alertmanager"
2023-01-09T04:47:33.530346738Z level=info ts=2023-01-09T04:47:33.530296221Z caller=operator.go:1390 component=prometheusoperator key=openshift-monitoring/k8s msg="sync prometheus"
2023-01-09T04:47:33.530406938Z level=info ts=2023-01-09T04:47:33.53036484Z caller=operator.go:1559 component=prometheusoperator key=openshift-monitoring/k8s msg="update prometheus status"
2023-01-09T04:47:33.777400430Z level=info ts=2023-01-09T04:47:33.777346129Z caller=operator.go:754 component=alertmanageroperator key=openshift-monitoring/main msg="sync alertmanager"
2023-01-09T04:47:33.930468076Z level=info ts=2023-01-09T04:47:33.930418983Z caller=operator.go:754 component=alertmanageroperator key=openshift-monitoring/main msg="sync alertmanager"
2023-01-09T04:47:33.975983473Z level=info ts=2023-01-09T04:47:33.975934321Z caller=operator.go:1390 component=prometheusoperator key=openshift-monitoring/k8s msg="sync prometheus"
2023-01-09T04:47:33.976139837Z level=info ts=2023-01-09T04:47:33.976084963Z caller=operator.go:1559 component=prometheusoperator key=openshift-monitoring/k8s msg="update prometheus status"
2023-01-09T04:47:34.040833851Z level=info ts=2023-01-09T04:47:34.040761632Z caller=operator.go:754 component=alertmanageroperator key=openshift-monitoring/main msg="sync alertmanager"
2023-01-09T04:47:34.204417577Z level=info ts=2023-01-09T04:47:34.204363622Z caller=operator.go:1390 component=prometheusoperator key=openshift-monitoring/k8s msg="sync prometheus"
2023-01-09T04:47:34.204464401Z level=info ts=2023-01-09T04:47:34.204440205Z caller=operator.go:1559 component=prometheusoperator key=openshift-monitoring/k8s msg="update prometheus status"
2023-01-09T04:47:34.478612281Z level=info ts=2023-01-09T04:47:34.478568149Z caller=operator.go:1559 component=prometheusoperator key=openshift-monitoring/k8s msg="update prometheus status"
2023-01-09T04:47:36.731579565Z level=info ts=2023-01-09T04:47:36.731526599Z caller=operator.go:1559 component=prometheusoperator key=openshift-monitoring/k8s msg="update prometheus status"
2023-01-09T04:47:56.513681101Z level=info ts=2023-01-09T04:47:56.513623063Z caller=operator.go:754 component=alertmanageroperator key=openshift-monitoring/main msg="sync alertmanager"
2023-01-09T04:48:06.414681189Z level=info ts=2023-01-09T04:48:06.414621418Z caller=operator.go:1559 component=prometheusoperator key=openshift-monitoring/k8s msg="update prometheus status"
2023-01-09T04:48:12.576045962Z level=info ts=2023-01-09T04:48:12.575988389Z caller=operator.go:1390 component=prometheusoperator key=openshift-monitoring/k8s msg="sync prometheus"
2023-01-09T04:48:12.854058690Z level=info ts=2023-01-09T04:48:12.854011279Z caller=operator.go:1390 component=prometheusoperator key=openshift-monitoring/k8s msg="sync prometheus"
2023-01-09T04:48:12.854128937Z level=info ts=2023-01-09T04:48:12.854088033Z caller=operator.go:1559 component=prometheusoperator key=openshift-monitoring/k8s msg="update prometheus status"
2023-01-09T04:48:13.088731835Z level=info ts=2023-01-09T04:48:13.08867863Z caller=operator.go:1390 component=prometheusoperator key=openshift-monitoring/k8s msg="sync prometheus"
2023-01-09T04:48:13.088767967Z level=info ts=2023-01-09T04:48:13.088741248Z caller=operator.go:1559 component=prometheusoperator key=openshift-monitoring/k8s msg="update prometheus status"
2023-01-09T04:48:13.353641376Z level=info ts=2023-01-09T04:48:13.353599037Z caller=operator.go:1390 component=prometheusoperator key=openshift-monitoring/k8s msg="sync prometheus"
2023-01-09T04:48:13.353669265Z level=info ts=2023-01-09T04:48:13.353630586Z caller=operator.go:1559 component=prometheusoperator key=openshift-monitoring/k8s msg="update prometheus status"
2023-01-09T04:48:13.590676635Z level=info ts=2023-01-09T04:48:13.59063093Z caller=operator.go:1559 component=prometheusoperator key=openshift-monitoring/k8s msg="update prometheus status"
2023-01-09T04:48:16.302606235Z level=info ts=2023-01-09T04:48:16.302554889Z caller=operator.go:1390 component=prometheusoperator key=openshift-monitoring/k8s msg="sync prometheus"
2023-01-09T04:48:16.583231748Z level=info ts=2023-01-09T04:48:16.583187495Z caller=operator.go:1390 component=prometheusoperator key=openshift-monitoring/k8s msg="sync prometheus"
2023-01-09T04:48:16.583320081Z level=info ts=2023-01-09T04:48:16.583287233Z caller=operator.go:1559 component=prometheusoperator key=openshift-monitoring/k8s msg="update prometheus status"
2023-01-09T04:48:16.771655655Z level=info ts=2023-01-09T04:48:16.771601345Z caller=operator.go:754 component=alertmanageroperator key=openshift-monitoring/main msg="sync alertmanager"
2023-01-09T04:48:16.815915389Z level=info ts=2023-01-09T04:48:16.815870549Z caller=operator.go:1390 component=prometheusoperator key=openshift-monitoring/k8s msg="sync prometheus"
2023-01-09T04:48:16.815958938Z level=info ts=2023-01-09T04:48:16.81593654Z caller=operator.go:1559 component=prometheusoperator key=openshift-monitoring/k8s msg="update prometheus status"
2023-01-09T04:48:17.053321244Z level=info ts=2023-01-09T04:48:17.05327056Z caller=operator.go:1559 component=prometheusoperator key=openshift-monitoring/k8s msg="update prometheus status"
2023-01-09T04:48:21.168545449Z level=info ts=2023-01-09T04:48:21.168498937Z caller=operator.go:1559 component=prometheusoperator key=openshift-monitoring/k8s msg="update prometheus status"
2023-01-09T04:48:26.842609302Z level=info ts=2023-01-09T04:48:26.842553789Z caller=operator.go:754 component=alertmanageroperator key=openshift-monitoring/main msg="sync alertmanager"
2023-01-09T04:48:35.890295519Z level=info ts=2023-01-09T04:48:35.890247743Z caller=operator.go:1390 component=prometheusoperator key=openshift-monitoring/k8s msg="sync prometheus"
2023-01-09T04:48:36.003870237Z level=error ts=2023-01-09T04:48:36.003794318Z caller=klog.go:116 component=k8s_client_runtime func=ErrorDepth msg="sync \"openshift-monitoring/k8s\" failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-monitoring/configmaps?labelSelector=prometheus-name%3Dk8s\": dial tcp 172.30.0.1:443: connect: connection refused"
2023-01-09T04:48:36.003939578Z level=info ts=2023-01-09T04:48:36.003920458Z caller=operator.go:1390 component=prometheusoperator key=openshift-monitoring/k8s msg="sync prometheus"
2023-01-09T04:48:36.004025439Z level=info ts=2023-01-09T04:48:36.003989401Z caller=operator.go:1559 component=prometheusoperator key=openshift-monitoring/k8s msg="update prometheus status"
2023-01-09T04:48:36.005520202Z level=error ts=2023-01-09T04:48:36.00548962Z caller=klog.go:116 component=k8s_client_runtime func=ErrorDepth msg="status \"openshift-monitoring/k8s\" failed: failed to retrieve statefulset state: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-monitoring/pods?labelSelector=app.kubernetes.io%2Finstance%3Dk8s%2Capp.kubernetes.io%2Fmanaged-by%3Dprometheus-operator%2Capp.kubernetes.io%2Fname%3Dprometheus%2Coperator.prometheus.io%2Fname%3Dk8s%2Coperator.prometheus.io%2Fshard%3D0%2Cprometheus%3Dk8s\": dial tcp 172.30.0.1:443: connect: connection refused"
2023-01-09T04:48:36.010604362Z level=info ts=2023-01-09T04:48:36.010570943Z caller=operator.go:1559 component=prometheusoperator key=openshift-monitoring/k8s msg="update prometheus status"
2023-01-09T04:48:36.012106929Z level=error ts=2023-01-09T04:48:36.012082497Z caller=klog.go:116 component=k8s_client_runtime func=ErrorDepth msg="status \"openshift-monitoring/k8s\" failed: failed to retrieve statefulset state: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-monitoring/pods?labelSelector=app.kubernetes.io%2Finstance%3Dk8s%2Capp.kubernetes.io%2Fmanaged-by%3Dprometheus-operator%2Capp.kubernetes.io%2Fname%3Dprometheus%2Coperator.prometheus.io%2Fname%3Dk8s%2Coperator.prometheus.io%2Fshard%3D0%2Cprometheus%3Dk8s\": dial tcp 172.30.0.1:443: connect: connection refused"
2023-01-09T04:48:36.022301753Z level=info ts=2023-01-09T04:48:36.022249479Z caller=operator.go:1559 component=prometheusoperator key=openshift-monitoring/k8s msg="update prometheus status"
2023-01-09T04:48:36.024286331Z level=error ts=2023-01-09T04:48:36.024244903Z caller=klog.go:116 component=k8s_client_runtime func=ErrorDepth msg="status \"openshift-monitoring/k8s\" failed: failed to retrieve statefulset state: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-monitoring/pods?labelSelector=app.kubernetes.io%2Finstance%3Dk8s%2Capp.kubernetes.io%2Fmanaged-by%3Dprometheus-operator%2Capp.kubernetes.io%2Fname%3Dprometheus%2Coperator.prometheus.io%2Fname%3Dk8s%2Coperator.prometheus.io%2Fshard%3D0%2Cprometheus%3Dk8s\": dial tcp 172.30.0.1:443: connect: connection refused"
2023-01-09T04:48:36.044390813Z level=info ts=2023-01-09T04:48:36.044357194Z caller=operator.go:1559 component=prometheusoperator key=openshift-monitoring/k8s msg="update prometheus status"
2023-01-09T04:48:36.045775413Z level=error ts=2023-01-09T04:48:36.045734746Z caller=klog.go:116 component=k8s_client_runtime func=ErrorDepth msg="status \"openshift-monitoring/k8s\" failed: failed to retrieve statefulset state: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-monitoring/pods?labelSelector=app.kubernetes.io%2Finstance%3Dk8s%2Capp.kubernetes.io%2Fmanaged-by%3Dprometheus-operator%2Capp.kubernetes.io%2Fname%3Dprometheus%2Coperator.prometheus.io%2Fname%3Dk8s%2Coperator.prometheus.io%2Fshard%3D0%2Cprometheus%3Dk8s\": dial tcp 172.30.0.1:443: connect: connection refused"
2023-01-09T04:48:36.085917826Z level=info ts=2023-01-09T04:48:36.085866255Z caller=operator.go:1559 component=prometheusoperator key=openshift-monitoring/k8s msg="update prometheus status"
2023-01-09T04:48:36.087316972Z level=error ts=2023-01-09T04:48:36.087285008Z caller=klog.go:116 component=k8s_client_runtime func=ErrorDepth msg="status \"openshift-monitoring/k8s\" failed: failed to retrieve statefulset state: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-monitoring/pods?labelSelector=app.kubernetes.io%2Finstance%3Dk8s%2Capp.kubernetes.io%2Fmanaged-by%3Dprometheus-operator%2Capp.kubernetes.io%2Fname%3Dprometheus%2Coperator.prometheus.io%2Fname%3Dk8s%2Coperator.prometheus.io%2Fshard%3D0%2Cprometheus%3Dk8s\": dial tcp 172.30.0.1:443: connect: connection refused"
2023-01-09T04:48:36.121512843Z level=error ts=2023-01-09T04:48:36.121473255Z caller=klog.go:116 component=k8s_client_runtime func=ErrorDepth msg="sync \"openshift-monitoring/k8s\" failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-monitoring/configmaps?labelSelector=prometheus-name%3Dk8s\": dial tcp 172.30.0.1:443: connect: connection refused"
2023-01-09T04:48:36.121565161Z level=info ts=2023-01-09T04:48:36.121547158Z caller=operator.go:1390 component=prometheusoperator key=openshift-monitoring/k8s msg="sync prometheus"
2023-01-09T04:48:36.121645461Z level=info ts=2023-01-09T04:48:36.121616981Z caller=operator.go:1559 component=prometheusoperator key=openshift-monitoring/k8s msg="update prometheus status"
2023-01-09T04:48:36.123173034Z level=error ts=2023-01-09T04:48:36.123134029Z caller=klog.go:116 component=k8s_client_runtime func=ErrorDepth msg="status \"openshift-monitoring/k8s\" failed: failed to retrieve statefulset state: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-monitoring/pods?labelSelector=app.kubernetes.io%2Finstance%3Dk8s%2Capp.kubernetes.io%2Fmanaged-by%3Dprometheus-operator%2Capp.kubernetes.io%2Fname%3Dprometheus%2Coperator.prometheus.io%2Fname%3Dk8s%2Coperator.prometheus.io%2Fshard%3D0%2Cprometheus%3Dk8s\": dial tcp 172.30.0.1:443: connect: connection refused"
2023-01-09T04:48:36.167498333Z level=info ts=2023-01-09T04:48:36.167447336Z caller=operator.go:1559 component=prometheusoperator key=openshift-monitoring/k8s msg="update prometheus status"
2023-01-09T04:48:36.170759251Z level=error ts=2023-01-09T04:48:36.170715098Z caller=klog.go:116 component=k8s_client_runtime func=ErrorDepth msg="status \"openshift-monitoring/k8s\" failed: failed to retrieve statefulset state: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-monitoring/pods?labelSelector=app.kubernetes.io%2Finstance%3Dk8s%2Capp.kubernetes.io%2Fmanaged-by%3Dprometheus-operator%2Capp.kubernetes.io%2Fname%3Dprometheus%2Coperator.prometheus.io%2Fname%3Dk8s%2Coperator.prometheus.io%2Fshard%3D0%2Cprometheus%3Dk8s\": dial tcp 172.30.0.1:443: connect: connection refused"
2023-01-09T04:48:36.228658337Z level=error ts=2023-01-09T04:48:36.228614638Z caller=klog.go:116 component=k8s_client_runtime func=ErrorDepth msg="sync \"openshift-monitoring/k8s\" failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-monitoring/configmaps?labelSelector=prometheus-name%3Dk8s\": dial tcp 172.30.0.1:443: connect: connection refused"
2023-01-09T04:48:36.228708275Z level=info ts=2023-01-09T04:48:36.228690356Z caller=operator.go:1390 component=prometheusoperator key=openshift-monitoring/k8s msg="sync prometheus"
2023-01-09T04:48:36.228791349Z level=info ts=2023-01-09T04:48:36.228764612Z caller=operator.go:1559 component=prometheusoperator key=openshift-monitoring/k8s msg="update prometheus status"
2023-01-09T04:48:36.230202053Z level=error ts=2023-01-09T04:48:36.230174404Z caller=klog.go:116 component=k8s_client_runtime func=ErrorDepth msg="status \"openshift-monitoring/k8s\" failed: failed to retrieve statefulset state: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-monitoring/pods?labelSelector=app.kubernetes.io%2Finstance%3Dk8s%2Capp.kubernetes.io%2Fmanaged-by%3Dprometheus-operator%2Capp.kubernetes.io%2Fname%3Dprometheus%2Coperator.prometheus.io%2Fname%3Dk8s%2Coperator.prometheus.io%2Fshard%3D0%2Cprometheus%3Dk8s\": dial tcp 172.30.0.1:443: connect: connection refused"
2023-01-09T04:48:36.343199576Z level=error ts=2023-01-09T04:48:36.34315324Z caller=klog.go:116 component=k8s_client_runtime func=ErrorDepth msg="sync \"openshift-monitoring/k8s\" failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-monitoring/configmaps?labelSelector=prometheus-name%3Dk8s\": dial tcp 172.30.0.1:443: connect: connection refused"
2023-01-09T04:48:36.343256332Z level=info ts=2023-01-09T04:48:36.343238526Z caller=operator.go:1390 component=prometheusoperator key=openshift-monitoring/k8s msg="sync prometheus"
2023-01-09T04:48:36.343355376Z level=info ts=2023-01-09T04:48:36.34331183Z caller=operator.go:1559 component=prometheusoperator key=openshift-monitoring/k8s msg="update prometheus status"
2023-01-09T04:48:36.344764687Z level=error ts=2023-01-09T04:48:36.344730263Z caller=klog.go:116 component=k8s_client_runtime func=ErrorDepth msg="status \"openshift-monitoring/k8s\" failed: failed to retrieve statefulset state: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-monitoring/pods?labelSelector=app.kubernetes.io%2Finstance%3Dk8s%2Capp.kubernetes.io%2Fmanaged-by%3Dprometheus-operator%2Capp.kubernetes.io%2Fname%3Dprometheus%2Coperator.prometheus.io%2Fname%3Dk8s%2Coperator.prometheus.io%2Fshard%3D0%2Cprometheus%3Dk8s\": dial tcp 172.30.0.1:443: connect: connection refused"
2023-01-09T04:48:36.451072913Z level=error ts=2023-01-09T04:48:36.451027201Z caller=klog.go:116 component=k8s_client_runtime func=ErrorDepth msg="sync \"openshift-monitoring/k8s\" failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-monitoring/configmaps?labelSelector=prometheus-name%3Dk8s\": dial tcp 172.30.0.1:443: connect: connection refused"
2023-01-09T04:48:36.451127414Z level=info ts=2023-01-09T04:48:36.451106599Z caller=operator.go:1390 component=prometheusoperator key=openshift-monitoring/k8s msg="sync prometheus"
2023-01-09T04:48:36.451212936Z level=info ts=2023-01-09T04:48:36.451181946Z caller=operator.go:1559 component=prometheusoperator key=openshift-monitoring/k8s msg="update prometheus status"
2023-01-09T04:48:36.452702945Z level=error ts=2023-01-09T04:48:36.452672915Z caller=klog.go:116 component=k8s_client_runtime func=ErrorDepth msg="status \"openshift-monitoring/k8s\" failed: failed to retrieve statefulset state: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-monitoring/pods?labelSelector=app.kubernetes.io%2Finstance%3Dk8s%2Capp.kubernetes.io%2Fmanaged-by%3Dprometheus-operator%2Capp.kubernetes.io%2Fname%3Dprometheus%2Coperator.prometheus.io%2Fname%3Dk8s%2Coperator.prometheus.io%2Fshard%3D0%2Cprometheus%3Dk8s\": dial tcp 172.30.0.1:443: connect: connection refused"
2023-01-09T04:48:36.490927616Z level=info ts=2023-01-09T04:48:36.490880791Z caller=operator.go:1559 component=prometheusoperator key=openshift-monitoring/k8s msg="update prometheus status"
2023-01-09T04:48:36.492542992Z level=error ts=2023-01-09T04:48:36.492494939Z caller=klog.go:116 component=k8s_client_runtime func=ErrorDepth msg="status \"openshift-monitoring/k8s\" failed: failed to retrieve statefulset state: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-monitoring/pods?labelSelector=app.kubernetes.io%2Finstance%3Dk8s%2Capp.kubernetes.io%2Fmanaged-by%3Dprometheus-operator%2Capp.kubernetes.io%2Fname%3Dprometheus%2Coperator.prometheus.io%2Fname%3Dk8s%2Coperator.prometheus.io%2Fshard%3D0%2Cprometheus%3Dk8s\": dial tcp 172.30.0.1:443: connect: connection refused"
2023-01-09T04:48:36.578289128Z level=error ts=2023-01-09T04:48:36.578244079Z caller=klog.go:116 component=k8s_client_runtime func=ErrorDepth msg="sync \"openshift-monitoring/k8s\" failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-monitoring/configmaps?labelSelector=prometheus-name%3Dk8s\": dial tcp 172.30.0.1:443: connect: connection refused"
2023-01-09T04:48:36.578355659Z level=info ts=2023-01-09T04:48:36.578336603Z caller=operator.go:1390 component=prometheusoperator key=openshift-monitoring/k8s msg="sync prometheus"
2023-01-09T04:48:36.578443514Z level=info ts=2023-01-09T04:48:36.578414883Z caller=operator.go:1559 component=prometheusoperator key=openshift-monitoring/k8s msg="update prometheus status"
2023-01-09T04:48:36.580231593Z level=error ts=2023-01-09T04:48:36.580165113Z caller=klog.go:116 component=k8s_client_runtime func=ErrorDepth msg="status \"openshift-monitoring/k8s\" failed: failed to retrieve statefulset state: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-monitoring/pods?labelSelector=app.kubernetes.io%2Finstance%3Dk8s%2Capp.kubernetes.io%2Fmanaged-by%3Dprometheus-operator%2Capp.kubernetes.io%2Fname%3Dprometheus%2Coperator.prometheus.io%2Fname%3Dk8s%2Coperator.prometheus.io%2Fshard%3D0%2Cprometheus%3Dk8s\": dial tcp 172.30.0.1:443: connect: connection refused"
2023-01-09T04:48:36.696404357Z level=error ts=2023-01-09T04:48:36.696356368Z caller=klog.go:116 component=k8s_client_runtime func=ErrorDepth msg="sync \"openshift-monitoring/k8s\" failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-monitoring/configmaps?labelSelector=prometheus-name%3Dk8s\": dial tcp 172.30.0.1:443: connect: connection refused"
2023-01-09T04:48:36.696487776Z level=info ts=2023-01-09T04:48:36.696469408Z caller=operator.go:1559 component=prometheusoperator key=openshift-monitoring/k8s msg="update prometheus status"
2023-01-09T04:48:36.698134292Z level=error ts=2023-01-09T04:48:36.698096401Z caller=klog.go:116 component=k8s_client_runtime func=ErrorDepth msg="status \"openshift-monitoring/k8s\" failed: failed to retrieve statefulset state: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-monitoring/pods?labelSelector=app.kubernetes.io%2Finstance%3Dk8s%2Capp.kubernetes.io%2Fmanaged-by%3Dprometheus-operator%2Capp.kubernetes.io%2Fname%3Dprometheus%2Coperator.prometheus.io%2Fname%3Dk8s%2Coperator.prometheus.io%2Fshard%3D0%2Cprometheus%3Dk8s\": dial tcp 172.30.0.1:443: connect: connection refused"
2023-01-09T04:48:36.739260608Z level=info ts=2023-01-09T04:48:36.739209464Z caller=operator.go:1390 component=prometheusoperator key=openshift-monitoring/k8s msg="sync prometheus"
2023-01-09T04:48:36.850500891Z level=error ts=2023-01-09T04:48:36.850451828Z caller=klog.go:116 component=k8s_client_runtime func=ErrorDepth msg="sync \"openshift-monitoring/k8s\" failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-monitoring/configmaps?labelSelector=prometheus-name%3Dk8s\": dial tcp 172.30.0.1:443: connect: connection refused"
2023-01-09T04:48:36.850565231Z level=info ts=2023-01-09T04:48:36.850544256Z caller=operator.go:1559 component=prometheusoperator key=openshift-monitoring/k8s msg="update prometheus status"
2023-01-09T04:48:36.851949903Z level=error ts=2023-01-09T04:48:36.851920873Z caller=klog.go:116 component=k8s_client_runtime func=ErrorDepth msg="status \"openshift-monitoring/k8s\" failed: failed to retrieve statefulset state: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-monitoring/pods?labelSelector=app.kubernetes.io%2Finstance%3Dk8s%2Capp.kubernetes.io%2Fmanaged-by%3Dprometheus-operator%2Capp.kubernetes.io%2Fname%3Dprometheus%2Coperator.prometheus.io%2Fname%3Dk8s%2Coperator.prometheus.io%2Fshard%3D0%2Cprometheus%3Dk8s\": dial tcp 172.30.0.1:443: connect: connection refused"
2023-01-09T04:48:37.491267288Z level=info ts=2023-01-09T04:48:37.491213767Z caller=operator.go:1390 component=prometheusoperator key=openshift-monitoring/k8s msg="sync prometheus"
2023-01-09T04:48:37.601608682Z level=error ts=2023-01-09T04:48:37.601558508Z caller=klog.go:116 component=k8s_client_runtime func=ErrorDepth msg="sync \"openshift-monitoring/k8s\" failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-monitoring/configmaps?labelSelector=prometheus-name%3Dk8s\": dial tcp 172.30.0.1:443: connect: connection refused"
2023-01-09T04:48:37.601681837Z level=info ts=2023-01-09T04:48:37.601661185Z caller=operator.go:1559 component=prometheusoperator key=openshift-monitoring/k8s msg="update prometheus status"
2023-01-09T04:48:37.603068313Z level=error ts=2023-01-09T04:48:37.60303756Z caller=klog.go:116 component=k8s_client_runtime func=ErrorDepth msg="status \"openshift-monitoring/k8s\" failed: failed to retrieve statefulset state: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-monitoring/pods?labelSelector=app.kubernetes.io%2Finstance%3Dk8s%2Capp.kubernetes.io%2Fmanaged-by%3Dprometheus-operator%2Capp.kubernetes.io%2Fname%3Dprometheus%2Coperator.prometheus.io%2Fname%3Dk8s%2Coperator.prometheus.io%2Fshard%3D0%2Cprometheus%3Dk8s\": dial tcp 172.30.0.1:443: connect: connection refused"
2023-01-09T04:48:38.882188965Z level=info ts=2023-01-09T04:48:38.882133781Z caller=operator.go:1390 component=prometheusoperator key=openshift-monitoring/k8s msg="sync prometheus"
2023-01-09T04:48:39.014846795Z level=error ts=2023-01-09T04:48:39.014771728Z caller=klog.go:116 component=k8s_client_runtime func=ErrorDepth msg="sync \"openshift-monitoring/k8s\" failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-monitoring/configmaps?labelSelector=prometheus-name%3Dk8s\": dial tcp 172.30.0.1:443: connect: connection refused"
2023-01-09T04:48:39.014924652Z level=info ts=2023-01-09T04:48:39.014890911Z caller=operator.go:1559 component=prometheusoperator key=openshift-monitoring/k8s msg="update prometheus status"
2023-01-09T04:48:39.016303259Z level=error ts=2023-01-09T04:48:39.016263357Z caller=klog.go:116 component=k8s_client_runtime func=ErrorDepth msg="status \"openshift-monitoring/k8s\" failed: failed to retrieve statefulset state: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-monitoring/pods?labelSelector=app.kubernetes.io%2Finstance%3Dk8s%2Capp.kubernetes.io%2Fmanaged-by%3Dprometheus-operator%2Capp.kubernetes.io%2Fname%3Dprometheus%2Coperator.prometheus.io%2Fname%3Dk8s%2Coperator.prometheus.io%2Fshard%3D0%2Cprometheus%3Dk8s\": dial tcp 172.30.0.1:443: connect: connection refused"
2023-01-09T04:48:41.574985912Z level=info ts=2023-01-09T04:48:41.574934217Z caller=operator.go:1390 component=prometheusoperator key=openshift-monitoring/k8s msg="sync prometheus"
2023-01-09T04:48:41.612934862Z level=info ts=2023-01-09T04:48:41.612877263Z caller=operator.go:1559 component=prometheusoperator key=openshift-monitoring/k8s msg="update prometheus status"
2023-01-09T04:48:41.614335494Z level=error ts=2023-01-09T04:48:41.614300874Z caller=klog.go:116 component=k8s_client_runtime func=ErrorDepth msg="status \"openshift-monitoring/k8s\" failed: failed to retrieve statefulset state: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-monitoring/pods?labelSelector=app.kubernetes.io%2Finstance%3Dk8s%2Capp.kubernetes.io%2Fmanaged-by%3Dprometheus-operator%2Capp.kubernetes.io%2Fname%3Dprometheus%2Coperator.prometheus.io%2Fname%3Dk8s%2Coperator.prometheus.io%2Fshard%3D0%2Cprometheus%3Dk8s\": dial tcp 172.30.0.1:443: connect: connection refused"
2023-01-09T04:48:41.688120482Z level=error ts=2023-01-09T04:48:41.688069377Z caller=klog.go:116 component=k8s_client_runtime func=ErrorDepth msg="sync \"openshift-monitoring/k8s\" failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-monitoring/configmaps?labelSelector=prometheus-name%3Dk8s\": dial tcp 172.30.0.1:443: connect: connection refused"
2023-01-09T04:48:41.688176013Z level=info ts=2023-01-09T04:48:41.688156594Z caller=operator.go:1559 component=prometheusoperator key=openshift-monitoring/k8s msg="update prometheus status"
2023-01-09T04:48:41.689470818Z level=error ts=2023-01-09T04:48:41.689441626Z caller=klog.go:116 component=k8s_client_runtime func=ErrorDepth msg="status \"openshift-monitoring/k8s\" failed: failed to retrieve statefulset state: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-monitoring/pods?labelSelector=app.kubernetes.io%2Finstance%3Dk8s%2Capp.kubernetes.io%2Fmanaged-by%3Dprometheus-operator%2Capp.kubernetes.io%2Fname%3Dprometheus%2Coperator.prometheus.io%2Fname%3Dk8s%2Coperator.prometheus.io%2Fshard%3D0%2Cprometheus%3Dk8s\": dial tcp 172.30.0.1:443: connect: connection refused"
2023-01-09T04:48:46.808829532Z level=info ts=2023-01-09T04:48:46.808767724Z caller=operator.go:1390 component=prometheusoperator key=openshift-monitoring/k8s msg="sync prometheus"
2023-01-09T04:48:46.924110006Z level=error ts=2023-01-09T04:48:46.924061532Z caller=klog.go:116 component=k8s_client_runtime func=ErrorDepth msg="sync \"openshift-monitoring/k8s\" failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-monitoring/configmaps?labelSelector=prometheus-name%3Dk8s\": dial tcp 172.30.0.1:443: connect: connection refused"
2023-01-09T04:48:46.924182622Z level=info ts=2023-01-09T04:48:46.924164183Z caller=operator.go:1559 component=prometheusoperator key=openshift-monitoring/k8s msg="update prometheus status"
2023-01-09T04:48:46.925562296Z level=error ts=2023-01-09T04:48:46.925525679Z caller=klog.go:116 component=k8s_client_runtime func=ErrorDepth msg="status \"openshift-monitoring/k8s\" failed: failed to retrieve statefulset state: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-monitoring/pods?labelSelector=app.kubernetes.io%2Finstance%3Dk8s%2Capp.kubernetes.io%2Fmanaged-by%3Dprometheus-operator%2Capp.kubernetes.io%2Fname%3Dprometheus%2Coperator.prometheus.io%2Fname%3Dk8s%2Coperator.prometheus.io%2Fshard%3D0%2Cprometheus%3Dk8s\": dial tcp 172.30.0.1:443: connect: connection refused"
2023-01-09T04:48:57.165179918Z level=info ts=2023-01-09T04:48:57.165118178Z caller=operator.go:1390 component=prometheusoperator key=openshift-monitoring/k8s msg="sync prometheus"
2023-01-09T04:49:00.706904163Z level=info ts=2023-01-09T04:49:00.706841589Z caller=operator.go:754 component=alertmanageroperator key=openshift-monitoring/main msg="sync alertmanager"
2023-01-09T04:49:00.850530208Z level=info ts=2023-01-09T04:49:00.85048064Z caller=operator.go:1390 component=prometheusoperator key=openshift-monitoring/k8s msg="sync prometheus"
2023-01-09T04:49:00.850612237Z level=info ts=2023-01-09T04:49:00.850571244Z caller=operator.go:1559 component=prometheusoperator key=openshift-monitoring/k8s msg="update prometheus status"
2023-01-09T04:49:01.095196346Z level=info ts=2023-01-09T04:49:01.095142597Z caller=operator.go:1559 component=prometheusoperator key=openshift-monitoring/k8s msg="update prometheus status"
2023-01-09T04:49:04.074402302Z level=info ts=2023-01-09T04:49:04.074333778Z caller=operator.go:754 component=alertmanageroperator key=openshift-monitoring/main msg="sync alertmanager"
2023-01-09T04:49:04.074459203Z level=info ts=2023-01-09T04:49:04.074426209Z caller=operator.go:1390 component=prometheusoperator key=openshift-monitoring/k8s msg="sync prometheus"
2023-01-09T04:49:04.306116171Z level=info ts=2023-01-09T04:49:04.30605801Z caller=operator.go:1559 component=prometheusoperator key=openshift-monitoring/k8s msg="update prometheus status"
2023-01-09T04:49:55.117160628Z level=info ts=2023-01-09T04:49:55.117102656Z caller=operator.go:1390 component=prometheusoperator key=openshift-monitoring/k8s msg="sync prometheus"
2023-01-09T04:49:55.327352443Z level=info ts=2023-01-09T04:49:55.327303463Z caller=operator.go:754 component=alertmanageroperator key=openshift-monitoring/main msg="sync alertmanager"
2023-01-09T04:49:55.357867995Z level=info ts=2023-01-09T04:49:55.357822335Z caller=operator.go:1390 component=prometheusoperator key=openshift-monitoring/k8s msg="sync prometheus"
2023-01-09T04:49:55.357906315Z level=info ts=2023-01-09T04:49:55.357868261Z caller=operator.go:1559 component=prometheusoperator key=openshift-monitoring/k8s msg="update prometheus status"
2023-01-09T04:49:55.571923705Z level=info ts=2023-01-09T04:49:55.571877082Z caller=operator.go:1559 component=prometheusoperator key=openshift-monitoring/k8s msg="update prometheus status"
2023-01-09T04:54:09.296377037Z level=info ts=2023-01-09T04:54:09.296295769Z caller=operator.go:1559 component=prometheusoperator key=openshift-monitoring/k8s msg="update prometheus status"
2023-01-09T05:30:32.646235399Z level=info ts=2023-01-09T05:30:32.646170092Z caller=operator.go:1559 component=prometheusoperator key=openshift-monitoring/k8s msg="update prometheus status"
2023-01-09T05:30:32.651527026Z level=info ts=2023-01-09T05:30:32.651480023Z caller=operator.go:754 component=alertmanageroperator key=openshift-monitoring/main msg="sync alertmanager"
2023-01-09T05:30:35.226978531Z level=info ts=2023-01-09T05:30:35.226928152Z caller=operator.go:1559 component=prometheusoperator key=openshift-monitoring/k8s msg="update prometheus status"
2023-01-09T05:30:35.268610084Z level=info ts=2023-01-09T05:30:35.268568834Z caller=operator.go:754 component=alertmanageroperator key=openshift-monitoring/main msg="sync alertmanager"
2023-01-09T05:30:35.302443776Z level=info ts=2023-01-09T05:30:35.302399595Z caller=operator.go:1559 component=prometheusoperator key=openshift-monitoring/k8s msg="update prometheus status"
2023-01-09T05:30:35.388948903Z level=info ts=2023-01-09T05:30:35.388907722Z caller=operator.go:754 component=alertmanageroperator key=openshift-monitoring/main msg="sync alertmanager"
2023-01-09T05:30:51.394549175Z level=info ts=2023-01-09T05:30:51.39450328Z caller=operator.go:1559 component=prometheusoperator key=openshift-monitoring/k8s msg="update prometheus status"
2023-01-09T05:31:05.795442798Z level=info ts=2023-01-09T05:31:05.795386541Z caller=operator.go:754 component=alertmanageroperator key=openshift-monitoring/main msg="sync alertmanager"
2023-01-09T05:31:17.986407883Z level=info ts=2023-01-09T05:31:17.98634072Z caller=operator.go:1390 component=prometheusoperator key=openshift-monitoring/k8s msg="sync prometheus"
2023-01-09T05:31:18.257106573Z level=info ts=2023-01-09T05:31:18.257051607Z caller=operator.go:754 component=alertmanageroperator key=openshift-monitoring/main msg="sync alertmanager"
2023-01-09T05:31:18.291771010Z level=info ts=2023-01-09T05:31:18.291717444Z caller=operator.go:1390 component=prometheusoperator key=openshift-monitoring/k8s msg="sync prometheus"
2023-01-09T05:31:18.291921628Z level=info ts=2023-01-09T05:31:18.291890905Z caller=operator.go:1559 component=prometheusoperator key=openshift-monitoring/k8s msg="update prometheus status"
2023-01-09T05:31:18.614617446Z level=info ts=2023-01-09T05:31:18.614562835Z caller=operator.go:1559 component=prometheusoperator key=openshift-monitoring/k8s msg="update prometheus status"
2023-01-09T05:32:17.811987132Z level=info ts=2023-01-09T05:32:17.811922334Z caller=operator.go:1390 component=prometheusoperator key=openshift-monitoring/k8s msg="sync prometheus"
2023-01-09T05:32:18.025508280Z level=info ts=2023-01-09T05:32:18.025462256Z caller=operator.go:754 component=alertmanageroperator key=openshift-monitoring/main msg="sync alertmanager"
2023-01-09T05:32:18.058495388Z level=info ts=2023-01-09T05:32:18.058448185Z caller=operator.go:1390 component=prometheusoperator key=openshift-monitoring/k8s msg="sync prometheus"
2023-01-09T05:32:18.058640175Z level=info ts=2023-01-09T05:32:18.058578504Z caller=operator.go:1559 component=prometheusoperator key=openshift-monitoring/k8s msg="update prometheus status"
2023-01-09T05:32:18.411318265Z level=info ts=2023-01-09T05:32:18.411262367Z caller=operator.go:1559 component=prometheusoperator key=openshift-monitoring/k8s msg="update prometheus status"
2023-01-09T06:11:57.567607620Z level=info ts=2023-01-09T06:11:57.567547322Z caller=operator.go:1390 component=prometheusoperator key=openshift-monitoring/k8s msg="sync prometheus"
2023-01-09T06:11:57.796394802Z level=info ts=2023-01-09T06:11:57.796341747Z caller=operator.go:754 component=alertmanageroperator key=openshift-monitoring/main msg="sync alertmanager"
2023-01-09T06:11:57.917882849Z level=info ts=2023-01-09T06:11:57.917820306Z caller=operator.go:1390 component=prometheusoperator key=openshift-monitoring/k8s msg="sync prometheus"
2023-01-09T06:11:57.917925189Z level=info ts=2023-01-09T06:11:57.917878796Z caller=operator.go:1559 component=prometheusoperator key=openshift-monitoring/k8s msg="update prometheus status"
2023-01-09T06:11:58.189704751Z level=info ts=2023-01-09T06:11:58.189637241Z caller=operator.go:1390 component=prometheusoperator key=openshift-monitoring/k8s msg="sync prometheus"
2023-01-09T06:11:58.189744200Z level=info ts=2023-01-09T06:11:58.18972263Z caller=operator.go:1559 component=prometheusoperator key=openshift-monitoring/k8s msg="update prometheus status"
2023-01-09T06:11:58.453440869Z level=info ts=2023-01-09T06:11:58.45337777Z caller=operator.go:1559 component=prometheusoperator key=openshift-monitoring/k8s msg="update prometheus status"
2023-01-09T06:12:42.006236868Z level=info ts=2023-01-09T06:12:42.006183796Z caller=operator.go:1390 component=prometheusoperator key=openshift-monitoring/k8s msg="sync prometheus"
2023-01-09T06:12:42.245836476Z level=info ts=2023-01-09T06:12:42.245777828Z caller=operator.go:754 component=alertmanageroperator key=openshift-monitoring/main msg="sync alertmanager"
2023-01-09T06:12:42.285350061Z level=info ts=2023-01-09T06:12:42.285302209Z caller=operator.go:1390 component=prometheusoperator key=openshift-monitoring/k8s msg="sync prometheus"
2023-01-09T06:12:42.285430697Z level=info ts=2023-01-09T06:12:42.285399087Z caller=operator.go:1559 component=prometheusoperator key=openshift-monitoring/k8s msg="update prometheus status"
2023-01-09T06:12:42.290432034Z level=info ts=2023-01-09T06:12:42.290389751Z caller=operator.go:754 component=alertmanageroperator key=openshift-monitoring/main msg="sync alertmanager"
2023-01-09T06:12:42.600989246Z level=info ts=2023-01-09T06:12:42.600929146Z caller=operator.go:1390 component=prometheusoperator key=openshift-monitoring/k8s msg="sync prometheus"
2023-01-09T06:12:42.601058197Z level=info ts=2023-01-09T06:12:42.601006985Z caller=operator.go:1559 component=prometheusoperator key=openshift-monitoring/k8s msg="update prometheus status"
2023-01-09T06:12:42.882199799Z level=info ts=2023-01-09T06:12:42.882139677Z caller=operator.go:1559 component=prometheusoperator key=openshift-monitoring/k8s msg="update prometheus status"
