---
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  annotations:
    exclude.release.openshift.io/internal-openshift-hosted: "true"
    include.release.openshift.io/self-managed-high-availability: "true"
    include.release.openshift.io/single-node-developer: "true"
  creationTimestamp: "2023-01-09T04:37:13Z"
  generation: 1
  managedFields:
  - apiVersion: monitoring.coreos.com/v1
    fieldsType: FieldsV1
    fieldsV1:
      f:metadata:
        f:annotations:
          .: {}
          f:exclude.release.openshift.io/internal-openshift-hosted: {}
          f:include.release.openshift.io/self-managed-high-availability: {}
          f:include.release.openshift.io/single-node-developer: {}
        f:ownerReferences:
          .: {}
          k:{"uid":"f3a03fe4-e8d1-4fcc-92c7-00d0f120f589"}: {}
      f:spec:
        .: {}
        f:endpoints: {}
        f:jobLabel: {}
        f:selector: {}
    manager: cluster-version-operator
    operation: Update
    time: "2023-01-09T04:37:13Z"
  name: openshift-controller-manager-operator
  namespace: openshift-controller-manager-operator
  ownerReferences:
  - apiVersion: config.openshift.io/v1
    kind: ClusterVersion
    name: version
    uid: f3a03fe4-e8d1-4fcc-92c7-00d0f120f589
  resourceVersion: "1499"
  uid: 0caefcc5-0d0f-4ef5-a6e6-1300d3e5ffe2
spec:
  endpoints:
  - bearerTokenFile: /var/run/secrets/kubernetes.io/serviceaccount/token
    interval: 30s
    metricRelabelings:
    - action: drop
      regex: etcd_(debugging|disk|request|server).*
      sourceLabels:
      - __name__
    port: https
    scheme: https
    tlsConfig:
      caFile: /etc/prometheus/configmaps/serving-certs-ca-bundle/service-ca.crt
      certFile: /etc/prometheus/secrets/metrics-client-certs/tls.crt
      keyFile: /etc/prometheus/secrets/metrics-client-certs/tls.key
      serverName: metrics.openshift-controller-manager-operator.svc
  jobLabel: component
  selector:
    matchLabels:
      app: openshift-controller-manager-operator
