2023-01-09T04:42:14.558955506Z I0109 04:42:14.558865       1 cmd.go:209] Using service-serving-cert provided certificates
2023-01-09T04:42:14.559247091Z I0109 04:42:14.559230       1 observer_polling.go:159] Starting file observer
2023-01-09T04:42:14.572623770Z I0109 04:42:14.572586       1 builder.go:262] kube-apiserver-operator version 4.12.0-202301052135.p0.g336ffd5.assembly.stream-336ffd5-336ffd5e7491f565faccf843571303377b1d4825
2023-01-09T04:42:14.906277426Z W0109 04:42:14.906238       1 secure_serving.go:69] Use of insecure cipher 'TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256' detected.
2023-01-09T04:42:14.906277426Z W0109 04:42:14.906258       1 secure_serving.go:69] Use of insecure cipher 'TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256' detected.
2023-01-09T04:42:14.908596467Z I0109 04:42:14.908565       1 leaderelection.go:248] attempting to acquire leader lease openshift-kube-apiserver-operator/kube-apiserver-operator-lock...
2023-01-09T04:42:14.908756337Z I0109 04:42:14.908736       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
2023-01-09T04:42:14.908756337Z I0109 04:42:14.908742       1 configmap_cafile_content.go:202] "Starting controller" name="client-ca::kube-system::extension-apiserver-authentication::client-ca-file"
2023-01-09T04:42:14.908768326Z I0109 04:42:14.908760       1 shared_informer.go:255] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
2023-01-09T04:42:14.908768326Z I0109 04:42:14.908762       1 shared_informer.go:255] Waiting for caches to sync for RequestHeaderAuthRequestController
2023-01-09T04:42:14.908826513Z I0109 04:42:14.908809       1 configmap_cafile_content.go:202] "Starting controller" name="client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file"
2023-01-09T04:42:14.908826513Z I0109 04:42:14.908823       1 shared_informer.go:255] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file
2023-01-09T04:42:14.909103722Z I0109 04:42:14.909065       1 secure_serving.go:210] Serving securely on [::]:8443
2023-01-09T04:42:14.909184391Z I0109 04:42:14.909089       1 dynamic_serving_content.go:132] "Starting controller" name="serving-cert::/var/run/secrets/serving-cert/tls.crt::/var/run/secrets/serving-cert/tls.key"
2023-01-09T04:42:14.909202244Z I0109 04:42:14.909101       1 tlsconfig.go:240] "Starting DynamicServingCertificateController"
2023-01-09T04:42:14.921753612Z I0109 04:42:14.921713       1 leaderelection.go:258] successfully acquired lease openshift-kube-apiserver-operator/kube-apiserver-operator-lock
2023-01-09T04:42:14.921819918Z I0109 04:42:14.921785       1 event.go:285] Event(v1.ObjectReference{Kind:"ConfigMap", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator-lock", UID:"b80c93f5-d1d9-4bbe-b7a2-f1157f8cce93", APIVersion:"v1", ResourceVersion:"9368", FieldPath:""}): type: 'Normal' reason: 'LeaderElection' kube-apiserver-operator-57d845b467-d22t9_59cc63e0-85b8-4f99-b906-a3b4a67d6eeb became leader
2023-01-09T04:42:14.921831543Z I0109 04:42:14.921816       1 event.go:285] Event(v1.ObjectReference{Kind:"Lease", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator-lock", UID:"58424be1-3ce8-44ca-8a22-ce3889d97152", APIVersion:"coordination.k8s.io/v1", ResourceVersion:"9369", FieldPath:""}): type: 'Normal' reason: 'LeaderElection' kube-apiserver-operator-57d845b467-d22t9_59cc63e0-85b8-4f99-b906-a3b4a67d6eeb became leader
2023-01-09T04:42:14.923123856Z I0109 04:42:14.923098       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'FastControllerResync' Controller "EventWatchController" resync interval is set to 0s which might lead to client request throttling
2023-01-09T04:42:14.935327663Z I0109 04:42:14.935285       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'FastControllerResync' Controller "ConnectivityCheckController" resync interval is set to 0s which might lead to client request throttling
2023-01-09T04:42:14.938212116Z I0109 04:42:14.938178       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'FastControllerResync' Controller "RevisionController" resync interval is set to 0s which might lead to client request throttling
2023-01-09T04:42:14.938523997Z I0109 04:42:14.938492       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'FastControllerResync' Controller "PruneController" resync interval is set to 0s which might lead to client request throttling
2023-01-09T04:42:14.938816630Z I0109 04:42:14.938798       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'FastControllerResync' Controller "NodeController" resync interval is set to 0s which might lead to client request throttling
2023-01-09T04:42:14.939054648Z I0109 04:42:14.939033       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'FastControllerResync' Controller "UnsupportedConfigOverridesController" resync interval is set to 0s which might lead to client request throttling
2023-01-09T04:42:14.939143198Z I0109 04:42:14.939123       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'FastControllerResync' Controller "LoggingSyncer" resync interval is set to 0s which might lead to client request throttling
2023-01-09T04:42:14.939234644Z I0109 04:42:14.939198       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'FastControllerResync' Controller "GuardController" resync interval is set to 0s which might lead to client request throttling
2023-01-09T04:42:14.949327904Z I0109 04:42:14.949277       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'FastControllerResync' Controller "FeatureUpgradeableController" resync interval is set to 0s which might lead to client request throttling
2023-01-09T04:42:14.949426117Z I0109 04:42:14.949405       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'FastControllerResync' Controller "auditPolicyController" resync interval is set to 10s which might lead to client request throttling
2023-01-09T04:42:14.949722575Z I0109 04:42:14.949618       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'FastControllerResync' Controller "KubeletVersionSkewController" resync interval is set to 0s which might lead to client request throttling
2023-01-09T04:42:14.950290687Z I0109 04:42:14.950254       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'FastControllerResync' Controller "webhookSupportabilityController" resync interval is set to 0s which might lead to client request throttling
2023-01-09T04:42:14.950517817Z I0109 04:42:14.950498       1 base_controller.go:67] Waiting for caches to sync for ServiceAccountIssuerController
2023-01-09T04:42:14.950806484Z I0109 04:42:14.950780       1 base_controller.go:67] Waiting for caches to sync for BoundSATokenSignerController
2023-01-09T04:42:14.950855616Z I0109 04:42:14.950834       1 base_controller.go:67] Waiting for caches to sync for auditPolicyController
2023-01-09T04:42:14.951211533Z I0109 04:42:14.951182       1 base_controller.go:67] Waiting for caches to sync for EventWatchController
2023-01-09T04:42:14.951211533Z I0109 04:42:14.951203       1 base_controller.go:67] Waiting for caches to sync for ConfigObserver
2023-01-09T04:42:14.951255950Z I0109 04:42:14.951236       1 base_controller.go:67] Waiting for caches to sync for NodeKubeconfigController
2023-01-09T04:42:14.951255950Z I0109 04:42:14.951243       1 base_controller.go:67] Waiting for caches to sync for RemoveStaleConditionsController
2023-01-09T04:42:14.951289043Z I0109 04:42:14.951270       1 base_controller.go:67] Waiting for caches to sync for ConnectivityCheckController
2023-01-09T04:42:14.951328409Z I0109 04:42:14.951308       1 base_controller.go:67] Waiting for caches to sync for StatusSyncer_kube-apiserver
2023-01-09T04:42:14.951391388Z I0109 04:42:14.951379       1 certrotationcontroller.go:654] Starting CertRotation
2023-01-09T04:42:14.951433468Z I0109 04:42:14.951409       1 certrotationcontroller.go:619] Waiting for CertRotation
2023-01-09T04:42:14.951455954Z I0109 04:42:14.951448       1 base_controller.go:67] Waiting for caches to sync for EncryptionConditionController
2023-01-09T04:42:14.951480200Z I0109 04:42:14.951321       1 base_controller.go:67] Waiting for caches to sync for KubeletVersionSkewController
2023-01-09T04:42:14.951490838Z I0109 04:42:14.951480       1 base_controller.go:67] Waiting for caches to sync for EncryptionKeyController
2023-01-09T04:42:14.951594894Z I0109 04:42:14.951572       1 base_controller.go:67] Waiting for caches to sync for FeatureUpgradeableController
2023-01-09T04:42:14.951607702Z I0109 04:42:14.951591       1 base_controller.go:67] Waiting for caches to sync for EncryptionStateController
2023-01-09T04:42:14.951607702Z I0109 04:42:14.951600       1 base_controller.go:67] Waiting for caches to sync for CertRotationTimeUpgradeableController
2023-01-09T04:42:14.951618804Z I0109 04:42:14.951610       1 base_controller.go:67] Waiting for caches to sync for EncryptionPruneController
2023-01-09T04:42:14.951640542Z I0109 04:42:14.951627       1 base_controller.go:67] Waiting for caches to sync for EncryptionMigrationController
2023-01-09T04:42:14.951659644Z I0109 04:42:14.951330       1 base_controller.go:67] Waiting for caches to sync for WorkerLatencyProfile
2023-01-09T04:42:14.951659644Z I0109 04:42:14.951343       1 base_controller.go:67] Waiting for caches to sync for webhookSupportabilityController
2023-01-09T04:42:14.951670461Z I0109 04:42:14.951643       1 termination_observer.go:145] Starting TerminationObserver
2023-01-09T04:42:14.951888566Z I0109 04:42:14.951863       1 base_controller.go:67] Waiting for caches to sync for ResourceSyncController
2023-01-09T04:42:14.952446409Z I0109 04:42:14.952422       1 base_controller.go:67] Waiting for caches to sync for InstallerController
2023-01-09T04:42:14.952471135Z I0109 04:42:14.952463       1 base_controller.go:67] Waiting for caches to sync for RevisionController
2023-01-09T04:42:14.952527683Z I0109 04:42:14.952493       1 base_controller.go:67] Waiting for caches to sync for MissingStaticPodController
2023-01-09T04:42:14.952613969Z I0109 04:42:14.952600       1 base_controller.go:67] Waiting for caches to sync for InstallerStateController
2023-01-09T04:42:14.952669349Z I0109 04:42:14.952656       1 base_controller.go:67] Waiting for caches to sync for StaticPodStateController
2023-01-09T04:42:14.952744912Z I0109 04:42:14.952714       1 base_controller.go:67] Waiting for caches to sync for UnsupportedConfigOverridesController
2023-01-09T04:42:14.952744912Z I0109 04:42:14.952731       1 base_controller.go:67] Waiting for caches to sync for LoggingSyncer
2023-01-09T04:42:14.952764466Z I0109 04:42:14.952756       1 base_controller.go:67] Waiting for caches to sync for GuardController
2023-01-09T04:42:14.952775100Z I0109 04:42:14.952767       1 base_controller.go:67] Waiting for caches to sync for PruneController
2023-01-09T04:42:14.952803413Z I0109 04:42:14.952783       1 base_controller.go:67] Waiting for caches to sync for StartupMonitorPodCondition
2023-01-09T04:42:14.953042818Z I0109 04:42:14.953020       1 base_controller.go:67] Waiting for caches to sync for StaticPodStateFallback
2023-01-09T04:42:14.953092849Z I0109 04:42:14.952676       1 base_controller.go:67] Waiting for caches to sync for TargetConfigController
2023-01-09T04:42:14.953130285Z I0109 04:42:14.952607       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'FastControllerResync' Controller "InstallerController" resync interval is set to 0s which might lead to client request throttling
2023-01-09T04:42:14.953364077Z I0109 04:42:14.953338       1 base_controller.go:67] Waiting for caches to sync for BackingResourceController
2023-01-09T04:42:14.953450607Z I0109 04:42:14.953432       1 base_controller.go:67] Waiting for caches to sync for KubeAPIServerStaticResources
2023-01-09T04:42:14.953869310Z I0109 04:42:14.953838       1 base_controller.go:67] Waiting for caches to sync for NodeController
2023-01-09T04:42:15.008950228Z I0109 04:42:15.008904       1 shared_informer.go:262] Caches are synced for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
2023-01-09T04:42:15.009049748Z I0109 04:42:15.008918       1 shared_informer.go:262] Caches are synced for client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file
2023-01-09T04:42:15.009074246Z I0109 04:42:15.008929       1 shared_informer.go:262] Caches are synced for RequestHeaderAuthRequestController
2023-01-09T04:42:15.051218371Z I0109 04:42:15.051179       1 base_controller.go:73] Caches are synced for ServiceAccountIssuerController 
2023-01-09T04:42:15.051218371Z I0109 04:42:15.051203       1 base_controller.go:110] Starting #1 worker of ServiceAccountIssuerController controller ...
2023-01-09T04:42:15.051318540Z I0109 04:42:15.051300       1 base_controller.go:73] Caches are synced for RemoveStaleConditionsController 
2023-01-09T04:42:15.051318540Z I0109 04:42:15.051315       1 base_controller.go:110] Starting #1 worker of RemoveStaleConditionsController controller ...
2023-01-09T04:42:15.051749021Z I0109 04:42:15.051722       1 base_controller.go:73] Caches are synced for KubeletVersionSkewController 
2023-01-09T04:42:15.051749021Z I0109 04:42:15.051737       1 base_controller.go:110] Starting #1 worker of KubeletVersionSkewController controller ...
2023-01-09T04:42:15.053382410Z I0109 04:42:15.053364       1 base_controller.go:73] Caches are synced for LoggingSyncer 
2023-01-09T04:42:15.053411168Z I0109 04:42:15.053382       1 base_controller.go:110] Starting #1 worker of LoggingSyncer controller ...
2023-01-09T04:42:15.053455207Z I0109 04:42:15.053437       1 base_controller.go:73] Caches are synced for UnsupportedConfigOverridesController 
2023-01-09T04:42:15.053455207Z I0109 04:42:15.053450       1 base_controller.go:110] Starting #1 worker of UnsupportedConfigOverridesController controller ...
2023-01-09T04:42:15.053533385Z I0109 04:42:15.053509       1 base_controller.go:73] Caches are synced for PruneController 
2023-01-09T04:42:15.053533385Z I0109 04:42:15.053525       1 base_controller.go:110] Starting #1 worker of PruneController controller ...
2023-01-09T04:42:15.053744134Z I0109 04:42:15.053727       1 prune_controller.go:261] No nodes, nothing to prune
2023-01-09T04:42:15.054735040Z I0109 04:42:15.054716       1 base_controller.go:73] Caches are synced for NodeController 
2023-01-09T04:42:15.054735040Z I0109 04:42:15.054730       1 base_controller.go:110] Starting #1 worker of NodeController controller ...
2023-01-09T04:42:15.055057319Z I0109 04:42:15.055026       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'MasterNodeObserved' Observed new master node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:42:15.055068664Z I0109 04:42:15.055051       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'MasterNodeObserved' Observed new master node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:42:15.055068664Z I0109 04:42:15.055061       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'MasterNodeObserved' Observed new master node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:42:15.059700530Z I0109 04:42:15.059675       1 prune_controller.go:261] No nodes, nothing to prune
2023-01-09T04:42:15.080761053Z I0109 04:42:15.080706       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'MasterNodeObserved' Observed new master node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:42:15.080761053Z I0109 04:42:15.080740       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'MasterNodeObserved' Observed new master node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:42:15.080799949Z I0109 04:42:15.080754       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'MasterNodeObserved' Observed new master node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:42:15.152377822Z I0109 04:42:15.152331       1 base_controller.go:73] Caches are synced for FeatureUpgradeableController 
2023-01-09T04:42:15.152377822Z I0109 04:42:15.152354       1 base_controller.go:110] Starting #1 worker of FeatureUpgradeableController controller ...
2023-01-09T04:42:15.152412426Z I0109 04:42:15.152379       1 base_controller.go:73] Caches are synced for webhookSupportabilityController 
2023-01-09T04:42:15.152412426Z I0109 04:42:15.152392       1 base_controller.go:110] Starting #1 worker of webhookSupportabilityController controller ...
2023-01-09T04:42:15.206312507Z E0109 04:42:15.206270       1 degraded_webhook.go:128] dial tcp 172.30.195.54:443: connect: connection refused
2023-01-09T04:42:15.551946676Z I0109 04:42:15.551909       1 base_controller.go:73] Caches are synced for StatusSyncer_kube-apiserver 
2023-01-09T04:42:15.551946676Z I0109 04:42:15.551935       1 base_controller.go:110] Starting #1 worker of StatusSyncer_kube-apiserver controller ...
2023-01-09T04:42:15.552733015Z I0109 04:42:15.552703       1 status_controller.go:211] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"InstallerControllerDegraded: missing required resources: [configmaps: aggregator-client-ca,check-endpoints-kubeconfig,client-ca,control-plane-node-kubeconfig, secrets: aggregator-client,bound-service-account-signing-key,check-endpoints-client-cert-key,control-plane-node-admin-client-cert-key,external-loadbalancer-serving-certkey,internal-loadbalancer-serving-certkey,kubelet-client,localhost-serving-cert-certkey,node-kubeconfigs,service-network-serving-certkey, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]\nNodeKubeconfigControllerDegraded: \"secret/node-kubeconfigs\": secret \"node-system-admin-client\" not found\nCertRotation_KubeControllerManagerClient_Degraded: configmaps \"kube-control-plane-signer-ca\" already exists\nNodeControllerDegraded: All master nodes are ready","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"All is well","reason":"AsExpected","status":"False","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"StaticPodsAvailable: 0 nodes are active; ","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:42:15.751594363Z I0109 04:42:15.751555       1 base_controller.go:73] Caches are synced for ConnectivityCheckController 
2023-01-09T04:42:15.751681464Z I0109 04:42:15.751637       1 base_controller.go:110] Starting #1 worker of ConnectivityCheckController controller ...
2023-01-09T04:42:15.751780721Z I0109 04:42:15.751704       1 servicehostname.go:40] syncing servicenetwork hostnames: [172.30.0.1 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local openshift openshift.default openshift.default.svc openshift.default.svc.cluster.local]
2023-01-09T04:42:15.751817270Z I0109 04:42:15.751796       1 externalloadbalancer.go:27] syncing external loadbalancer hostnames: api.sn-loggvls-jsm.qe.devcluster.openshift.com
2023-01-09T04:42:15.751828465Z I0109 04:42:15.751815       1 internalloadbalancer.go:27] syncing internal loadbalancer hostnames: api-int.sn-loggvls-jsm.qe.devcluster.openshift.com
2023-01-09T04:42:15.751828465Z I0109 04:42:15.751823       1 certrotationcontroller.go:637] Finished waiting for CertRotation
2023-01-09T04:42:15.751854521Z I0109 04:42:15.751838       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:42:15.751913378Z I0109 04:42:15.751880       1 base_controller.go:67] Waiting for caches to sync for CertRotationController
2023-01-09T04:42:15.751954312Z I0109 04:42:15.751938       1 base_controller.go:67] Waiting for caches to sync for CertRotationController
2023-01-09T04:42:15.752112118Z I0109 04:42:15.752061       1 servicehostname.go:40] syncing servicenetwork hostnames: [172.30.0.1 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local openshift openshift.default openshift.default.svc openshift.default.svc.cluster.local]
2023-01-09T04:42:15.752112118Z I0109 04:42:15.751943       1 base_controller.go:67] Waiting for caches to sync for CertRotationController
2023-01-09T04:42:15.752132419Z I0109 04:42:15.751907       1 base_controller.go:67] Waiting for caches to sync for CertRotationController
2023-01-09T04:42:15.752132419Z I0109 04:42:15.751904       1 base_controller.go:67] Waiting for caches to sync for CertRotationController
2023-01-09T04:42:15.752132419Z I0109 04:42:15.751917       1 base_controller.go:67] Waiting for caches to sync for CertRotationController
2023-01-09T04:42:15.752155130Z I0109 04:42:15.752130       1 base_controller.go:73] Caches are synced for CertRotationController 
2023-01-09T04:42:15.752155130Z I0109 04:42:15.752138       1 base_controller.go:110] Starting #1 worker of CertRotationController controller ...
2023-01-09T04:42:15.752155130Z I0109 04:42:15.751922       1 base_controller.go:67] Waiting for caches to sync for CertRotationController
2023-01-09T04:42:15.752166286Z I0109 04:42:15.751924       1 base_controller.go:67] Waiting for caches to sync for CertRotationController
2023-01-09T04:42:15.752166286Z I0109 04:42:15.751904       1 externalloadbalancer.go:27] syncing external loadbalancer hostnames: api.sn-loggvls-jsm.qe.devcluster.openshift.com
2023-01-09T04:42:15.752176879Z I0109 04:42:15.752034       1 base_controller.go:67] Waiting for caches to sync for CertRotationController
2023-01-09T04:42:15.752187122Z I0109 04:42:15.752174       1 base_controller.go:67] Waiting for caches to sync for CertRotationController
2023-01-09T04:42:15.752247730Z I0109 04:42:15.752221       1 base_controller.go:67] Waiting for caches to sync for CertRotationController
2023-01-09T04:42:15.752247730Z I0109 04:42:15.752239       1 base_controller.go:67] Waiting for caches to sync for CertRotationController
2023-01-09T04:42:15.760755904Z I0109 04:42:15.760727       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:42:15.930368171Z I0109 04:42:15.930312       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded message changed from "InstallerControllerDegraded: missing required resources: [configmaps: aggregator-client-ca,check-endpoints-kubeconfig,client-ca,control-plane-node-kubeconfig, secrets: aggregator-client,bound-service-account-signing-key,check-endpoints-client-cert-key,control-plane-node-admin-client-cert-key,external-loadbalancer-serving-certkey,internal-loadbalancer-serving-certkey,kubelet-client,localhost-serving-cert-certkey,node-kubeconfigs,service-network-serving-certkey, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]\nNodeKubeconfigControllerDegraded: \"secret/node-kubeconfigs\": secret \"node-system-admin-client\" not found\nCertRotation_KubeControllerManagerClient_Degraded: configmaps \"kube-control-plane-signer-ca\" already exists" to "InstallerControllerDegraded: missing required resources: [configmaps: aggregator-client-ca,check-endpoints-kubeconfig,client-ca,control-plane-node-kubeconfig, secrets: aggregator-client,bound-service-account-signing-key,check-endpoints-client-cert-key,control-plane-node-admin-client-cert-key,external-loadbalancer-serving-certkey,internal-loadbalancer-serving-certkey,kubelet-client,localhost-serving-cert-certkey,node-kubeconfigs,service-network-serving-certkey, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]\nNodeKubeconfigControllerDegraded: \"secret/node-kubeconfigs\": secret \"node-system-admin-client\" not found\nCertRotation_KubeControllerManagerClient_Degraded: configmaps \"kube-control-plane-signer-ca\" already exists\nNodeControllerDegraded: All master nodes are ready",Upgradeable message changed from "All is well" to "KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced."
2023-01-09T04:42:15.930909332Z I0109 04:42:15.930873       1 status_controller.go:211] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"InstallerControllerDegraded: missing required resources: [configmaps: aggregator-client-ca,check-endpoints-kubeconfig,client-ca,control-plane-node-kubeconfig, secrets: aggregator-client,bound-service-account-signing-key,check-endpoints-client-cert-key,control-plane-node-admin-client-cert-key,external-loadbalancer-serving-certkey,internal-loadbalancer-serving-certkey,kubelet-client,localhost-serving-cert-certkey,node-kubeconfigs,service-network-serving-certkey, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]\nNodeKubeconfigControllerDegraded: \"secret/node-kubeconfigs\": secret \"node-system-admin-client\" not found\nCertRotation_KubeControllerManagerClient_Degraded: configmaps \"kube-control-plane-signer-ca\" already exists\nNodeControllerDegraded: All master nodes are ready","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"All is well","reason":"AsExpected","status":"False","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"StaticPodsAvailable: 0 nodes are active; ","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:42:15.953046671Z I0109 04:42:15.953014       1 base_controller.go:73] Caches are synced for GuardController 
2023-01-09T04:42:15.953046671Z I0109 04:42:15.953033       1 base_controller.go:73] Caches are synced for StaticPodStateController 
2023-01-09T04:42:15.953072057Z I0109 04:42:15.953043       1 base_controller.go:73] Caches are synced for InstallerController 
2023-01-09T04:42:15.953072057Z I0109 04:42:15.953053       1 base_controller.go:110] Starting #1 worker of InstallerController controller ...
2023-01-09T04:42:15.953105182Z I0109 04:42:15.953033       1 base_controller.go:110] Starting #1 worker of GuardController controller ...
2023-01-09T04:42:15.953140434Z I0109 04:42:15.953045       1 base_controller.go:110] Starting #1 worker of StaticPodStateController controller ...
2023-01-09T04:42:15.953150822Z I0109 04:42:15.953020       1 base_controller.go:73] Caches are synced for StartupMonitorPodCondition 
2023-01-09T04:42:15.953178078Z I0109 04:42:15.953162       1 base_controller.go:110] Starting #1 worker of StartupMonitorPodCondition controller ...
2023-01-09T04:42:15.953225699Z I0109 04:42:15.953020       1 base_controller.go:73] Caches are synced for InstallerStateController 
2023-01-09T04:42:15.953225699Z I0109 04:42:15.953214       1 base_controller.go:110] Starting #1 worker of InstallerStateController controller ...
2023-01-09T04:42:15.953251275Z I0109 04:42:15.953130       1 base_controller.go:73] Caches are synced for StaticPodStateFallback 
2023-01-09T04:42:15.953263072Z I0109 04:42:15.953248       1 base_controller.go:110] Starting #1 worker of StaticPodStateFallback controller ...
2023-01-09T04:42:15.953536194Z I0109 04:42:15.953506       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: aggregator-client-ca,check-endpoints-kubeconfig,client-ca,control-plane-node-kubeconfig, secrets: aggregator-client,bound-service-account-signing-key,check-endpoints-client-cert-key,control-plane-node-admin-client-cert-key,external-loadbalancer-serving-certkey,internal-loadbalancer-serving-certkey,kubelet-client,localhost-serving-cert-certkey,node-kubeconfigs,service-network-serving-certkey, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0
2023-01-09T04:42:15.957172398Z E0109 04:42:15.957146       1 guard_controller.go:268] Missing operand on node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:42:15.957172398Z E0109 04:42:15.957166       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:42:15.957198511Z E0109 04:42:15.957176       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:42:15.961590369Z E0109 04:42:15.961555       1 base_controller.go:272] InstallerController reconciliation failed: missing required resources: [configmaps: aggregator-client-ca,check-endpoints-kubeconfig,client-ca,control-plane-node-kubeconfig, secrets: aggregator-client,bound-service-account-signing-key,check-endpoints-client-cert-key,control-plane-node-admin-client-cert-key,external-loadbalancer-serving-certkey,internal-loadbalancer-serving-certkey,kubelet-client,localhost-serving-cert-certkey,node-kubeconfigs,service-network-serving-certkey, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]
2023-01-09T04:42:15.962402480Z I0109 04:42:15.962379       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:42:15.962726916Z I0109 04:42:15.962686       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: aggregator-client-ca,check-endpoints-kubeconfig,client-ca,control-plane-node-kubeconfig, secrets: aggregator-client,bound-service-account-signing-key,check-endpoints-client-cert-key,control-plane-node-admin-client-cert-key,external-loadbalancer-serving-certkey,internal-loadbalancer-serving-certkey,kubelet-client,localhost-serving-cert-certkey,node-kubeconfigs,service-network-serving-certkey, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0
2023-01-09T04:42:15.962798677Z E0109 04:42:15.962748       1 base_controller.go:272] InstallerController reconciliation failed: missing required resources: [configmaps: aggregator-client-ca,check-endpoints-kubeconfig,client-ca,control-plane-node-kubeconfig, secrets: aggregator-client,bound-service-account-signing-key,check-endpoints-client-cert-key,control-plane-node-admin-client-cert-key,external-loadbalancer-serving-certkey,internal-loadbalancer-serving-certkey,kubelet-client,localhost-serving-cert-certkey,node-kubeconfigs,service-network-serving-certkey, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]
2023-01-09T04:42:15.967510025Z I0109 04:42:15.967454       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: aggregator-client-ca,check-endpoints-kubeconfig,client-ca,control-plane-node-kubeconfig, secrets: aggregator-client,bound-service-account-signing-key,check-endpoints-client-cert-key,control-plane-node-admin-client-cert-key,external-loadbalancer-serving-certkey,internal-loadbalancer-serving-certkey,kubelet-client,localhost-serving-cert-certkey,node-kubeconfigs,service-network-serving-certkey, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0
2023-01-09T04:42:15.967576893Z E0109 04:42:15.967557       1 base_controller.go:272] InstallerController reconciliation failed: missing required resources: [configmaps: aggregator-client-ca,check-endpoints-kubeconfig,client-ca,control-plane-node-kubeconfig, secrets: aggregator-client,bound-service-account-signing-key,check-endpoints-client-cert-key,control-plane-node-admin-client-cert-key,external-loadbalancer-serving-certkey,internal-loadbalancer-serving-certkey,kubelet-client,localhost-serving-cert-certkey,node-kubeconfigs,service-network-serving-certkey, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]
2023-01-09T04:42:15.982385582Z I0109 04:42:15.982347       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:42:15.982605750Z I0109 04:42:15.982565       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: aggregator-client-ca,check-endpoints-kubeconfig,client-ca,control-plane-node-kubeconfig, secrets: aggregator-client,bound-service-account-signing-key,check-endpoints-client-cert-key,control-plane-node-admin-client-cert-key,external-loadbalancer-serving-certkey,internal-loadbalancer-serving-certkey,kubelet-client,localhost-serving-cert-certkey,node-kubeconfigs,service-network-serving-certkey, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0
2023-01-09T04:42:15.982667500Z E0109 04:42:15.982650       1 base_controller.go:272] InstallerController reconciliation failed: missing required resources: [configmaps: aggregator-client-ca,check-endpoints-kubeconfig,client-ca,control-plane-node-kubeconfig, secrets: aggregator-client,bound-service-account-signing-key,check-endpoints-client-cert-key,control-plane-node-admin-client-cert-key,external-loadbalancer-serving-certkey,internal-loadbalancer-serving-certkey,kubelet-client,localhost-serving-cert-certkey,node-kubeconfigs,service-network-serving-certkey, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]
2023-01-09T04:42:15.988667426Z I0109 04:42:15.988611       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: aggregator-client-ca,check-endpoints-kubeconfig,client-ca,control-plane-node-kubeconfig, secrets: aggregator-client,bound-service-account-signing-key,check-endpoints-client-cert-key,control-plane-node-admin-client-cert-key,external-loadbalancer-serving-certkey,internal-loadbalancer-serving-certkey,kubelet-client,localhost-serving-cert-certkey,node-kubeconfigs,service-network-serving-certkey, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0
2023-01-09T04:42:15.988790731Z E0109 04:42:15.988762       1 base_controller.go:272] InstallerController reconciliation failed: missing required resources: [configmaps: aggregator-client-ca,check-endpoints-kubeconfig,client-ca,control-plane-node-kubeconfig, secrets: aggregator-client,bound-service-account-signing-key,check-endpoints-client-cert-key,control-plane-node-admin-client-cert-key,external-loadbalancer-serving-certkey,internal-loadbalancer-serving-certkey,kubelet-client,localhost-serving-cert-certkey,node-kubeconfigs,service-network-serving-certkey, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]
2023-01-09T04:42:16.048843148Z E0109 04:42:16.048794       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:42:16.049618026Z I0109 04:42:16.049575       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:42:16.049692798Z E0109 04:42:16.049674       1 base_controller.go:272] InstallerController reconciliation failed: missing required resources: [configmaps: aggregator-client-ca,check-endpoints-kubeconfig,client-ca,control-plane-node-kubeconfig, secrets: aggregator-client,bound-service-account-signing-key,check-endpoints-client-cert-key,control-plane-node-admin-client-cert-key,external-loadbalancer-serving-certkey,internal-loadbalancer-serving-certkey,kubelet-client,localhost-serving-cert-certkey,node-kubeconfigs,service-network-serving-certkey, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]
2023-01-09T04:42:16.049704795Z I0109 04:42:16.049682       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: aggregator-client-ca,check-endpoints-kubeconfig,client-ca,control-plane-node-kubeconfig, secrets: aggregator-client,bound-service-account-signing-key,check-endpoints-client-cert-key,control-plane-node-admin-client-cert-key,external-loadbalancer-serving-certkey,internal-loadbalancer-serving-certkey,kubelet-client,localhost-serving-cert-certkey,node-kubeconfigs,service-network-serving-certkey, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0
2023-01-09T04:42:16.056175335Z E0109 04:42:16.056150       1 guard_controller.go:268] Missing operand on node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:42:16.056175335Z E0109 04:42:16.056170       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:42:16.056199258Z E0109 04:42:16.056180       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:42:16.056380257Z E0109 04:42:16.056366       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:42:16.068539769Z E0109 04:42:16.068515       1 guard_controller.go:268] Missing operand on node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:42:16.068539769Z E0109 04:42:16.068535       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:42:16.068585574Z E0109 04:42:16.068546       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:42:16.068701840Z E0109 04:42:16.068688       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:42:16.069831607Z I0109 04:42:16.069798       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: aggregator-client-ca,check-endpoints-kubeconfig,client-ca,control-plane-node-kubeconfig, secrets: aggregator-client,bound-service-account-signing-key,check-endpoints-client-cert-key,control-plane-node-admin-client-cert-key,external-loadbalancer-serving-certkey,internal-loadbalancer-serving-certkey,kubelet-client,localhost-serving-cert-certkey,node-kubeconfigs,service-network-serving-certkey, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0
2023-01-09T04:42:16.069890236Z E0109 04:42:16.069874       1 base_controller.go:272] InstallerController reconciliation failed: missing required resources: [configmaps: aggregator-client-ca,check-endpoints-kubeconfig,client-ca,control-plane-node-kubeconfig, secrets: aggregator-client,bound-service-account-signing-key,check-endpoints-client-cert-key,control-plane-node-admin-client-cert-key,external-loadbalancer-serving-certkey,internal-loadbalancer-serving-certkey,kubelet-client,localhost-serving-cert-certkey,node-kubeconfigs,service-network-serving-certkey, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]
2023-01-09T04:42:16.090672846Z E0109 04:42:16.090647       1 guard_controller.go:268] Missing operand on node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:42:16.090672846Z E0109 04:42:16.090667       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:42:16.090692278Z E0109 04:42:16.090677       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:42:16.090859921Z E0109 04:42:16.090845       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:42:16.127640407Z E0109 04:42:16.127604       1 base_controller.go:272] StatusSyncer_kube-apiserver reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io "kube-apiserver": the object has been modified; please apply your changes to the latest version and try again
2023-01-09T04:42:16.128130132Z I0109 04:42:16.128108       1 status_controller.go:211] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"InstallerControllerDegraded: missing required resources: [configmaps: aggregator-client-ca,check-endpoints-kubeconfig,client-ca,control-plane-node-kubeconfig, secrets: aggregator-client,bound-service-account-signing-key,check-endpoints-client-cert-key,control-plane-node-admin-client-cert-key,external-loadbalancer-serving-certkey,internal-loadbalancer-serving-certkey,kubelet-client,localhost-serving-cert-certkey,node-kubeconfigs,service-network-serving-certkey, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]\nNodeKubeconfigControllerDegraded: \"secret/node-kubeconfigs\": secret \"node-system-admin-client\" not found\nCertRotation_KubeControllerManagerClient_Degraded: configmaps \"kube-control-plane-signer-ca\" already exists\nNodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0","reason":"AsExpected","status":"False","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:42:16.134241006Z E0109 04:42:16.134201       1 guard_controller.go:268] Missing operand on node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:42:16.134241006Z E0109 04:42:16.134229       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:42:16.134257984Z E0109 04:42:16.134240       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:42:16.134416177Z E0109 04:42:16.134402       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:42:16.140290651Z I0109 04:42:16.140266       1 request.go:601] Waited for 1.188628139s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config/configmaps?limit=500&resourceVersion=0
2023-01-09T04:42:16.152565011Z I0109 04:42:16.152537       1 base_controller.go:73] Caches are synced for CertRotationTimeUpgradeableController 
2023-01-09T04:42:16.152565011Z I0109 04:42:16.152553       1 base_controller.go:110] Starting #1 worker of CertRotationTimeUpgradeableController controller ...
2023-01-09T04:42:16.210817796Z E0109 04:42:16.210780       1 degraded_webhook.go:128] dial tcp 172.30.195.54:443: connect: connection refused
2023-01-09T04:42:16.221916989Z E0109 04:42:16.221790       1 guard_controller.go:268] Missing operand on node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:42:16.221916989Z E0109 04:42:16.221824       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:42:16.221916989Z E0109 04:42:16.221841       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:42:16.222173063Z E0109 04:42:16.222151       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:42:16.224581505Z E0109 04:42:16.224550       1 guard_controller.go:268] Missing operand on node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:42:16.224610170Z E0109 04:42:16.224585       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:42:16.224610170Z E0109 04:42:16.224603       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:42:16.224887207Z E0109 04:42:16.224859       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:42:16.330543051Z I0109 04:42:16.330504       1 status_controller.go:211] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"InstallerControllerDegraded: missing required resources: [configmaps: aggregator-client-ca,check-endpoints-kubeconfig,client-ca,control-plane-node-kubeconfig, secrets: aggregator-client,bound-service-account-signing-key,check-endpoints-client-cert-key,control-plane-node-admin-client-cert-key,external-loadbalancer-serving-certkey,internal-loadbalancer-serving-certkey,kubelet-client,localhost-serving-cert-certkey,node-kubeconfigs,service-network-serving-certkey, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]\nNodeKubeconfigControllerDegraded: \"secret/node-kubeconfigs\": secret \"node-system-admin-client\" not found\nCertRotation_KubeControllerManagerClient_Degraded: configmaps \"kube-control-plane-signer-ca\" already exists\nNodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0","reason":"AsExpected","status":"False","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:42:16.330818786Z I0109 04:42:16.330761       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded message changed from "InstallerControllerDegraded: missing required resources: [configmaps: aggregator-client-ca,check-endpoints-kubeconfig,client-ca,control-plane-node-kubeconfig, secrets: aggregator-client,bound-service-account-signing-key,check-endpoints-client-cert-key,control-plane-node-admin-client-cert-key,external-loadbalancer-serving-certkey,internal-loadbalancer-serving-certkey,kubelet-client,localhost-serving-cert-certkey,node-kubeconfigs,service-network-serving-certkey, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]\nNodeKubeconfigControllerDegraded: \"secret/node-kubeconfigs\": secret \"node-system-admin-client\" not found\nCertRotation_KubeControllerManagerClient_Degraded: configmaps \"kube-control-plane-signer-ca\" already exists\nNodeControllerDegraded: All master nodes are ready" to "InstallerControllerDegraded: missing required resources: [configmaps: aggregator-client-ca,check-endpoints-kubeconfig,client-ca,control-plane-node-kubeconfig, secrets: aggregator-client,bound-service-account-signing-key,check-endpoints-client-cert-key,control-plane-node-admin-client-cert-key,external-loadbalancer-serving-certkey,internal-loadbalancer-serving-certkey,kubelet-client,localhost-serving-cert-certkey,node-kubeconfigs,service-network-serving-certkey, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]\nNodeKubeconfigControllerDegraded: \"secret/node-kubeconfigs\": secret \"node-system-admin-client\" not found\nCertRotation_KubeControllerManagerClient_Degraded: configmaps \"kube-control-plane-signer-ca\" already exists\nNodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]",Progressing message changed from "All is well" to "NodeInstallerProgressing: 3 nodes are at revision 0",Available message changed from "StaticPodsAvailable: 0 nodes are active; " to "StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0"
2023-01-09T04:42:16.351222695Z I0109 04:42:16.351188       1 base_controller.go:73] Caches are synced for auditPolicyController 
2023-01-09T04:42:16.351222695Z I0109 04:42:16.351205       1 base_controller.go:110] Starting #1 worker of auditPolicyController controller ...
2023-01-09T04:42:16.351860873Z I0109 04:42:16.351835       1 base_controller.go:73] Caches are synced for WorkerLatencyProfile 
2023-01-09T04:42:16.351860873Z I0109 04:42:16.351850       1 base_controller.go:110] Starting #1 worker of WorkerLatencyProfile controller ...
2023-01-09T04:42:16.352820363Z I0109 04:42:16.352757       1 base_controller.go:73] Caches are synced for MissingStaticPodController 
2023-01-09T04:42:16.352851030Z I0109 04:42:16.352816       1 base_controller.go:110] Starting #1 worker of MissingStaticPodController controller ...
2023-01-09T04:42:16.360117022Z I0109 04:42:16.360085       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:42:16.360539444Z I0109 04:42:16.360505       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: client-ca, secrets: aggregator-client,bound-service-account-signing-key,check-endpoints-client-cert-key,control-plane-node-admin-client-cert-key,external-loadbalancer-serving-certkey,internal-loadbalancer-serving-certkey,kubelet-client,localhost-serving-cert-certkey,node-kubeconfigs,service-network-serving-certkey, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0
2023-01-09T04:42:16.367704959Z E0109 04:42:16.367675       1 base_controller.go:272] InstallerController reconciliation failed: missing required resources: [configmaps: client-ca, secrets: aggregator-client,bound-service-account-signing-key,check-endpoints-client-cert-key,control-plane-node-admin-client-cert-key,external-loadbalancer-serving-certkey,internal-loadbalancer-serving-certkey,kubelet-client,localhost-serving-cert-certkey,node-kubeconfigs,service-network-serving-certkey, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]
2023-01-09T04:42:16.368178084Z I0109 04:42:16.368153       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:42:16.368593751Z I0109 04:42:16.368566       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: client-ca, secrets: aggregator-client,bound-service-account-signing-key,check-endpoints-client-cert-key,control-plane-node-admin-client-cert-key,external-loadbalancer-serving-certkey,internal-loadbalancer-serving-certkey,kubelet-client,localhost-serving-cert-certkey,node-kubeconfigs,service-network-serving-certkey, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0
2023-01-09T04:42:16.368707941Z E0109 04:42:16.368693       1 base_controller.go:272] InstallerController reconciliation failed: missing required resources: [configmaps: client-ca, secrets: aggregator-client,bound-service-account-signing-key,check-endpoints-client-cert-key,control-plane-node-admin-client-cert-key,external-loadbalancer-serving-certkey,internal-loadbalancer-serving-certkey,kubelet-client,localhost-serving-cert-certkey,node-kubeconfigs,service-network-serving-certkey, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]
2023-01-09T04:42:16.379493685Z I0109 04:42:16.379466       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:42:16.379847793Z I0109 04:42:16.379809       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: client-ca, secrets: aggregator-client,bound-service-account-signing-key,check-endpoints-client-cert-key,control-plane-node-admin-client-cert-key,external-loadbalancer-serving-certkey,internal-loadbalancer-serving-certkey,kubelet-client,localhost-serving-cert-certkey,node-kubeconfigs,service-network-serving-certkey, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0
2023-01-09T04:42:16.380058044Z E0109 04:42:16.380033       1 base_controller.go:272] InstallerController reconciliation failed: missing required resources: [configmaps: client-ca, secrets: aggregator-client,bound-service-account-signing-key,check-endpoints-client-cert-key,control-plane-node-admin-client-cert-key,external-loadbalancer-serving-certkey,internal-loadbalancer-serving-certkey,kubelet-client,localhost-serving-cert-certkey,node-kubeconfigs,service-network-serving-certkey, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]
2023-01-09T04:42:16.385062253Z E0109 04:42:16.385039       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:42:16.385087486Z E0109 04:42:16.385064       1 guard_controller.go:268] Missing operand on node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:42:16.385087486Z E0109 04:42:16.385079       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:42:16.391219785Z I0109 04:42:16.391187       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: client-ca, secrets: aggregator-client,bound-service-account-signing-key,check-endpoints-client-cert-key,control-plane-node-admin-client-cert-key,external-loadbalancer-serving-certkey,internal-loadbalancer-serving-certkey,kubelet-client,localhost-serving-cert-certkey,node-kubeconfigs,service-network-serving-certkey, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0
2023-01-09T04:42:16.391397918Z E0109 04:42:16.391379       1 base_controller.go:272] InstallerController reconciliation failed: missing required resources: [configmaps: client-ca, secrets: aggregator-client,bound-service-account-signing-key,check-endpoints-client-cert-key,control-plane-node-admin-client-cert-key,external-loadbalancer-serving-certkey,internal-loadbalancer-serving-certkey,kubelet-client,localhost-serving-cert-certkey,node-kubeconfigs,service-network-serving-certkey, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]
2023-01-09T04:42:16.527315139Z E0109 04:42:16.527278       1 base_controller.go:272] StatusSyncer_kube-apiserver reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io "kube-apiserver": the object has been modified; please apply your changes to the latest version and try again
2023-01-09T04:42:16.527903839Z I0109 04:42:16.527880       1 status_controller.go:211] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"InstallerControllerDegraded: missing required resources: [configmaps: client-ca, secrets: aggregator-client,bound-service-account-signing-key,check-endpoints-client-cert-key,control-plane-node-admin-client-cert-key,external-loadbalancer-serving-certkey,internal-loadbalancer-serving-certkey,kubelet-client,localhost-serving-cert-certkey,node-kubeconfigs,service-network-serving-certkey, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]\nNodeKubeconfigControllerDegraded: \"secret/node-kubeconfigs\": secret \"node-system-admin-client\" not found\nCertRotation_KubeControllerManagerClient_Degraded: configmaps \"kube-control-plane-signer-ca\" already exists\nNodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0","reason":"AsExpected","status":"False","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:42:16.735145879Z I0109 04:42:16.734872       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded message changed from "InstallerControllerDegraded: missing required resources: [configmaps: aggregator-client-ca,check-endpoints-kubeconfig,client-ca,control-plane-node-kubeconfig, secrets: aggregator-client,bound-service-account-signing-key,check-endpoints-client-cert-key,control-plane-node-admin-client-cert-key,external-loadbalancer-serving-certkey,internal-loadbalancer-serving-certkey,kubelet-client,localhost-serving-cert-certkey,node-kubeconfigs,service-network-serving-certkey, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]\nNodeKubeconfigControllerDegraded: \"secret/node-kubeconfigs\": secret \"node-system-admin-client\" not found\nCertRotation_KubeControllerManagerClient_Degraded: configmaps \"kube-control-plane-signer-ca\" already exists\nNodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]" to "InstallerControllerDegraded: missing required resources: [configmaps: client-ca, secrets: aggregator-client,bound-service-account-signing-key,check-endpoints-client-cert-key,control-plane-node-admin-client-cert-key,external-loadbalancer-serving-certkey,internal-loadbalancer-serving-certkey,kubelet-client,localhost-serving-cert-certkey,node-kubeconfigs,service-network-serving-certkey, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]\nNodeKubeconfigControllerDegraded: \"secret/node-kubeconfigs\": secret \"node-system-admin-client\" not found\nCertRotation_KubeControllerManagerClient_Degraded: configmaps \"kube-control-plane-signer-ca\" already exists\nNodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]"
2023-01-09T04:42:16.735222763Z I0109 04:42:16.735180       1 status_controller.go:211] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"InstallerControllerDegraded: missing required resources: [configmaps: client-ca, secrets: aggregator-client,bound-service-account-signing-key,check-endpoints-client-cert-key,control-plane-node-admin-client-cert-key,external-loadbalancer-serving-certkey,internal-loadbalancer-serving-certkey,kubelet-client,localhost-serving-cert-certkey,node-kubeconfigs,service-network-serving-certkey, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]\nNodeKubeconfigControllerDegraded: \"secret/node-kubeconfigs\": secret \"node-system-admin-client\" not found\nCertRotation_KubeControllerManagerClient_Degraded: configmaps \"kube-control-plane-signer-ca\" already exists\nNodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0","reason":"AsExpected","status":"False","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:42:16.761526923Z E0109 04:42:16.761481       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal]
2023-01-09T04:42:16.761935524Z I0109 04:42:16.761899       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:42:16.765128649Z E0109 04:42:16.765098       1 base_controller.go:272] InstallerController reconciliation failed: missing required resources: [configmaps: client-ca, secrets: aggregator-client,bound-service-account-signing-key,check-endpoints-client-cert-key,control-plane-node-admin-client-cert-key,external-loadbalancer-serving-certkey,internal-loadbalancer-serving-certkey,kubelet-client,localhost-serving-cert-certkey,node-kubeconfigs,service-network-serving-certkey, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]
2023-01-09T04:42:16.765167677Z I0109 04:42:16.765143       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: client-ca, secrets: aggregator-client,bound-service-account-signing-key,check-endpoints-client-cert-key,control-plane-node-admin-client-cert-key,external-loadbalancer-serving-certkey,internal-loadbalancer-serving-certkey,kubelet-client,localhost-serving-cert-certkey,node-kubeconfigs,service-network-serving-certkey, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0
2023-01-09T04:42:16.928553125Z E0109 04:42:16.928520       1 base_controller.go:272] StatusSyncer_kube-apiserver reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io "kube-apiserver": the object has been modified; please apply your changes to the latest version and try again
2023-01-09T04:42:16.929091110Z I0109 04:42:16.929071       1 status_controller.go:211] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"InstallerControllerDegraded: missing required resources: [configmaps: client-ca, secrets: aggregator-client,bound-service-account-signing-key,check-endpoints-client-cert-key,control-plane-node-admin-client-cert-key,external-loadbalancer-serving-certkey,internal-loadbalancer-serving-certkey,kubelet-client,localhost-serving-cert-certkey,node-kubeconfigs,service-network-serving-certkey, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]\nNodeKubeconfigControllerDegraded: \"secret/node-kubeconfigs\": secret \"node-system-admin-client\" not found\nCertRotation_KubeControllerManagerClient_Degraded: configmaps \"kube-control-plane-signer-ca\" already exists\nNodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal]","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0","reason":"AsExpected","status":"False","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:42:17.130344898Z I0109 04:42:17.130292       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded message changed from "InstallerControllerDegraded: missing required resources: [configmaps: client-ca, secrets: aggregator-client,bound-service-account-signing-key,check-endpoints-client-cert-key,control-plane-node-admin-client-cert-key,external-loadbalancer-serving-certkey,internal-loadbalancer-serving-certkey,kubelet-client,localhost-serving-cert-certkey,node-kubeconfigs,service-network-serving-certkey, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]\nNodeKubeconfigControllerDegraded: \"secret/node-kubeconfigs\": secret \"node-system-admin-client\" not found\nCertRotation_KubeControllerManagerClient_Degraded: configmaps \"kube-control-plane-signer-ca\" already exists\nNodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]" to "InstallerControllerDegraded: missing required resources: [configmaps: client-ca, secrets: aggregator-client,bound-service-account-signing-key,check-endpoints-client-cert-key,control-plane-node-admin-client-cert-key,external-loadbalancer-serving-certkey,internal-loadbalancer-serving-certkey,kubelet-client,localhost-serving-cert-certkey,node-kubeconfigs,service-network-serving-certkey, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]\nNodeKubeconfigControllerDegraded: \"secret/node-kubeconfigs\": secret \"node-system-admin-client\" not found\nCertRotation_KubeControllerManagerClient_Degraded: configmaps \"kube-control-plane-signer-ca\" already exists\nNodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal]"
2023-01-09T04:42:17.130805626Z I0109 04:42:17.130772       1 status_controller.go:211] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"InstallerControllerDegraded: missing required resources: [configmaps: client-ca, secrets: aggregator-client,bound-service-account-signing-key,check-endpoints-client-cert-key,control-plane-node-admin-client-cert-key,external-loadbalancer-serving-certkey,internal-loadbalancer-serving-certkey,kubelet-client,localhost-serving-cert-certkey,node-kubeconfigs,service-network-serving-certkey, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]\nNodeKubeconfigControllerDegraded: \"secret/node-kubeconfigs\": secret \"node-system-admin-client\" not found\nCertRotation_KubeControllerManagerClient_Degraded: configmaps \"kube-control-plane-signer-ca\" already exists\nNodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal]","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0","reason":"AsExpected","status":"False","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:42:17.152614653Z I0109 04:42:17.152577       1 base_controller.go:73] Caches are synced for CertRotationController 
2023-01-09T04:42:17.152672197Z I0109 04:42:17.152659       1 base_controller.go:110] Starting #1 worker of CertRotationController controller ...
2023-01-09T04:42:17.154299604Z E0109 04:42:17.154268       1 guard_controller.go:268] Missing operand on node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:42:17.154456705Z E0109 04:42:17.154445       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:42:17.154533607Z E0109 04:42:17.154507       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:42:17.154588763Z I0109 04:42:17.154373       1 base_controller.go:73] Caches are synced for CertRotationController 
2023-01-09T04:42:17.154627374Z I0109 04:42:17.154614       1 base_controller.go:110] Starting #1 worker of CertRotationController controller ...
2023-01-09T04:42:17.162178214Z I0109 04:42:17.162141       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:42:17.163915573Z I0109 04:42:17.163872       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: client-ca, secrets: aggregator-client,bound-service-account-signing-key,check-endpoints-client-cert-key,control-plane-node-admin-client-cert-key,external-loadbalancer-serving-certkey,internal-loadbalancer-serving-certkey,kubelet-client,localhost-serving-cert-certkey,node-kubeconfigs,service-network-serving-certkey, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0
2023-01-09T04:42:17.164085629Z E0109 04:42:17.164063       1 base_controller.go:272] InstallerController reconciliation failed: missing required resources: [configmaps: client-ca, secrets: aggregator-client,bound-service-account-signing-key,check-endpoints-client-cert-key,control-plane-node-admin-client-cert-key,external-loadbalancer-serving-certkey,internal-loadbalancer-serving-certkey,kubelet-client,localhost-serving-cert-certkey,node-kubeconfigs,service-network-serving-certkey, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]
2023-01-09T04:42:17.328151142Z E0109 04:42:17.328099       1 base_controller.go:272] StatusSyncer_kube-apiserver reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io "kube-apiserver": the object has been modified; please apply your changes to the latest version and try again
2023-01-09T04:42:17.328623867Z I0109 04:42:17.328605       1 status_controller.go:211] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"InstallerControllerDegraded: missing required resources: [configmaps: client-ca, secrets: aggregator-client,bound-service-account-signing-key,check-endpoints-client-cert-key,control-plane-node-admin-client-cert-key,external-loadbalancer-serving-certkey,internal-loadbalancer-serving-certkey,kubelet-client,localhost-serving-cert-certkey,node-kubeconfigs,service-network-serving-certkey, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]\nNodeKubeconfigControllerDegraded: \"secret/node-kubeconfigs\": secret \"node-system-admin-client\" not found\nNodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal]","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0","reason":"AsExpected","status":"False","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:42:17.339600062Z I0109 04:42:17.339573       1 request.go:601] Waited for 2.387453824s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts?limit=500&resourceVersion=0
2023-01-09T04:42:17.355607331Z I0109 04:42:17.355576       1 base_controller.go:73] Caches are synced for BackingResourceController 
2023-01-09T04:42:17.355607331Z I0109 04:42:17.355596       1 base_controller.go:110] Starting #1 worker of BackingResourceController controller ...
2023-01-09T04:42:17.530599004Z I0109 04:42:17.530559       1 status_controller.go:211] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"InstallerControllerDegraded: missing required resources: [configmaps: client-ca, secrets: aggregator-client,bound-service-account-signing-key,check-endpoints-client-cert-key,control-plane-node-admin-client-cert-key,external-loadbalancer-serving-certkey,internal-loadbalancer-serving-certkey,kubelet-client,localhost-serving-cert-certkey,node-kubeconfigs,service-network-serving-certkey, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]\nNodeKubeconfigControllerDegraded: \"secret/node-kubeconfigs\": secret \"node-system-admin-client\" not found\nNodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal]","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0","reason":"AsExpected","status":"False","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:42:17.530759575Z I0109 04:42:17.530729       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded message changed from "InstallerControllerDegraded: missing required resources: [configmaps: client-ca, secrets: aggregator-client,bound-service-account-signing-key,check-endpoints-client-cert-key,control-plane-node-admin-client-cert-key,external-loadbalancer-serving-certkey,internal-loadbalancer-serving-certkey,kubelet-client,localhost-serving-cert-certkey,node-kubeconfigs,service-network-serving-certkey, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]\nNodeKubeconfigControllerDegraded: \"secret/node-kubeconfigs\": secret \"node-system-admin-client\" not found\nCertRotation_KubeControllerManagerClient_Degraded: configmaps \"kube-control-plane-signer-ca\" already exists\nNodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal]" to "InstallerControllerDegraded: missing required resources: [configmaps: client-ca, secrets: aggregator-client,bound-service-account-signing-key,check-endpoints-client-cert-key,control-plane-node-admin-client-cert-key,external-loadbalancer-serving-certkey,internal-loadbalancer-serving-certkey,kubelet-client,localhost-serving-cert-certkey,node-kubeconfigs,service-network-serving-certkey, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]\nNodeKubeconfigControllerDegraded: \"secret/node-kubeconfigs\": secret \"node-system-admin-client\" not found\nNodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal]"
2023-01-09T04:42:17.727661229Z E0109 04:42:17.727621       1 base_controller.go:272] StatusSyncer_kube-apiserver reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io "kube-apiserver": the object has been modified; please apply your changes to the latest version and try again
2023-01-09T04:42:17.751760105Z I0109 04:42:17.751725       1 base_controller.go:73] Caches are synced for BoundSATokenSignerController 
2023-01-09T04:42:17.751760105Z I0109 04:42:17.751743       1 base_controller.go:110] Starting #1 worker of BoundSATokenSignerController controller ...
2023-01-09T04:42:17.751834335Z I0109 04:42:17.751803       1 base_controller.go:73] Caches are synced for NodeKubeconfigController 
2023-01-09T04:42:17.751834335Z I0109 04:42:17.751824       1 base_controller.go:110] Starting #1 worker of NodeKubeconfigController controller ...
2023-01-09T04:42:17.751834335Z I0109 04:42:17.751827       1 base_controller.go:73] Caches are synced for EncryptionKeyController 
2023-01-09T04:42:17.751857043Z I0109 04:42:17.751833       1 base_controller.go:73] Caches are synced for EncryptionStateController 
2023-01-09T04:42:17.751857043Z I0109 04:42:17.751845       1 base_controller.go:73] Caches are synced for EncryptionConditionController 
2023-01-09T04:42:17.751857043Z I0109 04:42:17.751838       1 base_controller.go:110] Starting #1 worker of EncryptionKeyController controller ...
2023-01-09T04:42:17.751868786Z I0109 04:42:17.751851       1 base_controller.go:73] Caches are synced for EncryptionMigrationController 
2023-01-09T04:42:17.751868786Z I0109 04:42:17.751851       1 base_controller.go:73] Caches are synced for EncryptionPruneController 
2023-01-09T04:42:17.751868786Z I0109 04:42:17.751864       1 base_controller.go:110] Starting #1 worker of EncryptionMigrationController controller ...
2023-01-09T04:42:17.751887926Z I0109 04:42:17.751868       1 base_controller.go:110] Starting #1 worker of EncryptionPruneController controller ...
2023-01-09T04:42:17.751887926Z I0109 04:42:17.751874       1 base_controller.go:73] Caches are synced for ConfigObserver 
2023-01-09T04:42:17.751887926Z I0109 04:42:17.751847       1 base_controller.go:110] Starting #1 worker of EncryptionStateController controller ...
2023-01-09T04:42:17.751887926Z I0109 04:42:17.751884       1 base_controller.go:110] Starting #1 worker of ConfigObserver controller ...
2023-01-09T04:42:17.751931780Z I0109 04:42:17.751854       1 base_controller.go:110] Starting #1 worker of EncryptionConditionController controller ...
2023-01-09T04:42:17.752742238Z I0109 04:42:17.752714       1 base_controller.go:73] Caches are synced for RevisionController 
2023-01-09T04:42:17.752742238Z I0109 04:42:17.752732       1 base_controller.go:73] Caches are synced for CertRotationController 
2023-01-09T04:42:17.752767427Z I0109 04:42:17.752745       1 base_controller.go:110] Starting #1 worker of CertRotationController controller ...
2023-01-09T04:42:17.752767427Z I0109 04:42:17.752755       1 base_controller.go:73] Caches are synced for CertRotationController 
2023-01-09T04:42:17.752767427Z I0109 04:42:17.752762       1 base_controller.go:110] Starting #1 worker of CertRotationController controller ...
2023-01-09T04:42:17.752779661Z I0109 04:42:17.752747       1 base_controller.go:73] Caches are synced for CertRotationController 
2023-01-09T04:42:17.752789691Z I0109 04:42:17.752781       1 base_controller.go:110] Starting #1 worker of CertRotationController controller ...
2023-01-09T04:42:17.752800272Z I0109 04:42:17.752735       1 base_controller.go:110] Starting #1 worker of RevisionController controller ...
2023-01-09T04:42:17.752810260Z I0109 04:42:17.752801       1 base_controller.go:73] Caches are synced for ResourceSyncController 
2023-01-09T04:42:17.752810260Z I0109 04:42:17.752805       1 base_controller.go:73] Caches are synced for CertRotationController 
2023-01-09T04:42:17.752822772Z I0109 04:42:17.752815       1 base_controller.go:110] Starting #1 worker of CertRotationController controller ...
2023-01-09T04:42:17.752833360Z I0109 04:42:17.752808       1 base_controller.go:110] Starting #1 worker of ResourceSyncController controller ...
2023-01-09T04:42:17.753422772Z I0109 04:42:17.753396       1 base_controller.go:73] Caches are synced for TargetConfigController 
2023-01-09T04:42:17.753443477Z I0109 04:42:17.753419       1 base_controller.go:110] Starting #1 worker of TargetConfigController controller ...
2023-01-09T04:42:17.753582938Z I0109 04:42:17.753560       1 base_controller.go:73] Caches are synced for KubeAPIServerStaticResources 
2023-01-09T04:42:17.753625770Z I0109 04:42:17.753601       1 base_controller.go:110] Starting #1 worker of KubeAPIServerStaticResources controller ...
2023-01-09T04:42:17.753706180Z E0109 04:42:17.753688       1 base_controller.go:272] TargetConfigController reconciliation failed: no observedConfig
2023-01-09T04:42:17.753845476Z I0109 04:42:17.753818       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ConfigMissing' no observedConfig
2023-01-09T04:42:17.753902853Z I0109 04:42:17.753872       1 base_controller.go:73] Caches are synced for CertRotationController 
2023-01-09T04:42:17.753902853Z I0109 04:42:17.753892       1 base_controller.go:110] Starting #1 worker of CertRotationController controller ...
2023-01-09T04:42:17.753920922Z I0109 04:42:17.753912       1 base_controller.go:73] Caches are synced for CertRotationController 
2023-01-09T04:42:17.753931239Z I0109 04:42:17.753921       1 base_controller.go:110] Starting #1 worker of CertRotationController controller ...
2023-01-09T04:42:17.753941285Z I0109 04:42:17.753929       1 base_controller.go:73] Caches are synced for CertRotationController 
2023-01-09T04:42:17.753950773Z I0109 04:42:17.753939       1 base_controller.go:110] Starting #1 worker of CertRotationController controller ...
2023-01-09T04:42:17.754069284Z I0109 04:42:17.754051       1 base_controller.go:73] Caches are synced for CertRotationController 
2023-01-09T04:42:17.754069284Z I0109 04:42:17.754065       1 base_controller.go:110] Starting #1 worker of CertRotationController controller ...
2023-01-09T04:42:17.754089527Z I0109 04:42:17.754083       1 base_controller.go:73] Caches are synced for CertRotationController 
2023-01-09T04:42:17.754099884Z I0109 04:42:17.754089       1 base_controller.go:110] Starting #1 worker of CertRotationController controller ...
2023-01-09T04:42:17.754109836Z I0109 04:42:17.754092       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ObserveTLSSecurityProfile' minTLSVersion changed to VersionTLS12
2023-01-09T04:42:17.754129581Z I0109 04:42:17.754107       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ObserveTLSSecurityProfile' cipherSuites changed to ["TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256" "TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256" "TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384" "TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384" "TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256" "TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256"]
2023-01-09T04:42:17.754129581Z I0109 04:42:17.754118       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ObserveStorageFailed' configmaps openshift-etcd/etcd-endpoints: no etcd endpoint addresses found
2023-01-09T04:42:17.754143001Z I0109 04:42:17.754130       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ObserveStorageUpdated' Updated storage urls to https://localhost:2379
2023-01-09T04:42:17.754152961Z I0109 04:42:17.754140       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ObserveFeatureFlagsUpdated' Updated apiServerArguments.feature-gates to APIPriorityAndFairness=true,RotateKubeletServerCertificate=true,DownwardAPIHugePages=true,CSIMigrationAzureFile=false,CSIMigrationvSphere=false
2023-01-09T04:42:17.754185335Z I0109 04:42:17.754153       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ObservedConfigChanged' Writing updated observed config:   map[string]interface{}{
2023-01-09T04:42:17.754185335Z + 	"admission": map[string]interface{}{
2023-01-09T04:42:17.754185335Z + 		"pluginConfig": map[string]interface{}{
2023-01-09T04:42:17.754185335Z + 			"network.openshift.io/ExternalIPRanger":             map[string]interface{}{"configuration": map[string]interface{}{...}},
2023-01-09T04:42:17.754185335Z + 			"network.openshift.io/RestrictedEndpointsAdmission": map[string]interface{}{"configuration": map[string]interface{}{...}},
2023-01-09T04:42:17.754185335Z + 		},
2023-01-09T04:42:17.754185335Z + 	},
2023-01-09T04:42:17.754185335Z + 	"apiServerArguments": map[string]interface{}{
2023-01-09T04:42:17.754185335Z + 		"api-audiences":  []interface{}{string("https://kubernetes.default.svc")},
2023-01-09T04:42:17.754185335Z + 		"cloud-provider": []interface{}{string("aws")},
2023-01-09T04:42:17.754185335Z + 		"etcd-servers":   []interface{}{string("https://localhost:2379")},
2023-01-09T04:42:17.754185335Z + 		"feature-gates": []interface{}{
2023-01-09T04:42:17.754185335Z + 			string("APIPriorityAndFairness=true"),
2023-01-09T04:42:17.754185335Z + 			string("RotateKubeletServerCertificate=true"),
2023-01-09T04:42:17.754185335Z + 			string("DownwardAPIHugePages=true"), string("CSIMigrationAzureFile=false"),
2023-01-09T04:42:17.754185335Z + 			string("CSIMigrationvSphere=false"),
2023-01-09T04:42:17.754185335Z + 		},
2023-01-09T04:42:17.754185335Z + 		"service-account-issuer":   []interface{}{string("https://kubernetes.default.svc")},
2023-01-09T04:42:17.754185335Z + 		"service-account-jwks-uri": []interface{}{string("https://api-int.sn-loggvls-jsm.qe.devcluster.openshift.com:6443/"...)},
2023-01-09T04:42:17.754185335Z + 		"shutdown-delay-duration":  []interface{}{string("129s")},
2023-01-09T04:42:17.754185335Z + 	},
2023-01-09T04:42:17.754185335Z + 	"corsAllowedOrigins":          []interface{}{string(`//127\.0\.0\.1(:|$)`), string("//localhost(:|$)")},
2023-01-09T04:42:17.754185335Z + 	"gracefulTerminationDuration": string("194"),
2023-01-09T04:42:17.754185335Z + 	"servicesSubnet":              string("172.30.0.0/16"),
2023-01-09T04:42:17.754185335Z + 	"servingInfo": map[string]interface{}{
2023-01-09T04:42:17.754185335Z + 		"bindAddress": string("0.0.0.0:6443"),
2023-01-09T04:42:17.754185335Z + 		"bindNetwork": string("tcp4"),
2023-01-09T04:42:17.754185335Z + 		"cipherSuites": []interface{}{
2023-01-09T04:42:17.754185335Z + 			string("TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256"),
2023-01-09T04:42:17.754185335Z + 			string("TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256"),
2023-01-09T04:42:17.754185335Z + 			string("TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384"),
2023-01-09T04:42:17.754185335Z + 			string("TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384"),
2023-01-09T04:42:17.754185335Z + 			string("TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256"),
2023-01-09T04:42:17.754185335Z + 			string("TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256"),
2023-01-09T04:42:17.754185335Z + 		},
2023-01-09T04:42:17.754185335Z + 		"minTLSVersion": string("VersionTLS12"),
2023-01-09T04:42:17.754185335Z + 		"namedCertificates": []interface{}{
2023-01-09T04:42:17.754185335Z + 			map[string]interface{}{
2023-01-09T04:42:17.754185335Z + 				"certFile": string("/etc/kubernetes/static-pod-certs"...),
2023-01-09T04:42:17.754185335Z + 				"keyFile":  string("/etc/kubernetes/static-pod-certs"...),
2023-01-09T04:42:17.754185335Z + 			},
2023-01-09T04:42:17.754185335Z + 			map[string]interface{}{
2023-01-09T04:42:17.754185335Z + 				"certFile": string("/etc/kubernetes/static-pod-certs"...),
2023-01-09T04:42:17.754185335Z + 				"keyFile":  string("/etc/kubernetes/static-pod-certs"...),
2023-01-09T04:42:17.754185335Z + 			},
2023-01-09T04:42:17.754185335Z + 			map[string]interface{}{
2023-01-09T04:42:17.754185335Z + 				"certFile": string("/etc/kubernetes/static-pod-certs"...),
2023-01-09T04:42:17.754185335Z + 				"keyFile":  string("/etc/kubernetes/static-pod-certs"...),
2023-01-09T04:42:17.754185335Z + 			},
2023-01-09T04:42:17.754185335Z + 			map[string]interface{}{
2023-01-09T04:42:17.754185335Z + 				"certFile": string("/etc/kubernetes/static-pod-certs"...),
2023-01-09T04:42:17.754185335Z + 				"keyFile":  string("/etc/kubernetes/static-pod-certs"...),
2023-01-09T04:42:17.754185335Z + 			},
2023-01-09T04:42:17.754185335Z + 			map[string]interface{}{
2023-01-09T04:42:17.754185335Z + 				"certFile": string("/etc/kubernetes/static-pod-resou"...),
2023-01-09T04:42:17.754185335Z + 				"keyFile":  string("/etc/kubernetes/static-pod-resou"...),
2023-01-09T04:42:17.754185335Z + 			},
2023-01-09T04:42:17.754185335Z + 		},
2023-01-09T04:42:17.754185335Z + 	},
2023-01-09T04:42:17.754185335Z   }
2023-01-09T04:42:17.759457312Z E0109 04:42:17.759436       1 base_controller.go:272] TargetConfigController reconciliation failed: no observedConfig
2023-01-09T04:42:17.759496152Z I0109 04:42:17.759469       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ConfigMissing' no observedConfig
2023-01-09T04:42:17.762210573Z E0109 04:42:17.762178       1 base_controller.go:272] TargetConfigController reconciliation failed: no observedConfig
2023-01-09T04:42:17.762525208Z I0109 04:42:17.762486       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ConfigMissing' no observedConfig
2023-01-09T04:42:17.762525208Z I0109 04:42:17.762203       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:42:17.763055529Z I0109 04:42:17.763021       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: client-ca, secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0
2023-01-09T04:42:17.770475472Z E0109 04:42:17.770455       1 base_controller.go:272] TargetConfigController reconciliation failed: no observedConfig
2023-01-09T04:42:17.770505462Z I0109 04:42:17.770487       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ConfigMissing' no observedConfig
2023-01-09T04:42:17.810898981Z E0109 04:42:17.810847       1 base_controller.go:272] TargetConfigController reconciliation failed: no observedConfig
2023-01-09T04:42:17.810938455Z I0109 04:42:17.810891       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ConfigMissing' no observedConfig
2023-01-09T04:42:17.891238231Z E0109 04:42:17.891196       1 base_controller.go:272] TargetConfigController reconciliation failed: no observedConfig
2023-01-09T04:42:17.891279305Z I0109 04:42:17.891233       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ConfigMissing' no observedConfig
2023-01-09T04:42:17.951850004Z I0109 04:42:17.951789       1 base_controller.go:73] Caches are synced for EventWatchController 
2023-01-09T04:42:17.951850004Z I0109 04:42:17.951817       1 base_controller.go:110] Starting #1 worker of EventWatchController controller ...
2023-01-09T04:42:18.051507776Z E0109 04:42:18.051465       1 base_controller.go:272] TargetConfigController reconciliation failed: no observedConfig
2023-01-09T04:42:18.051554914Z I0109 04:42:18.051504       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ConfigMissing' no observedConfig
2023-01-09T04:42:18.214057203Z E0109 04:42:18.214019       1 degraded_webhook.go:56] volumesnapshotclasses.snapshot.storage.k8s.io: dial tcp 172.30.195.54:443: connect: connection refused
2023-01-09T04:42:18.223237791Z E0109 04:42:18.223190       1 degraded_webhook.go:128] dial tcp 172.30.240.111:8443: connect: connection refused
2023-01-09T04:42:18.340422045Z I0109 04:42:18.340372       1 request.go:601] Waited for 2.386995577s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:42:18.372394950Z E0109 04:42:18.372338       1 base_controller.go:272] TargetConfigController reconciliation failed: no observedConfig
2023-01-09T04:42:18.372427880Z I0109 04:42:18.372382       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ConfigMissing' no observedConfig
2023-01-09T04:42:19.013116714Z E0109 04:42:19.013070       1 base_controller.go:272] TargetConfigController reconciliation failed: no observedConfig
2023-01-09T04:42:19.013155838Z I0109 04:42:19.013106       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ConfigMissing' no observedConfig
2023-01-09T04:42:19.225832398Z E0109 04:42:19.225785       1 degraded_webhook.go:128] dial tcp 172.30.240.111:8443: connect: connection refused
2023-01-09T04:42:19.353974858Z I0109 04:42:19.353917       1 request.go:601] Waited for 1.600047473s due to client-side throttling, not priority and fairness, request: PUT:https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status
2023-01-09T04:42:20.293879451Z E0109 04:42:20.293842       1 base_controller.go:272] TargetConfigController reconciliation failed: no observedConfig
2023-01-09T04:42:20.293925705Z I0109 04:42:20.293878       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ConfigMissing' no observedConfig
2023-01-09T04:42:20.354613484Z I0109 04:42:20.354575       1 request.go:601] Waited for 2.592277001s due to client-side throttling, not priority and fairness, request: PUT:https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status
2023-01-09T04:42:20.562195008Z E0109 04:42:20.562143       1 base_controller.go:272] InstallerController reconciliation failed: missing required resources: [configmaps: client-ca, secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]
2023-01-09T04:42:20.562704233Z E0109 04:42:20.562671       1 base_controller.go:272] TargetConfigController reconciliation failed: no observedConfig
2023-01-09T04:42:20.562757474Z I0109 04:42:20.562728       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:42:20.562799718Z I0109 04:42:20.562759       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ConfigMissing' no observedConfig
2023-01-09T04:42:20.563426727Z I0109 04:42:20.563371       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: client-ca, secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0
2023-01-09T04:42:20.563507403Z E0109 04:42:20.563485       1 base_controller.go:272] InstallerController reconciliation failed: missing required resources: [configmaps: client-ca, secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]
2023-01-09T04:42:20.563831269Z I0109 04:42:20.563812       1 status_controller.go:211] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"InstallerControllerDegraded: missing required resources: [configmaps: client-ca, secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]\nNodeKubeconfigControllerDegraded: \"secret/node-kubeconfigs\": secret \"node-system-admin-client\" not found\nNodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal]","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0","reason":"AsExpected","status":"False","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:42:20.571804919Z I0109 04:42:20.571436       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded message changed from "InstallerControllerDegraded: missing required resources: [configmaps: client-ca, secrets: aggregator-client,bound-service-account-signing-key,check-endpoints-client-cert-key,control-plane-node-admin-client-cert-key,external-loadbalancer-serving-certkey,internal-loadbalancer-serving-certkey,kubelet-client,localhost-serving-cert-certkey,node-kubeconfigs,service-network-serving-certkey, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]\nNodeKubeconfigControllerDegraded: \"secret/node-kubeconfigs\": secret \"node-system-admin-client\" not found\nNodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal]" to "InstallerControllerDegraded: missing required resources: [configmaps: client-ca, secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]\nNodeKubeconfigControllerDegraded: \"secret/node-kubeconfigs\": secret \"node-system-admin-client\" not found\nNodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal]"
2023-01-09T04:42:21.511884484Z I0109 04:42:21.511835       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: client-ca, secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0
2023-01-09T04:42:21.511977861Z E0109 04:42:21.511956       1 base_controller.go:272] InstallerController reconciliation failed: missing required resources: [configmaps: client-ca, secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]
2023-01-09T04:42:21.554013513Z I0109 04:42:21.553947       1 request.go:601] Waited for 3.011174656s due to client-side throttling, not priority and fairness, request: PUT:https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status
2023-01-09T04:42:22.753885105Z I0109 04:42:22.753850       1 request.go:601] Waited for 3.384525707s due to client-side throttling, not priority and fairness, request: PUT:https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status
2023-01-09T04:42:22.854397356Z E0109 04:42:22.854354       1 base_controller.go:272] TargetConfigController reconciliation failed: no observedConfig
2023-01-09T04:42:22.854436086Z I0109 04:42:22.854391       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ConfigMissing' no observedConfig
2023-01-09T04:42:23.754590820Z I0109 04:42:23.754550       1 request.go:601] Waited for 3.584318949s due to client-side throttling, not priority and fairness, request: PUT:https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status
2023-01-09T04:42:23.961705625Z I0109 04:42:23.961660       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:42:23.961818007Z E0109 04:42:23.961795       1 base_controller.go:272] TargetConfigController reconciliation failed: no observedConfig
2023-01-09T04:42:23.961868016Z I0109 04:42:23.961841       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ConfigMissing' no observedConfig
2023-01-09T04:42:23.962884842Z I0109 04:42:23.962859       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: client-ca, secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0
2023-01-09T04:42:23.963082087Z E0109 04:42:23.963059       1 base_controller.go:272] InstallerController reconciliation failed: missing required resources: [configmaps: client-ca, secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]
2023-01-09T04:42:24.159329882Z W0109 04:42:24.159278       1 base_controller.go:236] Updating status of "GuardController" failed: Operation cannot be fulfilled on kubeapiservers.operator.openshift.io "cluster": the object has been modified; please apply your changes to the latest version and try again
2023-01-09T04:42:24.159329882Z E0109 04:42:24.159314       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:42:24.161384082Z E0109 04:42:24.161361       1 guard_controller.go:268] Missing operand on node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:42:24.161403890Z E0109 04:42:24.161381       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:42:24.161403890Z E0109 04:42:24.161393       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:42:24.954271311Z I0109 04:42:24.954231       1 request.go:601] Waited for 3.38473622s due to client-side throttling, not priority and fairness, request: PUT:https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status
2023-01-09T04:42:26.154090932Z I0109 04:42:26.154048       1 request.go:601] Waited for 3.343554707s due to client-side throttling, not priority and fairness, request: PUT:https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status
2023-01-09T04:42:27.354173168Z I0109 04:42:27.354126       1 request.go:601] Waited for 3.192317203s due to client-side throttling, not priority and fairness, request: PUT:https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status
2023-01-09T04:42:27.361460900Z E0109 04:42:27.361364       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:42:27.361962518Z E0109 04:42:27.361924       1 base_controller.go:272] TargetConfigController reconciliation failed: no observedConfig
2023-01-09T04:42:27.362478999Z I0109 04:42:27.362442       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:42:27.364098191Z I0109 04:42:27.364033       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ConfigMissing' no observedConfig
2023-01-09T04:42:27.364098191Z E0109 04:42:27.364044       1 base_controller.go:272] InstallerController reconciliation failed: missing required resources: [configmaps: client-ca, secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]
2023-01-09T04:42:27.364098191Z I0109 04:42:27.364072       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: client-ca, secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0
2023-01-09T04:42:27.364585215Z E0109 04:42:27.364561       1 guard_controller.go:268] Missing operand on node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:42:27.364604919Z E0109 04:42:27.364588       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:42:27.364637092Z E0109 04:42:27.364604       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:42:27.364855545Z E0109 04:42:27.364837       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:42:27.365450029Z I0109 04:42:27.365419       1 status_controller.go:211] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"InstallerControllerDegraded: missing required resources: [configmaps: client-ca, secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]\nNodeKubeconfigControllerDegraded: \"secret/node-kubeconfigs\": secret \"node-system-admin-client\" not found\nNodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0","reason":"AsExpected","status":"False","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:42:27.372666194Z I0109 04:42:27.372632       1 status_controller.go:211] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"InstallerControllerDegraded: missing required resources: [configmaps: client-ca, secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]\nNodeKubeconfigControllerDegraded: \"secret/node-kubeconfigs\": secret \"node-system-admin-client\" not found\nNodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0","reason":"AsExpected","status":"False","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:42:27.372900409Z I0109 04:42:27.372861       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded message changed from "InstallerControllerDegraded: missing required resources: [configmaps: client-ca, secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]\nNodeKubeconfigControllerDegraded: \"secret/node-kubeconfigs\": secret \"node-system-admin-client\" not found\nNodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal]" to "InstallerControllerDegraded: missing required resources: [configmaps: client-ca, secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]\nNodeKubeconfigControllerDegraded: \"secret/node-kubeconfigs\": secret \"node-system-admin-client\" not found\nNodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]"
2023-01-09T04:42:27.377061832Z E0109 04:42:27.377039       1 base_controller.go:272] StatusSyncer_kube-apiserver reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io "kube-apiserver": the object has been modified; please apply your changes to the latest version and try again
2023-01-09T04:42:27.758534426Z E0109 04:42:27.758490       1 base_controller.go:272] EncryptionPruneController reconciliation failed: Operation cannot be fulfilled on kubeapiservers.operator.openshift.io "cluster": the object has been modified; please apply your changes to the latest version and try again
2023-01-09T04:42:28.158808594Z E0109 04:42:28.158768       1 base_controller.go:272] EncryptionKeyController reconciliation failed: Operation cannot be fulfilled on kubeapiservers.operator.openshift.io "cluster": the object has been modified; please apply your changes to the latest version and try again
2023-01-09T04:42:28.354378307Z I0109 04:42:28.354276       1 request.go:601] Waited for 2.94267228s due to client-side throttling, not priority and fairness, request: PUT:https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status
2023-01-09T04:42:28.362615123Z E0109 04:42:28.362575       1 guard_controller.go:268] Missing operand on node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:42:28.362615123Z E0109 04:42:28.362607       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:42:28.362652466Z E0109 04:42:28.362622       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:42:28.362908730Z E0109 04:42:28.362879       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:42:28.558454213Z W0109 04:42:28.558406       1 base_controller.go:236] Updating status of "NodeKubeconfigController" failed: Operation cannot be fulfilled on kubeapiservers.operator.openshift.io "cluster": the object has been modified; please apply your changes to the latest version and try again
2023-01-09T04:42:28.558454213Z E0109 04:42:28.558436       1 base_controller.go:272] NodeKubeconfigController reconciliation failed: "secret/node-kubeconfigs": configmap "kube-apiserver-server-ca" not found
2023-01-09T04:42:28.758448875Z E0109 04:42:28.758403       1 base_controller.go:272] EncryptionMigrationController reconciliation failed: Operation cannot be fulfilled on kubeapiservers.operator.openshift.io "cluster": the object has been modified; please apply your changes to the latest version and try again
2023-01-09T04:42:28.959600731Z E0109 04:42:28.959561       1 base_controller.go:272] EncryptionStateController reconciliation failed: Operation cannot be fulfilled on kubeapiservers.operator.openshift.io "cluster": the object has been modified; please apply your changes to the latest version and try again
2023-01-09T04:42:29.158570863Z E0109 04:42:29.158530       1 base_controller.go:272] CertRotationController reconciliation failed: Operation cannot be fulfilled on kubeapiservers.operator.openshift.io "cluster": the object has been modified; please apply your changes to the latest version and try again
2023-01-09T04:42:29.354845417Z I0109 04:42:29.354800       1 request.go:601] Waited for 2.941414459s due to client-side throttling, not priority and fairness, request: PUT:https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status
2023-01-09T04:42:29.359319006Z E0109 04:42:29.359285       1 base_controller.go:272] RevisionController reconciliation failed: Operation cannot be fulfilled on kubeapiservers.operator.openshift.io "cluster": the object has been modified; please apply your changes to the latest version and try again
2023-01-09T04:42:29.558465953Z I0109 04:42:29.558412       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ObservedConfigWriteError' Failed to write observed config: Operation cannot be fulfilled on kubeapiservers.operator.openshift.io "cluster": the object has been modified; please apply your changes to the latest version and try again
2023-01-09T04:42:29.571405541Z I0109 04:42:29.571369       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:42:29.924373690Z E0109 04:42:29.924333       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:42:29.924373690Z E0109 04:42:29.924357       1 guard_controller.go:268] Missing operand on node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:42:29.924412866Z E0109 04:42:29.924374       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:42:29.959272092Z E0109 04:42:29.959239       1 base_controller.go:272] CertRotationController reconciliation failed: Operation cannot be fulfilled on kubeapiservers.operator.openshift.io "cluster": the object has been modified; please apply your changes to the latest version and try again
2023-01-09T04:42:30.158351195Z E0109 04:42:30.158305       1 base_controller.go:272] CertRotationController reconciliation failed: Operation cannot be fulfilled on kubeapiservers.operator.openshift.io "cluster": the object has been modified; please apply your changes to the latest version and try again
2023-01-09T04:42:30.362349064Z E0109 04:42:30.362309       1 base_controller.go:272] TargetConfigController reconciliation failed: no observedConfig
2023-01-09T04:42:30.362539341Z I0109 04:42:30.362329       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:42:30.362634750Z I0109 04:42:30.362608       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ConfigMissing' no observedConfig
2023-01-09T04:42:30.363141029Z I0109 04:42:30.363107       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: client-ca, secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0
2023-01-09T04:42:30.363366672Z E0109 04:42:30.363336       1 base_controller.go:272] InstallerController reconciliation failed: missing required resources: [configmaps: client-ca, secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]
2023-01-09T04:42:30.554504065Z I0109 04:42:30.554466       1 request.go:601] Waited for 2.941043329s due to client-side throttling, not priority and fairness, request: PUT:https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status
2023-01-09T04:42:31.158839487Z E0109 04:42:31.158796       1 base_controller.go:272] auditPolicyController reconciliation failed: Operation cannot be fulfilled on kubeapiservers.operator.openshift.io "cluster": the object has been modified; please apply your changes to the latest version and try again
2023-01-09T04:42:31.558222152Z E0109 04:42:31.558186       1 base_controller.go:272] BackingResourceController reconciliation failed: Operation cannot be fulfilled on kubeapiservers.operator.openshift.io "cluster": the object has been modified; please apply your changes to the latest version and try again
2023-01-09T04:42:31.754797678Z I0109 04:42:31.754757       1 request.go:601] Waited for 2.995746664s due to client-side throttling, not priority and fairness, request: PUT:https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status
2023-01-09T04:42:32.954776629Z I0109 04:42:32.954739       1 request.go:601] Waited for 2.994869657s due to client-side throttling, not priority and fairness, request: PUT:https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status
2023-01-09T04:42:33.094814566Z E0109 04:42:33.094774       1 base_controller.go:272] TargetConfigController reconciliation failed: no observedConfig
2023-01-09T04:42:33.094873845Z I0109 04:42:33.094841       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ConfigMissing' no observedConfig
2023-01-09T04:42:33.158206714Z E0109 04:42:33.158170       1 base_controller.go:272] KubeAPIServerStaticResources reconciliation failed: Operation cannot be fulfilled on kubeapiservers.operator.openshift.io "cluster": the object has been modified; please apply your changes to the latest version and try again
2023-01-09T04:42:33.562576102Z E0109 04:42:33.562531       1 base_controller.go:272] TargetConfigController reconciliation failed: no observedConfig
2023-01-09T04:42:33.562945961Z I0109 04:42:33.562577       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:42:33.563025780Z I0109 04:42:33.562986       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ConfigMissing' no observedConfig
2023-01-09T04:42:33.563560276Z I0109 04:42:33.563523       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: client-ca, secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0
2023-01-09T04:42:33.563745225Z E0109 04:42:33.563725       1 base_controller.go:272] InstallerController reconciliation failed: missing required resources: [configmaps: client-ca, secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]
2023-01-09T04:42:33.759144948Z E0109 04:42:33.759100       1 base_controller.go:272] webhookSupportabilityController reconciliation failed: Operation cannot be fulfilled on kubeapiservers.operator.openshift.io "cluster": the object has been modified; please apply your changes to the latest version and try again
2023-01-09T04:42:33.788856684Z E0109 04:42:33.788814       1 degraded_webhook.go:128] dial tcp 172.30.195.54:443: connect: connection refused
2023-01-09T04:42:34.154157130Z I0109 04:42:34.154109       1 request.go:601] Waited for 2.992591389s due to client-side throttling, not priority and fairness, request: PUT:https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status
2023-01-09T04:42:34.791793959Z E0109 04:42:34.791752       1 degraded_webhook.go:128] dial tcp 172.30.195.54:443: connect: connection refused
2023-01-09T04:42:35.092330612Z I0109 04:42:35.092271       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:42:35.120583289Z I0109 04:42:35.120546       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:42:35.354534344Z I0109 04:42:35.354501       1 request.go:601] Waited for 2.984245051s due to client-side throttling, not priority and fairness, request: PUT:https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status
2023-01-09T04:42:36.554725787Z I0109 04:42:36.554690       1 request.go:601] Waited for 2.991816009s due to client-side throttling, not priority and fairness, request: PUT:https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status
2023-01-09T04:42:36.762811000Z E0109 04:42:36.762768       1 base_controller.go:272] TargetConfigController reconciliation failed: no observedConfig
2023-01-09T04:42:36.762985593Z I0109 04:42:36.762953       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:42:36.763236763Z I0109 04:42:36.763204       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ConfigMissing' no observedConfig
2023-01-09T04:42:36.763779477Z I0109 04:42:36.763736       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: client-ca, secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0
2023-01-09T04:42:36.763838640Z E0109 04:42:36.763815       1 base_controller.go:272] InstallerController reconciliation failed: missing required resources: [configmaps: client-ca, secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]
2023-01-09T04:42:36.795371454Z E0109 04:42:36.795336       1 degraded_webhook.go:56] volumesnapshotclasses.snapshot.storage.k8s.io: dial tcp 172.30.195.54:443: connect: connection refused
2023-01-09T04:42:36.825304293Z E0109 04:42:36.825269       1 degraded_webhook.go:128] dial tcp 172.30.240.111:8443: connect: connection refused
2023-01-09T04:42:37.368899156Z I0109 04:42:37.368861       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:42:37.406167338Z I0109 04:42:37.406131       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:42:37.422557306Z I0109 04:42:37.422524       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:42:37.540555943Z I0109 04:42:37.540516       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:42:37.754455458Z I0109 04:42:37.754413       1 request.go:601] Waited for 2.741568203s due to client-side throttling, not priority and fairness, request: PUT:https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status
2023-01-09T04:42:37.828028321Z E0109 04:42:37.827968       1 degraded_webhook.go:128] dial tcp 172.30.240.111:8443: connect: connection refused
2023-01-09T04:42:38.754715569Z I0109 04:42:38.754668       1 request.go:601] Waited for 2.740554393s due to client-side throttling, not priority and fairness, request: PUT:https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status
2023-01-09T04:42:39.563151948Z I0109 04:42:39.563107       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:42:39.563234551Z E0109 04:42:39.563175       1 base_controller.go:272] TargetConfigController reconciliation failed: no observedConfig
2023-01-09T04:42:39.563956408Z E0109 04:42:39.563916       1 base_controller.go:272] InstallerController reconciliation failed: missing required resources: [configmaps: client-ca, secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]
2023-01-09T04:42:39.564097054Z I0109 04:42:39.564057       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ConfigMissing' no observedConfig
2023-01-09T04:42:39.564203521Z I0109 04:42:39.564172       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: client-ca, secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0
2023-01-09T04:42:39.758603036Z W0109 04:42:39.758556       1 base_controller.go:236] Updating status of "NodeKubeconfigController" failed: Operation cannot be fulfilled on kubeapiservers.operator.openshift.io "cluster": the object has been modified; please apply your changes to the latest version and try again
2023-01-09T04:42:39.758603036Z E0109 04:42:39.758586       1 base_controller.go:272] NodeKubeconfigController reconciliation failed: "secret/node-kubeconfigs": configmap "kube-apiserver-server-ca" not found
2023-01-09T04:42:39.953880820Z I0109 04:42:39.953839       1 request.go:601] Waited for 2.54043228s due to client-side throttling, not priority and fairness, request: PUT:https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status
2023-01-09T04:42:40.159090017Z E0109 04:42:40.159040       1 base_controller.go:272] EncryptionMigrationController reconciliation failed: Operation cannot be fulfilled on kubeapiservers.operator.openshift.io "cluster": the object has been modified; please apply your changes to the latest version and try again
2023-01-09T04:42:40.359401847Z E0109 04:42:40.359362       1 base_controller.go:272] EncryptionStateController reconciliation failed: Operation cannot be fulfilled on kubeapiservers.operator.openshift.io "cluster": the object has been modified; please apply your changes to the latest version and try again
2023-01-09T04:42:40.559187062Z E0109 04:42:40.559142       1 base_controller.go:272] CertRotationController reconciliation failed: Operation cannot be fulfilled on kubeapiservers.operator.openshift.io "cluster": the object has been modified; please apply your changes to the latest version and try again
2023-01-09T04:42:40.758266350Z E0109 04:42:40.758224       1 base_controller.go:272] RevisionController reconciliation failed: Operation cannot be fulfilled on kubeapiservers.operator.openshift.io "cluster": the object has been modified; please apply your changes to the latest version and try again
2023-01-09T04:42:40.941739586Z E0109 04:42:40.941693       1 base_controller.go:272] TargetConfigController reconciliation failed: no observedConfig
2023-01-09T04:42:40.942387234Z I0109 04:42:40.942338       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ConfigMissing' no observedConfig
2023-01-09T04:42:40.959072850Z E0109 04:42:40.959037       1 base_controller.go:272] ConfigObserver reconciliation failed: Operation cannot be fulfilled on kubeapiservers.operator.openshift.io "cluster": the object has been modified; please apply your changes to the latest version and try again
2023-01-09T04:42:40.959338686Z I0109 04:42:40.959310       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ObserveStorageFailed' configmaps openshift-etcd/etcd-endpoints: no etcd endpoint addresses found
2023-01-09T04:42:40.959348868Z I0109 04:42:40.959334       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ObserveStorageUpdated' Updated storage urls to https://localhost:2379
2023-01-09T04:42:40.959882417Z I0109 04:42:40.959851       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ObserveWebhookTokenAuthenticator' authentication-token webhook configuration status changed from false to true
2023-01-09T04:42:40.966614136Z E0109 04:42:40.966544       1 base_controller.go:272] TargetConfigController reconciliation failed: no observedConfig
2023-01-09T04:42:40.966685947Z I0109 04:42:40.966642       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/webhook-authenticator -n openshift-kube-apiserver because it was missing
2023-01-09T04:42:40.966764561Z I0109 04:42:40.966727       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ConfigMissing' no observedConfig
2023-01-09T04:42:40.967077297Z I0109 04:42:40.967035       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ObserveTLSSecurityProfile' minTLSVersion changed to VersionTLS12
2023-01-09T04:42:40.967113910Z I0109 04:42:40.967070       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ObserveTLSSecurityProfile' cipherSuites changed to ["TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256" "TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256" "TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384" "TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384" "TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256" "TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256"]
2023-01-09T04:42:40.968408146Z I0109 04:42:40.968377       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ObserveFeatureFlagsUpdated' Updated apiServerArguments.feature-gates to APIPriorityAndFairness=true,RotateKubeletServerCertificate=true,DownwardAPIHugePages=true,CSIMigrationAzureFile=false,CSIMigrationvSphere=false
2023-01-09T04:42:40.969869149Z I0109 04:42:40.969843       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ObservedConfigChanged' Writing updated observed config:   map[string]interface{}{
2023-01-09T04:42:40.969869149Z + 	"admission": map[string]interface{}{
2023-01-09T04:42:40.969869149Z + 		"pluginConfig": map[string]interface{}{
2023-01-09T04:42:40.969869149Z + 			"network.openshift.io/ExternalIPRanger":             map[string]interface{}{"configuration": map[string]interface{}{...}},
2023-01-09T04:42:40.969869149Z + 			"network.openshift.io/RestrictedEndpointsAdmission": map[string]interface{}{"configuration": map[string]interface{}{...}},
2023-01-09T04:42:40.969869149Z + 		},
2023-01-09T04:42:40.969869149Z + 	},
2023-01-09T04:42:40.969869149Z + 	"apiServerArguments": map[string]interface{}{
2023-01-09T04:42:40.969869149Z + 		"api-audiences":                            []interface{}{string("https://kubernetes.default.svc")},
2023-01-09T04:42:40.969869149Z + 		"authentication-token-webhook-config-file": []interface{}{string("/etc/kubernetes/static-pod-resources/secrets/webhook-authenticat"...)},
2023-01-09T04:42:40.969869149Z + 		"authentication-token-webhook-version":     []interface{}{string("v1")},
2023-01-09T04:42:40.969869149Z + 		"cloud-provider":                           []interface{}{string("aws")},
2023-01-09T04:42:40.969869149Z + 		"etcd-servers":                             []interface{}{string("https://localhost:2379")},
2023-01-09T04:42:40.969869149Z + 		"feature-gates": []interface{}{
2023-01-09T04:42:40.969869149Z + 			string("APIPriorityAndFairness=true"),
2023-01-09T04:42:40.969869149Z + 			string("RotateKubeletServerCertificate=true"),
2023-01-09T04:42:40.969869149Z + 			string("DownwardAPIHugePages=true"), string("CSIMigrationAzureFile=false"),
2023-01-09T04:42:40.969869149Z + 			string("CSIMigrationvSphere=false"),
2023-01-09T04:42:40.969869149Z + 		},
2023-01-09T04:42:40.969869149Z + 		"service-account-issuer":   []interface{}{string("https://kubernetes.default.svc")},
2023-01-09T04:42:40.969869149Z + 		"service-account-jwks-uri": []interface{}{string("https://api-int.sn-loggvls-jsm.qe.devcluster.openshift.com:6443/"...)},
2023-01-09T04:42:40.969869149Z + 		"shutdown-delay-duration":  []interface{}{string("129s")},
2023-01-09T04:42:40.969869149Z + 	},
2023-01-09T04:42:40.969869149Z + 	"corsAllowedOrigins":          []interface{}{string(`//127\.0\.0\.1(:|$)`), string("//localhost(:|$)")},
2023-01-09T04:42:40.969869149Z + 	"gracefulTerminationDuration": string("194"),
2023-01-09T04:42:40.969869149Z + 	"servicesSubnet":              string("172.30.0.0/16"),
2023-01-09T04:42:40.969869149Z + 	"servingInfo": map[string]interface{}{
2023-01-09T04:42:40.969869149Z + 		"bindAddress": string("0.0.0.0:6443"),
2023-01-09T04:42:40.969869149Z + 		"bindNetwork": string("tcp4"),
2023-01-09T04:42:40.969869149Z + 		"cipherSuites": []interface{}{
2023-01-09T04:42:40.969869149Z + 			string("TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256"),
2023-01-09T04:42:40.969869149Z + 			string("TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256"),
2023-01-09T04:42:40.969869149Z + 			string("TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384"),
2023-01-09T04:42:40.969869149Z + 			string("TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384"),
2023-01-09T04:42:40.969869149Z + 			string("TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256"),
2023-01-09T04:42:40.969869149Z + 			string("TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256"),
2023-01-09T04:42:40.969869149Z + 		},
2023-01-09T04:42:40.969869149Z + 		"minTLSVersion": string("VersionTLS12"),
2023-01-09T04:42:40.969869149Z + 		"namedCertificates": []interface{}{
2023-01-09T04:42:40.969869149Z + 			map[string]interface{}{
2023-01-09T04:42:40.969869149Z + 				"certFile": string("/etc/kubernetes/static-pod-certs"...),
2023-01-09T04:42:40.969869149Z + 				"keyFile":  string("/etc/kubernetes/static-pod-certs"...),
2023-01-09T04:42:40.969869149Z + 			},
2023-01-09T04:42:40.969869149Z + 			map[string]interface{}{
2023-01-09T04:42:40.969869149Z + 				"certFile": string("/etc/kubernetes/static-pod-certs"...),
2023-01-09T04:42:40.969869149Z + 				"keyFile":  string("/etc/kubernetes/static-pod-certs"...),
2023-01-09T04:42:40.969869149Z + 			},
2023-01-09T04:42:40.969869149Z + 			map[string]interface{}{
2023-01-09T04:42:40.969869149Z + 				"certFile": string("/etc/kubernetes/static-pod-certs"...),
2023-01-09T04:42:40.969869149Z + 				"keyFile":  string("/etc/kubernetes/static-pod-certs"...),
2023-01-09T04:42:40.969869149Z + 			},
2023-01-09T04:42:40.969869149Z + 			map[string]interface{}{
2023-01-09T04:42:40.969869149Z + 				"certFile": string("/etc/kubernetes/static-pod-certs"...),
2023-01-09T04:42:40.969869149Z + 				"keyFile":  string("/etc/kubernetes/static-pod-certs"...),
2023-01-09T04:42:40.969869149Z + 			},
2023-01-09T04:42:40.969869149Z + 			map[string]interface{}{
2023-01-09T04:42:40.969869149Z + 				"certFile": string("/etc/kubernetes/static-pod-resou"...),
2023-01-09T04:42:40.969869149Z + 				"keyFile":  string("/etc/kubernetes/static-pod-resou"...),
2023-01-09T04:42:40.969869149Z + 			},
2023-01-09T04:42:40.969869149Z + 		},
2023-01-09T04:42:40.969869149Z + 	},
2023-01-09T04:42:40.969869149Z   }
2023-01-09T04:42:41.154086380Z I0109 04:42:41.154043       1 request.go:601] Waited for 2.340383794s due to client-side throttling, not priority and fairness, request: PUT:https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status
2023-01-09T04:42:41.158654854Z W0109 04:42:41.158621       1 base_controller.go:236] Updating status of "GuardController" failed: Operation cannot be fulfilled on kubeapiservers.operator.openshift.io "cluster": the object has been modified; please apply your changes to the latest version and try again
2023-01-09T04:42:41.158688922Z E0109 04:42:41.158653       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal]
2023-01-09T04:42:41.160755402Z E0109 04:42:41.160725       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:42:41.160755402Z E0109 04:42:41.160748       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:42:41.160781839Z E0109 04:42:41.160762       1 guard_controller.go:268] Missing operand on node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:42:41.358893464Z E0109 04:42:41.358854       1 base_controller.go:272] CertRotationController reconciliation failed: Operation cannot be fulfilled on kubeapiservers.operator.openshift.io "cluster": the object has been modified; please apply your changes to the latest version and try again
2023-01-09T04:42:41.758221697Z E0109 04:42:41.758181       1 base_controller.go:272] CertRotationController reconciliation failed: Operation cannot be fulfilled on kubeapiservers.operator.openshift.io "cluster": the object has been modified; please apply your changes to the latest version and try again
2023-01-09T04:42:41.962411753Z E0109 04:42:41.962367       1 base_controller.go:272] NodeKubeconfigController reconciliation failed: "secret/node-kubeconfigs": configmap "kube-apiserver-server-ca" not found
2023-01-09T04:42:41.962740957Z I0109 04:42:41.962705       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:42:41.962788873Z E0109 04:42:41.962713       1 base_controller.go:272] TargetConfigController reconciliation failed: no observedConfig
2023-01-09T04:42:41.963086839Z I0109 04:42:41.963048       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ConfigMissing' no observedConfig
2023-01-09T04:42:41.963135280Z E0109 04:42:41.963071       1 base_controller.go:272] NodeKubeconfigController reconciliation failed: "secret/node-kubeconfigs": configmap "kube-apiserver-server-ca" not found
2023-01-09T04:42:41.963882968Z I0109 04:42:41.963850       1 status_controller.go:211] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"InstallerControllerDegraded: missing required resources: [configmaps: client-ca, secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]\nNodeKubeconfigControllerDegraded: \"secret/node-kubeconfigs\": configmap \"kube-apiserver-server-ca\" not found\nNodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0","reason":"AsExpected","status":"False","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:42:41.964164459Z I0109 04:42:41.964122       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: client-ca, secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0
2023-01-09T04:42:41.964380182Z E0109 04:42:41.964350       1 base_controller.go:272] InstallerController reconciliation failed: missing required resources: [configmaps: client-ca, secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]
2023-01-09T04:42:41.965158857Z E0109 04:42:41.965133       1 base_controller.go:272] NodeKubeconfigController reconciliation failed: "secret/node-kubeconfigs": configmap "kube-apiserver-server-ca" not found
2023-01-09T04:42:41.971851662Z I0109 04:42:41.970922       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded message changed from "InstallerControllerDegraded: missing required resources: [configmaps: client-ca, secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]\nNodeKubeconfigControllerDegraded: \"secret/node-kubeconfigs\": secret \"node-system-admin-client\" not found\nNodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]" to "InstallerControllerDegraded: missing required resources: [configmaps: client-ca, secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]\nNodeKubeconfigControllerDegraded: \"secret/node-kubeconfigs\": configmap \"kube-apiserver-server-ca\" not found\nNodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]"
2023-01-09T04:42:41.983083133Z E0109 04:42:41.983055       1 base_controller.go:272] NodeKubeconfigController reconciliation failed: "secret/node-kubeconfigs": configmap "kube-apiserver-server-ca" not found
2023-01-09T04:42:42.144562379Z E0109 04:42:42.144519       1 base_controller.go:272] NodeKubeconfigController reconciliation failed: "secret/node-kubeconfigs": configmap "kube-apiserver-server-ca" not found
2023-01-09T04:42:42.154185616Z I0109 04:42:42.154164       1 request.go:601] Waited for 2.317768292s due to client-side throttling, not priority and fairness, request: PUT:https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status
2023-01-09T04:42:42.465767685Z E0109 04:42:42.465717       1 base_controller.go:272] NodeKubeconfigController reconciliation failed: "secret/node-kubeconfigs": configmap "kube-apiserver-server-ca" not found
2023-01-09T04:42:42.559027162Z E0109 04:42:42.558955       1 base_controller.go:272] BackingResourceController reconciliation failed: Operation cannot be fulfilled on kubeapiservers.operator.openshift.io "cluster": the object has been modified; please apply your changes to the latest version and try again
2023-01-09T04:42:43.107068385Z E0109 04:42:43.107024       1 base_controller.go:272] NodeKubeconfigController reconciliation failed: "secret/node-kubeconfigs": configmap "kube-apiserver-server-ca" not found
2023-01-09T04:42:43.154420397Z I0109 04:42:43.154382       1 request.go:601] Waited for 2.395491655s due to client-side throttling, not priority and fairness, request: PUT:https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status
2023-01-09T04:42:43.770400867Z E0109 04:42:43.770346       1 base_controller.go:272] TargetConfigController reconciliation failed: no observedConfig
2023-01-09T04:42:43.770744745Z I0109 04:42:43.770682       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ConfigMissing' no observedConfig
2023-01-09T04:42:44.158519898Z E0109 04:42:44.158483       1 base_controller.go:272] KubeAPIServerStaticResources reconciliation failed: Operation cannot be fulfilled on kubeapiservers.operator.openshift.io "cluster": the object has been modified; please apply your changes to the latest version and try again
2023-01-09T04:42:44.354311652Z I0109 04:42:44.354273       1 request.go:601] Waited for 2.183559279s due to client-side throttling, not priority and fairness, request: PUT:https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status
2023-01-09T04:42:44.362303659Z E0109 04:42:44.362266       1 base_controller.go:272] TargetConfigController reconciliation failed: no observedConfig
2023-01-09T04:42:44.362615213Z I0109 04:42:44.362585       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ConfigMissing' no observedConfig
2023-01-09T04:42:44.363455547Z E0109 04:42:44.363418       1 base_controller.go:272] NodeKubeconfigController reconciliation failed: "secret/node-kubeconfigs": configmap "kube-apiserver-server-ca" not found
2023-01-09T04:42:44.363538657Z E0109 04:42:44.363519       1 base_controller.go:272] InstallerController reconciliation failed: missing required resources: [configmaps: client-ca, secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]
2023-01-09T04:42:44.363667404Z I0109 04:42:44.363636       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:42:44.363804468Z I0109 04:42:44.363768       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: client-ca, secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0
2023-01-09T04:42:44.387717705Z E0109 04:42:44.387678       1 base_controller.go:272] NodeKubeconfigController reconciliation failed: "secret/node-kubeconfigs": configmap "kube-apiserver-server-ca" not found
2023-01-09T04:42:44.412983492Z E0109 04:42:44.412939       1 degraded_webhook.go:128] dial tcp 172.30.195.54:443: connect: connection refused
2023-01-09T04:42:44.571883703Z I0109 04:42:44.571822       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:42:45.354782951Z I0109 04:42:45.354742       1 request.go:601] Waited for 2.184225738s due to client-side throttling, not priority and fairness, request: PUT:https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status
2023-01-09T04:42:45.416727006Z E0109 04:42:45.416683       1 degraded_webhook.go:128] dial tcp 172.30.195.54:443: connect: connection refused
2023-01-09T04:42:46.554753307Z I0109 04:42:46.554709       1 request.go:601] Waited for 1.941760536s due to client-side throttling, not priority and fairness, request: PUT:https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status
2023-01-09T04:42:46.563648016Z E0109 04:42:46.563615       1 base_controller.go:272] TargetConfigController reconciliation failed: no observedConfig
2023-01-09T04:42:46.564037823Z I0109 04:42:46.563974       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ConfigMissing' no observedConfig
2023-01-09T04:42:46.564037823Z I0109 04:42:46.563985       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:42:46.565249907Z I0109 04:42:46.565202       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: client-ca, secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0
2023-01-09T04:42:46.565363317Z E0109 04:42:46.565346       1 base_controller.go:272] InstallerController reconciliation failed: missing required resources: [configmaps: client-ca, secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]
2023-01-09T04:42:46.565834763Z E0109 04:42:46.565817       1 base_controller.go:272] NodeKubeconfigController reconciliation failed: "secret/node-kubeconfigs": configmap "kube-apiserver-server-ca" not found
2023-01-09T04:42:47.419241126Z E0109 04:42:47.419203       1 degraded_webhook.go:56] volumesnapshotclasses.snapshot.storage.k8s.io: dial tcp 172.30.195.54:443: connect: connection refused
2023-01-09T04:42:47.421196842Z E0109 04:42:47.421165       1 degraded_webhook.go:128] dial tcp 172.30.240.111:8443: connect: connection refused
2023-01-09T04:42:47.753869886Z I0109 04:42:47.753833       1 request.go:601] Waited for 1.940238698s due to client-side throttling, not priority and fairness, request: PUT:https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status
2023-01-09T04:42:48.423324411Z E0109 04:42:48.423280       1 degraded_webhook.go:128] dial tcp 172.30.240.111:8443: connect: connection refused
2023-01-09T04:42:48.753928365Z I0109 04:42:48.753889       1 request.go:601] Waited for 1.944295741s due to client-side throttling, not priority and fairness, request: PUT:https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status
2023-01-09T04:42:48.762668943Z E0109 04:42:48.762634       1 base_controller.go:272] TargetConfigController reconciliation failed: no observedConfig
2023-01-09T04:42:48.762767413Z I0109 04:42:48.762743       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ConfigMissing' no observedConfig
2023-01-09T04:42:48.763522558Z E0109 04:42:48.763489       1 base_controller.go:272] NodeKubeconfigController reconciliation failed: "secret/node-kubeconfigs": configmap "kube-apiserver-server-ca" not found
2023-01-09T04:42:48.764211806Z I0109 04:42:48.764173       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: client-ca, secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0
2023-01-09T04:42:48.764255251Z E0109 04:42:48.764198       1 base_controller.go:272] InstallerController reconciliation failed: missing required resources: [configmaps: client-ca, secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]
2023-01-09T04:42:48.764296708Z I0109 04:42:48.764250       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:42:48.959052322Z E0109 04:42:48.959012       1 base_controller.go:272] EncryptionStateController reconciliation failed: Operation cannot be fulfilled on kubeapiservers.operator.openshift.io "cluster": the object has been modified; please apply your changes to the latest version and try again
2023-01-09T04:42:49.159012140Z E0109 04:42:49.158943       1 base_controller.go:272] CertRotationController reconciliation failed: Operation cannot be fulfilled on kubeapiservers.operator.openshift.io "cluster": the object has been modified; please apply your changes to the latest version and try again
2023-01-09T04:42:49.359000981Z E0109 04:42:49.358949       1 base_controller.go:272] RevisionController reconciliation failed: Operation cannot be fulfilled on kubeapiservers.operator.openshift.io "cluster": the object has been modified; please apply your changes to the latest version and try again
2023-01-09T04:42:49.509015781Z E0109 04:42:49.508971       1 base_controller.go:272] NodeKubeconfigController reconciliation failed: "secret/node-kubeconfigs": configmap "kube-apiserver-server-ca" not found
2023-01-09T04:42:49.559342077Z I0109 04:42:49.559293       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ObservedConfigWriteError' Failed to write observed config: Operation cannot be fulfilled on kubeapiservers.operator.openshift.io "cluster": the object has been modified; please apply your changes to the latest version and try again
2023-01-09T04:42:49.754697509Z I0109 04:42:49.754658       1 request.go:601] Waited for 1.741755279s due to client-side throttling, not priority and fairness, request: PUT:https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status
2023-01-09T04:42:49.759193525Z W0109 04:42:49.759145       1 base_controller.go:236] Updating status of "GuardController" failed: Operation cannot be fulfilled on kubeapiservers.operator.openshift.io "cluster": the object has been modified; please apply your changes to the latest version and try again
2023-01-09T04:42:49.759193525Z E0109 04:42:49.759176       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal]
2023-01-09T04:42:49.761294538Z E0109 04:42:49.761269       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:42:49.761294538Z E0109 04:42:49.761288       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:42:49.761315432Z E0109 04:42:49.761299       1 guard_controller.go:268] Missing operand on node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:42:49.962398561Z E0109 04:42:49.962358       1 base_controller.go:272] CertRotationController reconciliation failed: Operation cannot be fulfilled on kubeapiservers.operator.openshift.io "cluster": the object has been modified; please apply your changes to the latest version and try again
2023-01-09T04:42:50.358957534Z E0109 04:42:50.358917       1 base_controller.go:272] CertRotationController reconciliation failed: Operation cannot be fulfilled on kubeapiservers.operator.openshift.io "cluster": the object has been modified; please apply your changes to the latest version and try again
2023-01-09T04:42:50.563909563Z I0109 04:42:50.563867       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:42:50.564288076Z E0109 04:42:50.564266       1 base_controller.go:272] TargetConfigController reconciliation failed: no observedConfig
2023-01-09T04:42:50.564664152Z I0109 04:42:50.564629       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ConfigMissing' no observedConfig
2023-01-09T04:42:50.565087991Z E0109 04:42:50.565053       1 base_controller.go:272] NodeKubeconfigController reconciliation failed: "secret/node-kubeconfigs": configmap "kube-apiserver-server-ca" not found
2023-01-09T04:42:50.565431030Z E0109 04:42:50.565402       1 base_controller.go:272] InstallerController reconciliation failed: missing required resources: [configmaps: client-ca, secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]
2023-01-09T04:42:50.565613277Z I0109 04:42:50.565585       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: client-ca, secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0
2023-01-09T04:42:50.954470855Z I0109 04:42:50.954431       1 request.go:601] Waited for 1.594670794s due to client-side throttling, not priority and fairness, request: PUT:https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status
2023-01-09T04:42:51.958782569Z E0109 04:42:51.958742       1 base_controller.go:272] KubeAPIServerStaticResources reconciliation failed: Operation cannot be fulfilled on kubeapiservers.operator.openshift.io "cluster": the object has been modified; please apply your changes to the latest version and try again
2023-01-09T04:42:52.154755682Z I0109 04:42:52.154715       1 request.go:601] Waited for 1.590490931s due to client-side throttling, not priority and fairness, request: PUT:https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status
2023-01-09T04:42:52.364283982Z E0109 04:42:52.364237       1 base_controller.go:272] NodeKubeconfigController reconciliation failed: "secret/node-kubeconfigs": configmap "kube-apiserver-server-ca" not found
2023-01-09T04:42:52.364698374Z E0109 04:42:52.364591       1 base_controller.go:272] TargetConfigController reconciliation failed: no observedConfig
2023-01-09T04:42:52.364733003Z I0109 04:42:52.364701       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ConfigMissing' no observedConfig
2023-01-09T04:42:52.364928974Z I0109 04:42:52.364910       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:42:52.365137211Z I0109 04:42:52.365089       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: client-ca, secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0
2023-01-09T04:42:52.365343990Z E0109 04:42:52.365311       1 base_controller.go:272] InstallerController reconciliation failed: missing required resources: [configmaps: client-ca, secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]
2023-01-09T04:42:53.354153961Z I0109 04:42:53.354111       1 request.go:601] Waited for 1.583452394s due to client-side throttling, not priority and fairness, request: PUT:https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status
2023-01-09T04:42:53.963209166Z E0109 04:42:53.963167       1 base_controller.go:272] TargetConfigController reconciliation failed: no observedConfig
2023-01-09T04:42:53.963321231Z I0109 04:42:53.963295       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ConfigMissing' no observedConfig
2023-01-09T04:42:53.963820881Z I0109 04:42:53.963789       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:42:53.964120261Z I0109 04:42:53.964100       1 prune_controller.go:269] Nothing to prune
2023-01-09T04:42:53.964350052Z E0109 04:42:53.964315       1 base_controller.go:272] NodeKubeconfigController reconciliation failed: "secret/node-kubeconfigs": configmap "kube-apiserver-server-ca" not found
2023-01-09T04:42:53.965411743Z I0109 04:42:53.965379       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: client-ca, secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-1,config-1,etcd-serving-ca-1,kube-apiserver-audit-policies-1,kube-apiserver-cert-syncer-kubeconfig-1,kube-apiserver-pod-1,kubelet-serving-ca-1,sa-token-signing-certs-1, secrets: etcd-client-1,localhost-recovery-client-token-1,localhost-recovery-serving-certkey-1
2023-01-09T04:42:54.354307952Z I0109 04:42:54.354270       1 request.go:601] Waited for 1.342998782s due to client-side throttling, not priority and fairness, request: PUT:https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status
2023-01-09T04:42:55.170358785Z W0109 04:42:55.170314       1 staticpod.go:38] revision 1 is unexpectedly already the latest available revision. This is a possible race!
2023-01-09T04:42:55.170358785Z E0109 04:42:55.170349       1 base_controller.go:272] RevisionController reconciliation failed: conflicting latestAvailableRevision 1
2023-01-09T04:42:55.170634130Z I0109 04:42:55.170604       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionTriggered' new revision 2 triggered by "configmap \"kube-apiserver-pod\" not found"
2023-01-09T04:42:55.174813957Z I0109 04:42:55.174766       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/revision-status-2 -n openshift-kube-apiserver because it was missing
2023-01-09T04:42:55.175098293Z E0109 04:42:55.175078       1 base_controller.go:272] TargetConfigController reconciliation failed: no observedConfig
2023-01-09T04:42:55.175135032Z I0109 04:42:55.175116       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ConfigMissing' no observedConfig
2023-01-09T04:42:55.175747839Z E0109 04:42:55.175728       1 base_controller.go:272] TargetConfigController reconciliation failed: no observedConfig
2023-01-09T04:42:55.175757832Z I0109 04:42:55.175748       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ConfigMissing' no observedConfig
2023-01-09T04:42:55.176388175Z E0109 04:42:55.176366       1 base_controller.go:272] NodeKubeconfigController reconciliation failed: "secret/node-kubeconfigs": configmap "kube-apiserver-server-ca" not found
2023-01-09T04:42:55.216102454Z E0109 04:42:55.216064       1 degraded_webhook.go:128] dial tcp 172.30.195.54:443: connect: connection refused
2023-01-09T04:42:55.354454954Z I0109 04:42:55.354412       1 request.go:601] Waited for 1.388620379s due to client-side throttling, not priority and fairness, request: PUT:https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status
2023-01-09T04:42:55.362341146Z E0109 04:42:55.362301       1 base_controller.go:272] InstallerController reconciliation failed: missing required resources: [configmaps: client-ca, secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-1,config-1,etcd-serving-ca-1,kube-apiserver-audit-policies-1,kube-apiserver-cert-syncer-kubeconfig-1,kube-apiserver-pod-1,kubelet-serving-ca-1,sa-token-signing-certs-1, secrets: etcd-client-1,localhost-recovery-client-token-1,localhost-recovery-serving-certkey-1]
2023-01-09T04:42:55.363302103Z E0109 04:42:55.363269       1 base_controller.go:272] TargetConfigController reconciliation failed: no observedConfig
2023-01-09T04:42:55.363637745Z I0109 04:42:55.363306       1 prune_controller.go:269] Nothing to prune
2023-01-09T04:42:55.363691654Z I0109 04:42:55.363671       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ConfigMissing' no observedConfig
2023-01-09T04:42:55.364142558Z E0109 04:42:55.364115       1 base_controller.go:272] NodeKubeconfigController reconciliation failed: "secret/node-kubeconfigs": configmap "kube-apiserver-server-ca" not found
2023-01-09T04:42:55.364424387Z I0109 04:42:55.364410       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:42:55.365164361Z E0109 04:42:55.365136       1 base_controller.go:272] InstallerController reconciliation failed: missing required resources: [configmaps: client-ca, secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-1,config-1,etcd-serving-ca-1,kube-apiserver-audit-policies-1,kube-apiserver-cert-syncer-kubeconfig-1,kube-apiserver-pod-1,kubelet-serving-ca-1,sa-token-signing-certs-1, secrets: etcd-client-1,localhost-recovery-client-token-1,localhost-recovery-serving-certkey-1]
2023-01-09T04:42:55.365209924Z I0109 04:42:55.365176       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: client-ca, secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-1,config-1,etcd-serving-ca-1,kube-apiserver-audit-policies-1,kube-apiserver-cert-syncer-kubeconfig-1,kube-apiserver-pod-1,kubelet-serving-ca-1,sa-token-signing-certs-1, secrets: etcd-client-1,localhost-recovery-client-token-1,localhost-recovery-serving-certkey-1
2023-01-09T04:42:55.365483232Z I0109 04:42:55.365459       1 status_controller.go:211] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"InstallerControllerDegraded: missing required resources: [configmaps: client-ca, secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-1,config-1,etcd-serving-ca-1,kube-apiserver-audit-policies-1,kube-apiserver-cert-syncer-kubeconfig-1,kube-apiserver-pod-1,kubelet-serving-ca-1,sa-token-signing-certs-1, secrets: etcd-client-1,localhost-recovery-client-token-1,localhost-recovery-serving-certkey-1]\nNodeKubeconfigControllerDegraded: \"secret/node-kubeconfigs\": configmap \"kube-apiserver-server-ca\" not found\nNodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:42:55Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 1","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 1","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:42:55.373877659Z I0109 04:42:55.373841       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded message changed from "InstallerControllerDegraded: missing required resources: [configmaps: client-ca, secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]\nNodeKubeconfigControllerDegraded: \"secret/node-kubeconfigs\": configmap \"kube-apiserver-server-ca\" not found\nNodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]" to "InstallerControllerDegraded: missing required resources: [configmaps: client-ca, secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-1,config-1,etcd-serving-ca-1,kube-apiserver-audit-policies-1,kube-apiserver-cert-syncer-kubeconfig-1,kube-apiserver-pod-1,kubelet-serving-ca-1,sa-token-signing-certs-1, secrets: etcd-client-1,localhost-recovery-client-token-1,localhost-recovery-serving-certkey-1]\nNodeKubeconfigControllerDegraded: \"secret/node-kubeconfigs\": configmap \"kube-apiserver-server-ca\" not found\nNodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]",Progressing changed from False to True ("NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 1"),Available message changed from "StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0" to "StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 1"
2023-01-09T04:42:55.558512454Z E0109 04:42:55.558468       1 base_controller.go:272] ConfigObserver reconciliation failed: Operation cannot be fulfilled on kubeapiservers.operator.openshift.io "cluster": the object has been modified; please apply your changes to the latest version and try again
2023-01-09T04:42:55.558864472Z I0109 04:42:55.558819       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ObserveStorageFailed' configmaps openshift-etcd/etcd-endpoints: no etcd endpoint addresses found
2023-01-09T04:42:55.558864472Z I0109 04:42:55.558846       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ObserveStorageUpdated' Updated storage urls to https://localhost:2379
2023-01-09T04:42:55.558864472Z I0109 04:42:55.558857       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ObserveTLSSecurityProfile' minTLSVersion changed to VersionTLS12
2023-01-09T04:42:55.558891794Z I0109 04:42:55.558864       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ObserveTLSSecurityProfile' cipherSuites changed to ["TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256" "TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256" "TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384" "TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384" "TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256" "TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256"]
2023-01-09T04:42:55.558902919Z I0109 04:42:55.558887       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ObserveFeatureFlagsUpdated' Updated apiServerArguments.feature-gates to APIPriorityAndFairness=true,RotateKubeletServerCertificate=true,DownwardAPIHugePages=true,CSIMigrationAzureFile=false,CSIMigrationvSphere=false
2023-01-09T04:42:55.560124028Z I0109 04:42:55.560094       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ObserveWebhookTokenAuthenticator' authentication-token webhook configuration status changed from false to true
2023-01-09T04:42:55.561708721Z I0109 04:42:55.561678       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ObservedConfigChanged' Writing updated observed config:   map[string]interface{}{
2023-01-09T04:42:55.561708721Z + 	"admission": map[string]interface{}{
2023-01-09T04:42:55.561708721Z + 		"pluginConfig": map[string]interface{}{
2023-01-09T04:42:55.561708721Z + 			"network.openshift.io/ExternalIPRanger":             map[string]interface{}{"configuration": map[string]interface{}{...}},
2023-01-09T04:42:55.561708721Z + 			"network.openshift.io/RestrictedEndpointsAdmission": map[string]interface{}{"configuration": map[string]interface{}{...}},
2023-01-09T04:42:55.561708721Z + 		},
2023-01-09T04:42:55.561708721Z + 	},
2023-01-09T04:42:55.561708721Z + 	"apiServerArguments": map[string]interface{}{
2023-01-09T04:42:55.561708721Z + 		"api-audiences":                            []interface{}{string("https://kubernetes.default.svc")},
2023-01-09T04:42:55.561708721Z + 		"authentication-token-webhook-config-file": []interface{}{string("/etc/kubernetes/static-pod-resources/secrets/webhook-authenticat"...)},
2023-01-09T04:42:55.561708721Z + 		"authentication-token-webhook-version":     []interface{}{string("v1")},
2023-01-09T04:42:55.561708721Z + 		"cloud-provider":                           []interface{}{string("aws")},
2023-01-09T04:42:55.561708721Z + 		"etcd-servers":                             []interface{}{string("https://localhost:2379")},
2023-01-09T04:42:55.561708721Z + 		"feature-gates": []interface{}{
2023-01-09T04:42:55.561708721Z + 			string("APIPriorityAndFairness=true"),
2023-01-09T04:42:55.561708721Z + 			string("RotateKubeletServerCertificate=true"),
2023-01-09T04:42:55.561708721Z + 			string("DownwardAPIHugePages=true"), string("CSIMigrationAzureFile=false"),
2023-01-09T04:42:55.561708721Z + 			string("CSIMigrationvSphere=false"),
2023-01-09T04:42:55.561708721Z + 		},
2023-01-09T04:42:55.561708721Z + 		"service-account-issuer":   []interface{}{string("https://kubernetes.default.svc")},
2023-01-09T04:42:55.561708721Z + 		"service-account-jwks-uri": []interface{}{string("https://api-int.sn-loggvls-jsm.qe.devcluster.openshift.com:6443/"...)},
2023-01-09T04:42:55.561708721Z + 		"shutdown-delay-duration":  []interface{}{string("129s")},
2023-01-09T04:42:55.561708721Z + 	},
2023-01-09T04:42:55.561708721Z + 	"corsAllowedOrigins":          []interface{}{string(`//127\.0\.0\.1(:|$)`), string("//localhost(:|$)")},
2023-01-09T04:42:55.561708721Z + 	"gracefulTerminationDuration": string("194"),
2023-01-09T04:42:55.561708721Z + 	"servicesSubnet":              string("172.30.0.0/16"),
2023-01-09T04:42:55.561708721Z + 	"servingInfo": map[string]interface{}{
2023-01-09T04:42:55.561708721Z + 		"bindAddress": string("0.0.0.0:6443"),
2023-01-09T04:42:55.561708721Z + 		"bindNetwork": string("tcp4"),
2023-01-09T04:42:55.561708721Z + 		"cipherSuites": []interface{}{
2023-01-09T04:42:55.561708721Z + 			string("TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256"),
2023-01-09T04:42:55.561708721Z + 			string("TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256"),
2023-01-09T04:42:55.561708721Z + 			string("TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384"),
2023-01-09T04:42:55.561708721Z + 			string("TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384"),
2023-01-09T04:42:55.561708721Z + 			string("TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256"),
2023-01-09T04:42:55.561708721Z + 			string("TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256"),
2023-01-09T04:42:55.561708721Z + 		},
2023-01-09T04:42:55.561708721Z + 		"minTLSVersion": string("VersionTLS12"),
2023-01-09T04:42:55.561708721Z + 		"namedCertificates": []interface{}{
2023-01-09T04:42:55.561708721Z + 			map[string]interface{}{
2023-01-09T04:42:55.561708721Z + 				"certFile": string("/etc/kubernetes/static-pod-certs"...),
2023-01-09T04:42:55.561708721Z + 				"keyFile":  string("/etc/kubernetes/static-pod-certs"...),
2023-01-09T04:42:55.561708721Z + 			},
2023-01-09T04:42:55.561708721Z + 			map[string]interface{}{
2023-01-09T04:42:55.561708721Z + 				"certFile": string("/etc/kubernetes/static-pod-certs"...),
2023-01-09T04:42:55.561708721Z + 				"keyFile":  string("/etc/kubernetes/static-pod-certs"...),
2023-01-09T04:42:55.561708721Z + 			},
2023-01-09T04:42:55.561708721Z + 			map[string]interface{}{
2023-01-09T04:42:55.561708721Z + 				"certFile": string("/etc/kubernetes/static-pod-certs"...),
2023-01-09T04:42:55.561708721Z + 				"keyFile":  string("/etc/kubernetes/static-pod-certs"...),
2023-01-09T04:42:55.561708721Z + 			},
2023-01-09T04:42:55.561708721Z + 			map[string]interface{}{
2023-01-09T04:42:55.561708721Z + 				"certFile": string("/etc/kubernetes/static-pod-certs"...),
2023-01-09T04:42:55.561708721Z + 				"keyFile":  string("/etc/kubernetes/static-pod-certs"...),
2023-01-09T04:42:55.561708721Z + 			},
2023-01-09T04:42:55.561708721Z + 			map[string]interface{}{
2023-01-09T04:42:55.561708721Z + 				"certFile": string("/etc/kubernetes/static-pod-resou"...),
2023-01-09T04:42:55.561708721Z + 				"keyFile":  string("/etc/kubernetes/static-pod-resou"...),
2023-01-09T04:42:55.561708721Z + 			},
2023-01-09T04:42:55.561708721Z + 		},
2023-01-09T04:42:55.561708721Z + 	},
2023-01-09T04:42:55.561708721Z   }
2023-01-09T04:42:55.759204031Z W0109 04:42:55.759159       1 base_controller.go:236] Updating status of "GuardController" failed: Operation cannot be fulfilled on kubeapiservers.operator.openshift.io "cluster": the object has been modified; please apply your changes to the latest version and try again
2023-01-09T04:42:55.759204031Z E0109 04:42:55.759193       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal]
2023-01-09T04:42:55.959145555Z E0109 04:42:55.959106       1 base_controller.go:272] CertRotationController reconciliation failed: Operation cannot be fulfilled on kubeapiservers.operator.openshift.io "cluster": the object has been modified; please apply your changes to the latest version and try again
2023-01-09T04:42:56.220042498Z E0109 04:42:56.219985       1 degraded_webhook.go:128] dial tcp 172.30.195.54:443: connect: connection refused
2023-01-09T04:42:56.358818815Z E0109 04:42:56.358777       1 base_controller.go:272] CertRotationController reconciliation failed: Operation cannot be fulfilled on kubeapiservers.operator.openshift.io "cluster": the object has been modified; please apply your changes to the latest version and try again
2023-01-09T04:42:56.554095387Z I0109 04:42:56.554058       1 request.go:601] Waited for 1.379281943s due to client-side throttling, not priority and fairness, request: PUT:https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status
2023-01-09T04:42:56.766184064Z I0109 04:42:56.766142       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:42:56.766986769Z I0109 04:42:56.766964       1 prune_controller.go:269] Nothing to prune
2023-01-09T04:42:56.767231159Z E0109 04:42:56.767196       1 base_controller.go:272] NodeKubeconfigController reconciliation failed: "secret/node-kubeconfigs": configmap "kube-apiserver-server-ca" not found
2023-01-09T04:42:56.768050799Z E0109 04:42:56.768021       1 base_controller.go:272] InstallerController reconciliation failed: missing required resources: [configmaps: client-ca, secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-1,config-1,etcd-serving-ca-1,kube-apiserver-audit-policies-1,kube-apiserver-cert-syncer-kubeconfig-1,kube-apiserver-pod-1,kubelet-serving-ca-1,sa-token-signing-certs-1, secrets: etcd-client-1,localhost-recovery-client-token-1,localhost-recovery-serving-certkey-1]
2023-01-09T04:42:56.768324592Z I0109 04:42:56.768298       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: client-ca, secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-1,config-1,etcd-serving-ca-1,kube-apiserver-audit-policies-1,kube-apiserver-cert-syncer-kubeconfig-1,kube-apiserver-pod-1,kubelet-serving-ca-1,sa-token-signing-certs-1, secrets: etcd-client-1,localhost-recovery-client-token-1,localhost-recovery-serving-certkey-1
2023-01-09T04:42:56.777072331Z I0109 04:42:56.777033       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/config -n openshift-kube-apiserver because it was missing
2023-01-09T04:42:56.777770833Z E0109 04:42:56.777741       1 base_controller.go:272] NodeKubeconfigController reconciliation failed: "secret/node-kubeconfigs": configmap "kube-apiserver-server-ca" not found
2023-01-09T04:42:56.786946114Z I0109 04:42:56.786912       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-apiserver-pod -n openshift-kube-apiserver because it was missing
2023-01-09T04:42:56.787874329Z E0109 04:42:56.787853       1 base_controller.go:272] NodeKubeconfigController reconciliation failed: "secret/node-kubeconfigs": configmap "kube-apiserver-server-ca" not found
2023-01-09T04:42:57.360155283Z E0109 04:42:57.360117       1 base_controller.go:272] KubeAPIServerStaticResources reconciliation failed: Operation cannot be fulfilled on kubeapiservers.operator.openshift.io "cluster": the object has been modified; please apply your changes to the latest version and try again
2023-01-09T04:42:57.375518711Z I0109 04:42:57.375462       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/client-ca -n openshift-kube-apiserver because it was missing
2023-01-09T04:42:57.376951161Z E0109 04:42:57.376912       1 base_controller.go:272] NodeKubeconfigController reconciliation failed: "secret/node-kubeconfigs": configmap "kube-apiserver-server-ca" not found
2023-01-09T04:42:57.964318651Z I0109 04:42:57.964277       1 prune_controller.go:269] Nothing to prune
2023-01-09T04:42:57.965408993Z E0109 04:42:57.965376       1 base_controller.go:272] NodeKubeconfigController reconciliation failed: "secret/node-kubeconfigs": configmap "kube-apiserver-server-ca" not found
2023-01-09T04:42:57.965705426Z I0109 04:42:57.965671       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:42:57.966205950Z I0109 04:42:57.966179       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-1,config-1,etcd-serving-ca-1,kube-apiserver-audit-policies-1,kube-apiserver-cert-syncer-kubeconfig-1,kube-apiserver-pod-1,kubelet-serving-ca-1,sa-token-signing-certs-1, secrets: etcd-client-1,localhost-recovery-client-token-1,localhost-recovery-serving-certkey-1
2023-01-09T04:42:57.977604442Z I0109 04:42:57.977568       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-apiserver-client-ca -n openshift-config-managed because it was missing
2023-01-09T04:42:58.223084422Z E0109 04:42:58.223042       1 degraded_webhook.go:56] volumesnapshotclasses.snapshot.storage.k8s.io: dial tcp 172.30.195.54:443: connect: connection refused
2023-01-09T04:42:58.257059278Z E0109 04:42:58.257021       1 degraded_webhook.go:128] dial tcp 172.30.240.111:8443: connect: connection refused
2023-01-09T04:42:58.575620362Z I0109 04:42:58.575562       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-apiserver-server-ca -n openshift-kube-apiserver because it was missing
2023-01-09T04:42:58.963125606Z E0109 04:42:58.963084       1 base_controller.go:272] InstallerController reconciliation failed: missing required resources: [secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-1,config-1,etcd-serving-ca-1,kube-apiserver-audit-policies-1,kube-apiserver-cert-syncer-kubeconfig-1,kube-apiserver-pod-1,kubelet-serving-ca-1,sa-token-signing-certs-1, secrets: etcd-client-1,localhost-recovery-client-token-1,localhost-recovery-serving-certkey-1]
2023-01-09T04:42:58.964446955Z I0109 04:42:58.964412       1 prune_controller.go:269] Nothing to prune
2023-01-09T04:42:58.964725237Z I0109 04:42:58.964692       1 status_controller.go:211] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"InstallerControllerDegraded: missing required resources: [secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-1,config-1,etcd-serving-ca-1,kube-apiserver-audit-policies-1,kube-apiserver-cert-syncer-kubeconfig-1,kube-apiserver-pod-1,kubelet-serving-ca-1,sa-token-signing-certs-1, secrets: etcd-client-1,localhost-recovery-client-token-1,localhost-recovery-serving-certkey-1]\nNodeKubeconfigControllerDegraded: \"secret/node-kubeconfigs\": configmap \"kube-apiserver-server-ca\" not found\nNodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:42:55Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 1","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 1","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:42:58.964808486Z I0109 04:42:58.964788       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:42:58.964844968Z E0109 04:42:58.964810       1 base_controller.go:272] InstallerController reconciliation failed: missing required resources: [secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-1,config-1,etcd-serving-ca-1,kube-apiserver-audit-policies-1,kube-apiserver-cert-syncer-kubeconfig-1,kube-apiserver-pod-1,kubelet-serving-ca-1,sa-token-signing-certs-1, secrets: etcd-client-1,localhost-recovery-client-token-1,localhost-recovery-serving-certkey-1]
2023-01-09T04:42:58.964901600Z I0109 04:42:58.964825       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-1,config-1,etcd-serving-ca-1,kube-apiserver-audit-policies-1,kube-apiserver-cert-syncer-kubeconfig-1,kube-apiserver-pod-1,kubelet-serving-ca-1,sa-token-signing-certs-1, secrets: etcd-client-1,localhost-recovery-client-token-1,localhost-recovery-serving-certkey-1
2023-01-09T04:42:58.970840830Z I0109 04:42:58.970819       1 request.go:601] Waited for 1.005029719s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:42:58.972157495Z I0109 04:42:58.972109       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded message changed from "InstallerControllerDegraded: missing required resources: [configmaps: client-ca, secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-1,config-1,etcd-serving-ca-1,kube-apiserver-audit-policies-1,kube-apiserver-cert-syncer-kubeconfig-1,kube-apiserver-pod-1,kubelet-serving-ca-1,sa-token-signing-certs-1, secrets: etcd-client-1,localhost-recovery-client-token-1,localhost-recovery-serving-certkey-1]\nNodeKubeconfigControllerDegraded: \"secret/node-kubeconfigs\": configmap \"kube-apiserver-server-ca\" not found\nNodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]" to "InstallerControllerDegraded: missing required resources: [secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-1,config-1,etcd-serving-ca-1,kube-apiserver-audit-policies-1,kube-apiserver-cert-syncer-kubeconfig-1,kube-apiserver-pod-1,kubelet-serving-ca-1,sa-token-signing-certs-1, secrets: etcd-client-1,localhost-recovery-client-token-1,localhost-recovery-serving-certkey-1]\nNodeKubeconfigControllerDegraded: \"secret/node-kubeconfigs\": configmap \"kube-apiserver-server-ca\" not found\nNodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]"
2023-01-09T04:42:59.176374129Z I0109 04:42:59.176309       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ConfigMapCreateFailed' Failed to create ConfigMap/kube-apiserver-client-ca -n openshift-config-managed: configmaps "kube-apiserver-client-ca" already exists
2023-01-09T04:42:59.259618607Z E0109 04:42:59.259577       1 degraded_webhook.go:128] dial tcp 172.30.240.111:8443: connect: connection refused
2023-01-09T04:42:59.559400075Z I0109 04:42:59.559341       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RevisionCreateFailed' Failed to create revision 2: configmaps "kube-apiserver-pod" not found
2023-01-09T04:42:59.571891286Z I0109 04:42:59.571853       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:42:59.765747981Z I0109 04:42:59.765700       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:42:59.766422914Z I0109 04:42:59.766387       1 prune_controller.go:269] Nothing to prune
2023-01-09T04:42:59.767072322Z I0109 04:42:59.767030       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-1,config-1,etcd-serving-ca-1,kube-apiserver-audit-policies-1,kube-apiserver-cert-syncer-kubeconfig-1,kube-apiserver-pod-1,kubelet-serving-ca-1,sa-token-signing-certs-1, secrets: etcd-client-1,localhost-recovery-client-token-1,localhost-recovery-serving-certkey-1
2023-01-09T04:42:59.767434672Z E0109 04:42:59.767410       1 base_controller.go:272] InstallerController reconciliation failed: missing required resources: [secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-1,config-1,etcd-serving-ca-1,kube-apiserver-audit-policies-1,kube-apiserver-cert-syncer-kubeconfig-1,kube-apiserver-pod-1,kubelet-serving-ca-1,sa-token-signing-certs-1, secrets: etcd-client-1,localhost-recovery-client-token-1,localhost-recovery-serving-certkey-1]
2023-01-09T04:42:59.971047367Z I0109 04:42:59.971006       1 request.go:601] Waited for 1.394828975s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T04:43:00.359395113Z E0109 04:43:00.359355       1 base_controller.go:272] ConfigObserver reconciliation failed: Operation cannot be fulfilled on kubeapiservers.operator.openshift.io "cluster": the object has been modified; please apply your changes to the latest version and try again
2023-01-09T04:43:00.579171322Z I0109 04:43:00.576900       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-apiserver-server-ca -n openshift-config-managed because it was missing
2023-01-09T04:43:00.764277234Z E0109 04:43:00.764232       1 base_controller.go:272] RevisionController reconciliation failed: Operation cannot be fulfilled on kubeapiservers.operator.openshift.io "cluster": the object has been modified; please apply your changes to the latest version and try again
2023-01-09T04:43:00.764809391Z I0109 04:43:00.764781       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionTriggered' new revision 2 triggered by "configmap \"kube-apiserver-pod-1\" not found"
2023-01-09T04:43:00.765355962Z I0109 04:43:00.765325       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:43:00.765414725Z I0109 04:43:00.765329       1 prune_controller.go:269] Nothing to prune
2023-01-09T04:43:00.766502972Z I0109 04:43:00.766472       1 status_controller.go:211] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"InstallerControllerDegraded: missing required resources: [secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-1,config-1,etcd-serving-ca-1,kube-apiserver-audit-policies-1,kube-apiserver-cert-syncer-kubeconfig-1,kube-apiserver-pod-1,kubelet-serving-ca-1,sa-token-signing-certs-1, secrets: etcd-client-1,localhost-recovery-client-token-1,localhost-recovery-serving-certkey-1]\nNodeKubeconfigControllerDegraded: \"secret/node-kubeconfigs\": configmap \"kube-apiserver-server-ca\" not found\nNodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]\nRevisionControllerDegraded: Operation cannot be fulfilled on kubeapiservers.operator.openshift.io \"cluster\": the object has been modified; please apply your changes to the latest version and try again","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:42:55Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 1","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 1","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:43:00.766845205Z E0109 04:43:00.766818       1 base_controller.go:272] InstallerController reconciliation failed: missing required resources: [secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-1,config-1,etcd-serving-ca-1,kube-apiserver-audit-policies-1,kube-apiserver-cert-syncer-kubeconfig-1,kube-apiserver-pod-1,kubelet-serving-ca-1,sa-token-signing-certs-1, secrets: etcd-client-1,localhost-recovery-client-token-1,localhost-recovery-serving-certkey-1]
2023-01-09T04:43:00.766898683Z I0109 04:43:00.766862       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-1,config-1,etcd-serving-ca-1,kube-apiserver-audit-policies-1,kube-apiserver-cert-syncer-kubeconfig-1,kube-apiserver-pod-1,kubelet-serving-ca-1,sa-token-signing-certs-1, secrets: etcd-client-1,localhost-recovery-client-token-1,localhost-recovery-serving-certkey-1
2023-01-09T04:43:00.774274956Z I0109 04:43:00.774242       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded message changed from "InstallerControllerDegraded: missing required resources: [secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-1,config-1,etcd-serving-ca-1,kube-apiserver-audit-policies-1,kube-apiserver-cert-syncer-kubeconfig-1,kube-apiserver-pod-1,kubelet-serving-ca-1,sa-token-signing-certs-1, secrets: etcd-client-1,localhost-recovery-client-token-1,localhost-recovery-serving-certkey-1]\nNodeKubeconfigControllerDegraded: \"secret/node-kubeconfigs\": configmap \"kube-apiserver-server-ca\" not found\nNodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]" to "InstallerControllerDegraded: missing required resources: [secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-1,config-1,etcd-serving-ca-1,kube-apiserver-audit-policies-1,kube-apiserver-cert-syncer-kubeconfig-1,kube-apiserver-pod-1,kubelet-serving-ca-1,sa-token-signing-certs-1, secrets: etcd-client-1,localhost-recovery-client-token-1,localhost-recovery-serving-certkey-1]\nNodeKubeconfigControllerDegraded: \"secret/node-kubeconfigs\": configmap \"kube-apiserver-server-ca\" not found\nNodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]\nRevisionControllerDegraded: Operation cannot be fulfilled on kubeapiservers.operator.openshift.io \"cluster\": the object has been modified; please apply your changes to the latest version and try again"
2023-01-09T04:43:00.971391202Z I0109 04:43:00.971347       1 request.go:601] Waited for 1.198740556s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps
2023-01-09T04:43:01.176257615Z I0109 04:43:01.176211       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/node-kubeconfigs -n openshift-kube-apiserver because it was missing
2023-01-09T04:43:01.289715110Z E0109 04:43:01.289674       1 degraded_webhook.go:128] dial tcp 172.30.195.54:443: connect: connection refused
2023-01-09T04:43:01.364457155Z I0109 04:43:01.364414       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:43:01.364652656Z I0109 04:43:01.364637       1 prune_controller.go:269] Nothing to prune
2023-01-09T04:43:01.370187262Z I0109 04:43:01.370142       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: bound-sa-token-signing-certs-1,config-1,etcd-serving-ca-1,kube-apiserver-audit-policies-1,kube-apiserver-cert-syncer-kubeconfig-1,kube-apiserver-pod-1,kubelet-serving-ca-1,sa-token-signing-certs-1, secrets: etcd-client-1,localhost-recovery-client-token-1,localhost-recovery-serving-certkey-1
2023-01-09T04:43:01.641616777Z E0109 04:43:01.641579       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:43:01.641616777Z E0109 04:43:01.641604       1 guard_controller.go:268] Missing operand on node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:43:01.641650395Z E0109 04:43:01.641614       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:43:01.774522389Z I0109 04:43:01.774456       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapUpdated' Updated ConfigMap/revision-status-2 -n openshift-kube-apiserver:
2023-01-09T04:43:01.774522389Z cause by changes in data.reason
2023-01-09T04:43:01.964050780Z E0109 04:43:01.963984       1 base_controller.go:272] InstallerController reconciliation failed: missing required resources: [configmaps: bound-sa-token-signing-certs-1,config-1,etcd-serving-ca-1,kube-apiserver-audit-policies-1,kube-apiserver-cert-syncer-kubeconfig-1,kube-apiserver-pod-1,kubelet-serving-ca-1,sa-token-signing-certs-1, secrets: etcd-client-1,localhost-recovery-client-token-1,localhost-recovery-serving-certkey-1]
2023-01-09T04:43:01.965495284Z I0109 04:43:01.965462       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:43:01.965543430Z I0109 04:43:01.965515       1 prune_controller.go:269] Nothing to prune
2023-01-09T04:43:01.971536130Z I0109 04:43:01.971480       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: bound-sa-token-signing-certs-1,config-1,etcd-serving-ca-1,kube-apiserver-audit-policies-1,kube-apiserver-cert-syncer-kubeconfig-1,kube-apiserver-pod-1,kubelet-serving-ca-1,sa-token-signing-certs-1, secrets: etcd-client-1,localhost-recovery-client-token-1,localhost-recovery-serving-certkey-1
2023-01-09T04:43:01.971934453Z E0109 04:43:01.971899       1 base_controller.go:272] InstallerController reconciliation failed: missing required resources: [configmaps: bound-sa-token-signing-certs-1,config-1,etcd-serving-ca-1,kube-apiserver-audit-policies-1,kube-apiserver-cert-syncer-kubeconfig-1,kube-apiserver-pod-1,kubelet-serving-ca-1,sa-token-signing-certs-1, secrets: etcd-client-1,localhost-recovery-client-token-1,localhost-recovery-serving-certkey-1]
2023-01-09T04:43:01.973234771Z I0109 04:43:01.973196       1 status_controller.go:211] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"InstallerControllerDegraded: missing required resources: [configmaps: bound-sa-token-signing-certs-1,config-1,etcd-serving-ca-1,kube-apiserver-audit-policies-1,kube-apiserver-cert-syncer-kubeconfig-1,kube-apiserver-pod-1,kubelet-serving-ca-1,sa-token-signing-certs-1, secrets: etcd-client-1,localhost-recovery-client-token-1,localhost-recovery-serving-certkey-1]\nNodeKubeconfigControllerDegraded: \"secret/node-kubeconfigs\": configmap \"kube-apiserver-server-ca\" not found\nNodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]\nRevisionControllerDegraded: Operation cannot be fulfilled on kubeapiservers.operator.openshift.io \"cluster\": the object has been modified; please apply your changes to the latest version and try again","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:42:55Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 1","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 1","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:43:01.980485241Z I0109 04:43:01.980434       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded message changed from "InstallerControllerDegraded: missing required resources: [secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-1,config-1,etcd-serving-ca-1,kube-apiserver-audit-policies-1,kube-apiserver-cert-syncer-kubeconfig-1,kube-apiserver-pod-1,kubelet-serving-ca-1,sa-token-signing-certs-1, secrets: etcd-client-1,localhost-recovery-client-token-1,localhost-recovery-serving-certkey-1]\nNodeKubeconfigControllerDegraded: \"secret/node-kubeconfigs\": configmap \"kube-apiserver-server-ca\" not found\nNodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]\nRevisionControllerDegraded: Operation cannot be fulfilled on kubeapiservers.operator.openshift.io \"cluster\": the object has been modified; please apply your changes to the latest version and try again" to "InstallerControllerDegraded: missing required resources: [configmaps: bound-sa-token-signing-certs-1,config-1,etcd-serving-ca-1,kube-apiserver-audit-policies-1,kube-apiserver-cert-syncer-kubeconfig-1,kube-apiserver-pod-1,kubelet-serving-ca-1,sa-token-signing-certs-1, secrets: etcd-client-1,localhost-recovery-client-token-1,localhost-recovery-serving-certkey-1]\nNodeKubeconfigControllerDegraded: \"secret/node-kubeconfigs\": configmap \"kube-apiserver-server-ca\" not found\nNodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]\nRevisionControllerDegraded: Operation cannot be fulfilled on kubeapiservers.operator.openshift.io \"cluster\": the object has been modified; please apply your changes to the latest version and try again"
2023-01-09T04:43:02.170957463Z I0109 04:43:02.170915       1 request.go:601] Waited for 1.195210762s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2023-01-09T04:43:02.292163067Z E0109 04:43:02.292119       1 degraded_webhook.go:128] dial tcp 172.30.195.54:443: connect: connection refused
2023-01-09T04:43:02.763644095Z E0109 04:43:02.763590       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal]
2023-01-09T04:43:02.765158239Z I0109 04:43:02.765122       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:43:02.765296414Z I0109 04:43:02.765263       1 prune_controller.go:269] Nothing to prune
2023-01-09T04:43:02.767107496Z I0109 04:43:02.767070       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: bound-sa-token-signing-certs-1,config-1,etcd-serving-ca-1,kube-apiserver-audit-policies-1,kube-apiserver-cert-syncer-kubeconfig-1,kube-apiserver-pod-1,kubelet-serving-ca-1,sa-token-signing-certs-1, secrets: etcd-client-1,localhost-recovery-client-token-1,localhost-recovery-serving-certkey-1
2023-01-09T04:43:02.767210966Z I0109 04:43:02.767175       1 status_controller.go:211] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"InstallerControllerDegraded: missing required resources: [configmaps: bound-sa-token-signing-certs-1,config-1,etcd-serving-ca-1,kube-apiserver-audit-policies-1,kube-apiserver-cert-syncer-kubeconfig-1,kube-apiserver-pod-1,kubelet-serving-ca-1,sa-token-signing-certs-1, secrets: etcd-client-1,localhost-recovery-client-token-1,localhost-recovery-serving-certkey-1]\nNodeKubeconfigControllerDegraded: \"secret/node-kubeconfigs\": configmap \"kube-apiserver-server-ca\" not found\nNodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal]\nRevisionControllerDegraded: Operation cannot be fulfilled on kubeapiservers.operator.openshift.io \"cluster\": the object has been modified; please apply your changes to the latest version and try again","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:42:55Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 1","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 1","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:43:02.767322666Z E0109 04:43:02.767304       1 base_controller.go:272] InstallerController reconciliation failed: missing required resources: [configmaps: bound-sa-token-signing-certs-1,config-1,etcd-serving-ca-1,kube-apiserver-audit-policies-1,kube-apiserver-cert-syncer-kubeconfig-1,kube-apiserver-pod-1,kubelet-serving-ca-1,sa-token-signing-certs-1, secrets: etcd-client-1,localhost-recovery-client-token-1,localhost-recovery-serving-certkey-1]
2023-01-09T04:43:02.774475505Z I0109 04:43:02.774440       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded message changed from "InstallerControllerDegraded: missing required resources: [configmaps: bound-sa-token-signing-certs-1,config-1,etcd-serving-ca-1,kube-apiserver-audit-policies-1,kube-apiserver-cert-syncer-kubeconfig-1,kube-apiserver-pod-1,kubelet-serving-ca-1,sa-token-signing-certs-1, secrets: etcd-client-1,localhost-recovery-client-token-1,localhost-recovery-serving-certkey-1]\nNodeKubeconfigControllerDegraded: \"secret/node-kubeconfigs\": configmap \"kube-apiserver-server-ca\" not found\nNodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]\nRevisionControllerDegraded: Operation cannot be fulfilled on kubeapiservers.operator.openshift.io \"cluster\": the object has been modified; please apply your changes to the latest version and try again" to "InstallerControllerDegraded: missing required resources: [configmaps: bound-sa-token-signing-certs-1,config-1,etcd-serving-ca-1,kube-apiserver-audit-policies-1,kube-apiserver-cert-syncer-kubeconfig-1,kube-apiserver-pod-1,kubelet-serving-ca-1,sa-token-signing-certs-1, secrets: etcd-client-1,localhost-recovery-client-token-1,localhost-recovery-serving-certkey-1]\nNodeKubeconfigControllerDegraded: \"secret/node-kubeconfigs\": configmap \"kube-apiserver-server-ca\" not found\nNodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal]\nRevisionControllerDegraded: Operation cannot be fulfilled on kubeapiservers.operator.openshift.io \"cluster\": the object has been modified; please apply your changes to the latest version and try again"
2023-01-09T04:43:02.959885779Z E0109 04:43:02.959846       1 base_controller.go:272] ResourceSyncController reconciliation failed: Operation cannot be fulfilled on kubeapiservers.operator.openshift.io "cluster": the object has been modified; please apply your changes to the latest version and try again
2023-01-09T04:43:02.962969191Z I0109 04:43:02.962898       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ObserveStorageFailed' configmaps openshift-etcd/etcd-endpoints: no etcd endpoint addresses found
2023-01-09T04:43:02.976191125Z I0109 04:43:02.976142       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-apiserver-pod-2 -n openshift-kube-apiserver because it was missing
2023-01-09T04:43:03.171214021Z I0109 04:43:03.171173       1 request.go:601] Waited for 1.196274276s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T04:43:03.363756394Z E0109 04:43:03.363720       1 base_controller.go:272] ConfigObserver reconciliation failed: configmaps openshift-etcd/etcd-endpoints: no etcd endpoint addresses found
2023-01-09T04:43:03.364415752Z I0109 04:43:03.364368       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ObserveStorageFailed' configmaps openshift-etcd/etcd-endpoints: no etcd endpoint addresses found
2023-01-09T04:43:03.365621787Z I0109 04:43:03.365575       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:43:03.366047488Z I0109 04:43:03.366030       1 prune_controller.go:269] Nothing to prune
2023-01-09T04:43:03.367330366Z I0109 04:43:03.367294       1 status_controller.go:211] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"InstallerControllerDegraded: missing required resources: [configmaps: bound-sa-token-signing-certs-1,config-1,etcd-serving-ca-1,kube-apiserver-audit-policies-1,kube-apiserver-cert-syncer-kubeconfig-1,kube-apiserver-pod-1,kubelet-serving-ca-1,sa-token-signing-certs-1, secrets: etcd-client-1,localhost-recovery-client-token-1,localhost-recovery-serving-certkey-1]\nNodeKubeconfigControllerDegraded: \"secret/node-kubeconfigs\": configmap \"kube-apiserver-server-ca\" not found\nNodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal]\nRevisionControllerDegraded: Operation cannot be fulfilled on kubeapiservers.operator.openshift.io \"cluster\": the object has been modified; please apply your changes to the latest version and try again\nConfigObservationDegraded: configmaps openshift-etcd/etcd-endpoints: no etcd endpoint addresses found","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:42:55Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 1","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 1","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:43:03.367601825Z I0109 04:43:03.367558       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: bound-sa-token-signing-certs-1,config-1,etcd-serving-ca-1,kube-apiserver-audit-policies-1,kube-apiserver-cert-syncer-kubeconfig-1,kube-apiserver-pod-1,kubelet-serving-ca-1,sa-token-signing-certs-1, secrets: etcd-client-1,localhost-recovery-client-token-1,localhost-recovery-serving-certkey-1
2023-01-09T04:43:03.369176151Z E0109 04:43:03.369147       1 base_controller.go:272] ConfigObserver reconciliation failed: configmaps openshift-etcd/etcd-endpoints: no etcd endpoint addresses found
2023-01-09T04:43:03.369589233Z E0109 04:43:03.369566       1 base_controller.go:272] InstallerController reconciliation failed: missing required resources: [configmaps: bound-sa-token-signing-certs-1,config-1,etcd-serving-ca-1,kube-apiserver-audit-policies-1,kube-apiserver-cert-syncer-kubeconfig-1,kube-apiserver-pod-1,kubelet-serving-ca-1,sa-token-signing-certs-1, secrets: etcd-client-1,localhost-recovery-client-token-1,localhost-recovery-serving-certkey-1]
2023-01-09T04:43:03.370462992Z I0109 04:43:03.370425       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ObserveStorageFailed' configmaps openshift-etcd/etcd-endpoints: no etcd endpoint addresses found
2023-01-09T04:43:03.372241703Z E0109 04:43:03.372213       1 base_controller.go:272] ConfigObserver reconciliation failed: configmaps openshift-etcd/etcd-endpoints: no etcd endpoint addresses found
2023-01-09T04:43:03.374001986Z I0109 04:43:03.373943       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded message changed from "InstallerControllerDegraded: missing required resources: [configmaps: bound-sa-token-signing-certs-1,config-1,etcd-serving-ca-1,kube-apiserver-audit-policies-1,kube-apiserver-cert-syncer-kubeconfig-1,kube-apiserver-pod-1,kubelet-serving-ca-1,sa-token-signing-certs-1, secrets: etcd-client-1,localhost-recovery-client-token-1,localhost-recovery-serving-certkey-1]\nNodeKubeconfigControllerDegraded: \"secret/node-kubeconfigs\": configmap \"kube-apiserver-server-ca\" not found\nNodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal]\nRevisionControllerDegraded: Operation cannot be fulfilled on kubeapiservers.operator.openshift.io \"cluster\": the object has been modified; please apply your changes to the latest version and try again" to "InstallerControllerDegraded: missing required resources: [configmaps: bound-sa-token-signing-certs-1,config-1,etcd-serving-ca-1,kube-apiserver-audit-policies-1,kube-apiserver-cert-syncer-kubeconfig-1,kube-apiserver-pod-1,kubelet-serving-ca-1,sa-token-signing-certs-1, secrets: etcd-client-1,localhost-recovery-client-token-1,localhost-recovery-serving-certkey-1]\nNodeKubeconfigControllerDegraded: \"secret/node-kubeconfigs\": configmap \"kube-apiserver-server-ca\" not found\nNodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal]\nRevisionControllerDegraded: Operation cannot be fulfilled on kubeapiservers.operator.openshift.io \"cluster\": the object has been modified; please apply your changes to the latest version and try again\nConfigObservationDegraded: configmaps openshift-etcd/etcd-endpoints: no etcd endpoint addresses found"
2023-01-09T04:43:03.404732098Z I0109 04:43:03.404678       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ObserveStorageFailed' configmaps openshift-etcd/etcd-endpoints: no etcd endpoint addresses found
2023-01-09T04:43:03.405438461Z E0109 04:43:03.405343       1 base_controller.go:272] ConfigObserver reconciliation failed: configmaps openshift-etcd/etcd-endpoints: no etcd endpoint addresses found
2023-01-09T04:43:03.564736686Z I0109 04:43:03.564693       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:43:03.565513237Z I0109 04:43:03.565476       1 prune_controller.go:269] Nothing to prune
2023-01-09T04:43:03.566212465Z E0109 04:43:03.566181       1 base_controller.go:272] ConfigObserver reconciliation failed: configmaps openshift-etcd/etcd-endpoints: no etcd endpoint addresses found
2023-01-09T04:43:03.566685175Z I0109 04:43:03.566648       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ObserveStorageFailed' configmaps openshift-etcd/etcd-endpoints: no etcd endpoint addresses found
2023-01-09T04:43:03.567563952Z I0109 04:43:03.567527       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: bound-sa-token-signing-certs-1,config-1,etcd-serving-ca-1,kube-apiserver-audit-policies-1,kube-apiserver-cert-syncer-kubeconfig-1,kube-apiserver-pod-1,kubelet-serving-ca-1,sa-token-signing-certs-1, secrets: etcd-client-1,localhost-recovery-client-token-1,localhost-recovery-serving-certkey-1
2023-01-09T04:43:03.567692127Z I0109 04:43:03.567631       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ObserveStorageFailed' configmaps openshift-etcd/etcd-endpoints: no etcd endpoint addresses found
2023-01-09T04:43:03.567718369Z E0109 04:43:03.567685       1 base_controller.go:272] InstallerController reconciliation failed: missing required resources: [configmaps: bound-sa-token-signing-certs-1,config-1,etcd-serving-ca-1,kube-apiserver-audit-policies-1,kube-apiserver-cert-syncer-kubeconfig-1,kube-apiserver-pod-1,kubelet-serving-ca-1,sa-token-signing-certs-1, secrets: etcd-client-1,localhost-recovery-client-token-1,localhost-recovery-serving-certkey-1]
2023-01-09T04:43:03.568119978Z E0109 04:43:03.568089       1 base_controller.go:272] ConfigObserver reconciliation failed: configmaps openshift-etcd/etcd-endpoints: no etcd endpoint addresses found
2023-01-09T04:43:03.727170100Z I0109 04:43:03.727100       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ObserveStorageFailed' configmaps openshift-etcd/etcd-endpoints: no etcd endpoint addresses found
2023-01-09T04:43:03.728736033Z E0109 04:43:03.728701       1 base_controller.go:272] ConfigObserver reconciliation failed: configmaps openshift-etcd/etcd-endpoints: no etcd endpoint addresses found
2023-01-09T04:43:03.759763467Z E0109 04:43:03.759719       1 base_controller.go:272] NodeKubeconfigController reconciliation failed: Operation cannot be fulfilled on kubeapiservers.operator.openshift.io "cluster": the object has been modified; please apply your changes to the latest version and try again
2023-01-09T04:43:04.176090395Z I0109 04:43:04.176032       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/config-2 -n openshift-kube-apiserver because it was missing
2023-01-09T04:43:04.176580346Z I0109 04:43:04.176543       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ObserveStorageFailed' configmaps openshift-etcd/etcd-endpoints: no etcd endpoint addresses found
2023-01-09T04:43:04.180710098Z E0109 04:43:04.180678       1 base_controller.go:272] ConfigObserver reconciliation failed: configmaps openshift-etcd/etcd-endpoints: no etcd endpoint addresses found
2023-01-09T04:43:04.295120812Z E0109 04:43:04.295081       1 degraded_webhook.go:56] volumesnapshotclasses.snapshot.storage.k8s.io: dial tcp 172.30.195.54:443: connect: connection refused
2023-01-09T04:43:04.331192610Z E0109 04:43:04.331153       1 degraded_webhook.go:128] dial tcp 172.30.240.111:8443: connect: connection refused
2023-01-09T04:43:04.371348768Z I0109 04:43:04.371307       1 request.go:601] Waited for 1.196981949s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T04:43:04.990124822Z I0109 04:43:04.990084       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:43:04.990526224Z I0109 04:43:04.990494       1 prune_controller.go:269] Nothing to prune
2023-01-09T04:43:04.990818965Z E0109 04:43:04.990793       1 base_controller.go:272] InstallerController reconciliation failed: missing required resources: [configmaps: bound-sa-token-signing-certs-1,config-1,etcd-serving-ca-1,kube-apiserver-audit-policies-1,kube-apiserver-cert-syncer-kubeconfig-1,kube-apiserver-pod-1,kubelet-serving-ca-1,sa-token-signing-certs-1, secrets: etcd-client-1,localhost-recovery-client-token-1,localhost-recovery-serving-certkey-1]
2023-01-09T04:43:04.991561168Z I0109 04:43:04.991532       1 status_controller.go:211] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:43:04Z","message":"ConfigObservationDegraded: configmaps openshift-etcd/etcd-endpoints: no etcd endpoint addresses found\nGuardControllerDegraded: [Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal]\nInstallerControllerDegraded: missing required resources: [configmaps: bound-sa-token-signing-certs-1,config-1,etcd-serving-ca-1,kube-apiserver-audit-policies-1,kube-apiserver-cert-syncer-kubeconfig-1,kube-apiserver-pod-1,kubelet-serving-ca-1,sa-token-signing-certs-1, secrets: etcd-client-1,localhost-recovery-client-token-1,localhost-recovery-serving-certkey-1]\nRevisionControllerDegraded: Operation cannot be fulfilled on kubeapiservers.operator.openshift.io \"cluster\": the object has been modified; please apply your changes to the latest version and try again","reason":"ConfigObservation_Error::GuardController_SyncError::InstallerController_Error::RevisionController_Error","status":"True","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:42:55Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 1","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 1","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:43:04.991816890Z I0109 04:43:04.991787       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: bound-sa-token-signing-certs-1,config-1,etcd-serving-ca-1,kube-apiserver-audit-policies-1,kube-apiserver-cert-syncer-kubeconfig-1,kube-apiserver-pod-1,kubelet-serving-ca-1,sa-token-signing-certs-1, secrets: etcd-client-1,localhost-recovery-client-token-1,localhost-recovery-serving-certkey-1
2023-01-09T04:43:04.994023926Z I0109 04:43:04.993973       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ObserveStorageFailed' configmaps openshift-etcd/etcd-endpoints: no etcd endpoint addresses found
2023-01-09T04:43:04.994367285Z E0109 04:43:04.994337       1 base_controller.go:272] ConfigObserver reconciliation failed: configmaps openshift-etcd/etcd-endpoints: no etcd endpoint addresses found
2023-01-09T04:43:04.997207991Z I0109 04:43:04.997170       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ObserveStorageFailed' configmaps openshift-etcd/etcd-endpoints: no etcd endpoint addresses found
2023-01-09T04:43:04.997456512Z E0109 04:43:04.997422       1 base_controller.go:272] ConfigObserver reconciliation failed: configmaps openshift-etcd/etcd-endpoints: no etcd endpoint addresses found
2023-01-09T04:43:04.998144959Z I0109 04:43:04.998113       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded changed from False to True ("ConfigObservationDegraded: configmaps openshift-etcd/etcd-endpoints: no etcd endpoint addresses found\nGuardControllerDegraded: [Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal]\nInstallerControllerDegraded: missing required resources: [configmaps: bound-sa-token-signing-certs-1,config-1,etcd-serving-ca-1,kube-apiserver-audit-policies-1,kube-apiserver-cert-syncer-kubeconfig-1,kube-apiserver-pod-1,kubelet-serving-ca-1,sa-token-signing-certs-1, secrets: etcd-client-1,localhost-recovery-client-token-1,localhost-recovery-serving-certkey-1]\nRevisionControllerDegraded: Operation cannot be fulfilled on kubeapiservers.operator.openshift.io \"cluster\": the object has been modified; please apply your changes to the latest version and try again")
2023-01-09T04:43:05.334433416Z E0109 04:43:05.334380       1 degraded_webhook.go:128] dial tcp 172.30.240.111:8443: connect: connection refused
2023-01-09T04:43:05.371577358Z I0109 04:43:05.371529       1 request.go:601] Waited for 1.398645341s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:43:05.411722554Z I0109 04:43:05.411668       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:43:05.429768973Z I0109 04:43:05.429731       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:43:05.575888293Z I0109 04:43:05.575839       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-apiserver-cert-syncer-kubeconfig-2 -n openshift-kube-apiserver because it was missing
2023-01-09T04:43:05.580969274Z I0109 04:43:05.580924       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ObserveStorageFailed' configmaps openshift-etcd/etcd-endpoints: no etcd endpoint addresses found
2023-01-09T04:43:05.589076743Z E0109 04:43:05.589037       1 base_controller.go:272] ConfigObserver reconciliation failed: configmaps openshift-etcd/etcd-endpoints: no etcd endpoint addresses found
2023-01-09T04:43:06.291650643Z I0109 04:43:06.291597       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ObserveStorageFailed' configmaps openshift-etcd/etcd-endpoints: no etcd endpoint addresses found
2023-01-09T04:43:06.293191008Z E0109 04:43:06.293146       1 base_controller.go:272] ConfigObserver reconciliation failed: configmaps openshift-etcd/etcd-endpoints: no etcd endpoint addresses found
2023-01-09T04:43:06.571442408Z I0109 04:43:06.571404       1 request.go:601] Waited for 1.395760376s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2023-01-09T04:43:06.724362147Z I0109 04:43:06.724318       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:43:06.742709394Z I0109 04:43:06.742663       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:43:06.958009503Z I0109 04:43:06.957946       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ObserveStorageFailed' configmaps openshift-etcd/etcd-endpoints: no etcd endpoint addresses found
2023-01-09T04:43:06.960259452Z E0109 04:43:06.960218       1 base_controller.go:272] ConfigObserver reconciliation failed: configmaps openshift-etcd/etcd-endpoints: no etcd endpoint addresses found
2023-01-09T04:43:06.976530600Z I0109 04:43:06.976493       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/bound-sa-token-signing-certs-2 -n openshift-kube-apiserver because it was missing
2023-01-09T04:43:06.980559395Z I0109 04:43:06.980518       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ObserveStorageFailed' configmaps openshift-etcd/etcd-endpoints: no etcd endpoint addresses found
2023-01-09T04:43:06.980774704Z E0109 04:43:06.980757       1 base_controller.go:272] ConfigObserver reconciliation failed: configmaps openshift-etcd/etcd-endpoints: no etcd endpoint addresses found
2023-01-09T04:43:07.028745941Z I0109 04:43:07.028705       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:43:07.253620549Z I0109 04:43:07.253576       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:43:07.389881161Z E0109 04:43:07.389839       1 degraded_webhook.go:128] dial tcp 172.30.195.54:443: connect: connection refused
2023-01-09T04:43:07.771157777Z I0109 04:43:07.771120       1 request.go:601] Waited for 1.391466603s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T04:43:08.178760459Z E0109 04:43:08.178698       1 base_controller.go:272] ConfigObserver reconciliation failed: configmaps openshift-etcd/etcd-endpoints: no etcd endpoint addresses found
2023-01-09T04:43:08.181580157Z I0109 04:43:08.181543       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ObserveStorageFailed' configmaps openshift-etcd/etcd-endpoints: no etcd endpoint addresses found
2023-01-09T04:43:08.181813078Z I0109 04:43:08.181793       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/etcd-serving-ca-2 -n openshift-kube-apiserver because it was missing
2023-01-09T04:43:08.392933035Z E0109 04:43:08.392893       1 degraded_webhook.go:128] dial tcp 172.30.195.54:443: connect: connection refused
2023-01-09T04:43:08.771278820Z I0109 04:43:08.771237       1 request.go:601] Waited for 1.177152562s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2023-01-09T04:43:09.375407527Z I0109 04:43:09.375350       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-apiserver-server-ca-2 -n openshift-kube-apiserver because it was missing
2023-01-09T04:43:09.377074559Z I0109 04:43:09.377039       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ObserveStorageFailed' configmaps openshift-etcd/etcd-endpoints: no etcd endpoint addresses found
2023-01-09T04:43:09.378770823Z E0109 04:43:09.378747       1 base_controller.go:272] ConfigObserver reconciliation failed: configmaps openshift-etcd/etcd-endpoints: no etcd endpoint addresses found
2023-01-09T04:43:09.771551846Z I0109 04:43:09.771506       1 request.go:601] Waited for 1.198309237s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/trusted-ca-bundle
2023-01-09T04:43:10.375448076Z I0109 04:43:10.375391       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kubelet-serving-ca-2 -n openshift-kube-apiserver because it was missing
2023-01-09T04:43:10.377072988Z I0109 04:43:10.377045       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ObserveStorageFailed' configmaps openshift-etcd/etcd-endpoints: no etcd endpoint addresses found
2023-01-09T04:43:10.379015733Z E0109 04:43:10.378974       1 base_controller.go:272] ConfigObserver reconciliation failed: configmaps openshift-etcd/etcd-endpoints: no etcd endpoint addresses found
2023-01-09T04:43:10.395978763Z E0109 04:43:10.395939       1 degraded_webhook.go:56] volumesnapshotclasses.snapshot.storage.k8s.io: dial tcp 172.30.195.54:443: connect: connection refused
2023-01-09T04:43:10.398259882Z E0109 04:43:10.398220       1 degraded_webhook.go:128] dial tcp 172.30.240.111:8443: connect: connection refused
2023-01-09T04:43:11.377750785Z I0109 04:43:11.377698       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/sa-token-signing-certs-2 -n openshift-kube-apiserver because it was missing
2023-01-09T04:43:11.379245891Z I0109 04:43:11.379207       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ObserveStorageFailed' configmaps openshift-etcd/etcd-endpoints: no etcd endpoint addresses found
2023-01-09T04:43:11.381027909Z E0109 04:43:11.380977       1 base_controller.go:272] ConfigObserver reconciliation failed: configmaps openshift-etcd/etcd-endpoints: no etcd endpoint addresses found
2023-01-09T04:43:11.400852684Z E0109 04:43:11.400811       1 degraded_webhook.go:128] dial tcp 172.30.240.111:8443: connect: connection refused
2023-01-09T04:43:12.376436353Z I0109 04:43:12.376392       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-apiserver-audit-policies-2 -n openshift-kube-apiserver because it was missing
2023-01-09T04:43:12.378187305Z I0109 04:43:12.378151       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ObserveStorageFailed' configmaps openshift-etcd/etcd-endpoints: no etcd endpoint addresses found
2023-01-09T04:43:12.378608658Z E0109 04:43:12.378588       1 base_controller.go:272] ConfigObserver reconciliation failed: configmaps openshift-etcd/etcd-endpoints: no etcd endpoint addresses found
2023-01-09T04:43:13.375445302Z I0109 04:43:13.375388       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/etcd-client-2 -n openshift-kube-apiserver because it was missing
2023-01-09T04:43:13.566300792Z E0109 04:43:13.566261       1 guard_controller.go:268] Missing operand on node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:43:13.566300792Z E0109 04:43:13.566289       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:43:13.566417844Z E0109 04:43:13.566300       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:43:13.579725926Z E0109 04:43:13.579669       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:43:13.582040123Z I0109 04:43:13.581978       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:43:13.582410386Z E0109 04:43:13.582381       1 base_controller.go:272] ConfigObserver reconciliation failed: configmaps openshift-etcd/etcd-endpoints: no etcd endpoint addresses found
2023-01-09T04:43:13.582733039Z I0109 04:43:13.582704       1 prune_controller.go:269] Nothing to prune
2023-01-09T04:43:13.587884270Z E0109 04:43:13.584313       1 base_controller.go:272] ConfigObserver reconciliation failed: configmaps openshift-etcd/etcd-endpoints: no etcd endpoint addresses found
2023-01-09T04:43:13.587919944Z I0109 04:43:13.586604       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ObserveStorageFailed' configmaps openshift-etcd/etcd-endpoints: no etcd endpoint addresses found
2023-01-09T04:43:13.587919944Z I0109 04:43:13.587893       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ObserveStorageFailed' configmaps openshift-etcd/etcd-endpoints: no etcd endpoint addresses found
2023-01-09T04:43:13.587919944Z E0109 04:43:13.587670       1 base_controller.go:272] InstallerController reconciliation failed: missing required resources: [configmaps: bound-sa-token-signing-certs-1,config-1,etcd-serving-ca-1,kube-apiserver-audit-policies-1,kube-apiserver-cert-syncer-kubeconfig-1,kube-apiserver-pod-1,kubelet-serving-ca-1,sa-token-signing-certs-1, secrets: etcd-client-1,localhost-recovery-client-token-1,localhost-recovery-serving-certkey-1]
2023-01-09T04:43:13.587919944Z I0109 04:43:13.587789       1 status_controller.go:211] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:43:04Z","message":"ConfigObservationDegraded: configmaps openshift-etcd/etcd-endpoints: no etcd endpoint addresses found\nGuardControllerDegraded: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]\nInstallerControllerDegraded: missing required resources: [configmaps: bound-sa-token-signing-certs-1,config-1,etcd-serving-ca-1,kube-apiserver-audit-policies-1,kube-apiserver-cert-syncer-kubeconfig-1,kube-apiserver-pod-1,kubelet-serving-ca-1,sa-token-signing-certs-1, secrets: etcd-client-1,localhost-recovery-client-token-1,localhost-recovery-serving-certkey-1]\nRevisionControllerDegraded: Operation cannot be fulfilled on kubeapiservers.operator.openshift.io \"cluster\": the object has been modified; please apply your changes to the latest version and try again","reason":"ConfigObservation_Error::GuardController_SyncError::InstallerController_Error::RevisionController_Error","status":"True","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:42:55Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 1","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 1","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:43:13.588026015Z I0109 04:43:13.587800       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: bound-sa-token-signing-certs-1,config-1,etcd-serving-ca-1,kube-apiserver-audit-policies-1,kube-apiserver-cert-syncer-kubeconfig-1,kube-apiserver-pod-1,kubelet-serving-ca-1,sa-token-signing-certs-1, secrets: etcd-client-1,localhost-recovery-client-token-1,localhost-recovery-serving-certkey-1
2023-01-09T04:43:13.595745413Z I0109 04:43:13.595712       1 status_controller.go:211] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:43:04Z","message":"ConfigObservationDegraded: configmaps openshift-etcd/etcd-endpoints: no etcd endpoint addresses found\nGuardControllerDegraded: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]\nInstallerControllerDegraded: missing required resources: [configmaps: bound-sa-token-signing-certs-1,config-1,etcd-serving-ca-1,kube-apiserver-audit-policies-1,kube-apiserver-cert-syncer-kubeconfig-1,kube-apiserver-pod-1,kubelet-serving-ca-1,sa-token-signing-certs-1, secrets: etcd-client-1,localhost-recovery-client-token-1,localhost-recovery-serving-certkey-1]\nRevisionControllerDegraded: Operation cannot be fulfilled on kubeapiservers.operator.openshift.io \"cluster\": the object has been modified; please apply your changes to the latest version and try again","reason":"ConfigObservation_Error::GuardController_SyncError::InstallerController_Error::RevisionController_Error","status":"True","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:42:55Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 1","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 1","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:43:13.596250085Z I0109 04:43:13.595976       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded message changed from "ConfigObservationDegraded: configmaps openshift-etcd/etcd-endpoints: no etcd endpoint addresses found\nGuardControllerDegraded: [Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal]\nInstallerControllerDegraded: missing required resources: [configmaps: bound-sa-token-signing-certs-1,config-1,etcd-serving-ca-1,kube-apiserver-audit-policies-1,kube-apiserver-cert-syncer-kubeconfig-1,kube-apiserver-pod-1,kubelet-serving-ca-1,sa-token-signing-certs-1, secrets: etcd-client-1,localhost-recovery-client-token-1,localhost-recovery-serving-certkey-1]\nRevisionControllerDegraded: Operation cannot be fulfilled on kubeapiservers.operator.openshift.io \"cluster\": the object has been modified; please apply your changes to the latest version and try again" to "ConfigObservationDegraded: configmaps openshift-etcd/etcd-endpoints: no etcd endpoint addresses found\nGuardControllerDegraded: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]\nInstallerControllerDegraded: missing required resources: [configmaps: bound-sa-token-signing-certs-1,config-1,etcd-serving-ca-1,kube-apiserver-audit-policies-1,kube-apiserver-cert-syncer-kubeconfig-1,kube-apiserver-pod-1,kubelet-serving-ca-1,sa-token-signing-certs-1, secrets: etcd-client-1,localhost-recovery-client-token-1,localhost-recovery-serving-certkey-1]\nRevisionControllerDegraded: Operation cannot be fulfilled on kubeapiservers.operator.openshift.io \"cluster\": the object has been modified; please apply your changes to the latest version and try again"
2023-01-09T04:43:13.600434496Z E0109 04:43:13.600411       1 base_controller.go:272] StatusSyncer_kube-apiserver reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io "kube-apiserver": the object has been modified; please apply your changes to the latest version and try again
2023-01-09T04:43:14.571972668Z I0109 04:43:14.571922       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:43:14.770672934Z I0109 04:43:14.770629       1 request.go:601] Waited for 1.188224474s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:43:15.026658835Z E0109 04:43:15.026622       1 guard_controller.go:268] Missing operand on node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:43:15.026658835Z E0109 04:43:15.026653       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:43:15.026683020Z E0109 04:43:15.026670       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:43:15.027229593Z E0109 04:43:15.027198       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:43:15.770909127Z I0109 04:43:15.770872       1 request.go:601] Waited for 1.398250759s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets
2023-01-09T04:43:15.775324949Z I0109 04:43:15.775276       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/localhost-recovery-serving-certkey-2 -n openshift-kube-apiserver because it was missing
2023-01-09T04:43:16.575727477Z I0109 04:43:16.575680       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/localhost-recovery-client-token-2 -n openshift-kube-apiserver because it was missing
2023-01-09T04:43:16.970827189Z I0109 04:43:16.970784       1 request.go:601] Waited for 1.017118336s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2023-01-09T04:43:17.753439082Z I0109 04:43:17.753386       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ObserveStorageFailed' configmaps openshift-etcd/etcd-endpoints: no etcd endpoint addresses found
2023-01-09T04:43:17.755419375Z E0109 04:43:17.755377       1 base_controller.go:272] ConfigObserver reconciliation failed: configmaps openshift-etcd/etcd-endpoints: no etcd endpoint addresses found
2023-01-09T04:43:17.971014376Z I0109 04:43:17.970942       1 request.go:601] Waited for 1.395434878s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets
2023-01-09T04:43:17.976959566Z I0109 04:43:17.976915       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/webhook-authenticator-2 -n openshift-kube-apiserver because it was missing
2023-01-09T04:43:17.986820220Z I0109 04:43:17.986775       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionCreate' Revision 1 created because configmap "kube-apiserver-pod-1" not found
2023-01-09T04:43:17.990353824Z I0109 04:43:17.988041       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ObserveStorageFailed' configmaps openshift-etcd/etcd-endpoints: no etcd endpoint addresses found
2023-01-09T04:43:17.990353824Z I0109 04:43:17.988411       1 prune_controller.go:269] Nothing to prune
2023-01-09T04:43:17.990353824Z I0109 04:43:17.988756       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:43:17.990817831Z I0109 04:43:17.990787       1 status_controller.go:211] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:43:04Z","message":"ConfigObservationDegraded: configmaps openshift-etcd/etcd-endpoints: no etcd endpoint addresses found\nGuardControllerDegraded: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]\nInstallerControllerDegraded: missing required resources: [configmaps: bound-sa-token-signing-certs-1,config-1,etcd-serving-ca-1,kube-apiserver-audit-policies-1,kube-apiserver-cert-syncer-kubeconfig-1,kube-apiserver-pod-1,kubelet-serving-ca-1,sa-token-signing-certs-1, secrets: etcd-client-1,localhost-recovery-client-token-1,localhost-recovery-serving-certkey-1]","reason":"ConfigObservation_Error::GuardController_SyncError::InstallerController_Error","status":"True","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:42:55Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 1","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 1","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:43:17.991442181Z E0109 04:43:17.991407       1 base_controller.go:272] ConfigObserver reconciliation failed: configmaps openshift-etcd/etcd-endpoints: no etcd endpoint addresses found
2023-01-09T04:43:17.995671060Z I0109 04:43:17.995635       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ObserveStorageFailed' configmaps openshift-etcd/etcd-endpoints: no etcd endpoint addresses found
2023-01-09T04:43:17.996183259Z E0109 04:43:17.996155       1 base_controller.go:272] ConfigObserver reconciliation failed: configmaps openshift-etcd/etcd-endpoints: no etcd endpoint addresses found
2023-01-09T04:43:18.001520605Z I0109 04:43:17.999368       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded message changed from "ConfigObservationDegraded: configmaps openshift-etcd/etcd-endpoints: no etcd endpoint addresses found\nGuardControllerDegraded: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]\nInstallerControllerDegraded: missing required resources: [configmaps: bound-sa-token-signing-certs-1,config-1,etcd-serving-ca-1,kube-apiserver-audit-policies-1,kube-apiserver-cert-syncer-kubeconfig-1,kube-apiserver-pod-1,kubelet-serving-ca-1,sa-token-signing-certs-1, secrets: etcd-client-1,localhost-recovery-client-token-1,localhost-recovery-serving-certkey-1]\nRevisionControllerDegraded: Operation cannot be fulfilled on kubeapiservers.operator.openshift.io \"cluster\": the object has been modified; please apply your changes to the latest version and try again" to "ConfigObservationDegraded: configmaps openshift-etcd/etcd-endpoints: no etcd endpoint addresses found\nGuardControllerDegraded: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]\nInstallerControllerDegraded: missing required resources: [configmaps: bound-sa-token-signing-certs-1,config-1,etcd-serving-ca-1,kube-apiserver-audit-policies-1,kube-apiserver-cert-syncer-kubeconfig-1,kube-apiserver-pod-1,kubelet-serving-ca-1,sa-token-signing-certs-1, secrets: etcd-client-1,localhost-recovery-client-token-1,localhost-recovery-serving-certkey-1]"
2023-01-09T04:43:18.813649344Z E0109 04:43:18.813610       1 degraded_webhook.go:128] dial tcp 172.30.195.54:443: connect: connection refused
2023-01-09T04:43:19.170859007Z I0109 04:43:19.170815       1 request.go:601] Waited for 1.180938495s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T04:43:19.817130487Z E0109 04:43:19.817093       1 degraded_webhook.go:128] dial tcp 172.30.195.54:443: connect: connection refused
2023-01-09T04:43:20.171606959Z I0109 04:43:20.171565       1 request.go:601] Waited for 1.398947906s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/localhost-recovery-client-token
2023-01-09T04:43:21.819626913Z E0109 04:43:21.819594       1 degraded_webhook.go:56] volumesnapshotclasses.snapshot.storage.k8s.io: dial tcp 172.30.195.54:443: connect: connection refused
2023-01-09T04:43:21.856928139Z E0109 04:43:21.856889       1 degraded_webhook.go:128] dial tcp 172.30.240.111:8443: connect: connection refused
2023-01-09T04:43:22.173511782Z I0109 04:43:22.173476       1 installer_controller.go:524] node ip-10-0-199-219.us-east-2.compute.internal static pod not found and needs new revision 2
2023-01-09T04:43:22.173560122Z I0109 04:43:22.173516       1 installer_controller.go:532] "ip-10-0-199-219.us-east-2.compute.internal" moving to (v1.NodeStatus) {
2023-01-09T04:43:22.173560122Z  NodeName: (string) (len=42) "ip-10-0-199-219.us-east-2.compute.internal",
2023-01-09T04:43:22.173560122Z  CurrentRevision: (int32) 0,
2023-01-09T04:43:22.173560122Z  TargetRevision: (int32) 2,
2023-01-09T04:43:22.173560122Z  LastFailedRevision: (int32) 0,
2023-01-09T04:43:22.173560122Z  LastFailedTime: (*v1.Time)(<nil>),
2023-01-09T04:43:22.173560122Z  LastFailedReason: (string) "",
2023-01-09T04:43:22.173560122Z  LastFailedCount: (int) 0,
2023-01-09T04:43:22.173560122Z  LastFallbackCount: (int) 0,
2023-01-09T04:43:22.173560122Z  LastFailedRevisionErrors: ([]string) <nil>
2023-01-09T04:43:22.173560122Z }
2023-01-09T04:43:22.184456363Z I0109 04:43:22.184404       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeTargetRevisionChanged' Updating node "ip-10-0-199-219.us-east-2.compute.internal" from revision 0 to 2 because node ip-10-0-199-219.us-east-2.compute.internal static pod not found
2023-01-09T04:43:22.186298425Z I0109 04:43:22.186260       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ObserveStorageFailed' configmaps openshift-etcd/etcd-endpoints: no etcd endpoint addresses found
2023-01-09T04:43:22.186900751Z I0109 04:43:22.186868       1 prune_controller.go:269] Nothing to prune
2023-01-09T04:43:22.187432546Z I0109 04:43:22.187405       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:43:22.188879655Z I0109 04:43:22.188840       1 status_controller.go:211] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:43:04Z","message":"ConfigObservationDegraded: configmaps openshift-etcd/etcd-endpoints: no etcd endpoint addresses found\nGuardControllerDegraded: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]\nInstallerControllerDegraded: missing required resources: [configmaps: bound-sa-token-signing-certs-1,config-1,etcd-serving-ca-1,kube-apiserver-audit-policies-1,kube-apiserver-cert-syncer-kubeconfig-1,kube-apiserver-pod-1,kubelet-serving-ca-1,sa-token-signing-certs-1, secrets: etcd-client-1,localhost-recovery-client-token-1,localhost-recovery-serving-certkey-1]","reason":"ConfigObservation_Error::GuardController_SyncError::InstallerController_Error","status":"True","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:42:55Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 2","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 2","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:43:22.190388173Z E0109 04:43:22.190359       1 base_controller.go:272] ConfigObserver reconciliation failed: configmaps openshift-etcd/etcd-endpoints: no etcd endpoint addresses found
2023-01-09T04:43:22.193140368Z I0109 04:43:22.193103       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ObserveStorageFailed' configmaps openshift-etcd/etcd-endpoints: no etcd endpoint addresses found
2023-01-09T04:43:22.193545546Z E0109 04:43:22.193520       1 base_controller.go:272] ConfigObserver reconciliation failed: configmaps openshift-etcd/etcd-endpoints: no etcd endpoint addresses found
2023-01-09T04:43:22.195594966Z I0109 04:43:22.195563       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Progressing message changed from "NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 1" to "NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 2",Available message changed from "StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 1" to "StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 2"
2023-01-09T04:43:22.216150108Z I0109 04:43:22.216109       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ObserveStorageFailed' configmaps openshift-etcd/etcd-endpoints: no etcd endpoint addresses found
2023-01-09T04:43:22.216776820Z I0109 04:43:22.216747       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:43:22.216943751Z I0109 04:43:22.216900       1 status_controller.go:211] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:43:22Z","message":"NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]\nConfigObservationDegraded: configmaps openshift-etcd/etcd-endpoints: no etcd endpoint addresses found","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:42:55Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 2","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 2","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:43:22.217255175Z I0109 04:43:22.217228       1 prune_controller.go:269] Nothing to prune
2023-01-09T04:43:22.219542029Z E0109 04:43:22.219517       1 base_controller.go:272] ConfigObserver reconciliation failed: configmaps openshift-etcd/etcd-endpoints: no etcd endpoint addresses found
2023-01-09T04:43:22.219816067Z I0109 04:43:22.219792       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ObserveStorageFailed' configmaps openshift-etcd/etcd-endpoints: no etcd endpoint addresses found
2023-01-09T04:43:22.223384509Z E0109 04:43:22.223359       1 base_controller.go:272] ConfigObserver reconciliation failed: configmaps openshift-etcd/etcd-endpoints: no etcd endpoint addresses found
2023-01-09T04:43:22.224786337Z I0109 04:43:22.223836       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded changed from True to False ("NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]\nConfigObservationDegraded: configmaps openshift-etcd/etcd-endpoints: no etcd endpoint addresses found")
2023-01-09T04:43:22.860112734Z E0109 04:43:22.860067       1 degraded_webhook.go:128] dial tcp 172.30.240.111:8443: connect: connection refused
2023-01-09T04:43:23.371104947Z I0109 04:43:23.371062       1 request.go:601] Waited for 1.182556644s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver
2023-01-09T04:43:24.570896292Z I0109 04:43:24.570853       1 request.go:601] Waited for 1.391490588s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T04:43:24.889730934Z E0109 04:43:24.889688       1 degraded_webhook.go:128] dial tcp 172.30.195.54:443: connect: connection refused
2023-01-09T04:43:25.893113076Z E0109 04:43:25.893061       1 degraded_webhook.go:128] dial tcp 172.30.195.54:443: connect: connection refused
2023-01-09T04:43:27.577082399Z I0109 04:43:27.577026       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/installer-2-ip-10-0-199-219.us-east-2.compute.internal -n openshift-kube-apiserver because it was missing
2023-01-09T04:43:27.579332597Z E0109 04:43:27.579296       1 guard_controller.go:268] Missing operand on node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:43:27.579332597Z E0109 04:43:27.579319       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:43:27.579363292Z E0109 04:43:27.579329       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:43:27.579616030Z E0109 04:43:27.579603       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:43:27.586731550Z E0109 04:43:27.586442       1 guard_controller.go:268] Missing operand on node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:43:27.586731550Z E0109 04:43:27.586473       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:43:27.586731550Z E0109 04:43:27.586498       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:43:27.587314333Z E0109 04:43:27.587279       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:43:27.594244837Z E0109 04:43:27.594210       1 guard_controller.go:268] Missing operand on node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:43:27.594271305Z E0109 04:43:27.594241       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:43:27.594271305Z E0109 04:43:27.594257       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:43:27.594653897Z E0109 04:43:27.594634       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:43:27.896488718Z E0109 04:43:27.896440       1 degraded_webhook.go:56] volumesnapshotclasses.snapshot.storage.k8s.io: dial tcp 172.30.195.54:443: connect: connection refused
2023-01-09T04:43:27.927941944Z E0109 04:43:27.927902       1 degraded_webhook.go:128] dial tcp 172.30.240.111:8443: connect: connection refused
2023-01-09T04:43:28.148384336Z E0109 04:43:28.148334       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:43:28.148384336Z E0109 04:43:28.148361       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:43:28.148384336Z E0109 04:43:28.148378       1 guard_controller.go:268] Missing operand on node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:43:28.158982442Z E0109 04:43:28.158943       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal]
2023-01-09T04:43:28.160223085Z I0109 04:43:28.160194       1 prune_controller.go:269] Nothing to prune
2023-01-09T04:43:28.160578495Z I0109 04:43:28.160557       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:43:28.161552202Z E0109 04:43:28.161520       1 base_controller.go:272] ConfigObserver reconciliation failed: configmaps openshift-etcd/etcd-endpoints: no etcd endpoint addresses found
2023-01-09T04:43:28.162277064Z I0109 04:43:28.162249       1 status_controller.go:211] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:43:22Z","message":"NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal]\nConfigObservationDegraded: configmaps openshift-etcd/etcd-endpoints: no etcd endpoint addresses found","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:42:55Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 2","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 2","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:43:28.162613655Z I0109 04:43:28.162570       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ObserveStorageFailed' configmaps openshift-etcd/etcd-endpoints: no etcd endpoint addresses found
2023-01-09T04:43:28.163936379Z I0109 04:43:28.163903       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ObserveStorageFailed' configmaps openshift-etcd/etcd-endpoints: no etcd endpoint addresses found
2023-01-09T04:43:28.165479059Z E0109 04:43:28.165451       1 base_controller.go:272] ConfigObserver reconciliation failed: configmaps openshift-etcd/etcd-endpoints: no etcd endpoint addresses found
2023-01-09T04:43:28.169325243Z I0109 04:43:28.169290       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]\nConfigObservationDegraded: configmaps openshift-etcd/etcd-endpoints: no etcd endpoint addresses found" to "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal]\nConfigObservationDegraded: configmaps openshift-etcd/etcd-endpoints: no etcd endpoint addresses found"
2023-01-09T04:43:28.173691116Z I0109 04:43:28.173654       1 installer_controller.go:512] "ip-10-0-199-219.us-east-2.compute.internal" is in transition to 2, but has not made progress because installer is not finished, but in Pending phase
2023-01-09T04:43:28.771164139Z I0109 04:43:28.771119       1 request.go:601] Waited for 1.193155273s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:43:28.930822340Z E0109 04:43:28.930777       1 degraded_webhook.go:128] dial tcp 172.30.240.111:8443: connect: connection refused
2023-01-09T04:43:29.571956676Z I0109 04:43:29.571917       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:43:29.971226898Z I0109 04:43:29.971189       1 request.go:601] Waited for 1.796860964s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:43:30.971560242Z I0109 04:43:30.971518       1 request.go:601] Waited for 1.198161687s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver
2023-01-09T04:43:32.010526393Z E0109 04:43:32.010476       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:43:32.010526393Z E0109 04:43:32.010513       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:43:32.010554234Z E0109 04:43:32.010530       1 guard_controller.go:268] Missing operand on node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:43:32.011156664Z E0109 04:43:32.011104       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal]
2023-01-09T04:43:32.024958421Z I0109 04:43:32.024907       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ObserveStorageUpdated' Updated storage urls to https://10.0.199.219:2379,https://localhost:2379
2023-01-09T04:43:32.029296928Z I0109 04:43:32.029248       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ObservedConfigChanged' Writing updated observed config:   map[string]interface{}{
2023-01-09T04:43:32.029296928Z   	"admission": map[string]interface{}{"pluginConfig": map[string]interface{}{"network.openshift.io/ExternalIPRanger": map[string]interface{}{"configuration": map[string]interface{}{"allowIngressIP": bool(false), "apiVersion": string("network.openshift.io/v1"), "kind": string("ExternalIPRangerAdmissionConfig")}}, "network.openshift.io/RestrictedEndpointsAdmission": map[string]interface{}{"configuration": map[string]interface{}{"apiVersion": string("network.openshift.io/v1"), "kind": string("RestrictedEndpointsAdmissionConfig"), "restrictedCIDRs": []interface{}{string("10.128.0.0/14"), string("172.30.0.0/16")}}}}},
2023-01-09T04:43:32.029296928Z   	"apiServerArguments": map[string]interface{}{
2023-01-09T04:43:32.029296928Z   		... // 2 identical entries
2023-01-09T04:43:32.029296928Z   		"authentication-token-webhook-version": []interface{}{string("v1")},
2023-01-09T04:43:32.029296928Z   		"cloud-provider":                       []interface{}{string("aws")},
2023-01-09T04:43:32.029296928Z   		"etcd-servers": []interface{}{
2023-01-09T04:43:32.029296928Z + 			string("https://10.0.199.219:2379"),
2023-01-09T04:43:32.029296928Z   			string("https://localhost:2379"),
2023-01-09T04:43:32.029296928Z   		},
2023-01-09T04:43:32.029296928Z   		"feature-gates":          []interface{}{string("APIPriorityAndFairness=true"), string("RotateKubeletServerCertificate=true"), string("DownwardAPIHugePages=true"), string("CSIMigrationAzureFile=false"), ...},
2023-01-09T04:43:32.029296928Z   		"service-account-issuer": []interface{}{string("https://kubernetes.default.svc")},
2023-01-09T04:43:32.029296928Z   		... // 2 identical entries
2023-01-09T04:43:32.029296928Z   	},
2023-01-09T04:43:32.029296928Z   	"corsAllowedOrigins":          []interface{}{string(`//127\.0\.0\.1(:|$)`), string("//localhost(:|$)")},
2023-01-09T04:43:32.029296928Z   	"gracefulTerminationDuration": string("194"),
2023-01-09T04:43:32.029296928Z   	... // 2 identical entries
2023-01-09T04:43:32.029296928Z   }
2023-01-09T04:43:32.055597196Z I0109 04:43:32.048395       1 prune_controller.go:269] Nothing to prune
2023-01-09T04:43:32.055597196Z I0109 04:43:32.049582       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:43:32.084102005Z I0109 04:43:32.084026       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:43:32.086280761Z I0109 04:43:32.086247       1 status_controller.go:211] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:43:22Z","message":"NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal]","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:42:55Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 2","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 2","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:43:32.087759711Z I0109 04:43:32.087559       1 prune_controller.go:269] Nothing to prune
2023-01-09T04:43:32.095155043Z I0109 04:43:32.094197       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal]\nConfigObservationDegraded: configmaps openshift-etcd/etcd-endpoints: no etcd endpoint addresses found" to "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal]"
2023-01-09T04:43:32.095155043Z I0109 04:43:32.094842       1 status_controller.go:211] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:43:22Z","message":"NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal]","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:42:55Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 2","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 2","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:43:32.100772409Z E0109 04:43:32.100747       1 base_controller.go:272] StatusSyncer_kube-apiserver reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io "kube-apiserver": the object has been modified; please apply your changes to the latest version and try again
2023-01-09T04:43:32.134786891Z E0109 04:43:32.134751       1 guard_controller.go:268] Missing operand on node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:43:32.134814795Z E0109 04:43:32.134783       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:43:32.134814795Z E0109 04:43:32.134798       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:43:32.148867740Z E0109 04:43:32.148834       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:43:32.150570900Z I0109 04:43:32.150536       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:43:32.151196644Z I0109 04:43:32.151165       1 status_controller.go:211] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:43:22Z","message":"NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:42:55Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 2","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 2","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:43:32.152570191Z I0109 04:43:32.152526       1 prune_controller.go:269] Nothing to prune
2023-01-09T04:43:32.167749505Z I0109 04:43:32.167702       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal]" to "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]"
2023-01-09T04:43:33.170676171Z I0109 04:43:33.170624       1 request.go:601] Waited for 1.115908507s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T04:43:34.171463200Z I0109 04:43:34.171425       1 request.go:601] Waited for 1.796274946s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:43:35.371601717Z I0109 04:43:35.371563       1 request.go:601] Waited for 1.396573592s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/installer-2-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:43:35.375166124Z I0109 04:43:35.375140       1 installer_controller.go:512] "ip-10-0-199-219.us-east-2.compute.internal" is in transition to 2, but has not made progress because installer is not finished, but in Running phase
2023-01-09T04:43:37.577967664Z I0109 04:43:37.577912       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapUpdated' Updated ConfigMap/config -n openshift-kube-apiserver:
2023-01-09T04:43:37.577967664Z cause by changes in data.config.yaml
2023-01-09T04:43:37.579452063Z I0109 04:43:37.579418       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionTriggered' new revision 3 triggered by "configmap/config has changed"
2023-01-09T04:43:38.771525610Z I0109 04:43:38.771481       1 request.go:601] Waited for 1.192237533s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-pod
2023-01-09T04:43:38.980196237Z I0109 04:43:38.980146       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/revision-status-3 -n openshift-kube-apiserver because it was missing
2023-01-09T04:43:39.777181172Z I0109 04:43:39.777118       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-apiserver-pod-3 -n openshift-kube-apiserver because it was missing
2023-01-09T04:43:40.171158226Z I0109 04:43:40.171117       1 request.go:601] Waited for 1.190455263s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T04:43:40.575185001Z I0109 04:43:40.575140       1 installer_controller.go:512] "ip-10-0-199-219.us-east-2.compute.internal" is in transition to 2, but has not made progress because installer is not finished, but in Running phase
2023-01-09T04:43:40.976890419Z I0109 04:43:40.976839       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/config-3 -n openshift-kube-apiserver because it was missing
2023-01-09T04:43:41.171350976Z I0109 04:43:41.171309       1 request.go:601] Waited for 1.195764983s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T04:43:41.979521829Z I0109 04:43:41.979473       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-apiserver-cert-syncer-kubeconfig-3 -n openshift-kube-apiserver because it was missing
2023-01-09T04:43:42.976450449Z I0109 04:43:42.976400       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/bound-sa-token-signing-certs-3 -n openshift-kube-apiserver because it was missing
2023-01-09T04:43:43.976349597Z I0109 04:43:43.976306       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/etcd-serving-ca-3 -n openshift-kube-apiserver because it was missing
2023-01-09T04:43:44.192060191Z E0109 04:43:44.192023       1 guard_controller.go:268] Missing operand on node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:43:44.192060191Z E0109 04:43:44.192049       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:43:44.192107568Z E0109 04:43:44.192066       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:43:44.192413165Z E0109 04:43:44.192391       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:43:44.573473383Z I0109 04:43:44.573432       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:43:44.977700191Z I0109 04:43:44.977648       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-apiserver-server-ca-3 -n openshift-kube-apiserver because it was missing
2023-01-09T04:43:45.436044718Z E0109 04:43:45.436008       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:43:45.436068112Z E0109 04:43:45.436042       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:43:45.436068112Z E0109 04:43:45.436059       1 guard_controller.go:268] Missing operand on node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:43:45.449655238Z E0109 04:43:45.449620       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal]
2023-01-09T04:43:45.451825621Z I0109 04:43:45.451792       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:43:45.452664364Z I0109 04:43:45.452639       1 prune_controller.go:269] Nothing to prune
2023-01-09T04:43:45.453419499Z I0109 04:43:45.453389       1 status_controller.go:211] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:43:22Z","message":"NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal]","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:42:55Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 2","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 2","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:43:45.461497935Z I0109 04:43:45.461457       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]" to "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal]"
2023-01-09T04:43:45.977777812Z I0109 04:43:45.977720       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kubelet-serving-ca-3 -n openshift-kube-apiserver because it was missing
2023-01-09T04:43:46.570899951Z I0109 04:43:46.570858       1 request.go:601] Waited for 1.119514093s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2023-01-09T04:43:47.571634666Z I0109 04:43:47.571596       1 request.go:601] Waited for 1.593999808s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps
2023-01-09T04:43:47.576599706Z I0109 04:43:47.576547       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/sa-token-signing-certs-3 -n openshift-kube-apiserver because it was missing
2023-01-09T04:43:48.771092619Z I0109 04:43:48.771049       1 request.go:601] Waited for 1.396488402s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-server-ca
2023-01-09T04:43:48.977199354Z I0109 04:43:48.977145       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-apiserver-audit-policies-3 -n openshift-kube-apiserver because it was missing
2023-01-09T04:43:49.971466857Z I0109 04:43:49.971426       1 request.go:601] Waited for 1.366573666s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2023-01-09T04:43:50.376558189Z I0109 04:43:50.376499       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/etcd-client-3 -n openshift-kube-apiserver because it was missing
2023-01-09T04:43:51.171054381Z I0109 04:43:51.171013       1 request.go:601] Waited for 1.151088697s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver
2023-01-09T04:43:51.974828108Z I0109 04:43:51.974782       1 installer_controller.go:512] "ip-10-0-199-219.us-east-2.compute.internal" is in transition to 2, but has not made progress because installer is not finished, but in Running phase
2023-01-09T04:43:52.579694127Z I0109 04:43:52.579641       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/localhost-recovery-serving-certkey-3 -n openshift-kube-apiserver because it was missing
2023-01-09T04:43:53.177395073Z I0109 04:43:53.177333       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/localhost-recovery-client-token-3 -n openshift-kube-apiserver because it was missing
2023-01-09T04:43:53.979123871Z I0109 04:43:53.979066       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/webhook-authenticator-3 -n openshift-kube-apiserver because it was missing
2023-01-09T04:43:53.990008087Z I0109 04:43:53.989949       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionCreate' Revision 2 created because configmap/config has changed
2023-01-09T04:43:53.991184492Z I0109 04:43:53.991151       1 prune_controller.go:269] Nothing to prune
2023-01-09T04:43:53.991481946Z I0109 04:43:53.991449       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:43:53.993795173Z I0109 04:43:53.993754       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionTriggered' new revision 3 triggered by "configmap/config has changed"
2023-01-09T04:43:54.013176687Z I0109 04:43:54.013131       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:43:54.025237635Z I0109 04:43:54.025188       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:43:54.047865147Z E0109 04:43:54.047824       1 degraded_webhook.go:128] dial tcp 172.30.195.54:443: connect: connection refused
2023-01-09T04:43:55.052407060Z E0109 04:43:55.052358       1 degraded_webhook.go:128] dial tcp 172.30.195.54:443: connect: connection refused
2023-01-09T04:43:55.170696750Z I0109 04:43:55.170655       1 request.go:601] Waited for 1.178475565s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:43:55.577765442Z W0109 04:43:55.577726       1 staticpod.go:38] revision 3 is unexpectedly already the latest available revision. This is a possible race!
2023-01-09T04:43:55.592827009Z E0109 04:43:55.592785       1 base_controller.go:272] RevisionController reconciliation failed: conflicting latestAvailableRevision 3
2023-01-09T04:43:55.594391123Z I0109 04:43:55.594357       1 prune_controller.go:269] Nothing to prune
2023-01-09T04:43:55.594788411Z I0109 04:43:55.594769       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:43:55.597388001Z I0109 04:43:55.597353       1 status_controller.go:211] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:43:22Z","message":"NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal]\nRevisionControllerDegraded: conflicting latestAvailableRevision 3","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:42:55Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 2","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 2","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:43:55.605266940Z I0109 04:43:55.605204       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal]" to "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal]\nRevisionControllerDegraded: conflicting latestAvailableRevision 3"
2023-01-09T04:43:55.609039978Z I0109 04:43:55.608979       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:43:55.609775468Z I0109 04:43:55.609747       1 prune_controller.go:269] Nothing to prune
2023-01-09T04:43:55.611553849Z I0109 04:43:55.611522       1 status_controller.go:211] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:43:22Z","message":"NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal]","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:42:55Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 2","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 2","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:43:55.619709486Z I0109 04:43:55.619666       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal]\nRevisionControllerDegraded: conflicting latestAvailableRevision 3" to "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal]"
2023-01-09T04:43:56.170976513Z I0109 04:43:56.170935       1 request.go:601] Waited for 1.596065436s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-server-ca
2023-01-09T04:43:56.959611472Z I0109 04:43:56.959572       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:43:56.994131348Z I0109 04:43:56.994076       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:43:57.013857380Z I0109 04:43:57.013824       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:43:57.055382848Z E0109 04:43:57.055350       1 degraded_webhook.go:56] volumesnapshotclasses.snapshot.storage.k8s.io: dial tcp 172.30.195.54:443: connect: connection refused
2023-01-09T04:43:57.093620316Z I0109 04:43:57.093578       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:43:57.096033995Z E0109 04:43:57.095974       1 degraded_webhook.go:128] dial tcp 172.30.240.111:8443: connect: connection refused
2023-01-09T04:43:57.171151651Z I0109 04:43:57.171111       1 request.go:601] Waited for 1.391236447s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T04:43:58.099081006Z E0109 04:43:58.099031       1 degraded_webhook.go:128] dial tcp 172.30.240.111:8443: connect: connection refused
2023-01-09T04:43:58.171155942Z I0109 04:43:58.171115       1 request.go:601] Waited for 1.392161988s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2023-01-09T04:43:59.617796849Z I0109 04:43:59.617753       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:43:59.619267642Z I0109 04:43:59.619230       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:43:59.859355594Z I0109 04:43:59.859312       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:43:59.861461769Z I0109 04:43:59.861434       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:44:00.131630172Z E0109 04:44:00.131591       1 degraded_webhook.go:128] dial tcp 172.30.195.54:443: connect: connection refused
2023-01-09T04:44:00.180682057Z I0109 04:44:00.179334       1 installer_controller.go:500] "ip-10-0-199-219.us-east-2.compute.internal" moving to (v1.NodeStatus) {
2023-01-09T04:44:00.180682057Z  NodeName: (string) (len=42) "ip-10-0-199-219.us-east-2.compute.internal",
2023-01-09T04:44:00.180682057Z  CurrentRevision: (int32) 0,
2023-01-09T04:44:00.180682057Z  TargetRevision: (int32) 3,
2023-01-09T04:44:00.180682057Z  LastFailedRevision: (int32) 0,
2023-01-09T04:44:00.180682057Z  LastFailedTime: (*v1.Time)(<nil>),
2023-01-09T04:44:00.180682057Z  LastFailedReason: (string) "",
2023-01-09T04:44:00.180682057Z  LastFailedCount: (int) 0,
2023-01-09T04:44:00.180682057Z  LastFallbackCount: (int) 0,
2023-01-09T04:44:00.180682057Z  LastFailedRevisionErrors: ([]string) <nil>
2023-01-09T04:44:00.180682057Z }
2023-01-09T04:44:00.180682057Z  because new revision pending
2023-01-09T04:44:00.189061743Z E0109 04:44:00.189027       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:44:00.189089116Z E0109 04:44:00.189058       1 guard_controller.go:268] Missing operand on node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:44:00.189089116Z E0109 04:44:00.189075       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:44:00.196524208Z I0109 04:44:00.196486       1 prune_controller.go:269] Nothing to prune
2023-01-09T04:44:00.208363219Z I0109 04:44:00.208313       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:44:00.209515732Z I0109 04:44:00.209480       1 status_controller.go:211] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:43:22Z","message":"NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal]","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:42:55Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 3","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 3","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:44:00.220499979Z I0109 04:44:00.217683       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Progressing message changed from "NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 2" to "NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 3",Available message changed from "StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 2" to "StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 3"
2023-01-09T04:44:00.227720087Z E0109 04:44:00.227691       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal]
2023-01-09T04:44:00.229572547Z I0109 04:44:00.229541       1 prune_controller.go:269] Nothing to prune
2023-01-09T04:44:00.231201318Z I0109 04:44:00.231171       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:44:00.232695562Z I0109 04:44:00.232662       1 status_controller.go:211] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:43:22Z","message":"NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal]","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:42:55Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 3","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 3","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:44:00.240453745Z I0109 04:44:00.240413       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal]" to "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal]"
2023-01-09T04:44:01.136037739Z E0109 04:44:01.135956       1 degraded_webhook.go:128] dial tcp 172.30.195.54:443: connect: connection refused
2023-01-09T04:44:01.371287413Z I0109 04:44:01.371251       1 request.go:601] Waited for 1.171700623s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T04:44:02.221630892Z I0109 04:44:02.221582       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:44:02.222019671Z I0109 04:44:02.221948       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:44:02.533674395Z E0109 04:44:02.533637       1 guard_controller.go:268] Missing operand on node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:44:02.533700921Z E0109 04:44:02.533670       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:44:02.533700921Z E0109 04:44:02.533688       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:44:02.552630137Z E0109 04:44:02.552582       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:44:02.553838298Z I0109 04:44:02.553802       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:44:02.555453054Z I0109 04:44:02.555415       1 status_controller.go:211] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:43:22Z","message":"NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:42:55Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 3","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 3","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:44:02.556453517Z I0109 04:44:02.556414       1 prune_controller.go:269] Nothing to prune
2023-01-09T04:44:02.564740740Z I0109 04:44:02.564696       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal]" to "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]"
2023-01-09T04:44:02.571141100Z I0109 04:44:02.571108       1 request.go:601] Waited for 1.392748949s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2023-01-09T04:44:03.139156315Z E0109 04:44:03.139120       1 degraded_webhook.go:56] volumesnapshotclasses.snapshot.storage.k8s.io: dial tcp 172.30.195.54:443: connect: connection refused
2023-01-09T04:44:03.176712675Z E0109 04:44:03.176673       1 degraded_webhook.go:128] dial tcp 172.30.240.111:8443: connect: connection refused
2023-01-09T04:44:03.232909459Z E0109 04:44:03.232833       1 guard_controller.go:268] Missing operand on node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:44:03.232909459Z E0109 04:44:03.232868       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:44:03.232909459Z E0109 04:44:03.232883       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:44:03.233348175Z E0109 04:44:03.233323       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:44:03.246129377Z E0109 04:44:03.246080       1 guard_controller.go:268] Missing operand on node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:44:03.246129377Z E0109 04:44:03.246113       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:44:03.246164660Z E0109 04:44:03.246130       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:44:03.246599855Z E0109 04:44:03.246565       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:44:03.250367115Z E0109 04:44:03.250331       1 guard_controller.go:268] Missing operand on node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:44:03.250367115Z E0109 04:44:03.250353       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:44:03.250397545Z E0109 04:44:03.250363       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:44:03.250656661Z E0109 04:44:03.250635       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:44:03.571627506Z I0109 04:44:03.571578       1 request.go:601] Waited for 1.396686263s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/client-ca
2023-01-09T04:44:04.180006287Z E0109 04:44:04.179945       1 degraded_webhook.go:128] dial tcp 172.30.240.111:8443: connect: connection refused
2023-01-09T04:44:04.771096922Z I0109 04:44:04.771052       1 request.go:601] Waited for 1.543414677s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2023-01-09T04:44:05.805443018Z I0109 04:44:05.805402       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:44:05.808637914Z I0109 04:44:05.808605       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:44:05.881099309Z I0109 04:44:05.881051       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:44:05.882333039Z I0109 04:44:05.882303       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:44:05.971166947Z I0109 04:44:05.971123       1 request.go:601] Waited for 1.550315534s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver
2023-01-09T04:44:06.269403874Z I0109 04:44:06.269367       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:44:06.611572058Z E0109 04:44:06.611534       1 degraded_webhook.go:128] dial tcp 172.30.195.54:443: connect: connection refused
2023-01-09T04:44:07.171289817Z I0109 04:44:07.171250       1 request.go:601] Waited for 1.196629619s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver
2023-01-09T04:44:07.580149149Z I0109 04:44:07.580091       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/installer-3-ip-10-0-199-219.us-east-2.compute.internal -n openshift-kube-apiserver because it was missing
2023-01-09T04:44:07.587728002Z E0109 04:44:07.587689       1 guard_controller.go:268] Missing operand on node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:44:07.587728002Z E0109 04:44:07.587714       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:44:07.587766169Z E0109 04:44:07.587724       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:44:07.588032167Z E0109 04:44:07.588015       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:44:07.596351353Z E0109 04:44:07.596312       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:44:07.596351353Z E0109 04:44:07.596333       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:44:07.596351353Z E0109 04:44:07.596344       1 guard_controller.go:268] Missing operand on node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:44:07.612293824Z E0109 04:44:07.612258       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal]
2023-01-09T04:44:07.613154461Z I0109 04:44:07.613119       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:44:07.615934676Z I0109 04:44:07.615908       1 prune_controller.go:269] Nothing to prune
2023-01-09T04:44:07.619199945Z I0109 04:44:07.619167       1 status_controller.go:211] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:43:22Z","message":"NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal]","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:42:55Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 3","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 3","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:44:07.621195153Z E0109 04:44:07.621169       1 degraded_webhook.go:128] dial tcp 172.30.195.54:443: connect: connection refused
2023-01-09T04:44:07.621624527Z E0109 04:44:07.621609       1 guard_controller.go:268] Missing operand on node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:44:07.621645813Z E0109 04:44:07.621632       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:44:07.621654263Z E0109 04:44:07.621649       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:44:07.627237681Z I0109 04:44:07.627204       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]" to "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal]"
2023-01-09T04:44:07.633892635Z E0109 04:44:07.633864       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:44:07.635406573Z I0109 04:44:07.635366       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:44:07.635800176Z I0109 04:44:07.635780       1 prune_controller.go:269] Nothing to prune
2023-01-09T04:44:07.637919304Z I0109 04:44:07.637892       1 status_controller.go:211] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:43:22Z","message":"NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:42:55Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 3","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 3","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:44:07.646630395Z I0109 04:44:07.646599       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal]" to "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]"
2023-01-09T04:44:08.153372919Z E0109 04:44:08.153329       1 guard_controller.go:268] Missing operand on node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:44:08.153372919Z E0109 04:44:08.153356       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:44:08.153372919Z E0109 04:44:08.153367       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:44:08.153682420Z E0109 04:44:08.153666       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:44:08.374978037Z I0109 04:44:08.374928       1 installer_controller.go:512] "ip-10-0-199-219.us-east-2.compute.internal" is in transition to 3, but has not made progress because installer is not finished, but in Pending phase
2023-01-09T04:44:08.771321756Z I0109 04:44:08.771275       1 request.go:601] Waited for 1.191142365s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver
2023-01-09T04:44:09.237652484Z E0109 04:44:09.237610       1 guard_controller.go:268] Missing operand on node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:44:09.237652484Z E0109 04:44:09.237638       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:44:09.237692021Z E0109 04:44:09.237652       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:44:09.237962003Z E0109 04:44:09.237942       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:44:09.624420451Z E0109 04:44:09.624379       1 degraded_webhook.go:56] volumesnapshotclasses.snapshot.storage.k8s.io: dial tcp 172.30.195.54:443: connect: connection refused
2023-01-09T04:44:09.651864689Z E0109 04:44:09.651815       1 degraded_webhook.go:128] dial tcp 172.30.240.111:8443: connect: connection refused
2023-01-09T04:44:09.971459642Z I0109 04:44:09.971420       1 request.go:601] Waited for 1.748959349s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver
2023-01-09T04:44:10.654063628Z E0109 04:44:10.654022       1 degraded_webhook.go:128] dial tcp 172.30.240.111:8443: connect: connection refused
2023-01-09T04:44:10.971662938Z I0109 04:44:10.971622       1 request.go:601] Waited for 1.79168225s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T04:44:12.171490963Z I0109 04:44:12.171450       1 request.go:601] Waited for 1.796346209s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2023-01-09T04:44:12.691282507Z E0109 04:44:12.691234       1 degraded_webhook.go:128] dial tcp 172.30.195.54:443: connect: connection refused
2023-01-09T04:44:13.171548966Z I0109 04:44:13.171513       1 request.go:601] Waited for 1.19715875s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:44:13.694092205Z E0109 04:44:13.694052       1 degraded_webhook.go:128] dial tcp 172.30.195.54:443: connect: connection refused
2023-01-09T04:44:14.174423118Z I0109 04:44:14.174380       1 installer_controller.go:512] "ip-10-0-199-219.us-east-2.compute.internal" is in transition to 3, but has not made progress because installer is not finished, but in Running phase
2023-01-09T04:44:14.848152664Z E0109 04:44:14.848112       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:44:14.848152664Z E0109 04:44:14.848141       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:44:14.848196741Z E0109 04:44:14.848152       1 guard_controller.go:268] Missing operand on node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:44:14.860431597Z E0109 04:44:14.860385       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal]
2023-01-09T04:44:14.862308024Z I0109 04:44:14.862271       1 prune_controller.go:269] Nothing to prune
2023-01-09T04:44:14.862616943Z I0109 04:44:14.862597       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:44:14.863467928Z I0109 04:44:14.863437       1 status_controller.go:211] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:43:22Z","message":"NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal]","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:42:55Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 3","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 3","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:44:14.872530969Z I0109 04:44:14.872492       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]" to "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal]"
2023-01-09T04:44:15.697156906Z E0109 04:44:15.697113       1 degraded_webhook.go:56] volumesnapshotclasses.snapshot.storage.k8s.io: dial tcp 172.30.195.54:443: connect: connection refused
2023-01-09T04:44:15.728627847Z E0109 04:44:15.728589       1 degraded_webhook.go:128] dial tcp 172.30.240.111:8443: connect: connection refused
2023-01-09T04:44:15.902884097Z E0109 04:44:15.902846       1 guard_controller.go:268] Missing operand on node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:44:15.902884097Z E0109 04:44:15.902874       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:44:15.902920263Z E0109 04:44:15.902888       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:44:15.915187210Z E0109 04:44:15.915152       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:44:15.916630270Z I0109 04:44:15.916590       1 prune_controller.go:269] Nothing to prune
2023-01-09T04:44:15.917096595Z I0109 04:44:15.917070       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:44:15.919704925Z I0109 04:44:15.919655       1 status_controller.go:211] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:43:22Z","message":"NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:42:55Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 3","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 3","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:44:15.927562033Z I0109 04:44:15.927523       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal]" to "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]"
2023-01-09T04:44:15.970776374Z I0109 04:44:15.970734       1 request.go:601] Waited for 1.107571317s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T04:44:16.428714391Z I0109 04:44:16.428657       1 status_controller.go:211] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:44:16Z","message":"GuardControllerDegraded: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]","reason":"GuardController_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:42:55Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 3","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 3","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:44:16.436505615Z I0109 04:44:16.436460       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded changed from False to True ("GuardControllerDegraded: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]")
2023-01-09T04:44:16.731183514Z E0109 04:44:16.731144       1 degraded_webhook.go:128] dial tcp 172.30.240.111:8443: connect: connection refused
2023-01-09T04:44:16.971399684Z I0109 04:44:16.971333       1 request.go:601] Waited for 1.054830913s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2023-01-09T04:44:18.171663702Z I0109 04:44:18.171625       1 request.go:601] Waited for 1.595682234s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-pod
2023-01-09T04:44:18.758514226Z E0109 04:44:18.758474       1 degraded_webhook.go:128] dial tcp 172.30.195.54:443: connect: connection refused
2023-01-09T04:44:19.174100074Z I0109 04:44:19.174057       1 installer_controller.go:512] "ip-10-0-199-219.us-east-2.compute.internal" is in transition to 3, but has not made progress because installer is not finished, but in Running phase
2023-01-09T04:44:19.371300716Z I0109 04:44:19.371260       1 request.go:601] Waited for 1.193144252s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/client-ca
2023-01-09T04:44:19.761753573Z E0109 04:44:19.761697       1 degraded_webhook.go:128] dial tcp 172.30.195.54:443: connect: connection refused
2023-01-09T04:44:21.764513067Z E0109 04:44:21.764475       1 degraded_webhook.go:56] volumesnapshotclasses.snapshot.storage.k8s.io: dial tcp 172.30.195.54:443: connect: connection refused
2023-01-09T04:44:21.802595510Z E0109 04:44:21.802558       1 degraded_webhook.go:128] dial tcp 172.30.240.111:8443: connect: connection refused
2023-01-09T04:44:22.374059896Z I0109 04:44:22.374018       1 installer_controller.go:512] "ip-10-0-199-219.us-east-2.compute.internal" is in transition to 3, but has not made progress because installer is not finished, but in Running phase
2023-01-09T04:44:22.804803213Z E0109 04:44:22.804761       1 degraded_webhook.go:128] dial tcp 172.30.240.111:8443: connect: connection refused
2023-01-09T04:44:29.573778692Z I0109 04:44:29.573726       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:44:38.599910767Z E0109 04:44:38.599594       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:44:38.599910767Z E0109 04:44:38.599627       1 guard_controller.go:268] Missing operand on node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:44:38.599910767Z E0109 04:44:38.599643       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:44:38.619933547Z E0109 04:44:38.619896       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal]
2023-01-09T04:44:38.635127317Z E0109 04:44:38.635086       1 guard_controller.go:268] Missing operand on node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:44:38.635127317Z E0109 04:44:38.635120       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:44:38.635158688Z E0109 04:44:38.635136       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:44:38.636610656Z I0109 04:44:38.636563       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:44:38.638450097Z I0109 04:44:38.638397       1 status_controller.go:211] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:44:16Z","message":"GuardControllerDegraded: [Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal]","reason":"GuardController_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:42:55Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 3","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 3","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:44:38.638521123Z I0109 04:44:38.638496       1 prune_controller.go:269] Nothing to prune
2023-01-09T04:44:38.652245706Z I0109 04:44:38.649847       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded message changed from "GuardControllerDegraded: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]" to "GuardControllerDegraded: [Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal]"
2023-01-09T04:44:38.655212374Z E0109 04:44:38.655175       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:44:38.663374416Z E0109 04:44:38.663320       1 guard_controller.go:268] Missing operand on node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:44:38.663443438Z E0109 04:44:38.663428       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:44:38.663486797Z E0109 04:44:38.663476       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:44:38.666503730Z I0109 04:44:38.666465       1 status_controller.go:211] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:44:16Z","message":"GuardControllerDegraded: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]","reason":"GuardController_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:42:55Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 3","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 3","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:44:38.667036029Z I0109 04:44:38.667009       1 prune_controller.go:269] Nothing to prune
2023-01-09T04:44:38.673265532Z I0109 04:44:38.673233       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:44:38.675288543Z I0109 04:44:38.675260       1 status_controller.go:211] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:44:16Z","message":"GuardControllerDegraded: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]","reason":"GuardController_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:42:55Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 3","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 3","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:44:38.675564171Z I0109 04:44:38.675526       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded message changed from "GuardControllerDegraded: [Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal]" to "GuardControllerDegraded: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]"
2023-01-09T04:44:38.682112389Z E0109 04:44:38.682082       1 base_controller.go:272] StatusSyncer_kube-apiserver reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io "kube-apiserver": the object has been modified; please apply your changes to the latest version and try again
2023-01-09T04:44:38.683838966Z E0109 04:44:38.683810       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:44:38.798168963Z E0109 04:44:38.798124       1 guard_controller.go:268] Missing operand on node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:44:38.798168963Z E0109 04:44:38.798148       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:44:38.798201184Z E0109 04:44:38.798159       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:44:38.798497848Z E0109 04:44:38.798480       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:44:39.821855011Z I0109 04:44:39.821817       1 request.go:601] Waited for 1.147901814s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T04:44:40.411862754Z E0109 04:44:40.411824       1 guard_controller.go:268] Missing operand on node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:44:40.411862754Z E0109 04:44:40.411857       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:44:40.411899991Z E0109 04:44:40.411873       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:44:40.412603961Z E0109 04:44:40.412574       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:44:40.825828438Z I0109 04:44:40.825786       1 installer_controller.go:512] "ip-10-0-199-219.us-east-2.compute.internal" is in transition to 3, but has not made progress because installer is not finished, but in Running phase
2023-01-09T04:44:42.940825109Z E0109 04:44:42.940785       1 guard_controller.go:268] Missing operand on node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:44:42.940925925Z E0109 04:44:42.940885       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:44:42.940925925Z E0109 04:44:42.940912       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:44:42.941450636Z E0109 04:44:42.941424       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:44:43.599691124Z E0109 04:44:43.599642       1 guard_controller.go:268] Missing operand on node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:44:43.599691124Z E0109 04:44:43.599671       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:44:43.599691124Z E0109 04:44:43.599683       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:44:43.600008580Z E0109 04:44:43.599980       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:44:43.824811935Z I0109 04:44:43.824772       1 installer_controller.go:512] "ip-10-0-199-219.us-east-2.compute.internal" is in transition to 3, but has not made progress because installer is not finished, but in Running phase
2023-01-09T04:44:45.846047655Z E0109 04:44:45.845984       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:44:45.846047655Z E0109 04:44:45.846036       1 guard_controller.go:268] Missing operand on node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:44:45.846081058Z E0109 04:44:45.846048       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:44:45.859284733Z E0109 04:44:45.859248       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal]
2023-01-09T04:44:45.860390487Z I0109 04:44:45.860353       1 prune_controller.go:269] Nothing to prune
2023-01-09T04:44:45.860917113Z I0109 04:44:45.860883       1 status_controller.go:211] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:44:16Z","message":"GuardControllerDegraded: [Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal]","reason":"GuardController_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:42:55Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 3","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 3","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:44:45.862611823Z I0109 04:44:45.862584       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:44:45.871116736Z I0109 04:44:45.871083       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded message changed from "GuardControllerDegraded: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]" to "GuardControllerDegraded: [Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal]"
2023-01-09T04:44:45.939459277Z E0109 04:44:45.939423       1 guard_controller.go:274] Missing PodIP in operand kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal on node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:44:45.939459277Z E0109 04:44:45.939450       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:44:45.939491260Z E0109 04:44:45.939461       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:44:45.951188873Z E0109 04:44:45.951140       1 base_controller.go:272] GuardController reconciliation failed: [Missing PodIP in operand kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:44:45.952822341Z I0109 04:44:45.952785       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:44:45.953128735Z I0109 04:44:45.953107       1 prune_controller.go:269] Nothing to prune
2023-01-09T04:44:45.954331623Z I0109 04:44:45.954304       1 status_controller.go:211] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:44:16Z","message":"GuardControllerDegraded: [Missing PodIP in operand kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]","reason":"GuardController_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:42:55Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 3","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 3","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:44:45.963113903Z I0109 04:44:45.963066       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded message changed from "GuardControllerDegraded: [Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal]" to "GuardControllerDegraded: [Missing PodIP in operand kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]"
2023-01-09T04:44:46.150029171Z E0109 04:44:46.149973       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:44:46.150067799Z E0109 04:44:46.150031       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:44:47.021727034Z I0109 04:44:47.021689       1 request.go:601] Waited for 1.085676462s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2023-01-09T04:44:47.853193959Z I0109 04:44:47.853155       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:44:47.930697003Z E0109 04:44:47.930661       1 degraded_webhook.go:128] dial tcp 172.30.240.111:8443: connect: connection refused
2023-01-09T04:44:48.221844044Z I0109 04:44:48.221789       1 request.go:601] Waited for 1.995308069s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:44:48.253136233Z I0109 04:44:48.253098       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:44:48.933626795Z E0109 04:44:48.933590       1 degraded_webhook.go:128] dial tcp 172.30.240.111:8443: connect: connection refused
2023-01-09T04:44:49.222027956Z I0109 04:44:49.221970       1 request.go:601] Waited for 1.996918751s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver
2023-01-09T04:44:49.825615426Z I0109 04:44:49.825565       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorVersionChanged' clusteroperator/kube-apiserver version "kube-apiserver" changed from "" to "1.25.4"
2023-01-09T04:44:49.825615426Z I0109 04:44:49.825595       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorVersionChanged' clusteroperator/kube-apiserver version "operator" changed from "" to "4.12.0-0.nightly-2023-01-08-142418"
2023-01-09T04:44:49.825788031Z I0109 04:44:49.825770       1 status_controller.go:211] clusteroperator/kube-apiserver diff {"status":{"versions":[{"name":"raw-internal","version":"4.12.0-0.nightly-2023-01-08-142418"},{"name":"kube-apiserver","version":"1.25.4"},{"name":"operator","version":"4.12.0-0.nightly-2023-01-08-142418"}]}}
2023-01-09T04:44:49.834367783Z I0109 04:44:49.834338       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: status.versions changed from [{"raw-internal" "4.12.0-0.nightly-2023-01-08-142418"}] to [{"raw-internal" "4.12.0-0.nightly-2023-01-08-142418"} {"kube-apiserver" "1.25.4"} {"operator" "4.12.0-0.nightly-2023-01-08-142418"}]
2023-01-09T04:44:49.834591275Z I0109 04:44:49.834575       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorVersionChanged' clusteroperator/kube-apiserver version "kube-apiserver" changed from "" to "1.25.4"
2023-01-09T04:44:49.834600488Z I0109 04:44:49.834586       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorVersionChanged' clusteroperator/kube-apiserver version "operator" changed from "" to "4.12.0-0.nightly-2023-01-08-142418"
2023-01-09T04:44:49.834822356Z I0109 04:44:49.834805       1 status_controller.go:211] clusteroperator/kube-apiserver diff {"status":{"versions":[{"name":"raw-internal","version":"4.12.0-0.nightly-2023-01-08-142418"},{"name":"kube-apiserver","version":"1.25.4"},{"name":"operator","version":"4.12.0-0.nightly-2023-01-08-142418"}]}}
2023-01-09T04:44:49.847468293Z E0109 04:44:49.847436       1 base_controller.go:272] StatusSyncer_kube-apiserver reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io "kube-apiserver": the object has been modified; please apply your changes to the latest version and try again
2023-01-09T04:44:49.885906618Z I0109 04:44:49.885873       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:44:49.901036183Z I0109 04:44:49.900968       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:44:50.222077491Z I0109 04:44:50.222041       1 request.go:601] Waited for 1.595439163s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/installer-3-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:44:50.257863666Z I0109 04:44:50.257326       1 tlsconfig.go:178] "Loaded client CA" index=0 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"admin-kubeconfig-signer\" [] issuer=\"<self>\" (2023-01-09 04:28:21 +0000 UTC to 2033-01-06 04:28:21 +0000 UTC (now=2023-01-09 04:44:50.257289211 +0000 UTC))"
2023-01-09T04:44:50.257863666Z I0109 04:44:50.257367       1 tlsconfig.go:178] "Loaded client CA" index=1 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"kubelet-signer\" [] issuer=\"<self>\" (2023-01-09 04:28:24 +0000 UTC to 2023-01-10 04:28:24 +0000 UTC (now=2023-01-09 04:44:50.257349953 +0000 UTC))"
2023-01-09T04:44:50.257863666Z I0109 04:44:50.257394       1 tlsconfig.go:178] "Loaded client CA" index=2 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"kube-control-plane-signer\" [] issuer=\"<self>\" (2023-01-09 04:28:24 +0000 UTC to 2024-01-09 04:28:24 +0000 UTC (now=2023-01-09 04:44:50.257376996 +0000 UTC))"
2023-01-09T04:44:50.257863666Z I0109 04:44:50.257421       1 tlsconfig.go:178] "Loaded client CA" index=3 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"kube-apiserver-to-kubelet-signer\" [] issuer=\"<self>\" (2023-01-09 04:28:24 +0000 UTC to 2024-01-09 04:28:24 +0000 UTC (now=2023-01-09 04:44:50.257403362 +0000 UTC))"
2023-01-09T04:44:50.257863666Z I0109 04:44:50.257447       1 tlsconfig.go:178] "Loaded client CA" index=4 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"kubelet-bootstrap-kubeconfig-signer\" [] issuer=\"<self>\" (2023-01-09 04:28:22 +0000 UTC to 2033-01-06 04:28:22 +0000 UTC (now=2023-01-09 04:44:50.257430746 +0000 UTC))"
2023-01-09T04:44:50.257863666Z I0109 04:44:50.257476       1 tlsconfig.go:178] "Loaded client CA" index=5 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"kube-csr-signer_@1673239265\" [] issuer=\"kubelet-signer\" (2023-01-09 04:41:04 +0000 UTC to 2023-01-10 04:28:24 +0000 UTC (now=2023-01-09 04:44:50.257457361 +0000 UTC))"
2023-01-09T04:44:50.257863666Z I0109 04:44:50.257504       1 tlsconfig.go:178] "Loaded client CA" index=6 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"openshift-kube-apiserver-operator_node-system-admin-signer@1673239266\" [] issuer=\"<self>\" (2023-01-09 04:41:06 +0000 UTC to 2024-01-09 04:41:07 +0000 UTC (now=2023-01-09 04:44:50.257484739 +0000 UTC))"
2023-01-09T04:44:50.257863666Z I0109 04:44:50.257530       1 tlsconfig.go:178] "Loaded client CA" index=7 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"aggregator-signer\" [] issuer=\"<self>\" (2023-01-09 04:28:22 +0000 UTC to 2023-01-10 04:28:22 +0000 UTC (now=2023-01-09 04:44:50.257514416 +0000 UTC))"
2023-01-09T04:44:50.257863666Z I0109 04:44:50.257697       1 tlsconfig.go:200] "Loaded serving cert" certName="serving-cert::/var/run/secrets/serving-cert/tls.crt::/var/run/secrets/serving-cert/tls.key" certDetail="\"metrics.openshift-kube-apiserver-operator.svc\" [serving] validServingFor=[metrics.openshift-kube-apiserver-operator.svc,metrics.openshift-kube-apiserver-operator.svc.cluster.local] issuer=\"openshift-service-serving-signer@1673239264\" (2023-01-09 04:41:14 +0000 UTC to 2025-01-08 04:41:15 +0000 UTC (now=2023-01-09 04:44:50.257675163 +0000 UTC))"
2023-01-09T04:44:50.257863666Z I0109 04:44:50.257834       1 named_certificates.go:53] "Loaded SNI cert" index=0 certName="self-signed loopback" certDetail="\"apiserver-loopback-client@1673239334\" [serving] validServingFor=[apiserver-loopback-client] issuer=\"apiserver-loopback-client-ca@1673239334\" (2023-01-09 03:42:14 +0000 UTC to 2024-01-09 03:42:14 +0000 UTC (now=2023-01-09 04:44:50.257814945 +0000 UTC))"
2023-01-09T04:44:50.992935380Z E0109 04:44:50.992892       1 degraded_webhook.go:128] dial tcp 172.30.240.111:8443: connect: connection refused
2023-01-09T04:44:51.029243066Z I0109 04:44:51.029193       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/kube-apiserver-guard-ip-10-0-199-219.us-east-2.compute.internal -n openshift-kube-apiserver because it was missing
2023-01-09T04:44:51.073095350Z E0109 04:44:51.073058       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:44:51.074796928Z I0109 04:44:51.074762       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:44:51.075168165Z I0109 04:44:51.075142       1 prune_controller.go:269] Nothing to prune
2023-01-09T04:44:51.077222934Z I0109 04:44:51.077193       1 status_controller.go:211] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:44:16Z","message":"GuardControllerDegraded: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]","reason":"GuardController_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:42:55Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 3","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 3","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:44:51.088480547Z I0109 04:44:51.088436       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded message changed from "GuardControllerDegraded: [Missing PodIP in operand kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]" to "GuardControllerDegraded: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]"
2023-01-09T04:44:51.222080693Z I0109 04:44:51.222042       1 request.go:601] Waited for 1.396170477s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:44:51.995942723Z E0109 04:44:51.995893       1 degraded_webhook.go:128] dial tcp 172.30.240.111:8443: connect: connection refused
2023-01-09T04:44:52.421422068Z I0109 04:44:52.421373       1 request.go:601] Waited for 1.348813682s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T04:44:53.047812191Z I0109 04:44:53.047768       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:44:53.247666014Z I0109 04:44:53.247621       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:44:53.264595148Z I0109 04:44:53.264551       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:44:53.285485194Z I0109 04:44:53.285441       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:44:53.422127231Z I0109 04:44:53.422090       1 request.go:601] Waited for 1.997387777s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/trusted-ca-bundle
2023-01-09T04:44:53.624786798Z I0109 04:44:53.624748       1 installer_controller.go:512] "ip-10-0-199-219.us-east-2.compute.internal" is in transition to 3, but has not made progress because static pod is pending
2023-01-09T04:44:54.065209653Z E0109 04:44:54.065169       1 degraded_webhook.go:128] dial tcp 172.30.240.111:8443: connect: connection refused
2023-01-09T04:44:54.621954480Z I0109 04:44:54.621915       1 request.go:601] Waited for 1.573724318s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:44:54.626506364Z E0109 04:44:54.626468       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:44:54.626506364Z E0109 04:44:54.626491       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:44:54.626830121Z E0109 04:44:54.626812       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:44:55.068061632Z E0109 04:44:55.068021       1 degraded_webhook.go:128] dial tcp 172.30.240.111:8443: connect: connection refused
2023-01-09T04:44:55.821653355Z I0109 04:44:55.821607       1 request.go:601] Waited for 1.596301449s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver
2023-01-09T04:44:56.821674330Z I0109 04:44:56.821632       1 request.go:601] Waited for 1.648762217s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T04:44:57.424681565Z E0109 04:44:57.424640       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:44:57.424681565Z E0109 04:44:57.424664       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:44:57.425028430Z E0109 04:44:57.425003       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:44:58.022200091Z I0109 04:44:58.022155       1 request.go:601] Waited for 1.395977276s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T04:44:59.825108754Z E0109 04:44:59.825072       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:44:59.825108754Z E0109 04:44:59.825097       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:44:59.825420694Z E0109 04:44:59.825408       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:44:59.828584857Z E0109 04:44:59.828566       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:44:59.828597667Z E0109 04:44:59.828587       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:45:00.825004665Z I0109 04:45:00.824938       1 installer_controller.go:512] "ip-10-0-199-219.us-east-2.compute.internal" is in transition to 3, but has not made progress because static pod is pending
2023-01-09T04:45:01.425323323Z E0109 04:45:01.425275       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:45:02.224742647Z E0109 04:45:02.224698       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:45:02.224742647Z E0109 04:45:02.224727       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:45:02.225131795Z E0109 04:45:02.225112       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:45:02.625493548Z E0109 04:45:02.625452       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:45:02.625493548Z E0109 04:45:02.625479       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:45:02.625822726Z E0109 04:45:02.625806       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:45:03.025175160Z E0109 04:45:03.025132       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:45:03.025175160Z E0109 04:45:03.025159       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:45:03.025489388Z E0109 04:45:03.025473       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:45:03.425882999Z E0109 04:45:03.425845       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:45:03.425882999Z E0109 04:45:03.425870       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:45:03.426246790Z E0109 04:45:03.426229       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:45:03.825478206Z E0109 04:45:03.825440       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:45:03.825478206Z E0109 04:45:03.825462       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:45:03.825812337Z E0109 04:45:03.825797       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:45:04.224809402Z E0109 04:45:04.224765       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:45:04.224809402Z E0109 04:45:04.224795       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:45:04.225186673Z E0109 04:45:04.225165       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:45:04.625305372Z E0109 04:45:04.625266       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:45:04.625305372Z E0109 04:45:04.625289       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:45:04.625633561Z E0109 04:45:04.625618       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:45:04.940238496Z E0109 04:45:04.940204       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:45:04.940238496Z E0109 04:45:04.940228       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:45:05.025804873Z E0109 04:45:05.025761       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:45:06.225730248Z I0109 04:45:06.225690       1 installer_controller.go:512] "ip-10-0-199-219.us-east-2.compute.internal" is in transition to 3, but has not made progress because static pod is pending
2023-01-09T04:45:06.455216189Z I0109 04:45:06.455182       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:45:06.527957847Z E0109 04:45:06.527921       1 degraded_webhook.go:128] dial tcp 172.30.240.111:8443: connect: connection refused
2023-01-09T04:45:06.853772670Z I0109 04:45:06.853722       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:45:07.421697239Z I0109 04:45:07.421661       1 request.go:601] Waited for 1.058355943s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T04:45:07.531186328Z E0109 04:45:07.531141       1 degraded_webhook.go:128] dial tcp 172.30.240.111:8443: connect: connection refused
2023-01-09T04:45:08.422008887Z I0109 04:45:08.421944       1 request.go:601] Waited for 1.196759863s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:45:08.425468869Z E0109 04:45:08.425427       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:45:08.425468869Z E0109 04:45:08.425454       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:45:08.425871386Z E0109 04:45:08.425839       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:45:08.429209712Z E0109 04:45:08.429181       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:45:08.429209712Z E0109 04:45:08.429203       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:45:09.597273547Z E0109 04:45:09.597233       1 degraded_webhook.go:128] dial tcp 172.30.240.111:8443: connect: connection refused
2023-01-09T04:45:09.626657742Z E0109 04:45:09.626622       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:45:10.599433892Z E0109 04:45:10.599392       1 degraded_webhook.go:128] dial tcp 172.30.240.111:8443: connect: connection refused
2023-01-09T04:45:10.825411823Z E0109 04:45:10.825368       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:45:10.825411823Z E0109 04:45:10.825406       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:45:10.825905255Z E0109 04:45:10.825887       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:45:11.225380131Z E0109 04:45:11.225339       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:45:11.225380131Z E0109 04:45:11.225364       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:45:11.225698256Z E0109 04:45:11.225684       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:45:14.454738420Z I0109 04:45:14.454675       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ObserveStorageUpdated' Updated storage urls to https://10.0.160.211:2379,https://10.0.199.219:2379,https://localhost:2379
2023-01-09T04:45:14.455211762Z I0109 04:45:14.455179       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ObservedConfigChanged' Writing updated observed config:   map[string]interface{}{
2023-01-09T04:45:14.455211762Z   	"admission": map[string]interface{}{"pluginConfig": map[string]interface{}{"network.openshift.io/ExternalIPRanger": map[string]interface{}{"configuration": map[string]interface{}{"allowIngressIP": bool(false), "apiVersion": string("network.openshift.io/v1"), "kind": string("ExternalIPRangerAdmissionConfig")}}, "network.openshift.io/RestrictedEndpointsAdmission": map[string]interface{}{"configuration": map[string]interface{}{"apiVersion": string("network.openshift.io/v1"), "kind": string("RestrictedEndpointsAdmissionConfig"), "restrictedCIDRs": []interface{}{string("10.128.0.0/14"), string("172.30.0.0/16")}}}}},
2023-01-09T04:45:14.455211762Z   	"apiServerArguments": map[string]interface{}{
2023-01-09T04:45:14.455211762Z   		... // 2 identical entries
2023-01-09T04:45:14.455211762Z   		"authentication-token-webhook-version": []interface{}{string("v1")},
2023-01-09T04:45:14.455211762Z   		"cloud-provider":                       []interface{}{string("aws")},
2023-01-09T04:45:14.455211762Z   		"etcd-servers": []interface{}{
2023-01-09T04:45:14.455211762Z + 			string("https://10.0.160.211:2379"),
2023-01-09T04:45:14.455211762Z   			string("https://10.0.199.219:2379"),
2023-01-09T04:45:14.455211762Z   			string("https://localhost:2379"),
2023-01-09T04:45:14.455211762Z   		},
2023-01-09T04:45:14.455211762Z   		"feature-gates":          []interface{}{string("APIPriorityAndFairness=true"), string("RotateKubeletServerCertificate=true"), string("DownwardAPIHugePages=true"), string("CSIMigrationAzureFile=false"), ...},
2023-01-09T04:45:14.455211762Z   		"service-account-issuer": []interface{}{string("https://kubernetes.default.svc")},
2023-01-09T04:45:14.455211762Z   		... // 2 identical entries
2023-01-09T04:45:14.455211762Z   	},
2023-01-09T04:45:14.455211762Z   	"corsAllowedOrigins":          []interface{}{string(`//127\.0\.0\.1(:|$)`), string("//localhost(:|$)")},
2023-01-09T04:45:14.455211762Z   	"gracefulTerminationDuration": string("194"),
2023-01-09T04:45:14.455211762Z   	... // 2 identical entries
2023-01-09T04:45:14.455211762Z   }
2023-01-09T04:45:14.472105435Z I0109 04:45:14.472053       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ObserveStorageUpdated' Updated storage urls to https://10.0.160.211:2379,https://10.0.199.219:2379,https://localhost:2379
2023-01-09T04:45:14.472105435Z I0109 04:45:14.472078       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ObservedConfigChanged' Writing updated observed config:   map[string]interface{}{
2023-01-09T04:45:14.472105435Z   	"admission": map[string]interface{}{"pluginConfig": map[string]interface{}{"network.openshift.io/ExternalIPRanger": map[string]interface{}{"configuration": map[string]interface{}{"allowIngressIP": bool(false), "apiVersion": string("network.openshift.io/v1"), "kind": string("ExternalIPRangerAdmissionConfig")}}, "network.openshift.io/RestrictedEndpointsAdmission": map[string]interface{}{"configuration": map[string]interface{}{"apiVersion": string("network.openshift.io/v1"), "kind": string("RestrictedEndpointsAdmissionConfig"), "restrictedCIDRs": []interface{}{string("10.128.0.0/14"), string("172.30.0.0/16")}}}}},
2023-01-09T04:45:14.472105435Z   	"apiServerArguments": map[string]interface{}{
2023-01-09T04:45:14.472105435Z   		... // 2 identical entries
2023-01-09T04:45:14.472105435Z   		"authentication-token-webhook-version": []interface{}{string("v1")},
2023-01-09T04:45:14.472105435Z   		"cloud-provider":                       []interface{}{string("aws")},
2023-01-09T04:45:14.472105435Z   		"etcd-servers": []interface{}{
2023-01-09T04:45:14.472105435Z + 			string("https://10.0.160.211:2379"),
2023-01-09T04:45:14.472105435Z   			string("https://10.0.199.219:2379"),
2023-01-09T04:45:14.472105435Z   			string("https://localhost:2379"),
2023-01-09T04:45:14.472105435Z   		},
2023-01-09T04:45:14.472105435Z   		"feature-gates":          []interface{}{string("APIPriorityAndFairness=true"), string("RotateKubeletServerCertificate=true"), string("DownwardAPIHugePages=true"), string("CSIMigrationAzureFile=false"), ...},
2023-01-09T04:45:14.472105435Z   		"service-account-issuer": []interface{}{string("https://kubernetes.default.svc")},
2023-01-09T04:45:14.472105435Z   		... // 2 identical entries
2023-01-09T04:45:14.472105435Z   	},
2023-01-09T04:45:14.472105435Z   	"corsAllowedOrigins":          []interface{}{string(`//127\.0\.0\.1(:|$)`), string("//localhost(:|$)")},
2023-01-09T04:45:14.472105435Z   	"gracefulTerminationDuration": string("194"),
2023-01-09T04:45:14.472105435Z   	... // 2 identical entries
2023-01-09T04:45:14.472105435Z   }
2023-01-09T04:45:14.474272055Z I0109 04:45:14.474238       1 prune_controller.go:269] Nothing to prune
2023-01-09T04:45:14.477966613Z I0109 04:45:14.477878       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:45:14.490827147Z I0109 04:45:14.490775       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapUpdated' Updated ConfigMap/config -n openshift-kube-apiserver:
2023-01-09T04:45:14.490827147Z cause by changes in data.config.yaml
2023-01-09T04:45:14.494763120Z I0109 04:45:14.494722       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionTriggered' new revision 4 triggered by "configmap/config has changed"
2023-01-09T04:45:15.670180735Z I0109 04:45:15.670131       1 request.go:601] Waited for 1.175420015s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps
2023-01-09T04:45:15.674587232Z I0109 04:45:15.674552       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/revision-status-4 -n openshift-kube-apiserver because it was missing
2023-01-09T04:45:16.477823253Z I0109 04:45:16.477769       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-apiserver-pod-4 -n openshift-kube-apiserver because it was missing
2023-01-09T04:45:16.519504896Z E0109 04:45:16.519471       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:45:17.070482305Z I0109 04:45:17.070440       1 request.go:601] Waited for 1.114880832s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2023-01-09T04:45:17.876200561Z I0109 04:45:17.876150       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/config-4 -n openshift-kube-apiserver because it was missing
2023-01-09T04:45:18.270315209Z I0109 04:45:18.270279       1 request.go:601] Waited for 1.587650612s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T04:45:19.270569944Z I0109 04:45:19.270530       1 request.go:601] Waited for 1.596723013s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/trusted-ca-bundle
2023-01-09T04:45:19.478203553Z I0109 04:45:19.478151       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-apiserver-cert-syncer-kubeconfig-4 -n openshift-kube-apiserver because it was missing
2023-01-09T04:45:19.673573079Z E0109 04:45:19.673532       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:45:19.684612314Z E0109 04:45:19.684573       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal]
2023-01-09T04:45:19.685613619Z I0109 04:45:19.685581       1 prune_controller.go:269] Nothing to prune
2023-01-09T04:45:19.687484080Z I0109 04:45:19.687451       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:45:19.687556852Z I0109 04:45:19.687538       1 status_controller.go:211] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:44:16Z","message":"GuardControllerDegraded: [Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal]","reason":"GuardController_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:42:55Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 3","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 3","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:45:19.694798633Z I0109 04:45:19.694699       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded message changed from "GuardControllerDegraded: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]" to "GuardControllerDegraded: [Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal]"
2023-01-09T04:45:20.469783562Z I0109 04:45:20.469741       1 request.go:601] Waited for 1.37037666s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2023-01-09T04:45:20.888180065Z I0109 04:45:20.888129       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/bound-sa-token-signing-certs-4 -n openshift-kube-apiserver because it was missing
2023-01-09T04:45:21.470001663Z I0109 04:45:21.469946       1 request.go:601] Waited for 1.782178912s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:45:22.470576425Z I0109 04:45:22.470537       1 request.go:601] Waited for 1.797204824s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/localhost-recovery-client-token
2023-01-09T04:45:22.673944734Z I0109 04:45:22.673889       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/etcd-serving-ca-4 -n openshift-kube-apiserver because it was missing
2023-01-09T04:45:23.072938341Z E0109 04:45:23.072897       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:45:23.072938341Z E0109 04:45:23.072925       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:45:23.084502866Z E0109 04:45:23.084462       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:45:23.085876696Z I0109 04:45:23.085846       1 prune_controller.go:269] Nothing to prune
2023-01-09T04:45:23.085926708Z I0109 04:45:23.085886       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:45:23.086965780Z I0109 04:45:23.086931       1 status_controller.go:211] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:44:16Z","message":"GuardControllerDegraded: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]","reason":"GuardController_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:42:55Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 3","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 3","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:45:23.094142065Z I0109 04:45:23.094102       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded message changed from "GuardControllerDegraded: [Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal]" to "GuardControllerDegraded: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]"
2023-01-09T04:45:23.670089886Z I0109 04:45:23.670044       1 request.go:601] Waited for 1.596625629s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:45:24.275469605Z I0109 04:45:24.275414       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-apiserver-server-ca-4 -n openshift-kube-apiserver because it was missing
2023-01-09T04:45:24.870370316Z I0109 04:45:24.870331       1 request.go:601] Waited for 1.596891852s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T04:45:25.054267083Z I0109 04:45:25.054220       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:45:25.144630484Z I0109 04:45:25.144585       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:45:25.144880694Z I0109 04:45:25.144846       1 prune_controller.go:269] Nothing to prune
2023-01-09T04:45:25.452953683Z I0109 04:45:25.452897       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:45:26.070302315Z I0109 04:45:26.070261       1 request.go:601] Waited for 1.795010072s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps
2023-01-09T04:45:26.083336214Z I0109 04:45:26.083089       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kubelet-serving-ca-4 -n openshift-kube-apiserver because it was missing
2023-01-09T04:45:26.684261541Z E0109 04:45:26.684203       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:45:26.684261541Z E0109 04:45:26.684231       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:45:26.684634901Z E0109 04:45:26.684589       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:45:27.070497884Z I0109 04:45:27.070455       1 request.go:601] Waited for 1.78944801s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T04:45:27.874259718Z I0109 04:45:27.874203       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/sa-token-signing-certs-4 -n openshift-kube-apiserver because it was missing
2023-01-09T04:45:28.270205908Z I0109 04:45:28.270164       1 request.go:601] Waited for 1.792275765s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T04:45:29.270541626Z I0109 04:45:29.270494       1 request.go:601] Waited for 1.797603697s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver
2023-01-09T04:45:29.674389692Z I0109 04:45:29.674333       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-apiserver-audit-policies-4 -n openshift-kube-apiserver because it was missing
2023-01-09T04:45:30.272706158Z E0109 04:45:30.272667       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:45:30.272706158Z E0109 04:45:30.272693       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:45:30.273098774Z E0109 04:45:30.273078       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:45:30.469945600Z I0109 04:45:30.469908       1 request.go:601] Waited for 1.793093626s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2023-01-09T04:45:31.477713450Z I0109 04:45:31.477651       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/etcd-client-4 -n openshift-kube-apiserver because it was missing
2023-01-09T04:45:31.670019672Z I0109 04:45:31.669959       1 request.go:601] Waited for 1.790418706s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:45:32.670303853Z I0109 04:45:32.670266       1 request.go:601] Waited for 1.543681287s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver
2023-01-09T04:45:33.473236326Z E0109 04:45:33.473198       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:45:33.473236326Z E0109 04:45:33.473223       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:45:33.473607623Z E0109 04:45:33.473591       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:45:33.670315512Z I0109 04:45:33.670281       1 request.go:601] Waited for 1.187926933s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T04:45:34.278810793Z I0109 04:45:34.278758       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/localhost-recovery-serving-certkey-4 -n openshift-kube-apiserver because it was missing
2023-01-09T04:45:34.670529472Z I0109 04:45:34.670484       1 request.go:601] Waited for 1.193857245s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:45:34.891408487Z I0109 04:45:34.891314       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:45:34.893903412Z I0109 04:45:34.893563       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:45:35.275312787Z I0109 04:45:35.275263       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/localhost-recovery-client-token-4 -n openshift-kube-apiserver because it was missing
2023-01-09T04:45:35.673082974Z E0109 04:45:35.673036       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:45:35.673082974Z E0109 04:45:35.673061       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:45:35.673426445Z E0109 04:45:35.673410       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:45:35.676326165Z E0109 04:45:35.676298       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:45:35.676326165Z E0109 04:45:35.676320       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:45:36.277385738Z I0109 04:45:36.277316       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/webhook-authenticator-4 -n openshift-kube-apiserver because it was missing
2023-01-09T04:45:36.294463405Z I0109 04:45:36.294414       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionCreate' Revision 3 created because configmap/config has changed
2023-01-09T04:45:36.299148663Z I0109 04:45:36.299111       1 prune_controller.go:269] Nothing to prune
2023-01-09T04:45:36.300019907Z I0109 04:45:36.299976       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:45:36.313267744Z I0109 04:45:36.313222       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionTriggered' new revision 4 triggered by "configmap/config has changed"
2023-01-09T04:45:37.470527972Z I0109 04:45:37.470487       1 request.go:601] Waited for 1.169648171s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:45:37.674810690Z W0109 04:45:37.674774       1 staticpod.go:38] revision 4 is unexpectedly already the latest available revision. This is a possible race!
2023-01-09T04:45:37.688099835Z E0109 04:45:37.688061       1 base_controller.go:272] RevisionController reconciliation failed: conflicting latestAvailableRevision 4
2023-01-09T04:45:37.688888984Z I0109 04:45:37.688849       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:45:37.689293794Z I0109 04:45:37.689258       1 status_controller.go:211] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:44:16Z","message":"GuardControllerDegraded: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]\nRevisionControllerDegraded: conflicting latestAvailableRevision 4","reason":"GuardController_SyncError::RevisionController_Error","status":"True","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:42:55Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 3","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 3","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:45:37.689640832Z I0109 04:45:37.689267       1 prune_controller.go:269] Nothing to prune
2023-01-09T04:45:37.701551562Z I0109 04:45:37.701505       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded message changed from "GuardControllerDegraded: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]" to "GuardControllerDegraded: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]\nRevisionControllerDegraded: conflicting latestAvailableRevision 4"
2023-01-09T04:45:37.708721501Z I0109 04:45:37.708687       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:45:37.709249006Z I0109 04:45:37.709224       1 prune_controller.go:269] Nothing to prune
2023-01-09T04:45:37.710699942Z I0109 04:45:37.710663       1 status_controller.go:211] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:44:16Z","message":"GuardControllerDegraded: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]","reason":"GuardController_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:42:55Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 3","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 3","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:45:37.720325260Z I0109 04:45:37.720286       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded message changed from "GuardControllerDegraded: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]\nRevisionControllerDegraded: conflicting latestAvailableRevision 4" to "GuardControllerDegraded: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]"
2023-01-09T04:45:37.778032717Z I0109 04:45:37.777976       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:45:38.472876656Z E0109 04:45:38.472833       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:45:38.475769920Z E0109 04:45:38.475738       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:45:38.475769920Z E0109 04:45:38.475759       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:45:38.670150372Z I0109 04:45:38.670112       1 request.go:601] Waited for 1.768143701s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2023-01-09T04:45:39.670294405Z I0109 04:45:39.670253       1 request.go:601] Waited for 1.596678896s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:45:40.670323007Z I0109 04:45:40.670279       1 request.go:601] Waited for 1.596825287s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:45:41.273692381Z E0109 04:45:41.273651       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:45:41.276465089Z E0109 04:45:41.276437       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:45:41.276465089Z E0109 04:45:41.276458       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:45:41.670348555Z I0109 04:45:41.670305       1 request.go:601] Waited for 1.191876803s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2023-01-09T04:45:42.073469955Z I0109 04:45:42.073422       1 installer_controller.go:500] "ip-10-0-199-219.us-east-2.compute.internal" moving to (v1.NodeStatus) {
2023-01-09T04:45:42.073469955Z  NodeName: (string) (len=42) "ip-10-0-199-219.us-east-2.compute.internal",
2023-01-09T04:45:42.073469955Z  CurrentRevision: (int32) 0,
2023-01-09T04:45:42.073469955Z  TargetRevision: (int32) 4,
2023-01-09T04:45:42.073469955Z  LastFailedRevision: (int32) 0,
2023-01-09T04:45:42.073469955Z  LastFailedTime: (*v1.Time)(<nil>),
2023-01-09T04:45:42.073469955Z  LastFailedReason: (string) "",
2023-01-09T04:45:42.073469955Z  LastFailedCount: (int) 0,
2023-01-09T04:45:42.073469955Z  LastFallbackCount: (int) 0,
2023-01-09T04:45:42.073469955Z  LastFailedRevisionErrors: ([]string) <nil>
2023-01-09T04:45:42.073469955Z }
2023-01-09T04:45:42.073469955Z  because new revision pending
2023-01-09T04:45:42.086559279Z I0109 04:45:42.086516       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:45:42.087394016Z I0109 04:45:42.087361       1 prune_controller.go:269] Nothing to prune
2023-01-09T04:45:42.087983922Z I0109 04:45:42.087948       1 status_controller.go:211] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:44:16Z","message":"GuardControllerDegraded: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]","reason":"GuardController_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:42:55Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 4","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 4","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:45:42.097218413Z I0109 04:45:42.097173       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Progressing message changed from "NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 3" to "NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 4",Available message changed from "StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 3" to "StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 4"
2023-01-09T04:45:43.270458798Z I0109 04:45:43.270414       1 request.go:601] Waited for 1.184210673s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T04:45:43.653460251Z I0109 04:45:43.653415       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:45:43.873273218Z E0109 04:45:43.873231       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:45:43.876289594Z E0109 04:45:43.876254       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:45:44.053359395Z I0109 04:45:44.053318       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:45:44.270520182Z I0109 04:45:44.270480       1 request.go:601] Waited for 1.593725829s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/config
2023-01-09T04:45:45.470181600Z I0109 04:45:45.470135       1 request.go:601] Waited for 1.194584066s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-pod
2023-01-09T04:45:46.073025454Z E0109 04:45:46.072972       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:45:46.086763740Z E0109 04:45:46.086721       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal]
2023-01-09T04:45:46.089022021Z I0109 04:45:46.088964       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:45:46.089876849Z I0109 04:45:46.089842       1 prune_controller.go:269] Nothing to prune
2023-01-09T04:45:46.089922285Z I0109 04:45:46.089887       1 status_controller.go:211] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:44:16Z","message":"GuardControllerDegraded: [Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal]","reason":"GuardController_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:42:55Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 4","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 4","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:45:46.099901122Z I0109 04:45:46.098787       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded message changed from "GuardControllerDegraded: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]" to "GuardControllerDegraded: [Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal]"
2023-01-09T04:45:47.270599790Z I0109 04:45:47.270561       1 request.go:601] Waited for 1.182308248s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T04:45:48.469957306Z I0109 04:45:48.469913       1 request.go:601] Waited for 1.597109171s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods
2023-01-09T04:45:48.480408840Z I0109 04:45:48.480354       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/installer-4-ip-10-0-199-219.us-east-2.compute.internal -n openshift-kube-apiserver because it was missing
2023-01-09T04:45:49.470545935Z I0109 04:45:49.470502       1 request.go:601] Waited for 1.397725933s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:45:49.473713823Z E0109 04:45:49.473676       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:45:49.473713823Z E0109 04:45:49.473702       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:45:49.486439295Z E0109 04:45:49.486400       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:45:49.487177514Z I0109 04:45:49.487142       1 prune_controller.go:269] Nothing to prune
2023-01-09T04:45:49.488575227Z I0109 04:45:49.488544       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:45:49.489350429Z I0109 04:45:49.489316       1 status_controller.go:211] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:44:16Z","message":"GuardControllerDegraded: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]","reason":"GuardController_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:42:55Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 4","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 4","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:45:49.500505202Z I0109 04:45:49.498124       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded message changed from "GuardControllerDegraded: [Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal]" to "GuardControllerDegraded: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]"
2023-01-09T04:45:49.873405014Z I0109 04:45:49.873360       1 installer_controller.go:512] "ip-10-0-199-219.us-east-2.compute.internal" is in transition to 4, but has not made progress because installer is not finished, but in Running phase
2023-01-09T04:45:50.669977591Z I0109 04:45:50.669939       1 request.go:601] Waited for 1.39205325s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2023-01-09T04:45:51.670604974Z I0109 04:45:51.670564       1 request.go:601] Waited for 1.997414738s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:45:52.869638714Z I0109 04:45:52.869595       1 request.go:601] Waited for 1.394326527s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:45:52.872636652Z E0109 04:45:52.872601       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:45:52.872636652Z E0109 04:45:52.872625       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:45:52.872957945Z E0109 04:45:52.872939       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:45:52.875808412Z E0109 04:45:52.875782       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:45:52.875808412Z E0109 04:45:52.875804       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:45:54.228638796Z I0109 04:45:54.228598       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:45:54.873953085Z E0109 04:45:54.873914       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:45:55.385062531Z I0109 04:45:55.385025       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:45:55.398238257Z I0109 04:45:55.398205       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:45:55.873020987Z I0109 04:45:55.872974       1 installer_controller.go:512] "ip-10-0-199-219.us-east-2.compute.internal" is in transition to 4, but has not made progress because installer is not finished, but in Running phase
2023-01-09T04:45:57.315706407Z I0109 04:45:57.315669       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:45:57.379343780Z E0109 04:45:57.379302       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T04:45:57.534646584Z I0109 04:45:57.534614       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:45:57.666605064Z I0109 04:45:57.666569       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:45:57.682683011Z I0109 04:45:57.682639       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:45:58.384973839Z E0109 04:45:58.384938       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T04:45:58.853038805Z E0109 04:45:58.852976       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:45:58.853038805Z E0109 04:45:58.853021       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:45:58.853506421Z E0109 04:45:58.853491       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:45:59.564739215Z E0109 04:45:59.564703       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:45:59.564739215Z E0109 04:45:59.564728       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:45:59.565093638Z E0109 04:45:59.565073       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:46:00.410199041Z I0109 04:46:00.410158       1 prune_controller.go:269] Nothing to prune
2023-01-09T04:46:00.412582088Z I0109 04:46:00.412464       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:46:00.506500062Z I0109 04:46:00.506462       1 prune_controller.go:269] Nothing to prune
2023-01-09T04:46:00.507717740Z I0109 04:46:00.507621       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:46:01.157699865Z I0109 04:46:01.157651       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:46:01.610294912Z I0109 04:46:01.610241       1 request.go:601] Waited for 1.102579103s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T04:46:03.013774723Z I0109 04:46:03.013729       1 installer_controller.go:512] "ip-10-0-199-219.us-east-2.compute.internal" is in transition to 4, but has not made progress because installer is not finished, but in Running phase
2023-01-09T04:46:04.418205258Z I0109 04:46:04.418144       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapUpdated' Updated ConfigMap/sa-token-signing-certs -n openshift-kube-apiserver:
2023-01-09T04:46:04.418205258Z cause by changes in data.service-account-002.pub
2023-01-09T04:46:04.418701543Z I0109 04:46:04.418667       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionTriggered' new revision 5 triggered by "configmap/sa-token-signing-certs has changed"
2023-01-09T04:46:05.414960703Z I0109 04:46:05.414868       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/revision-status-5 -n openshift-kube-apiserver because it was missing
2023-01-09T04:46:05.609516708Z I0109 04:46:05.609467       1 request.go:601] Waited for 1.190579144s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T04:46:06.609729821Z I0109 04:46:06.609695       1 request.go:601] Waited for 1.194821524s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps
2023-01-09T04:46:06.616535463Z I0109 04:46:06.616488       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-apiserver-pod-5 -n openshift-kube-apiserver because it was missing
2023-01-09T04:46:07.809964051Z I0109 04:46:07.809924       1 request.go:601] Waited for 1.19353364s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps
2023-01-09T04:46:07.815633104Z I0109 04:46:07.815587       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/config-5 -n openshift-kube-apiserver because it was missing
2023-01-09T04:46:08.213062145Z I0109 04:46:08.213016       1 installer_controller.go:512] "ip-10-0-199-219.us-east-2.compute.internal" is in transition to 4, but has not made progress because installer is not finished, but in Running phase
2023-01-09T04:46:09.009947439Z I0109 04:46:09.009901       1 request.go:601] Waited for 1.194367656s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps
2023-01-09T04:46:09.016048276Z I0109 04:46:09.015978       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-apiserver-cert-syncer-kubeconfig-5 -n openshift-kube-apiserver because it was missing
2023-01-09T04:46:09.227284154Z I0109 04:46:09.227233       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:46:10.014642767Z I0109 04:46:10.014574       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/bound-sa-token-signing-certs-5 -n openshift-kube-apiserver because it was missing
2023-01-09T04:46:11.015111555Z I0109 04:46:11.015058       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/etcd-serving-ca-5 -n openshift-kube-apiserver because it was missing
2023-01-09T04:46:12.016141858Z I0109 04:46:12.016072       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-apiserver-server-ca-5 -n openshift-kube-apiserver because it was missing
2023-01-09T04:46:13.015713954Z I0109 04:46:13.015578       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kubelet-serving-ca-5 -n openshift-kube-apiserver because it was missing
2023-01-09T04:46:14.015150314Z I0109 04:46:14.015104       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/sa-token-signing-certs-5 -n openshift-kube-apiserver because it was missing
2023-01-09T04:46:15.017124712Z I0109 04:46:15.017073       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-apiserver-audit-policies-5 -n openshift-kube-apiserver because it was missing
2023-01-09T04:46:15.037974009Z E0109 04:46:15.037919       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:46:15.108788410Z I0109 04:46:15.108751       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:46:15.128983228Z I0109 04:46:15.128932       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:46:15.129375573Z I0109 04:46:15.129333       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:46:16.015583377Z I0109 04:46:16.015530       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/etcd-client-5 -n openshift-kube-apiserver because it was missing
2023-01-09T04:46:16.209843280Z I0109 04:46:16.209805       1 request.go:601] Waited for 1.171468232s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:46:17.410059755Z I0109 04:46:17.409983       1 request.go:601] Waited for 1.453708625s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:46:17.813264885Z E0109 04:46:17.813233       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:46:17.824574919Z E0109 04:46:17.824540       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal]
2023-01-09T04:46:17.826513463Z I0109 04:46:17.826482       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:46:17.826932127Z I0109 04:46:17.826895       1 prune_controller.go:269] Nothing to prune
2023-01-09T04:46:17.828357156Z I0109 04:46:17.828328       1 status_controller.go:211] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:44:16Z","message":"GuardControllerDegraded: [Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal]","reason":"GuardController_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:42:55Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 4","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 4","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:46:17.836317462Z I0109 04:46:17.836265       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded message changed from "GuardControllerDegraded: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]" to "GuardControllerDegraded: [Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal]"
2023-01-09T04:46:18.418038455Z I0109 04:46:18.416980       1 request.go:601] Waited for 1.558462446s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver
2023-01-09T04:46:19.218818877Z I0109 04:46:19.218762       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/localhost-recovery-serving-certkey-5 -n openshift-kube-apiserver because it was missing
2023-01-09T04:46:19.609896883Z I0109 04:46:19.609860       1 request.go:601] Waited for 1.781722885s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:46:20.609982421Z I0109 04:46:20.609945       1 request.go:601] Waited for 1.793270464s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2023-01-09T04:46:21.016172093Z I0109 04:46:21.016123       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/localhost-recovery-client-token-5 -n openshift-kube-apiserver because it was missing
2023-01-09T04:46:21.229332612Z E0109 04:46:21.229289       1 degraded_webhook.go:128] dial tcp 172.30.166.45:9443: connect: connection refused
2023-01-09T04:46:21.412590053Z E0109 04:46:21.412557       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:46:21.412590053Z E0109 04:46:21.412581       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:46:21.424374770Z E0109 04:46:21.424334       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:46:21.426162008Z I0109 04:46:21.426126       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:46:21.426252302Z I0109 04:46:21.426231       1 prune_controller.go:269] Nothing to prune
2023-01-09T04:46:21.427062158Z I0109 04:46:21.427030       1 status_controller.go:211] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:44:16Z","message":"GuardControllerDegraded: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]","reason":"GuardController_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:42:55Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 4","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 4","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:46:21.438504106Z I0109 04:46:21.436395       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded message changed from "GuardControllerDegraded: [Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal]" to "GuardControllerDegraded: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]"
2023-01-09T04:46:21.810166566Z I0109 04:46:21.810124       1 request.go:601] Waited for 1.568188659s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2023-01-09T04:46:22.231652482Z E0109 04:46:22.231612       1 degraded_webhook.go:128] dial tcp 172.30.166.45:9443: connect: connection refused
2023-01-09T04:46:22.617051815Z I0109 04:46:22.616979       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/webhook-authenticator-5 -n openshift-kube-apiserver because it was missing
2023-01-09T04:46:22.628927347Z I0109 04:46:22.628874       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionCreate' Revision 4 created because configmap/sa-token-signing-certs has changed
2023-01-09T04:46:22.629785969Z I0109 04:46:22.629747       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:46:22.630167893Z I0109 04:46:22.630137       1 prune_controller.go:269] Nothing to prune
2023-01-09T04:46:22.632201111Z I0109 04:46:22.632161       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionTriggered' new revision 5 triggered by "secret/localhost-recovery-client-token has changed,configmap/sa-token-signing-certs has changed"
2023-01-09T04:46:22.810174953Z I0109 04:46:22.810135       1 request.go:601] Waited for 1.596823705s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:46:23.346498166Z I0109 04:46:23.346438       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:46:23.738932651Z I0109 04:46:23.738889       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:46:24.010162493Z I0109 04:46:24.010123       1 request.go:601] Waited for 1.596630032s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:46:24.216133007Z I0109 04:46:24.216078       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapUpdated' Updated ConfigMap/revision-status-5 -n openshift-kube-apiserver:
2023-01-09T04:46:24.216133007Z cause by changes in data.reason
2023-01-09T04:46:24.226718971Z I0109 04:46:24.226673       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:46:24.252726304Z I0109 04:46:24.252682       1 prune_controller.go:269] Nothing to prune
2023-01-09T04:46:24.253917641Z I0109 04:46:24.253866       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:46:24.327229818Z E0109 04:46:24.327192       1 degraded_webhook.go:128] dial tcp 172.30.166.45:9443: connect: connection refused
2023-01-09T04:46:25.209716855Z I0109 04:46:25.209657       1 request.go:601] Waited for 1.591324082s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T04:46:25.330315785Z E0109 04:46:25.330275       1 degraded_webhook.go:128] dial tcp 172.30.166.45:9443: connect: connection refused
2023-01-09T04:46:25.815721718Z W0109 04:46:25.815680       1 staticpod.go:38] revision 5 is unexpectedly already the latest available revision. This is a possible race!
2023-01-09T04:46:25.827499044Z E0109 04:46:25.827462       1 base_controller.go:272] RevisionController reconciliation failed: conflicting latestAvailableRevision 5
2023-01-09T04:46:25.829923417Z I0109 04:46:25.829889       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:46:25.830181206Z I0109 04:46:25.830158       1 status_controller.go:211] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:44:16Z","message":"GuardControllerDegraded: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]\nRevisionControllerDegraded: conflicting latestAvailableRevision 5","reason":"GuardController_SyncError::RevisionController_Error","status":"True","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:42:55Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 4","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 4","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:46:25.830275667Z I0109 04:46:25.830257       1 prune_controller.go:269] Nothing to prune
2023-01-09T04:46:25.839097390Z I0109 04:46:25.837777       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded message changed from "GuardControllerDegraded: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]" to "GuardControllerDegraded: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]\nRevisionControllerDegraded: conflicting latestAvailableRevision 5"
2023-01-09T04:46:25.843926546Z I0109 04:46:25.843899       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:46:25.844343823Z I0109 04:46:25.844326       1 prune_controller.go:269] Nothing to prune
2023-01-09T04:46:25.845177233Z I0109 04:46:25.845140       1 status_controller.go:211] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:44:16Z","message":"GuardControllerDegraded: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]","reason":"GuardController_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:42:55Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 4","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 4","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:46:25.856234462Z I0109 04:46:25.856187       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded message changed from "GuardControllerDegraded: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]\nRevisionControllerDegraded: conflicting latestAvailableRevision 5" to "GuardControllerDegraded: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]"
2023-01-09T04:46:26.013506302Z I0109 04:46:26.013464       1 installer_controller.go:512] "ip-10-0-199-219.us-east-2.compute.internal" is in transition to 4, but has not made progress because installer is not finished, but in Running phase
2023-01-09T04:46:26.025783247Z I0109 04:46:26.025746       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:46:26.025838928Z I0109 04:46:26.025755       1 prune_controller.go:269] Nothing to prune
2023-01-09T04:46:26.027421848Z I0109 04:46:26.027388       1 status_controller.go:211] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:44:16Z","message":"GuardControllerDegraded: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]","reason":"GuardController_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:42:55Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 5","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 5","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:46:26.036166714Z I0109 04:46:26.035098       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Progressing message changed from "NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 4" to "NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 5",Available message changed from "StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 4" to "StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 5"
2023-01-09T04:46:26.181143076Z I0109 04:46:26.181097       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:46:26.209752228Z I0109 04:46:26.209714       1 request.go:601] Waited for 1.596076154s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T04:46:26.213657063Z I0109 04:46:26.213625       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:46:26.913745000Z I0109 04:46:26.913676       1 termination_observer.go:236] Observed event "TerminationPreShutdownHooksFinished" for API server pod "kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal" (last termination at 2023-01-09 04:44:45 +0000 UTC) at 0001-01-01 00:00:00 +0000 UTC
2023-01-09T04:46:27.409346269Z E0109 04:46:27.409302       1 degraded_webhook.go:128] dial tcp 172.30.166.45:9443: connect: connection refused
2023-01-09T04:46:27.410436142Z I0109 04:46:27.410417       1 request.go:601] Waited for 1.384836335s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:46:27.866076245Z I0109 04:46:27.866039       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:46:27.881489024Z I0109 04:46:27.881448       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:46:28.388361935Z I0109 04:46:28.388325       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:46:28.412192422Z E0109 04:46:28.412156       1 degraded_webhook.go:128] dial tcp 172.30.166.45:9443: connect: connection refused
2023-01-09T04:46:28.522832495Z I0109 04:46:28.522797       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:46:28.609757337Z I0109 04:46:28.609725       1 request.go:601] Waited for 1.396985394s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:46:29.610064179Z I0109 04:46:29.610022       1 request.go:601] Waited for 1.957802711s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:46:30.497570718Z E0109 04:46:30.497532       1 degraded_webhook.go:128] dial tcp 172.30.166.45:9443: connect: connection refused
2023-01-09T04:46:30.810391644Z I0109 04:46:30.810354       1 request.go:601] Waited for 1.197131492s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:46:30.813387133Z E0109 04:46:30.813362       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:46:30.813387133Z E0109 04:46:30.813383       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:46:30.813688297Z E0109 04:46:30.813675       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:46:31.499879549Z E0109 04:46:31.499840       1 degraded_webhook.go:128] dial tcp 172.30.166.45:9443: connect: connection refused
2023-01-09T04:46:32.010388040Z I0109 04:46:32.010353       1 request.go:601] Waited for 1.397657273s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/installer-4-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:46:32.013716785Z I0109 04:46:32.013693       1 installer_controller.go:500] "ip-10-0-199-219.us-east-2.compute.internal" moving to (v1.NodeStatus) {
2023-01-09T04:46:32.013716785Z  NodeName: (string) (len=42) "ip-10-0-199-219.us-east-2.compute.internal",
2023-01-09T04:46:32.013716785Z  CurrentRevision: (int32) 0,
2023-01-09T04:46:32.013716785Z  TargetRevision: (int32) 5,
2023-01-09T04:46:32.013716785Z  LastFailedRevision: (int32) 0,
2023-01-09T04:46:32.013716785Z  LastFailedTime: (*v1.Time)(<nil>),
2023-01-09T04:46:32.013716785Z  LastFailedReason: (string) "",
2023-01-09T04:46:32.013716785Z  LastFailedCount: (int) 0,
2023-01-09T04:46:32.013716785Z  LastFallbackCount: (int) 0,
2023-01-09T04:46:32.013716785Z  LastFailedRevisionErrors: ([]string) <nil>
2023-01-09T04:46:32.013716785Z }
2023-01-09T04:46:32.013716785Z  because new revision pending
2023-01-09T04:46:32.027638239Z I0109 04:46:32.027600       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:46:32.027837819Z I0109 04:46:32.027807       1 prune_controller.go:269] Nothing to prune
2023-01-09T04:46:33.209673095Z I0109 04:46:33.209629       1 request.go:601] Waited for 1.182405607s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2023-01-09T04:46:33.813191544Z E0109 04:46:33.813153       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:46:33.813191544Z E0109 04:46:33.813181       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:46:33.813724017Z E0109 04:46:33.813706       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:46:34.030362370Z E0109 04:46:34.030311       1 degraded_webhook.go:128] dial tcp 172.30.166.45:9443: connect: connection refused
2023-01-09T04:46:34.410084362Z I0109 04:46:34.410049       1 request.go:601] Waited for 1.596560898s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:46:35.032715669Z E0109 04:46:35.032678       1 degraded_webhook.go:128] dial tcp 172.30.166.45:9443: connect: connection refused
2023-01-09T04:46:36.413219551Z I0109 04:46:36.413181       1 installer_controller.go:500] "ip-10-0-199-219.us-east-2.compute.internal" moving to (v1.NodeStatus) {
2023-01-09T04:46:36.413219551Z  NodeName: (string) (len=42) "ip-10-0-199-219.us-east-2.compute.internal",
2023-01-09T04:46:36.413219551Z  CurrentRevision: (int32) 0,
2023-01-09T04:46:36.413219551Z  TargetRevision: (int32) 5,
2023-01-09T04:46:36.413219551Z  LastFailedRevision: (int32) 0,
2023-01-09T04:46:36.413219551Z  LastFailedTime: (*v1.Time)(<nil>),
2023-01-09T04:46:36.413219551Z  LastFailedReason: (string) "",
2023-01-09T04:46:36.413219551Z  LastFailedCount: (int) 0,
2023-01-09T04:46:36.413219551Z  LastFallbackCount: (int) 0,
2023-01-09T04:46:36.413219551Z  LastFailedRevisionErrors: ([]string) <nil>
2023-01-09T04:46:36.413219551Z }
2023-01-09T04:46:36.413219551Z  because new revision pending
2023-01-09T04:46:37.132101832Z E0109 04:46:37.132063       1 degraded_webhook.go:128] dial tcp 172.30.166.45:9443: connect: connection refused
2023-01-09T04:46:38.134625542Z E0109 04:46:38.134571       1 degraded_webhook.go:128] dial tcp 172.30.166.45:9443: connect: connection refused
2023-01-09T04:46:39.421880384Z I0109 04:46:39.420899       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/installer-5-ip-10-0-199-219.us-east-2.compute.internal -n openshift-kube-apiserver because it was missing
2023-01-09T04:46:39.813351012Z E0109 04:46:39.813312       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:46:39.813351012Z E0109 04:46:39.813336       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:46:39.813673172Z E0109 04:46:39.813659       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:46:40.013357396Z I0109 04:46:40.013295       1 installer_controller.go:512] "ip-10-0-199-219.us-east-2.compute.internal" is in transition to 5, but has not made progress because installer is not finished, but in Pending phase
2023-01-09T04:46:40.217251463Z E0109 04:46:40.217214       1 degraded_webhook.go:128] dial tcp 172.30.166.45:9443: connect: connection refused
2023-01-09T04:46:40.609798748Z I0109 04:46:40.609762       1 request.go:601] Waited for 1.187703404s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:46:41.220404449Z E0109 04:46:41.220354       1 degraded_webhook.go:128] dial tcp 172.30.166.45:9443: connect: connection refused
2023-01-09T04:46:41.610070879Z I0109 04:46:41.610034       1 request.go:601] Waited for 1.195853423s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver
2023-01-09T04:46:42.213455732Z E0109 04:46:42.213419       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:46:42.213455732Z E0109 04:46:42.213451       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:46:42.213942004Z E0109 04:46:42.213925       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:46:42.217331893Z E0109 04:46:42.217306       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:46:42.610097815Z I0109 04:46:42.610063       1 request.go:601] Waited for 1.195553015s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2023-01-09T04:46:44.213262396Z E0109 04:46:44.213227       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:46:44.225516643Z E0109 04:46:44.225486       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal]
2023-01-09T04:46:44.227004431Z I0109 04:46:44.226949       1 prune_controller.go:269] Nothing to prune
2023-01-09T04:46:44.227376648Z I0109 04:46:44.227338       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:46:44.235251031Z I0109 04:46:44.235221       1 status_controller.go:211] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:44:16Z","message":"GuardControllerDegraded: [Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal]","reason":"GuardController_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:42:55Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 5","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 5","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:46:44.243507172Z I0109 04:46:44.243472       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded message changed from "GuardControllerDegraded: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]" to "GuardControllerDegraded: [Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal]"
2023-01-09T04:46:45.316129330Z I0109 04:46:45.316091       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:46:45.328719304Z I0109 04:46:45.328682       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:46:45.394304009Z E0109 04:46:45.394263       1 degraded_webhook.go:128] dial tcp 172.30.166.45:9443: connect: connection refused
2023-01-09T04:46:45.409786843Z I0109 04:46:45.409757       1 request.go:601] Waited for 1.179704153s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T04:46:45.813611449Z I0109 04:46:45.813573       1 installer_controller.go:512] "ip-10-0-199-219.us-east-2.compute.internal" is in transition to 5, but has not made progress because installer is not finished, but in Running phase
2023-01-09T04:46:46.400165163Z E0109 04:46:46.400119       1 degraded_webhook.go:128] dial tcp 172.30.166.45:9443: connect: connection refused
2023-01-09T04:46:48.146355690Z E0109 04:46:48.146321       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:46:48.180391421Z I0109 04:46:48.180340       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:46:48.284095627Z I0109 04:46:48.284039       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:46:48.312584783Z I0109 04:46:48.312548       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:46:48.477548171Z E0109 04:46:48.477497       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T04:46:49.413749648Z E0109 04:46:49.413706       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:46:49.414137428Z E0109 04:46:49.414117       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal]
2023-01-09T04:46:49.483300205Z E0109 04:46:49.483258       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T04:46:49.613980924Z I0109 04:46:49.613941       1 installer_controller.go:512] "ip-10-0-199-219.us-east-2.compute.internal" is in transition to 5, but has not made progress because installer is not finished, but in Running phase
2023-01-09T04:46:51.490830460Z E0109 04:46:51.490787       1 degraded_webhook.go:128] dial tcp 172.30.166.45:9443: connect: connection refused
2023-01-09T04:46:52.493466372Z E0109 04:46:52.493427       1 degraded_webhook.go:128] dial tcp 172.30.166.45:9443: connect: connection refused
2023-01-09T04:46:53.300310417Z I0109 04:46:53.300270       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:46:54.228643719Z I0109 04:46:54.228602       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:46:54.523242659Z I0109 04:46:54.522934       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:46:54.524246604Z I0109 04:46:54.524208       1 prune_controller.go:269] Nothing to prune
2023-01-09T04:46:54.621794292Z I0109 04:46:54.621754       1 prune_controller.go:269] Nothing to prune
2023-01-09T04:46:54.622183969Z I0109 04:46:54.622160       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:46:55.722639689Z I0109 04:46:55.722593       1 request.go:601] Waited for 1.098004906s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T04:46:57.126141264Z I0109 04:46:57.126102       1 installer_controller.go:512] "ip-10-0-199-219.us-east-2.compute.internal" is in transition to 5, but has not made progress because installer is not finished, but in Running phase
2023-01-09T04:47:00.126138918Z I0109 04:47:00.126099       1 installer_controller.go:512] "ip-10-0-199-219.us-east-2.compute.internal" is in transition to 5, but has not made progress because installer is not finished, but in Running phase
2023-01-09T04:47:01.126491609Z E0109 04:47:01.126446       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:47:01.126531360Z E0109 04:47:01.126488       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:47:01.139922459Z E0109 04:47:01.139877       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:47:01.140972339Z I0109 04:47:01.140937       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:47:01.141059342Z I0109 04:47:01.140975       1 prune_controller.go:269] Nothing to prune
2023-01-09T04:47:01.143349111Z I0109 04:47:01.143314       1 status_controller.go:211] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:44:16Z","message":"GuardControllerDegraded: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]","reason":"GuardController_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:42:55Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 5","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 5","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:47:01.152589179Z I0109 04:47:01.152551       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded message changed from "GuardControllerDegraded: [Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal]" to "GuardControllerDegraded: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]"
2023-01-09T04:47:02.322670006Z I0109 04:47:02.322635       1 request.go:601] Waited for 1.179787689s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:47:03.521674310Z I0109 04:47:03.521635       1 request.go:601] Waited for 1.194577503s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:47:03.926151152Z E0109 04:47:03.926111       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:47:03.926151152Z E0109 04:47:03.926143       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:47:03.926664422Z E0109 04:47:03.926636       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:47:05.528394747Z I0109 04:47:05.528336       1 installer_controller.go:512] "ip-10-0-199-219.us-east-2.compute.internal" is in transition to 5, but has not made progress because installer is not finished, but in Running phase
2023-01-09T04:47:06.658602824Z E0109 04:47:06.658566       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:47:06.658602824Z E0109 04:47:06.658590       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:47:06.926875606Z E0109 04:47:06.926836       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:47:07.076682537Z I0109 04:47:07.076643       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:47:07.088801639Z I0109 04:47:07.088763       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:47:08.216972497Z I0109 04:47:08.216929       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:47:08.288940317Z E0109 04:47:08.288897       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T04:47:08.370330282Z I0109 04:47:08.370293       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:47:09.229662332Z I0109 04:47:09.229616       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:47:09.262968025Z I0109 04:47:09.262931       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:47:09.284494009Z I0109 04:47:09.284456       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:47:09.294512823Z E0109 04:47:09.294482       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T04:47:11.327073802Z I0109 04:47:11.327030       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:47:11.327404822Z I0109 04:47:11.327378       1 prune_controller.go:269] Nothing to prune
2023-01-09T04:47:11.435304698Z I0109 04:47:11.435266       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:47:11.438142439Z I0109 04:47:11.438103       1 prune_controller.go:269] Nothing to prune
2023-01-09T04:47:12.891155411Z I0109 04:47:12.891121       1 request.go:601] Waited for 1.180377679s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2023-01-09T04:47:13.696624291Z I0109 04:47:13.696584       1 installer_controller.go:512] "ip-10-0-199-219.us-east-2.compute.internal" is in transition to 5, but has not made progress because installer is not finished, but in Running phase
2023-01-09T04:47:13.891755324Z I0109 04:47:13.891724       1 request.go:601] Waited for 1.181705126s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2023-01-09T04:47:14.096060206Z E0109 04:47:14.096022       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:47:14.096060206Z E0109 04:47:14.096050       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:47:14.096387541Z E0109 04:47:14.096371       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:47:17.494969650Z I0109 04:47:17.494933       1 installer_controller.go:512] "ip-10-0-199-219.us-east-2.compute.internal" is in transition to 5, but has not made progress because installer is not finished, but in Running phase
2023-01-09T04:47:19.891437270Z I0109 04:47:19.891394       1 request.go:601] Waited for 1.072511885s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:47:21.110114003Z E0109 04:47:21.110066       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:47:21.110114003Z E0109 04:47:21.110093       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:47:21.110423991Z E0109 04:47:21.110406       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:47:21.891332564Z I0109 04:47:21.891279       1 request.go:601] Waited for 1.055504274s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver
2023-01-09T04:47:22.006256489Z E0109 04:47:22.006218       1 degraded_webhook.go:128] dial tcp 172.30.93.123:443: connect: connection refused
2023-01-09T04:47:23.009715545Z E0109 04:47:23.009655       1 degraded_webhook.go:128] dial tcp 172.30.93.123:443: connect: connection refused
2023-01-09T04:47:23.093172023Z I0109 04:47:23.093121       1 request.go:601] Waited for 1.245326409s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2023-01-09T04:47:23.496189346Z E0109 04:47:23.496154       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:47:23.496189346Z E0109 04:47:23.496181       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:47:23.496533206Z E0109 04:47:23.496516       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:47:25.011853300Z E0109 04:47:25.011815       1 degraded_webhook.go:56] pod-identity-webhook.amazonaws.com: dial tcp 172.30.93.123:443: connect: connection refused
2023-01-09T04:47:25.095010449Z E0109 04:47:25.094953       1 degraded_webhook.go:128] dial tcp 172.30.93.123:443: connect: connection refused
2023-01-09T04:47:25.095010449Z I0109 04:47:25.094962       1 installer_controller.go:512] "ip-10-0-199-219.us-east-2.compute.internal" is in transition to 5, but has not made progress because waiting for static pod of revision 5, found 3
2023-01-09T04:47:26.526653280Z I0109 04:47:26.526613       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:47:26.542156102Z I0109 04:47:26.542119       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:47:27.551566738Z I0109 04:47:27.551519       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:47:27.628470856Z E0109 04:47:27.628433       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T04:47:27.851482088Z I0109 04:47:27.851437       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:47:28.008118213Z I0109 04:47:28.008060       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:47:28.027582534Z I0109 04:47:28.027535       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:47:28.495341510Z I0109 04:47:28.495296       1 installer_controller.go:512] "ip-10-0-199-219.us-east-2.compute.internal" is in transition to 5, but has not made progress because waiting for static pod of revision 5, found 3
2023-01-09T04:47:28.634905958Z E0109 04:47:28.634870       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T04:47:30.664521809Z I0109 04:47:30.664478       1 prune_controller.go:269] Nothing to prune
2023-01-09T04:47:30.669216298Z I0109 04:47:30.664959       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:47:30.778634381Z I0109 04:47:30.773632       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:47:30.778634381Z I0109 04:47:30.774788       1 prune_controller.go:269] Nothing to prune
2023-01-09T04:47:31.891008529Z I0109 04:47:31.890960       1 request.go:601] Waited for 1.117631851s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T04:47:32.891154085Z I0109 04:47:32.891118       1 request.go:601] Waited for 1.593831581s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-pod
2023-01-09T04:47:33.163308428Z I0109 04:47:33.163261       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ObserveInternalRegistryHostnameChanged' Internal registry hostname changed to "image-registry.openshift-image-registry.svc:5000"
2023-01-09T04:47:33.163630925Z I0109 04:47:33.163581       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ObservedConfigChanged' Writing updated observed config:   map[string]interface{}{
2023-01-09T04:47:33.163630925Z   	... // 2 identical entries
2023-01-09T04:47:33.163630925Z   	"corsAllowedOrigins":          []interface{}{string(`//127\.0\.0\.1(:|$)`), string("//localhost(:|$)")},
2023-01-09T04:47:33.163630925Z   	"gracefulTerminationDuration": string("194"),
2023-01-09T04:47:33.163630925Z + 	"imagePolicyConfig": map[string]interface{}{
2023-01-09T04:47:33.163630925Z + 		"internalRegistryHostname": string("image-registry.openshift-image-registry.svc:5000"),
2023-01-09T04:47:33.163630925Z + 	},
2023-01-09T04:47:33.163630925Z   	"servicesSubnet": string("172.30.0.0/16"),
2023-01-09T04:47:33.163630925Z   	"servingInfo":    map[string]interface{}{"bindAddress": string("0.0.0.0:6443"), "bindNetwork": string("tcp4"), "cipherSuites": []interface{}{string("TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256"), string("TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256"), string("TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384"), string("TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384"), ...}, "minTLSVersion": string("VersionTLS12"), ...},
2023-01-09T04:47:33.163630925Z   }
2023-01-09T04:47:33.187139702Z I0109 04:47:33.187100       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:47:33.188479176Z I0109 04:47:33.188439       1 prune_controller.go:269] Nothing to prune
2023-01-09T04:47:33.541619469Z E0109 04:47:33.541578       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:47:33.541619469Z E0109 04:47:33.541609       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:47:33.542037008Z E0109 04:47:33.541973       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:47:33.567956682Z E0109 04:47:33.567914       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:47:34.090818695Z I0109 04:47:34.090778       1 request.go:601] Waited for 1.033281949s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2023-01-09T04:47:35.090956900Z I0109 04:47:35.090917       1 request.go:601] Waited for 1.406971973s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver
2023-01-09T04:47:36.291886432Z I0109 04:47:36.291833       1 request.go:601] Waited for 1.394443952s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:47:36.296523660Z E0109 04:47:36.296458       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:47:36.311901584Z E0109 04:47:36.311861       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal]
2023-01-09T04:47:36.313483087Z I0109 04:47:36.313446       1 prune_controller.go:269] Nothing to prune
2023-01-09T04:47:36.315465520Z I0109 04:47:36.315425       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:47:36.317485707Z I0109 04:47:36.317451       1 status_controller.go:211] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:44:16Z","message":"GuardControllerDegraded: [Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal]","reason":"GuardController_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:42:55Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 5","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 5","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:47:36.327577659Z I0109 04:47:36.327529       1 status_controller.go:211] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:44:16Z","message":"GuardControllerDegraded: [Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal]","reason":"GuardController_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:42:55Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 5","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 5","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:47:36.327744006Z I0109 04:47:36.327710       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded message changed from "GuardControllerDegraded: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]" to "GuardControllerDegraded: [Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal]"
2023-01-09T04:47:36.338542407Z E0109 04:47:36.338496       1 base_controller.go:272] StatusSyncer_kube-apiserver reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io "kube-apiserver": the object has been modified; please apply your changes to the latest version and try again
2023-01-09T04:47:36.399167742Z I0109 04:47:36.399127       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:47:37.491768436Z I0109 04:47:37.491726       1 request.go:601] Waited for 1.177055468s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T04:47:38.294574013Z I0109 04:47:38.294528       1 installer_controller.go:512] "ip-10-0-199-219.us-east-2.compute.internal" is in transition to 5, but has not made progress because waiting for static pod of revision 5, found 3
2023-01-09T04:47:38.691348559Z I0109 04:47:38.691299       1 request.go:601] Waited for 1.594966632s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:47:39.097094591Z E0109 04:47:39.097054       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:47:39.097094591Z E0109 04:47:39.097081       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:47:39.109285890Z E0109 04:47:39.109252       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:47:39.110904441Z I0109 04:47:39.110871       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:47:39.111176208Z I0109 04:47:39.111145       1 prune_controller.go:269] Nothing to prune
2023-01-09T04:47:39.111343644Z I0109 04:47:39.111315       1 status_controller.go:211] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:44:16Z","message":"GuardControllerDegraded: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]","reason":"GuardController_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:42:55Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 5","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 5","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:47:39.122205226Z I0109 04:47:39.120203       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded message changed from "GuardControllerDegraded: [Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal]" to "GuardControllerDegraded: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]"
2023-01-09T04:47:39.327416363Z E0109 04:47:39.323245       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:47:39.486789675Z I0109 04:47:39.486726       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:47:39.488038474Z I0109 04:47:39.488007       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:47:39.691615539Z I0109 04:47:39.691567       1 request.go:601] Waited for 1.196480786s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/localhost-recovery-client-token
2023-01-09T04:47:40.891355058Z I0109 04:47:40.891314       1 request.go:601] Waited for 1.56756684s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:47:41.895407454Z E0109 04:47:41.895367       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:47:41.909081509Z E0109 04:47:41.909044       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal]
2023-01-09T04:47:41.913351455Z I0109 04:47:41.913309       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:47:41.917703120Z I0109 04:47:41.917666       1 prune_controller.go:269] Nothing to prune
2023-01-09T04:47:41.920752302Z I0109 04:47:41.920712       1 status_controller.go:211] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:44:16Z","message":"GuardControllerDegraded: [Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal]","reason":"GuardController_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:42:55Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 5","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 5","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:47:41.929774461Z I0109 04:47:41.929664       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded message changed from "GuardControllerDegraded: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]" to "GuardControllerDegraded: [Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal]"
2023-01-09T04:47:42.297922113Z I0109 04:47:42.297860       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapUpdated' Updated ConfigMap/config -n openshift-kube-apiserver:
2023-01-09T04:47:42.297922113Z cause by changes in data.config.yaml
2023-01-09T04:47:42.302501361Z I0109 04:47:42.302458       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionTriggered' new revision 6 triggered by "configmap/config has changed"
2023-01-09T04:47:43.091692718Z I0109 04:47:43.091653       1 request.go:601] Waited for 1.178798s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T04:47:44.101323218Z I0109 04:47:44.101272       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/revision-status-6 -n openshift-kube-apiserver because it was missing
2023-01-09T04:47:44.291365835Z I0109 04:47:44.291325       1 request.go:601] Waited for 1.796594302s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:47:44.895041863Z E0109 04:47:44.894985       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:47:44.895041863Z E0109 04:47:44.895024       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:47:44.902689209Z I0109 04:47:44.902649       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:47:44.907345881Z E0109 04:47:44.907313       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:47:44.909271047Z I0109 04:47:44.909240       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:47:44.909640808Z I0109 04:47:44.909626       1 prune_controller.go:269] Nothing to prune
2023-01-09T04:47:44.910580076Z I0109 04:47:44.910545       1 status_controller.go:211] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:44:16Z","message":"GuardControllerDegraded: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]","reason":"GuardController_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:42:55Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 5","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 5","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:47:44.918562312Z I0109 04:47:44.918484       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded message changed from "GuardControllerDegraded: [Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal]" to "GuardControllerDegraded: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]"
2023-01-09T04:47:45.304823771Z I0109 04:47:45.304767       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:47:45.491516058Z I0109 04:47:45.491472       1 request.go:601] Waited for 1.593406073s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/client-ca
2023-01-09T04:47:45.698111005Z I0109 04:47:45.698055       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-apiserver-pod-6 -n openshift-kube-apiserver because it was missing
2023-01-09T04:47:46.691485658Z I0109 04:47:46.691444       1 request.go:601] Waited for 1.779954212s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:47:47.097171782Z I0109 04:47:47.097132       1 installer_controller.go:512] "ip-10-0-199-219.us-east-2.compute.internal" is in transition to 5, but has not made progress because waiting for static pod of revision 5, found 3
2023-01-09T04:47:47.498062468Z I0109 04:47:47.498005       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/config-6 -n openshift-kube-apiserver because it was missing
2023-01-09T04:47:47.891158472Z I0109 04:47:47.891119       1 request.go:601] Waited for 1.744063156s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver
2023-01-09T04:47:48.295256341Z E0109 04:47:48.295219       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:47:48.295256341Z E0109 04:47:48.295244       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:47:48.295592366Z E0109 04:47:48.295577       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:47:48.891157575Z I0109 04:47:48.891120       1 request.go:601] Waited for 1.595434634s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/trusted-ca-bundle
2023-01-09T04:47:49.097601202Z I0109 04:47:49.097549       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-apiserver-cert-syncer-kubeconfig-6 -n openshift-kube-apiserver because it was missing
2023-01-09T04:47:50.091677844Z I0109 04:47:50.091633       1 request.go:601] Waited for 1.59586166s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T04:47:50.698204006Z I0109 04:47:50.698136       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/bound-sa-token-signing-certs-6 -n openshift-kube-apiserver because it was missing
2023-01-09T04:47:51.291793689Z I0109 04:47:51.291744       1 request.go:601] Waited for 1.588595647s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T04:47:51.496502204Z E0109 04:47:51.496463       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:47:51.496578303Z E0109 04:47:51.496551       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:47:51.497129019Z E0109 04:47:51.497102       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:47:52.291813905Z I0109 04:47:52.291774       1 request.go:601] Waited for 1.593834547s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps
2023-01-09T04:47:52.321739138Z I0109 04:47:52.321688       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/etcd-serving-ca-6 -n openshift-kube-apiserver because it was missing
2023-01-09T04:47:53.491243738Z I0109 04:47:53.491198       1 request.go:601] Waited for 1.595386642s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/installer-5-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:47:53.897876725Z I0109 04:47:53.897822       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-apiserver-server-ca-6 -n openshift-kube-apiserver because it was missing
2023-01-09T04:47:54.690899181Z I0109 04:47:54.690857       1 request.go:601] Waited for 1.593886985s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:47:54.695735365Z E0109 04:47:54.695699       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:47:54.695735365Z E0109 04:47:54.695728       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:47:54.696084303Z E0109 04:47:54.696064       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:47:55.268320723Z E0109 04:47:55.268275       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:47:55.498440124Z I0109 04:47:55.498389       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kubelet-serving-ca-6 -n openshift-kube-apiserver because it was missing
2023-01-09T04:47:55.691093933Z I0109 04:47:55.691054       1 request.go:601] Waited for 1.338128997s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2023-01-09T04:47:55.929529560Z I0109 04:47:55.929484       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ObservedConfigChanged' Writing updated observed config:   map[string]interface{}{
2023-01-09T04:47:55.929529560Z   	"admission":          map[string]interface{}{"pluginConfig": map[string]interface{}{"network.openshift.io/ExternalIPRanger": map[string]interface{}{"configuration": map[string]interface{}{"allowIngressIP": bool(false), "apiVersion": string("network.openshift.io/v1"), "kind": string("ExternalIPRangerAdmissionConfig")}}, "network.openshift.io/RestrictedEndpointsAdmission": map[string]interface{}{"configuration": map[string]interface{}{"apiVersion": string("network.openshift.io/v1"), "kind": string("RestrictedEndpointsAdmissionConfig"), "restrictedCIDRs": []interface{}{string("10.128.0.0/14"), string("172.30.0.0/16")}}}}},
2023-01-09T04:47:55.929529560Z   	"apiServerArguments": map[string]interface{}{"api-audiences": []interface{}{string("https://kubernetes.default.svc")}, "authentication-token-webhook-config-file": []interface{}{string("/etc/kubernetes/static-pod-resources/secrets/webhook-authenticat"...)}, "authentication-token-webhook-version": []interface{}{string("v1")}, "cloud-provider": []interface{}{string("aws")}, ...},
2023-01-09T04:47:55.929529560Z + 	"authConfig": map[string]interface{}{
2023-01-09T04:47:55.929529560Z + 		"oauthMetadataFile": string("/etc/kubernetes/static-pod-resources/configmaps/oauth-metadata/oauthMetadata"),
2023-01-09T04:47:55.929529560Z + 	},
2023-01-09T04:47:55.929529560Z   	"corsAllowedOrigins":          []interface{}{string(`//127\.0\.0\.1(:|$)`), string("//localhost(:|$)")},
2023-01-09T04:47:55.929529560Z   	"gracefulTerminationDuration": string("194"),
2023-01-09T04:47:55.929529560Z   	... // 3 identical entries
2023-01-09T04:47:55.929529560Z   }
2023-01-09T04:47:55.948051538Z I0109 04:47:55.948009       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:47:55.948743020Z I0109 04:47:55.948722       1 prune_controller.go:269] Nothing to prune
2023-01-09T04:47:55.952494577Z I0109 04:47:55.952450       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ObservedConfigChanged' Writing updated observed config:   map[string]interface{}{
2023-01-09T04:47:55.952494577Z   	"admission":          map[string]interface{}{"pluginConfig": map[string]interface{}{"network.openshift.io/ExternalIPRanger": map[string]interface{}{"configuration": map[string]interface{}{"allowIngressIP": bool(false), "apiVersion": string("network.openshift.io/v1"), "kind": string("ExternalIPRangerAdmissionConfig")}}, "network.openshift.io/RestrictedEndpointsAdmission": map[string]interface{}{"configuration": map[string]interface{}{"apiVersion": string("network.openshift.io/v1"), "kind": string("RestrictedEndpointsAdmissionConfig"), "restrictedCIDRs": []interface{}{string("10.128.0.0/14"), string("172.30.0.0/16")}}}}},
2023-01-09T04:47:55.952494577Z   	"apiServerArguments": map[string]interface{}{"api-audiences": []interface{}{string("https://kubernetes.default.svc")}, "authentication-token-webhook-config-file": []interface{}{string("/etc/kubernetes/static-pod-resources/secrets/webhook-authenticat"...)}, "authentication-token-webhook-version": []interface{}{string("v1")}, "cloud-provider": []interface{}{string("aws")}, ...},
2023-01-09T04:47:55.952494577Z + 	"authConfig": map[string]interface{}{
2023-01-09T04:47:55.952494577Z + 		"oauthMetadataFile": string("/etc/kubernetes/static-pod-resources/configmaps/oauth-metadata/oauthMetadata"),
2023-01-09T04:47:55.952494577Z + 	},
2023-01-09T04:47:55.952494577Z   	"corsAllowedOrigins":          []interface{}{string(`//127\.0\.0\.1(:|$)`), string("//localhost(:|$)")},
2023-01-09T04:47:55.952494577Z   	"gracefulTerminationDuration": string("194"),
2023-01-09T04:47:55.952494577Z   	... // 3 identical entries
2023-01-09T04:47:55.952494577Z   }
2023-01-09T04:47:56.295276663Z I0109 04:47:56.295235       1 installer_controller.go:512] "ip-10-0-199-219.us-east-2.compute.internal" is in transition to 5, but has not made progress because waiting for static pod of revision 5, found 3
2023-01-09T04:47:56.828071625Z I0109 04:47:56.828028       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:47:56.841793692Z I0109 04:47:56.841761       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:47:56.891113644Z I0109 04:47:56.891061       1 request.go:601] Waited for 1.392844562s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps
2023-01-09T04:47:56.898562483Z I0109 04:47:56.898516       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/sa-token-signing-certs-6 -n openshift-kube-apiserver because it was missing
2023-01-09T04:47:57.891172632Z I0109 04:47:57.891134       1 request.go:601] Waited for 1.795612511s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T04:47:58.295313554Z E0109 04:47:58.295275       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:47:58.308657148Z E0109 04:47:58.308622       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal]
2023-01-09T04:47:58.309200930Z I0109 04:47:58.309171       1 prune_controller.go:269] Nothing to prune
2023-01-09T04:47:58.309532650Z I0109 04:47:58.309513       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:47:58.309840363Z I0109 04:47:58.309810       1 status_controller.go:211] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:44:16Z","message":"GuardControllerDegraded: [Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal]","reason":"GuardController_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:42:55Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 5","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 5","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:47:58.318074502Z I0109 04:47:58.318035       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded message changed from "GuardControllerDegraded: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]" to "GuardControllerDegraded: [Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal]"
2023-01-09T04:47:58.471071276Z I0109 04:47:58.471019       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:47:58.696961545Z I0109 04:47:58.696909       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-apiserver-audit-policies-6 -n openshift-kube-apiserver because it was missing
2023-01-09T04:47:58.891874260Z I0109 04:47:58.891822       1 request.go:601] Waited for 1.974603307s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps
2023-01-09T04:47:58.897947658Z I0109 04:47:58.897897       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/oauth-metadata -n openshift-kube-apiserver because it was missing
2023-01-09T04:47:58.964182889Z I0109 04:47:58.964141       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:47:59.059339793Z E0109 04:47:59.059301       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T04:47:59.111908310Z I0109 04:47:59.111868       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:47:59.564095520Z I0109 04:47:59.564040       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:47:59.584097681Z I0109 04:47:59.584058       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:48:00.065110182Z E0109 04:48:00.065049       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T04:48:00.091521740Z I0109 04:48:00.091479       1 request.go:601] Waited for 1.782272273s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2023-01-09T04:48:00.699064376Z I0109 04:48:00.698150       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/etcd-client-6 -n openshift-kube-apiserver because it was missing
2023-01-09T04:48:01.291779339Z I0109 04:48:01.291737       1 request.go:601] Waited for 1.793381267s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:48:01.897146339Z E0109 04:48:01.897109       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:48:01.897146339Z E0109 04:48:01.897136       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:48:01.911299230Z E0109 04:48:01.911241       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:48:01.912062366Z I0109 04:48:01.912029       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:48:01.912826355Z I0109 04:48:01.912799       1 prune_controller.go:269] Nothing to prune
2023-01-09T04:48:01.919842721Z I0109 04:48:01.919797       1 status_controller.go:211] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:44:16Z","message":"GuardControllerDegraded: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]","reason":"GuardController_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:42:55Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 5","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 5","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:48:01.929029582Z I0109 04:48:01.928958       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded message changed from "GuardControllerDegraded: [Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal]" to "GuardControllerDegraded: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]"
2023-01-09T04:48:02.097140289Z I0109 04:48:02.097093       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:48:02.097827932Z I0109 04:48:02.097794       1 prune_controller.go:269] Nothing to prune
2023-01-09T04:48:02.210229754Z I0109 04:48:02.210188       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:48:02.210627826Z I0109 04:48:02.210610       1 prune_controller.go:269] Nothing to prune
2023-01-09T04:48:02.491289130Z I0109 04:48:02.491252       1 request.go:601] Waited for 1.539874604s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver
2023-01-09T04:48:02.497128102Z I0109 04:48:02.497089       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:48:02.537368350Z I0109 04:48:02.537316       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:48:02.538767627Z I0109 04:48:02.537673       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:48:03.691792257Z I0109 04:48:03.691749       1 request.go:601] Waited for 1.771151907s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:48:04.097780562Z I0109 04:48:04.097729       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/localhost-recovery-serving-certkey-6 -n openshift-kube-apiserver because it was missing
2023-01-09T04:48:04.891185327Z I0109 04:48:04.891135       1 request.go:601] Waited for 1.795647823s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/installer-5-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:48:05.495621651Z E0109 04:48:05.495585       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:48:05.495621651Z E0109 04:48:05.495610       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:48:05.495937744Z E0109 04:48:05.495924       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:48:05.897699318Z I0109 04:48:05.897646       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/localhost-recovery-client-token-6 -n openshift-kube-apiserver because it was missing
2023-01-09T04:48:06.091216123Z I0109 04:48:06.091177       1 request.go:601] Waited for 1.756376111s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2023-01-09T04:48:06.697260014Z I0109 04:48:06.697223       1 installer_controller.go:512] "ip-10-0-199-219.us-east-2.compute.internal" is in transition to 5, but has not made progress because waiting for static pod of revision 5, found 3
2023-01-09T04:48:07.091517927Z I0109 04:48:07.091477       1 request.go:601] Waited for 1.396764148s due to client-side throttling, not priority and fairness, request: PUT:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/config
2023-01-09T04:48:07.099179480Z I0109 04:48:07.099130       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapUpdated' Updated ConfigMap/config -n openshift-kube-apiserver:
2023-01-09T04:48:07.099179480Z cause by changes in data.config.yaml
2023-01-09T04:48:07.299201732Z I0109 04:48:07.299150       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/webhook-authenticator-6 -n openshift-kube-apiserver because it was missing
2023-01-09T04:48:07.312033196Z I0109 04:48:07.311960       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionCreate' Revision 5 created because configmap/config has changed
2023-01-09T04:48:07.312691521Z I0109 04:48:07.312653       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:48:07.313388908Z I0109 04:48:07.313359       1 prune_controller.go:269] Nothing to prune
2023-01-09T04:48:07.324116420Z I0109 04:48:07.324062       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionTriggered' new revision 7 triggered by "configmap/config has changed,configmap/oauth-metadata has changed"
2023-01-09T04:48:08.291725466Z I0109 04:48:08.291676       1 request.go:601] Waited for 1.593706165s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:48:08.495028639Z E0109 04:48:08.494978       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:48:08.495058608Z E0109 04:48:08.495035       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:48:08.495376178Z E0109 04:48:08.495360       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:48:09.097446051Z I0109 04:48:09.097395       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/revision-status-7 -n openshift-kube-apiserver because it was missing
2023-01-09T04:48:09.491478276Z I0109 04:48:09.491435       1 request.go:601] Waited for 1.789149382s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T04:48:10.691355077Z I0109 04:48:10.691301       1 request.go:601] Waited for 1.593886023s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps
2023-01-09T04:48:10.698374814Z I0109 04:48:10.698322       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-apiserver-pod-7 -n openshift-kube-apiserver because it was missing
2023-01-09T04:48:11.691687740Z I0109 04:48:11.691640       1 request.go:601] Waited for 1.596642149s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:48:11.894909996Z E0109 04:48:11.894875       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:48:11.894909996Z E0109 04:48:11.894900       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:48:11.895277981Z E0109 04:48:11.895263       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:48:12.298281390Z I0109 04:48:12.298189       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/config-7 -n openshift-kube-apiserver because it was missing
2023-01-09T04:48:12.891072380Z I0109 04:48:12.890983       1 request.go:601] Waited for 1.595825641s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T04:48:13.550208762Z I0109 04:48:13.550169       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:48:13.560383638Z I0109 04:48:13.560321       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:48:13.571053072Z I0109 04:48:13.571015       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:48:13.891442732Z I0109 04:48:13.891403       1 request.go:601] Waited for 1.5934143s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps
2023-01-09T04:48:13.896677919Z I0109 04:48:13.896634       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-apiserver-cert-syncer-kubeconfig-7 -n openshift-kube-apiserver because it was missing
2023-01-09T04:48:15.091165958Z I0109 04:48:15.091127       1 request.go:601] Waited for 1.596561178s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:48:15.095209811Z E0109 04:48:15.095186       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:48:15.095231510Z E0109 04:48:15.095208       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:48:15.095556552Z E0109 04:48:15.095540       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:48:15.099185787Z E0109 04:48:15.099158       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:48:15.099185787Z E0109 04:48:15.099179       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:48:15.499546391Z I0109 04:48:15.499498       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/oauth-metadata-7 -n openshift-kube-apiserver because it was missing
2023-01-09T04:48:16.291089485Z I0109 04:48:16.291051       1 request.go:601] Waited for 1.595278453s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:48:16.497110395Z I0109 04:48:16.497043       1 installer_controller.go:512] "ip-10-0-199-219.us-east-2.compute.internal" is in transition to 5, but has not made progress because waiting for static pod of revision 5, found 3
2023-01-09T04:48:16.516314884Z I0109 04:48:16.516271       1 status_controller.go:211] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:44:16Z","message":"GuardControllerDegraded: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]","reason":"GuardController_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:42:55Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 6","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:48:16.516567871Z I0109 04:48:16.516539       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:48:16.516956067Z I0109 04:48:16.516933       1 prune_controller.go:269] Nothing to prune
2023-01-09T04:48:16.525846962Z I0109 04:48:16.525285       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Progressing message changed from "NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 5" to "NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 6",Available message changed from "StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 5" to "StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 6"
2023-01-09T04:48:17.099969134Z I0109 04:48:17.099925       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/bound-sa-token-signing-certs-7 -n openshift-kube-apiserver because it was missing
2023-01-09T04:48:17.291100397Z I0109 04:48:17.291060       1 request.go:601] Waited for 1.543437308s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver
2023-01-09T04:48:18.491151887Z I0109 04:48:18.491108       1 request.go:601] Waited for 1.975405033s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2023-01-09T04:48:18.695237607Z E0109 04:48:18.695197       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:48:19.097284495Z I0109 04:48:19.097234       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/etcd-serving-ca-7 -n openshift-kube-apiserver because it was missing
2023-01-09T04:48:19.691119570Z I0109 04:48:19.691068       1 request.go:601] Waited for 1.795049521s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T04:48:19.802529259Z I0109 04:48:19.802487       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:48:19.816957783Z I0109 04:48:19.816902       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:48:20.691816908Z I0109 04:48:20.691773       1 request.go:601] Waited for 1.794899462s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-pod
2023-01-09T04:48:20.774870806Z I0109 04:48:20.774832       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:48:20.851645436Z E0109 04:48:20.851609       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T04:48:20.903562205Z I0109 04:48:20.903517       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-apiserver-server-ca-7 -n openshift-kube-apiserver because it was missing
2023-01-09T04:48:20.912821719Z I0109 04:48:20.912784       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:48:21.610395766Z I0109 04:48:21.610347       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:48:21.628311288Z I0109 04:48:21.628270       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:48:21.857541575Z E0109 04:48:21.857503       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T04:48:21.891677811Z I0109 04:48:21.891640       1 request.go:601] Waited for 1.794813125s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:48:22.096285834Z E0109 04:48:22.096249       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:48:22.096285834Z E0109 04:48:22.096275       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:48:22.096657592Z E0109 04:48:22.096641       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:48:22.497857371Z I0109 04:48:22.497808       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kubelet-serving-ca-7 -n openshift-kube-apiserver because it was missing
2023-01-09T04:48:23.091275693Z I0109 04:48:23.091233       1 request.go:601] Waited for 1.595586251s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T04:48:23.207245373Z I0109 04:48:23.207199       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:48:23.495346741Z I0109 04:48:23.495305       1 installer_controller.go:500] "ip-10-0-199-219.us-east-2.compute.internal" moving to (v1.NodeStatus) {
2023-01-09T04:48:23.495346741Z  NodeName: (string) (len=42) "ip-10-0-199-219.us-east-2.compute.internal",
2023-01-09T04:48:23.495346741Z  CurrentRevision: (int32) 0,
2023-01-09T04:48:23.495346741Z  TargetRevision: (int32) 6,
2023-01-09T04:48:23.495346741Z  LastFailedRevision: (int32) 0,
2023-01-09T04:48:23.495346741Z  LastFailedTime: (*v1.Time)(<nil>),
2023-01-09T04:48:23.495346741Z  LastFailedReason: (string) "",
2023-01-09T04:48:23.495346741Z  LastFailedCount: (int) 0,
2023-01-09T04:48:23.495346741Z  LastFallbackCount: (int) 0,
2023-01-09T04:48:23.495346741Z  LastFailedRevisionErrors: ([]string) <nil>
2023-01-09T04:48:23.495346741Z }
2023-01-09T04:48:23.495346741Z  because new revision pending
2023-01-09T04:48:23.509927478Z I0109 04:48:23.509884       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:48:23.606905891Z I0109 04:48:23.606849       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:48:23.892350117Z I0109 04:48:23.892303       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:48:23.999141689Z I0109 04:48:23.999101       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:48:24.096497543Z I0109 04:48:24.096448       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/sa-token-signing-certs-7 -n openshift-kube-apiserver because it was missing
2023-01-09T04:48:24.227671255Z I0109 04:48:24.227627       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:48:24.236246602Z I0109 04:48:24.236213       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:48:24.291634189Z I0109 04:48:24.291595       1 request.go:601] Waited for 1.596258505s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver
2023-01-09T04:48:25.491030681Z I0109 04:48:25.490962       1 request.go:601] Waited for 1.980499768s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-6-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:48:25.696148182Z E0109 04:48:25.696109       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:48:25.696148182Z E0109 04:48:25.696138       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:48:25.696483531Z E0109 04:48:25.696466       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:48:26.097141269Z I0109 04:48:26.097096       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-apiserver-audit-policies-7 -n openshift-kube-apiserver because it was missing
2023-01-09T04:48:26.691766095Z I0109 04:48:26.691709       1 request.go:601] Waited for 1.995780624s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T04:48:27.517765704Z I0109 04:48:27.517712       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/revision-pruner-6-ip-10-0-199-219.us-east-2.compute.internal -n openshift-kube-apiserver because it was missing
2023-01-09T04:48:27.891478037Z I0109 04:48:27.891435       1 request.go:601] Waited for 1.983835634s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2023-01-09T04:48:28.110932936Z I0109 04:48:28.110871       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/etcd-client-7 -n openshift-kube-apiserver because it was missing
2023-01-09T04:48:29.091088933Z I0109 04:48:29.091049       1 request.go:601] Waited for 1.994081804s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:48:29.896537981Z E0109 04:48:29.896492       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:48:29.896537981Z E0109 04:48:29.896518       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:48:29.896850420Z E0109 04:48:29.896834       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:48:29.900512402Z E0109 04:48:29.900469       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:48:30.091394707Z I0109 04:48:30.091357       1 request.go:601] Waited for 2.185084648s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/localhost-recovery-client-token
2023-01-09T04:48:31.096268472Z I0109 04:48:31.096231       1 installer_controller.go:500] "ip-10-0-199-219.us-east-2.compute.internal" moving to (v1.NodeStatus) {
2023-01-09T04:48:31.096268472Z  NodeName: (string) (len=42) "ip-10-0-199-219.us-east-2.compute.internal",
2023-01-09T04:48:31.096268472Z  CurrentRevision: (int32) 0,
2023-01-09T04:48:31.096268472Z  TargetRevision: (int32) 6,
2023-01-09T04:48:31.096268472Z  LastFailedRevision: (int32) 0,
2023-01-09T04:48:31.096268472Z  LastFailedTime: (*v1.Time)(<nil>),
2023-01-09T04:48:31.096268472Z  LastFailedReason: (string) "",
2023-01-09T04:48:31.096268472Z  LastFailedCount: (int) 0,
2023-01-09T04:48:31.096268472Z  LastFallbackCount: (int) 0,
2023-01-09T04:48:31.096268472Z  LastFailedRevisionErrors: ([]string) <nil>
2023-01-09T04:48:31.096268472Z }
2023-01-09T04:48:31.096268472Z  because new revision pending
2023-01-09T04:48:31.291504058Z I0109 04:48:31.291470       1 request.go:601] Waited for 1.99378831s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2023-01-09T04:48:31.499425340Z I0109 04:48:31.499366       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/revision-pruner-6-ip-10-0-160-211.us-east-2.compute.internal -n openshift-kube-apiserver because it was missing
2023-01-09T04:48:32.298876699Z I0109 04:48:32.298822       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/localhost-recovery-serving-certkey-7 -n openshift-kube-apiserver because it was missing
2023-01-09T04:48:32.491399325Z I0109 04:48:32.491355       1 request.go:601] Waited for 1.957302513s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2023-01-09T04:48:33.491507281Z I0109 04:48:33.491465       1 request.go:601] Waited for 1.794083788s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver
2023-01-09T04:48:33.699391809Z E0109 04:48:33.699346       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:48:33.714553185Z E0109 04:48:33.714516       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal]
2023-01-09T04:48:33.716230822Z I0109 04:48:33.716193       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:48:33.719454484Z I0109 04:48:33.719409       1 status_controller.go:211] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:44:16Z","message":"GuardControllerDegraded: [Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal]","reason":"GuardController_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:42:55Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 6","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:48:33.738443201Z I0109 04:48:33.736441       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded message changed from "GuardControllerDegraded: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]" to "GuardControllerDegraded: [Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal]"
2023-01-09T04:48:34.099083192Z I0109 04:48:34.099033       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/localhost-recovery-client-token-7 -n openshift-kube-apiserver because it was missing
2023-01-09T04:48:34.691320003Z I0109 04:48:34.691281       1 request.go:601] Waited for 1.994571225s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:48:35.242481746Z I0109 04:48:35.242425       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ObserveStorageUpdated' Updated storage urls to https://10.0.145.4:2379,https://10.0.160.211:2379,https://10.0.199.219:2379,https://localhost:2379
2023-01-09T04:48:35.243495080Z I0109 04:48:35.243447       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ObservedConfigChanged' Writing updated observed config:   map[string]interface{}{
2023-01-09T04:48:35.243495080Z   	"admission": map[string]interface{}{"pluginConfig": map[string]interface{}{"network.openshift.io/ExternalIPRanger": map[string]interface{}{"configuration": map[string]interface{}{"allowIngressIP": bool(false), "apiVersion": string("network.openshift.io/v1"), "kind": string("ExternalIPRangerAdmissionConfig")}}, "network.openshift.io/RestrictedEndpointsAdmission": map[string]interface{}{"configuration": map[string]interface{}{"apiVersion": string("network.openshift.io/v1"), "kind": string("RestrictedEndpointsAdmissionConfig"), "restrictedCIDRs": []interface{}{string("10.128.0.0/14"), string("172.30.0.0/16")}}}}},
2023-01-09T04:48:35.243495080Z   	"apiServerArguments": map[string]interface{}{
2023-01-09T04:48:35.243495080Z   		... // 2 identical entries
2023-01-09T04:48:35.243495080Z   		"authentication-token-webhook-version": []interface{}{string("v1")},
2023-01-09T04:48:35.243495080Z   		"cloud-provider":                       []interface{}{string("aws")},
2023-01-09T04:48:35.243495080Z   		"etcd-servers": []interface{}{
2023-01-09T04:48:35.243495080Z + 			string("https://10.0.145.4:2379"),
2023-01-09T04:48:35.243495080Z   			string("https://10.0.160.211:2379"),
2023-01-09T04:48:35.243495080Z   			string("https://10.0.199.219:2379"),
2023-01-09T04:48:35.243495080Z   			string("https://localhost:2379"),
2023-01-09T04:48:35.243495080Z   		},
2023-01-09T04:48:35.243495080Z   		"feature-gates":          []interface{}{string("APIPriorityAndFairness=true"), string("RotateKubeletServerCertificate=true"), string("DownwardAPIHugePages=true"), string("CSIMigrationAzureFile=false"), ...},
2023-01-09T04:48:35.243495080Z   		"service-account-issuer": []interface{}{string("https://kubernetes.default.svc")},
2023-01-09T04:48:35.243495080Z   		... // 2 identical entries
2023-01-09T04:48:35.243495080Z   	},
2023-01-09T04:48:35.243495080Z   	"authConfig":         map[string]interface{}{"oauthMetadataFile": string("/etc/kubernetes/static-pod-resources/configmaps/oauth-metadata/o"...)},
2023-01-09T04:48:35.243495080Z   	"corsAllowedOrigins": []interface{}{string(`//127\.0\.0\.1(:|$)`), string("//localhost(:|$)")},
2023-01-09T04:48:35.243495080Z   	... // 4 identical entries
2023-01-09T04:48:35.243495080Z   }
2023-01-09T04:48:35.261518535Z I0109 04:48:35.261470       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ObserveStorageUpdated' Updated storage urls to https://10.0.145.4:2379,https://10.0.160.211:2379,https://10.0.199.219:2379,https://localhost:2379
2023-01-09T04:48:35.263102769Z I0109 04:48:35.262555       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:48:35.267138128Z I0109 04:48:35.267089       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ObservedConfigChanged' Writing updated observed config:   map[string]interface{}{
2023-01-09T04:48:35.267138128Z   	"admission": map[string]interface{}{"pluginConfig": map[string]interface{}{"network.openshift.io/ExternalIPRanger": map[string]interface{}{"configuration": map[string]interface{}{"allowIngressIP": bool(false), "apiVersion": string("network.openshift.io/v1"), "kind": string("ExternalIPRangerAdmissionConfig")}}, "network.openshift.io/RestrictedEndpointsAdmission": map[string]interface{}{"configuration": map[string]interface{}{"apiVersion": string("network.openshift.io/v1"), "kind": string("RestrictedEndpointsAdmissionConfig"), "restrictedCIDRs": []interface{}{string("10.128.0.0/14"), string("172.30.0.0/16")}}}}},
2023-01-09T04:48:35.267138128Z   	"apiServerArguments": map[string]interface{}{
2023-01-09T04:48:35.267138128Z   		... // 2 identical entries
2023-01-09T04:48:35.267138128Z   		"authentication-token-webhook-version": []interface{}{string("v1")},
2023-01-09T04:48:35.267138128Z   		"cloud-provider":                       []interface{}{string("aws")},
2023-01-09T04:48:35.267138128Z   		"etcd-servers": []interface{}{
2023-01-09T04:48:35.267138128Z + 			string("https://10.0.145.4:2379"),
2023-01-09T04:48:35.267138128Z   			string("https://10.0.160.211:2379"),
2023-01-09T04:48:35.267138128Z   			string("https://10.0.199.219:2379"),
2023-01-09T04:48:35.267138128Z   			string("https://localhost:2379"),
2023-01-09T04:48:35.267138128Z   		},
2023-01-09T04:48:35.267138128Z   		"feature-gates":          []interface{}{string("APIPriorityAndFairness=true"), string("RotateKubeletServerCertificate=true"), string("DownwardAPIHugePages=true"), string("CSIMigrationAzureFile=false"), ...},
2023-01-09T04:48:35.267138128Z   		"service-account-issuer": []interface{}{string("https://kubernetes.default.svc")},
2023-01-09T04:48:35.267138128Z   		... // 2 identical entries
2023-01-09T04:48:35.267138128Z   	},
2023-01-09T04:48:35.267138128Z   	"authConfig":         map[string]interface{}{"oauthMetadataFile": string("/etc/kubernetes/static-pod-resources/configmaps/oauth-metadata/o"...)},
2023-01-09T04:48:35.267138128Z   	"corsAllowedOrigins": []interface{}{string(`//127\.0\.0\.1(:|$)`), string("//localhost(:|$)")},
2023-01-09T04:48:35.267138128Z   	... // 4 identical entries
2023-01-09T04:48:35.267138128Z   }
2023-01-09T04:48:35.298758847Z I0109 04:48:35.298715       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/revision-pruner-6-ip-10-0-145-4.us-east-2.compute.internal -n openshift-kube-apiserver because it was missing
2023-01-09T04:48:35.891846658Z I0109 04:48:35.891808       1 request.go:601] Waited for 2.171531997s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2023-01-09T04:48:36.092418116Z E0109 04:48:36.092384       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:48:36.092418116Z E0109 04:48:36.092410       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:48:36.093736434Z W0109 04:48:36.093697       1 base_controller.go:236] Updating status of "GuardController" failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2023-01-09T04:48:36.093762565Z E0109 04:48:36.093740       1 base_controller.go:272] GuardController reconciliation failed: [Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ip-10-0-199-219.us-east-2.compute.internal": dial tcp 172.30.0.1:443: connect: connection refused, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:48:36.097220643Z E0109 04:48:36.097179       1 guard_controller.go:232] Unable to apply PodDisruptionBudget changes: Get "https://172.30.0.1:443/apis/policy/v1/namespaces/openshift-kube-apiserver/poddisruptionbudgets/kube-apiserver-guard-pdb": dial tcp 172.30.0.1:443: connect: connection refused
2023-01-09T04:48:36.099017397Z W0109 04:48:36.098953       1 base_controller.go:236] Updating status of "GuardController" failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2023-01-09T04:48:36.099051121Z E0109 04:48:36.098986       1 base_controller.go:272] GuardController reconciliation failed: Unable to apply PodDisruptionBudget changes: Get "https://172.30.0.1:443/apis/policy/v1/namespaces/openshift-kube-apiserver/poddisruptionbudgets/kube-apiserver-guard-pdb": dial tcp 172.30.0.1:443: connect: connection refused
2023-01-09T04:48:36.492375717Z I0109 04:48:36.492318       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'SecretCreateFailed' Failed to create Secret/webhook-authenticator-7 -n openshift-kube-apiserver: Post "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets": dial tcp 172.30.0.1:443: connect: connection refused
2023-01-09T04:48:36.492978607Z E0109 04:48:36.492895       1 event.go:276] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kube-apiserver-operator.17388aa82d98062e", GenerateName:"", Namespace:"openshift-kube-apiserver-operator", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}, Reason:"SecretCreateFailed", Message:"Failed to create Secret/webhook-authenticator-7 -n openshift-kube-apiserver: Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets\": dial tcp 172.30.0.1:443: connect: connection refused", Source:v1.EventSource{Component:"kube-apiserver-operator-revisioncontroller", Host:""}, FirstTimestamp:time.Date(2023, time.January, 9, 4, 48, 36, 492215854, time.Local), LastTimestamp:time.Date(2023, time.January, 9, 4, 48, 36, 492215854, time.Local), Count:1, Type:"Warning", EventTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'Post "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver-operator/events": dial tcp 172.30.0.1:443: connect: connection refused'(may retry after sleeping)
2023-01-09T04:48:36.493713086Z I0109 04:48:36.493677       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RevisionCreateFailed' Failed to create revision 7: Post "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets": dial tcp 172.30.0.1:443: connect: connection refused
2023-01-09T04:48:36.495074157Z E0109 04:48:36.495048       1 base_controller.go:272] RevisionController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2023-01-09T04:48:36.499039077Z I0109 04:48:36.499014       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionTriggered' new revision 7 triggered by "configmap/config has changed,configmap/oauth-metadata has changed"
2023-01-09T04:48:36.697408566Z W0109 04:48:36.697342       1 base_controller.go:236] Updating status of "NodeKubeconfigController" failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2023-01-09T04:48:36.697408566Z E0109 04:48:36.697395       1 base_controller.go:272] NodeKubeconfigController reconciliation failed: "secret/node-kubeconfigs": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs": dial tcp 172.30.0.1:443: connect: connection refused
2023-01-09T04:48:37.091773733Z I0109 04:48:37.091734       1 request.go:601] Waited for 2.388877109s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:48:37.492126584Z E0109 04:48:37.492087       1 base_controller.go:272] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2023-01-09T04:48:37.692475551Z E0109 04:48:37.692434       1 base_controller.go:272] PruneController reconciliation failed: Delete "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/revision-status-1": dial tcp 172.30.0.1:443: connect: connection refused
2023-01-09T04:48:37.891757638Z E0109 04:48:37.891714       1 termination_observer.go:175] key failed with : unable to list pods in "openshift-kube-apiserver" namespace: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver": dial tcp 172.30.0.1:443: connect: connection refused
2023-01-09T04:48:37.933161084Z I0109 04:48:37.933058       1 termination_observer.go:236] Observed event "TerminationGracefulTerminationFinished" for API server pod "kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal" (last termination at 2023-01-09 04:44:45 +0000 UTC) at 0001-01-01 00:00:00 +0000 UTC
2023-01-09T04:48:38.093114140Z E0109 04:48:38.093077       1 base_controller.go:272] auditPolicyController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies": dial tcp 172.30.0.1:443: connect: connection refused
2023-01-09T04:48:38.291864605Z I0109 04:48:38.291825       1 request.go:601] Waited for 2.390446491s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2023-01-09T04:48:38.294523307Z E0109 04:48:38.294492       1 base_controller.go:272] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-apiserver-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2023-01-09T04:48:38.693705437Z I0109 04:48:38.693659       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RevisionCreateFailed' Failed to create revision 7: Delete "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/encryption-config-7": dial tcp 172.30.0.1:443: connect: connection refused
2023-01-09T04:48:38.694770902Z E0109 04:48:38.694751       1 base_controller.go:272] RevisionController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2023-01-09T04:48:38.698153302Z I0109 04:48:38.698126       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionTriggered' new revision 7 triggered by "configmap/config has changed,configmap/oauth-metadata has changed"
2023-01-09T04:48:38.893221509Z W0109 04:48:38.893173       1 base_controller.go:236] Updating status of "NodeKubeconfigController" failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2023-01-09T04:48:38.893221509Z E0109 04:48:38.893211       1 base_controller.go:272] NodeKubeconfigController reconciliation failed: "secret/node-kubeconfigs": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs": dial tcp 172.30.0.1:443: connect: connection refused
2023-01-09T04:48:39.105880576Z E0109 04:48:39.105834       1 base_controller.go:272] KubeAPIServerStaticResources reconciliation failed: ["assets/kube-apiserver/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole-node-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-node-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole-crd-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-crd-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-auth-delegator.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-auth-delegator": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-node-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-node-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-crd-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-crd-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-rolebinding-kube-system.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:controller:kube-apiserver-check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-apiserver/rolebindings/system:openshift:controller:check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/delegated-incluster-authentication-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/authentication-reader-for-authenticated-users": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/localhost-recovery-client-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-apiserver-recovery": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/localhost-recovery-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/apiserver.openshift.io_apirequestcount.yaml" (string): Get "https://172.30.0.1:443/apis/apiextensions.k8s.io/v1/customresourcedefinitions/apirequestcounts.apiserver.openshift.io": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-flowschema.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/api-usage.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/api-usage": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/audit-errors.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/audit-errors": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/cpu-utilization.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/cpu-utilization": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-requests.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-requests": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-slos-basic.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-basic": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/podsecurity-violations.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/podsecurity": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-slos-extended.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-extended": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-slos.yaml" (string): Delete "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2023-01-09T04:48:39.293822189Z E0109 04:48:39.293777       1 base_controller.go:272] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2023-01-09T04:48:39.491747933Z I0109 04:48:39.491700       1 request.go:601] Waited for 2.199472696s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/installer-6-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:48:39.492369059Z I0109 04:48:39.492323       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 6 count 0 on node "ip-10-0-199-219.us-east-2.compute.internal": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/installer-6-ip-10-0-199-219.us-east-2.compute.internal": dial tcp 172.30.0.1:443: connect: connection refused
2023-01-09T04:48:39.492978266Z E0109 04:48:39.492888       1 event.go:276] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kube-apiserver-operator.17388aa8e068705a", GenerateName:"", Namespace:"openshift-kube-apiserver-operator", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}, Reason:"InstallerPodFailed", Message:"Failed to create installer pod for revision 6 count 0 on node \"ip-10-0-199-219.us-east-2.compute.internal\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/installer-6-ip-10-0-199-219.us-east-2.compute.internal\": dial tcp 172.30.0.1:443: connect: connection refused", Source:v1.EventSource{Component:"kube-apiserver-operator-installer-controller", Host:""}, FirstTimestamp:time.Date(2023, time.January, 9, 4, 48, 39, 492218970, time.Local), LastTimestamp:time.Date(2023, time.January, 9, 4, 48, 39, 492218970, time.Local), Count:1, Type:"Warning", EventTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'Post "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver-operator/events": dial tcp 172.30.0.1:443: connect: connection refused'(may retry after sleeping)
2023-01-09T04:48:39.493452409Z E0109 04:48:39.493422       1 base_controller.go:272] InstallerController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/installer-6-ip-10-0-199-219.us-east-2.compute.internal": dial tcp 172.30.0.1:443: connect: connection refused
2023-01-09T04:48:39.692042740Z E0109 04:48:39.691985       1 base_controller.go:272] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2023-01-09T04:48:40.092058178Z E0109 04:48:40.092020       1 termination_observer.go:175] key failed with : unable to list pods in "openshift-kube-apiserver" namespace: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver": dial tcp 172.30.0.1:443: connect: connection refused
2023-01-09T04:48:40.293649281Z E0109 04:48:40.293602       1 base_controller.go:272] auditPolicyController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies": dial tcp 172.30.0.1:443: connect: connection refused
2023-01-09T04:48:40.493770738Z E0109 04:48:40.493727       1 base_controller.go:272] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-apiserver-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2023-01-09T04:48:40.637954960Z E0109 04:48:40.637851       1 event.go:276] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kube-apiserver-operator.17388aa82d98062e", GenerateName:"", Namespace:"openshift-kube-apiserver-operator", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}, Reason:"SecretCreateFailed", Message:"Failed to create Secret/webhook-authenticator-7 -n openshift-kube-apiserver: Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets\": dial tcp 172.30.0.1:443: connect: connection refused", Source:v1.EventSource{Component:"kube-apiserver-operator-revisioncontroller", Host:""}, FirstTimestamp:time.Date(2023, time.January, 9, 4, 48, 36, 492215854, time.Local), LastTimestamp:time.Date(2023, time.January, 9, 4, 48, 36, 492215854, time.Local), Count:1, Type:"Warning", EventTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'Post "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver-operator/events": dial tcp 172.30.0.1:443: connect: connection refused'(may retry after sleeping)
2023-01-09T04:48:40.691022302Z I0109 04:48:40.690972       1 request.go:601] Waited for 2.198506397s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/trusted-ca-bundle
2023-01-09T04:48:40.893594684Z I0109 04:48:40.893549       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RevisionCreateFailed' Failed to create revision 7: Delete "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/encryption-config-7": dial tcp 172.30.0.1:443: connect: connection refused
2023-01-09T04:48:40.894629846Z E0109 04:48:40.894613       1 base_controller.go:272] RevisionController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2023-01-09T04:48:40.898255841Z I0109 04:48:40.898225       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionTriggered' new revision 7 triggered by "configmap/config has changed,configmap/oauth-metadata has changed"
2023-01-09T04:48:41.092526801Z W0109 04:48:41.092473       1 base_controller.go:236] Updating status of "NodeKubeconfigController" failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2023-01-09T04:48:41.092526801Z E0109 04:48:41.092513       1 base_controller.go:272] NodeKubeconfigController reconciliation failed: "secret/node-kubeconfigs": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs": dial tcp 172.30.0.1:443: connect: connection refused
2023-01-09T04:48:41.691730034Z I0109 04:48:41.691678       1 request.go:601] Waited for 2.197469103s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:48:41.892195413Z E0109 04:48:41.892157       1 base_controller.go:272] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2023-01-09T04:48:42.092016058Z E0109 04:48:42.091964       1 base_controller.go:272] PruneController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-6-ip-10-0-199-219.us-east-2.compute.internal": dial tcp 172.30.0.1:443: connect: connection refused
2023-01-09T04:48:42.092016058Z Delete "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/revision-status-1": dial tcp 172.30.0.1:443: connect: connection refused
2023-01-09T04:48:42.292132825Z E0109 04:48:42.292100       1 termination_observer.go:175] key failed with : unable to list pods in "openshift-kube-apiserver" namespace: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver": dial tcp 172.30.0.1:443: connect: connection refused
2023-01-09T04:48:42.367224504Z E0109 04:48:42.367119       1 event.go:276] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kube-apiserver-operator.17388aa8e068705a", GenerateName:"", Namespace:"openshift-kube-apiserver-operator", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}, Reason:"InstallerPodFailed", Message:"Failed to create installer pod for revision 6 count 0 on node \"ip-10-0-199-219.us-east-2.compute.internal\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/installer-6-ip-10-0-199-219.us-east-2.compute.internal\": dial tcp 172.30.0.1:443: connect: connection refused", Source:v1.EventSource{Component:"kube-apiserver-operator-installer-controller", Host:""}, FirstTimestamp:time.Date(2023, time.January, 9, 4, 48, 39, 492218970, time.Local), LastTimestamp:time.Date(2023, time.January, 9, 4, 48, 39, 492218970, time.Local), Count:1, Type:"Warning", EventTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'Post "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver-operator/events": dial tcp 172.30.0.1:443: connect: connection refused'(may retry after sleeping)
2023-01-09T04:48:42.493317485Z E0109 04:48:42.493283       1 base_controller.go:272] auditPolicyController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies": dial tcp 172.30.0.1:443: connect: connection refused
2023-01-09T04:48:42.693595475Z E0109 04:48:42.693563       1 base_controller.go:272] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-apiserver-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2023-01-09T04:48:42.891091895Z I0109 04:48:42.891053       1 request.go:601] Waited for 2.199343822s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2023-01-09T04:48:42.892865030Z E0109 04:48:42.892837       1 base_controller.go:272] TargetConfigController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2023-01-09T04:48:43.093538397Z I0109 04:48:43.093491       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RevisionCreateFailed' Failed to create revision 7: Delete "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/encryption-config-7": dial tcp 172.30.0.1:443: connect: connection refused
2023-01-09T04:48:43.094660717Z E0109 04:48:43.094638       1 base_controller.go:272] RevisionController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2023-01-09T04:48:43.097976581Z I0109 04:48:43.097950       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionTriggered' new revision 7 triggered by "configmap/config has changed,configmap/oauth-metadata has changed"
2023-01-09T04:48:43.293304135Z W0109 04:48:43.293257       1 base_controller.go:236] Updating status of "NodeKubeconfigController" failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2023-01-09T04:48:43.293365964Z E0109 04:48:43.293353       1 base_controller.go:272] NodeKubeconfigController reconciliation failed: "secret/node-kubeconfigs": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs": dial tcp 172.30.0.1:443: connect: connection refused
2023-01-09T04:48:44.091692589Z I0109 04:48:44.091653       1 request.go:601] Waited for 2.199399067s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2023-01-09T04:48:44.092307563Z E0109 04:48:44.092262       1 base_controller.go:272] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2023-01-09T04:48:44.491652063Z E0109 04:48:44.491613       1 termination_observer.go:175] key failed with : unable to list pods in "openshift-kube-apiserver" namespace: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver": dial tcp 172.30.0.1:443: connect: connection refused
2023-01-09T04:48:44.693547037Z E0109 04:48:44.693509       1 base_controller.go:272] auditPolicyController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies": dial tcp 172.30.0.1:443: connect: connection refused
2023-01-09T04:48:44.896204844Z E0109 04:48:44.896166       1 base_controller.go:272] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-apiserver-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2023-01-09T04:48:45.267812556Z E0109 04:48:45.267761       1 leaderelection.go:330] error retrieving resource lock openshift-kube-apiserver-operator/kube-apiserver-operator-lock: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver-operator/configmaps/kube-apiserver-operator-lock?timeout=1m47s": dial tcp 172.30.0.1:443: connect: connection refused
2023-01-09T04:48:45.291042318Z I0109 04:48:45.290984       1 request.go:601] Waited for 2.192582891s due to client-side throttling, not priority and fairness, request: DELETE:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/encryption-config-7
2023-01-09T04:48:45.293155457Z I0109 04:48:45.293094       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RevisionCreateFailed' Failed to create revision 7: Delete "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/encryption-config-7": dial tcp 172.30.0.1:443: connect: connection refused
2023-01-09T04:48:45.294487606Z E0109 04:48:45.294463       1 base_controller.go:272] RevisionController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2023-01-09T04:48:45.298059291Z I0109 04:48:45.298022       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionTriggered' new revision 7 triggered by "configmap/config has changed,configmap/oauth-metadata has changed"
2023-01-09T04:48:45.493180150Z W0109 04:48:45.493140       1 base_controller.go:236] Updating status of "NodeKubeconfigController" failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2023-01-09T04:48:45.493180150Z E0109 04:48:45.493171       1 base_controller.go:272] NodeKubeconfigController reconciliation failed: "secret/node-kubeconfigs": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs": dial tcp 172.30.0.1:443: connect: connection refused
2023-01-09T04:48:45.704232094Z E0109 04:48:45.704173       1 base_controller.go:272] KubeAPIServerStaticResources reconciliation failed: ["assets/kube-apiserver/ns.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole-node-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-node-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole-crd-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-crd-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-auth-delegator.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-auth-delegator": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-node-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-node-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-crd-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-crd-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-rolebinding-kube-system.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:controller:kube-apiserver-check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-apiserver/rolebindings/system:openshift:controller:check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/delegated-incluster-authentication-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/authentication-reader-for-authenticated-users": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/localhost-recovery-client-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-apiserver-recovery": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/localhost-recovery-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/apiserver.openshift.io_apirequestcount.yaml" (string): Get "https://172.30.0.1:443/apis/apiextensions.k8s.io/v1/customresourcedefinitions/apirequestcounts.apiserver.openshift.io": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-flowschema.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/api-usage.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/api-usage": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/audit-errors.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/audit-errors": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/cpu-utilization.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/cpu-utilization": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-requests.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-requests": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-slos-basic.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-basic": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/podsecurity-violations.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/podsecurity": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-slos-extended.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-extended": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-slos.yaml" (string): Delete "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2023-01-09T04:48:45.892727214Z E0109 04:48:45.892690       1 base_controller.go:272] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2023-01-09T04:48:46.292472445Z I0109 04:48:46.292440       1 request.go:601] Waited for 2.200072794s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2023-01-09T04:48:46.293045664Z E0109 04:48:46.293025       1 base_controller.go:272] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2023-01-09T04:48:46.491841485Z E0109 04:48:46.491803       1 base_controller.go:272] PruneController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-6-ip-10-0-199-219.us-east-2.compute.internal": dial tcp 172.30.0.1:443: connect: connection refused
2023-01-09T04:48:46.491841485Z Delete "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/revision-status-1": dial tcp 172.30.0.1:443: connect: connection refused
2023-01-09T04:48:46.692264569Z E0109 04:48:46.692226       1 termination_observer.go:175] key failed with : unable to list pods in "openshift-kube-apiserver" namespace: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver": dial tcp 172.30.0.1:443: connect: connection refused
2023-01-09T04:48:46.893485767Z E0109 04:48:46.893449       1 base_controller.go:272] auditPolicyController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies": dial tcp 172.30.0.1:443: connect: connection refused
2023-01-09T04:48:47.094074373Z E0109 04:48:47.094039       1 base_controller.go:272] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-apiserver-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2023-01-09T04:48:47.491598481Z I0109 04:48:47.491559       1 request.go:601] Waited for 2.19301313s due to client-side throttling, not priority and fairness, request: DELETE:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/encryption-config-7
2023-01-09T04:48:47.493913636Z I0109 04:48:47.493871       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RevisionCreateFailed' Failed to create revision 7: Delete "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/encryption-config-7": dial tcp 172.30.0.1:443: connect: connection refused
2023-01-09T04:48:47.495282697Z E0109 04:48:47.495247       1 base_controller.go:272] RevisionController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2023-01-09T04:48:47.499366846Z I0109 04:48:47.499317       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionTriggered' new revision 7 triggered by "configmap/config has changed,configmap/oauth-metadata has changed"
2023-01-09T04:48:47.693364606Z W0109 04:48:47.693310       1 base_controller.go:236] Updating status of "NodeKubeconfigController" failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2023-01-09T04:48:47.693364606Z E0109 04:48:47.693352       1 base_controller.go:272] NodeKubeconfigController reconciliation failed: "secret/node-kubeconfigs": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs": dial tcp 172.30.0.1:443: connect: connection refused
2023-01-09T04:48:48.292338201Z I0109 04:48:48.292281       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 6 count 0 on node "ip-10-0-199-219.us-east-2.compute.internal": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/installer-6-ip-10-0-199-219.us-east-2.compute.internal": dial tcp 172.30.0.1:443: connect: connection refused
2023-01-09T04:48:48.293431684Z E0109 04:48:48.293415       1 base_controller.go:272] InstallerController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/installer-6-ip-10-0-199-219.us-east-2.compute.internal": dial tcp 172.30.0.1:443: connect: connection refused
2023-01-09T04:48:48.491643445Z I0109 04:48:48.491607       1 request.go:601] Waited for 2.198485938s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2023-01-09T04:48:48.492224051Z E0109 04:48:48.492188       1 base_controller.go:272] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2023-01-09T04:48:48.891678715Z E0109 04:48:48.891634       1 termination_observer.go:175] key failed with : unable to list pods in "openshift-kube-apiserver" namespace: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver": dial tcp 172.30.0.1:443: connect: connection refused
2023-01-09T04:48:49.093203071Z E0109 04:48:49.093156       1 base_controller.go:272] auditPolicyController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies": dial tcp 172.30.0.1:443: connect: connection refused
2023-01-09T04:48:49.294225348Z E0109 04:48:49.294182       1 base_controller.go:272] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-apiserver-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2023-01-09T04:48:49.691547140Z I0109 04:48:49.691504       1 request.go:601] Waited for 2.191634074s due to client-side throttling, not priority and fairness, request: DELETE:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/encryption-config-7
2023-01-09T04:48:49.693517415Z I0109 04:48:49.693480       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RevisionCreateFailed' Failed to create revision 7: Delete "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/encryption-config-7": dial tcp 172.30.0.1:443: connect: connection refused
2023-01-09T04:48:49.694562122Z E0109 04:48:49.694542       1 base_controller.go:272] RevisionController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2023-01-09T04:48:49.698050378Z I0109 04:48:49.698014       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionTriggered' new revision 7 triggered by "configmap/config has changed,configmap/oauth-metadata has changed"
2023-01-09T04:48:49.893585690Z W0109 04:48:49.893536       1 base_controller.go:236] Updating status of "NodeKubeconfigController" failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2023-01-09T04:48:49.893585690Z E0109 04:48:49.893567       1 base_controller.go:272] NodeKubeconfigController reconciliation failed: "secret/node-kubeconfigs": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs": dial tcp 172.30.0.1:443: connect: connection refused
2023-01-09T04:48:50.639101651Z E0109 04:48:50.638981       1 event.go:276] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kube-apiserver-operator.17388aa82d98062e", GenerateName:"", Namespace:"openshift-kube-apiserver-operator", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}, Reason:"SecretCreateFailed", Message:"Failed to create Secret/webhook-authenticator-7 -n openshift-kube-apiserver: Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets\": dial tcp 172.30.0.1:443: connect: connection refused", Source:v1.EventSource{Component:"kube-apiserver-operator-revisioncontroller", Host:""}, FirstTimestamp:time.Date(2023, time.January, 9, 4, 48, 36, 492215854, time.Local), LastTimestamp:time.Date(2023, time.January, 9, 4, 48, 36, 492215854, time.Local), Count:1, Type:"Warning", EventTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'Post "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver-operator/events": dial tcp 172.30.0.1:443: connect: connection refused'(may retry after sleeping)
2023-01-09T04:48:50.691738011Z E0109 04:48:50.691700       1 base_controller.go:272] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2023-01-09T04:48:50.890917454Z I0109 04:48:50.890876       1 request.go:601] Waited for 2.198813588s due to client-side throttling, not priority and fairness, request: DELETE:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/revision-status-1
2023-01-09T04:48:50.891479747Z E0109 04:48:50.891462       1 base_controller.go:272] PruneController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-6-ip-10-0-199-219.us-east-2.compute.internal": dial tcp 172.30.0.1:443: connect: connection refused
2023-01-09T04:48:50.891479747Z Delete "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/revision-status-1": dial tcp 172.30.0.1:443: connect: connection refused
2023-01-09T04:48:51.091428447Z E0109 04:48:51.091386       1 termination_observer.go:175] key failed with : unable to list pods in "openshift-kube-apiserver" namespace: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver": dial tcp 172.30.0.1:443: connect: connection refused
2023-01-09T04:48:51.293529205Z E0109 04:48:51.293493       1 base_controller.go:272] auditPolicyController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies": dial tcp 172.30.0.1:443: connect: connection refused
2023-01-09T04:48:51.891401887Z I0109 04:48:51.891360       1 request.go:601] Waited for 2.19285251s due to client-side throttling, not priority and fairness, request: DELETE:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/encryption-config-7
2023-01-09T04:48:53.091594835Z I0109 04:48:53.091549       1 request.go:601] Waited for 2.199373563s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-6-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:48:53.842169480Z E0109 04:48:53.842134       1 reflector.go:140] k8s.io/client-go@v0.25.0/tools/cache/reflector.go:169: Failed to watch *v1.Secret: unknown (get secrets)
2023-01-09T04:48:53.848664110Z E0109 04:48:53.848627       1 base_controller.go:272] InstallerStateController reconciliation failed: pods is forbidden: User "system:serviceaccount:openshift-kube-apiserver-operator:kube-apiserver-operator" cannot list resource "pods" in API group "" in the namespace "openshift-kube-apiserver"
2023-01-09T04:48:53.848876091Z E0109 04:48:53.848794       1 reflector.go:140] k8s.io/client-go@v0.25.0/tools/cache/reflector.go:169: Failed to watch *v1.FeatureGate: unknown (get featuregates.config.openshift.io)
2023-01-09T04:48:53.848876091Z E0109 04:48:53.848827       1 reflector.go:140] k8s.io/client-go@v0.25.0/tools/cache/reflector.go:169: Failed to watch *v1.Pod: unknown (get pods)
2023-01-09T04:48:53.848876091Z E0109 04:48:53.848785       1 event.go:267] Server rejected event '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kube-apiserver-operator.17388aa8e068705a", GenerateName:"", Namespace:"openshift-kube-apiserver-operator", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}, Reason:"InstallerPodFailed", Message:"Failed to create installer pod for revision 6 count 0 on node \"ip-10-0-199-219.us-east-2.compute.internal\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/installer-6-ip-10-0-199-219.us-east-2.compute.internal\": dial tcp 172.30.0.1:443: connect: connection refused", Source:v1.EventSource{Component:"kube-apiserver-operator-installer-controller", Host:""}, FirstTimestamp:time.Date(2023, time.January, 9, 4, 48, 39, 492218970, time.Local), LastTimestamp:time.Date(2023, time.January, 9, 4, 48, 39, 492218970, time.Local), Count:1, Type:"Warning", EventTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'events is forbidden: User "system:serviceaccount:openshift-kube-apiserver-operator:kube-apiserver-operator" cannot create resource "events" in API group "" in the namespace "openshift-kube-apiserver-operator"' (will not retry!)
2023-01-09T04:48:53.849210636Z E0109 04:48:53.849166       1 reflector.go:140] k8s.io/client-go@v0.25.0/tools/cache/reflector.go:169: Failed to watch *v1.OAuth: unknown (get oauths.config.openshift.io)
2023-01-09T04:48:53.849332263Z E0109 04:48:53.849306       1 reflector.go:140] k8s.io/client-go@v0.25.0/tools/cache/reflector.go:169: Failed to watch *v1alpha1.StorageVersionMigration: unknown (get storageversionmigrations.migration.k8s.io)
2023-01-09T04:48:53.849355194Z E0109 04:48:53.849348       1 termination_observer.go:175] key failed with : unable to list pods in "openshift-kube-apiserver" namespace: pods is forbidden: User "system:serviceaccount:openshift-kube-apiserver-operator:kube-apiserver-operator" cannot list resource "pods" in API group "" in the namespace "openshift-kube-apiserver"
2023-01-09T04:48:53.850158589Z E0109 04:48:53.850134       1 reflector.go:140] k8s.io/client-go@v0.25.0/tools/cache/reflector.go:169: Failed to watch *v1.RoleBinding: unknown (get rolebindings.rbac.authorization.k8s.io)
2023-01-09T04:48:53.853030648Z E0109 04:48:53.852979       1 base_controller.go:272] StaticPodStateController reconciliation failed: kubeapiservers.operator.openshift.io "cluster" is forbidden: User "system:serviceaccount:openshift-kube-apiserver-operator:kube-apiserver-operator" cannot update resource "kubeapiservers/status" in API group "operator.openshift.io" at the cluster scope
2023-01-09T04:48:53.857873415Z E0109 04:48:53.856983       1 event.go:267] Server rejected event '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kube-apiserver-operator.17388aa8e068705a", GenerateName:"", Namespace:"openshift-kube-apiserver-operator", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}, Reason:"InstallerPodFailed", Message:"Failed to create installer pod for revision 6 count 0 on node \"ip-10-0-199-219.us-east-2.compute.internal\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/installer-6-ip-10-0-199-219.us-east-2.compute.internal\": dial tcp 172.30.0.1:443: connect: connection refused", Source:v1.EventSource{Component:"kube-apiserver-operator-installer-controller", Host:""}, FirstTimestamp:time.Date(2023, time.January, 9, 4, 48, 39, 492218970, time.Local), LastTimestamp:time.Date(2023, time.January, 9, 4, 48, 48, 292189224, time.Local), Count:2, Type:"Warning", EventTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'events "kube-apiserver-operator.17388aa8e068705a" is forbidden: User "system:serviceaccount:openshift-kube-apiserver-operator:kube-apiserver-operator" cannot patch resource "events" in API group "" in the namespace "openshift-kube-apiserver-operator"' (will not retry!)
2023-01-09T04:48:54.150688625Z E0109 04:48:54.150643       1 base_controller.go:272] PruneController reconciliation failed: pods "revision-pruner-6-ip-10-0-199-219.us-east-2.compute.internal" is forbidden: User "system:serviceaccount:openshift-kube-apiserver-operator:kube-apiserver-operator" cannot get resource "pods" in API group "" in the namespace "openshift-kube-apiserver"
2023-01-09T04:48:55.541777049Z I0109 04:48:55.541732       1 termination_observer.go:130] Observed termination of API server pod "kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal" at 2023-01-09 04:48:54 +0000 UTC
2023-01-09T04:48:55.690902707Z I0109 04:48:55.690852       1 request.go:601] Waited for 1.19153449s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods
2023-01-09T04:48:56.639404388Z E0109 04:48:56.639347       1 guard_controller.go:274] Missing PodIP in operand kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal on node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:48:56.639404388Z E0109 04:48:56.639381       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:48:56.639404388Z E0109 04:48:56.639395       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:48:56.683649026Z E0109 04:48:56.683604       1 base_controller.go:272] GuardController reconciliation failed: [Missing PodIP in operand kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:48:56.691020983Z I0109 04:48:56.690963       1 request.go:601] Waited for 1.576962255s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/localhost-recovery-client-token
2023-01-09T04:48:56.769539007Z E0109 04:48:56.769499       1 guard_controller.go:274] Missing PodIP in operand kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal on node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:48:56.769539007Z E0109 04:48:56.769528       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:48:56.769571606Z E0109 04:48:56.769539       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:48:57.213392097Z E0109 04:48:57.213350       1 base_controller.go:272] TargetConfigController reconciliation failed: Operation cannot be fulfilled on kubeapiservers.operator.openshift.io "cluster": the object has been modified; please apply your changes to the latest version and try again
2023-01-09T04:48:57.224929279Z W0109 04:48:57.224882       1 base_controller.go:236] Updating status of "GuardController" failed: Operation cannot be fulfilled on kubeapiservers.operator.openshift.io "cluster": the object has been modified; please apply your changes to the latest version and try again
2023-01-09T04:48:57.224959723Z E0109 04:48:57.224915       1 base_controller.go:272] GuardController reconciliation failed: [Missing PodIP in operand kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:48:57.243286080Z E0109 04:48:57.243229       1 guard_controller.go:274] Missing PodIP in operand kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal on node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:48:57.243286080Z E0109 04:48:57.243262       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:48:57.243286080Z E0109 04:48:57.243277       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:48:57.293732754Z I0109 04:48:57.293681       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:48:57.636857734Z W0109 04:48:57.636785       1 base_controller.go:236] Updating status of "GuardController" failed: Operation cannot be fulfilled on kubeapiservers.operator.openshift.io "cluster": the object has been modified; please apply your changes to the latest version and try again
2023-01-09T04:48:57.636857734Z E0109 04:48:57.636817       1 base_controller.go:272] GuardController reconciliation failed: [Missing PodIP in operand kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:48:57.660472344Z E0109 04:48:57.660432       1 guard_controller.go:274] Missing PodIP in operand kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal on node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:48:57.660514039Z E0109 04:48:57.660468       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:48:57.660514039Z E0109 04:48:57.660486       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:48:57.691554119Z I0109 04:48:57.691518       1 request.go:601] Waited for 1.796159478s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver
2023-01-09T04:48:58.159362073Z I0109 04:48:58.159314       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:48:58.162138242Z I0109 04:48:58.162096       1 status_controller.go:211] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:44:16Z","message":"GuardControllerDegraded: [Missing PodIP in operand kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]","reason":"GuardController_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:42:55Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 6","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:48:58.167152303Z E0109 04:48:58.167116       1 base_controller.go:272] GuardController reconciliation failed: [Missing PodIP in operand kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:48:58.298346898Z I0109 04:48:58.298285       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded message changed from "GuardControllerDegraded: [Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal]" to "GuardControllerDegraded: [Missing PodIP in operand kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]"
2023-01-09T04:48:58.306768562Z I0109 04:48:58.306711       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:48:58.372264554Z I0109 04:48:58.372184       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:48:58.836163712Z I0109 04:48:58.836100       1 externalloadbalancer.go:27] syncing external loadbalancer hostnames: api.sn-loggvls-jsm.qe.devcluster.openshift.com
2023-01-09T04:48:58.836468516Z I0109 04:48:58.836435       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:48:58.891816882Z I0109 04:48:58.891773       1 request.go:601] Waited for 2.634061148s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/kube-system/secrets?resourceVersion=22970
2023-01-09T04:48:59.092670620Z I0109 04:48:59.092607       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:48:59.096403162Z I0109 04:48:59.096351       1 status_controller.go:211] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:44:16Z","message":"GuardControllerDegraded: [Missing PodIP in operand kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]\nRevisionControllerDegraded: secrets \"encryption-config-7\" is forbidden: User \"system:serviceaccount:openshift-kube-apiserver-operator:kube-apiserver-operator\" cannot delete resource \"secrets\" in API group \"\" in the namespace \"openshift-kube-apiserver\"","reason":"GuardController_SyncError::RevisionController_ContentCreationError","status":"True","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:42:55Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 6","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:48:59.107144237Z I0109 04:48:59.107103       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionTriggered' new revision 7 triggered by "configmap/config has changed,configmap/oauth-metadata has changed"
2023-01-09T04:48:59.189467851Z I0109 04:48:59.189416       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded message changed from "GuardControllerDegraded: [Missing PodIP in operand kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]" to "GuardControllerDegraded: [Missing PodIP in operand kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]\nRevisionControllerDegraded: secrets \"encryption-config-7\" is forbidden: User \"system:serviceaccount:openshift-kube-apiserver-operator:kube-apiserver-operator\" cannot delete resource \"secrets\" in API group \"\" in the namespace \"openshift-kube-apiserver\""
2023-01-09T04:48:59.611523726Z E0109 04:48:59.611484       1 guard_controller.go:274] Missing PodIP in operand kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal on node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:48:59.611523726Z E0109 04:48:59.611512       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:48:59.611558439Z E0109 04:48:59.611524       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:48:59.611915356Z E0109 04:48:59.611898       1 base_controller.go:272] GuardController reconciliation failed: [Missing PodIP in operand kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:48:59.886672446Z I0109 04:48:59.886604       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:48:59.887114352Z E0109 04:48:59.887075       1 base_controller.go:272] KubeAPIServerStaticResources reconciliation failed: ["assets/kube-apiserver/ns.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole-node-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-node-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole-crd-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-crd-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-auth-delegator.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-auth-delegator": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-node-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-node-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-crd-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-crd-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-rolebinding-kube-system.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:controller:kube-apiserver-check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-apiserver/rolebindings/system:openshift:controller:check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/delegated-incluster-authentication-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/authentication-reader-for-authenticated-users": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/localhost-recovery-client-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-apiserver-recovery": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/localhost-recovery-sa.yaml" (string): serviceaccounts "localhost-recovery-client" is forbidden: User "system:serviceaccount:openshift-kube-apiserver-operator:kube-apiserver-operator" cannot get resource "serviceaccounts" in API group "" in the namespace "openshift-kube-apiserver"]
2023-01-09T04:48:59.888675930Z I0109 04:48:59.888629       1 status_controller.go:211] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:44:16Z","message":"GuardControllerDegraded: [Missing PodIP in operand kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrole-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrole-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrolebinding-auth-delegator.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-auth-delegator\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrolebinding-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrolebinding-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-rolebinding-kube-system.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:controller:kube-apiserver-check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-apiserver/rolebindings/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/delegated-incluster-authentication-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/authentication-reader-for-authenticated-users\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-apiserver-recovery\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/localhost-recovery-sa.yaml\" (string): serviceaccounts \"localhost-recovery-client\" is forbidden: User \"system:serviceaccount:openshift-kube-apiserver-operator:kube-apiserver-operator\" cannot get resource \"serviceaccounts\" in API group \"\" in the namespace \"openshift-kube-apiserver\"\nKubeAPIServerStaticResourcesDegraded: \nRevisionControllerDegraded: secrets \"encryption-config-7\" is forbidden: User \"system:serviceaccount:openshift-kube-apiserver-operator:kube-apiserver-operator\" cannot delete resource \"secrets\" in API group \"\" in the namespace \"openshift-kube-apiserver\"","reason":"GuardController_SyncError::KubeAPIServerStaticResources_SyncError::RevisionController_ContentCreationError","status":"True","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:42:55Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 6","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:48:59.908718104Z I0109 04:48:59.908659       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded message changed from "GuardControllerDegraded: [Missing PodIP in operand kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]\nRevisionControllerDegraded: secrets \"encryption-config-7\" is forbidden: User \"system:serviceaccount:openshift-kube-apiserver-operator:kube-apiserver-operator\" cannot delete resource \"secrets\" in API group \"\" in the namespace \"openshift-kube-apiserver\"" to "GuardControllerDegraded: [Missing PodIP in operand kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrole-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrole-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrolebinding-auth-delegator.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-auth-delegator\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrolebinding-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrolebinding-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-rolebinding-kube-system.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:controller:kube-apiserver-check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-apiserver/rolebindings/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/delegated-incluster-authentication-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/authentication-reader-for-authenticated-users\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-apiserver-recovery\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/localhost-recovery-sa.yaml\" (string): serviceaccounts \"localhost-recovery-client\" is forbidden: User \"system:serviceaccount:openshift-kube-apiserver-operator:kube-apiserver-operator\" cannot get resource \"serviceaccounts\" in API group \"\" in the namespace \"openshift-kube-apiserver\"\nKubeAPIServerStaticResourcesDegraded: \nRevisionControllerDegraded: secrets \"encryption-config-7\" is forbidden: User \"system:serviceaccount:openshift-kube-apiserver-operator:kube-apiserver-operator\" cannot delete resource \"secrets\" in API group \"\" in the namespace \"openshift-kube-apiserver\""
2023-01-09T04:48:59.917853885Z I0109 04:48:59.917788       1 servicehostname.go:40] syncing servicenetwork hostnames: [172.30.0.1 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local openshift openshift.default openshift.default.svc openshift.default.svc.cluster.local]
2023-01-09T04:49:00.091589251Z I0109 04:49:00.091547       1 request.go:601] Waited for 3.133612516s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-apiserver/configmaps?resourceVersion=23008
2023-01-09T04:49:00.710148104Z I0109 04:49:00.707813       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:49:00.710148104Z I0109 04:49:00.708832       1 status_controller.go:211] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:44:16Z","message":"BackingResourceControllerDegraded: \"manifests/installer-sa.yaml\" (string): serviceaccounts \"installer-sa\" is forbidden: User \"system:serviceaccount:openshift-kube-apiserver-operator:kube-apiserver-operator\" cannot get resource \"serviceaccounts\" in API group \"\" in the namespace \"openshift-kube-apiserver\"\nBackingResourceControllerDegraded: \"manifests/installer-cluster-rolebinding.yaml\" (string): clusterrolebindings.rbac.authorization.k8s.io \"system:openshift:operator:openshift-kube-apiserver-installer\" is forbidden: User \"system:serviceaccount:openshift-kube-apiserver-operator:kube-apiserver-operator\" cannot get resource \"clusterrolebindings\" in API group \"rbac.authorization.k8s.io\" at the cluster scope\nBackingResourceControllerDegraded: \nGuardControllerDegraded: [Missing PodIP in operand kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrole-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrole-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrolebinding-auth-delegator.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-auth-delegator\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrolebinding-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrolebinding-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-rolebinding-kube-system.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:controller:kube-apiserver-check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-apiserver/rolebindings/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/delegated-incluster-authentication-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/authentication-reader-for-authenticated-users\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-apiserver-recovery\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/localhost-recovery-sa.yaml\" (string): serviceaccounts \"localhost-recovery-client\" is forbidden: User \"system:serviceaccount:openshift-kube-apiserver-operator:kube-apiserver-operator\" cannot get resource \"serviceaccounts\" in API group \"\" in the namespace \"openshift-kube-apiserver\"\nKubeAPIServerStaticResourcesDegraded: \nRevisionControllerDegraded: secrets \"encryption-config-7\" is forbidden: User \"system:serviceaccount:openshift-kube-apiserver-operator:kube-apiserver-operator\" cannot delete resource \"secrets\" in API group \"\" in the namespace \"openshift-kube-apiserver\"","reason":"BackingResourceController_SyncError::GuardController_SyncError::KubeAPIServerStaticResources_SyncError::RevisionController_ContentCreationError","status":"True","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:42:55Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 6","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:49:00.722500427Z E0109 04:49:00.722463       1 base_controller.go:272] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): serviceaccounts "installer-sa" is forbidden: User "system:serviceaccount:openshift-kube-apiserver-operator:kube-apiserver-operator" cannot get resource "serviceaccounts" in API group "" in the namespace "openshift-kube-apiserver", "manifests/installer-cluster-rolebinding.yaml" (string): clusterrolebindings.rbac.authorization.k8s.io "system:openshift:operator:openshift-kube-apiserver-installer" is forbidden: User "system:serviceaccount:openshift-kube-apiserver-operator:kube-apiserver-operator" cannot get resource "clusterrolebindings" in API group "rbac.authorization.k8s.io" at the cluster scope]
2023-01-09T04:49:00.744326654Z I0109 04:49:00.744256       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded message changed from "GuardControllerDegraded: [Missing PodIP in operand kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrole-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrole-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrolebinding-auth-delegator.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-auth-delegator\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrolebinding-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrolebinding-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-rolebinding-kube-system.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:controller:kube-apiserver-check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-apiserver/rolebindings/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/delegated-incluster-authentication-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/authentication-reader-for-authenticated-users\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-apiserver-recovery\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/localhost-recovery-sa.yaml\" (string): serviceaccounts \"localhost-recovery-client\" is forbidden: User \"system:serviceaccount:openshift-kube-apiserver-operator:kube-apiserver-operator\" cannot get resource \"serviceaccounts\" in API group \"\" in the namespace \"openshift-kube-apiserver\"\nKubeAPIServerStaticResourcesDegraded: \nRevisionControllerDegraded: secrets \"encryption-config-7\" is forbidden: User \"system:serviceaccount:openshift-kube-apiserver-operator:kube-apiserver-operator\" cannot delete resource \"secrets\" in API group \"\" in the namespace \"openshift-kube-apiserver\"" to "BackingResourceControllerDegraded: \"manifests/installer-sa.yaml\" (string): serviceaccounts \"installer-sa\" is forbidden: User \"system:serviceaccount:openshift-kube-apiserver-operator:kube-apiserver-operator\" cannot get resource \"serviceaccounts\" in API group \"\" in the namespace \"openshift-kube-apiserver\"\nBackingResourceControllerDegraded: \"manifests/installer-cluster-rolebinding.yaml\" (string): clusterrolebindings.rbac.authorization.k8s.io \"system:openshift:operator:openshift-kube-apiserver-installer\" is forbidden: User \"system:serviceaccount:openshift-kube-apiserver-operator:kube-apiserver-operator\" cannot get resource \"clusterrolebindings\" in API group \"rbac.authorization.k8s.io\" at the cluster scope\nBackingResourceControllerDegraded: \nGuardControllerDegraded: [Missing PodIP in operand kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrole-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrole-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrolebinding-auth-delegator.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-auth-delegator\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrolebinding-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrolebinding-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-rolebinding-kube-system.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:controller:kube-apiserver-check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-apiserver/rolebindings/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/delegated-incluster-authentication-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/authentication-reader-for-authenticated-users\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-apiserver-recovery\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/localhost-recovery-sa.yaml\" (string): serviceaccounts \"localhost-recovery-client\" is forbidden: User \"system:serviceaccount:openshift-kube-apiserver-operator:kube-apiserver-operator\" cannot get resource \"serviceaccounts\" in API group \"\" in the namespace \"openshift-kube-apiserver\"\nKubeAPIServerStaticResourcesDegraded: \nRevisionControllerDegraded: secrets \"encryption-config-7\" is forbidden: User \"system:serviceaccount:openshift-kube-apiserver-operator:kube-apiserver-operator\" cannot delete resource \"secrets\" in API group \"\" in the namespace \"openshift-kube-apiserver\""
2023-01-09T04:49:00.788871125Z E0109 04:49:00.788819       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:49:00.788871125Z E0109 04:49:00.788847       1 guard_controller.go:274] Missing PodIP in operand kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal on node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:49:00.788871125Z E0109 04:49:00.788864       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:49:00.856886193Z E0109 04:49:00.856845       1 base_controller.go:272] auditPolicyController reconciliation failed: configmaps "kube-apiserver-audit-policies" is forbidden: User "system:serviceaccount:openshift-kube-apiserver-operator:kube-apiserver-operator" cannot get resource "configmaps" in API group "" in the namespace "openshift-kube-apiserver"
2023-01-09T04:49:01.054270950Z E0109 04:49:01.054230       1 base_controller.go:272] NodeKubeconfigController reconciliation failed: "secret/node-kubeconfigs": secrets "node-kubeconfigs" is forbidden: User "system:serviceaccount:openshift-kube-apiserver-operator:kube-apiserver-operator" cannot get resource "secrets" in API group "" in the namespace "openshift-kube-apiserver"
2023-01-09T04:49:01.056158552Z I0109 04:49:01.056123       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:49:01.058738495Z I0109 04:49:01.058687       1 status_controller.go:211] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:44:16Z","message":"BackingResourceControllerDegraded: \"manifests/installer-sa.yaml\" (string): serviceaccounts \"installer-sa\" is forbidden: User \"system:serviceaccount:openshift-kube-apiserver-operator:kube-apiserver-operator\" cannot get resource \"serviceaccounts\" in API group \"\" in the namespace \"openshift-kube-apiserver\"\nBackingResourceControllerDegraded: \"manifests/installer-cluster-rolebinding.yaml\" (string): clusterrolebindings.rbac.authorization.k8s.io \"system:openshift:operator:openshift-kube-apiserver-installer\" is forbidden: User \"system:serviceaccount:openshift-kube-apiserver-operator:kube-apiserver-operator\" cannot get resource \"clusterrolebindings\" in API group \"rbac.authorization.k8s.io\" at the cluster scope\nBackingResourceControllerDegraded: \nGuardControllerDegraded: [Missing PodIP in operand kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrole-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrole-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrolebinding-auth-delegator.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-auth-delegator\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrolebinding-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrolebinding-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-rolebinding-kube-system.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:controller:kube-apiserver-check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-apiserver/rolebindings/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/delegated-incluster-authentication-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/authentication-reader-for-authenticated-users\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-apiserver-recovery\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/localhost-recovery-sa.yaml\" (string): serviceaccounts \"localhost-recovery-client\" is forbidden: User \"system:serviceaccount:openshift-kube-apiserver-operator:kube-apiserver-operator\" cannot get resource \"serviceaccounts\" in API group \"\" in the namespace \"openshift-kube-apiserver\"\nKubeAPIServerStaticResourcesDegraded: \nNodeKubeconfigControllerDegraded: \"secret/node-kubeconfigs\": secrets \"node-kubeconfigs\" is forbidden: User \"system:serviceaccount:openshift-kube-apiserver-operator:kube-apiserver-operator\" cannot get resource \"secrets\" in API group \"\" in the namespace \"openshift-kube-apiserver\"\nRevisionControllerDegraded: secrets \"encryption-config-7\" is forbidden: User \"system:serviceaccount:openshift-kube-apiserver-operator:kube-apiserver-operator\" cannot delete resource \"secrets\" in API group \"\" in the namespace \"openshift-kube-apiserver\"","reason":"BackingResourceController_SyncError::GuardController_SyncError::KubeAPIServerStaticResources_SyncError::NodeKubeconfigController_SyncError::RevisionController_ContentCreationError","status":"True","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:42:55Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 6","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:49:01.068749815Z I0109 04:49:01.068698       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded message changed from "BackingResourceControllerDegraded: \"manifests/installer-sa.yaml\" (string): serviceaccounts \"installer-sa\" is forbidden: User \"system:serviceaccount:openshift-kube-apiserver-operator:kube-apiserver-operator\" cannot get resource \"serviceaccounts\" in API group \"\" in the namespace \"openshift-kube-apiserver\"\nBackingResourceControllerDegraded: \"manifests/installer-cluster-rolebinding.yaml\" (string): clusterrolebindings.rbac.authorization.k8s.io \"system:openshift:operator:openshift-kube-apiserver-installer\" is forbidden: User \"system:serviceaccount:openshift-kube-apiserver-operator:kube-apiserver-operator\" cannot get resource \"clusterrolebindings\" in API group \"rbac.authorization.k8s.io\" at the cluster scope\nBackingResourceControllerDegraded: \nGuardControllerDegraded: [Missing PodIP in operand kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrole-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrole-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrolebinding-auth-delegator.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-auth-delegator\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrolebinding-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrolebinding-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-rolebinding-kube-system.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:controller:kube-apiserver-check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-apiserver/rolebindings/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/delegated-incluster-authentication-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/authentication-reader-for-authenticated-users\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-apiserver-recovery\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/localhost-recovery-sa.yaml\" (string): serviceaccounts \"localhost-recovery-client\" is forbidden: User \"system:serviceaccount:openshift-kube-apiserver-operator:kube-apiserver-operator\" cannot get resource \"serviceaccounts\" in API group \"\" in the namespace \"openshift-kube-apiserver\"\nKubeAPIServerStaticResourcesDegraded: \nRevisionControllerDegraded: secrets \"encryption-config-7\" is forbidden: User \"system:serviceaccount:openshift-kube-apiserver-operator:kube-apiserver-operator\" cannot delete resource \"secrets\" in API group \"\" in the namespace \"openshift-kube-apiserver\"" to "BackingResourceControllerDegraded: \"manifests/installer-sa.yaml\" (string): serviceaccounts \"installer-sa\" is forbidden: User \"system:serviceaccount:openshift-kube-apiserver-operator:kube-apiserver-operator\" cannot get resource \"serviceaccounts\" in API group \"\" in the namespace \"openshift-kube-apiserver\"\nBackingResourceControllerDegraded: \"manifests/installer-cluster-rolebinding.yaml\" (string): clusterrolebindings.rbac.authorization.k8s.io \"system:openshift:operator:openshift-kube-apiserver-installer\" is forbidden: User \"system:serviceaccount:openshift-kube-apiserver-operator:kube-apiserver-operator\" cannot get resource \"clusterrolebindings\" in API group \"rbac.authorization.k8s.io\" at the cluster scope\nBackingResourceControllerDegraded: \nGuardControllerDegraded: [Missing PodIP in operand kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrole-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrole-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrolebinding-auth-delegator.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-auth-delegator\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrolebinding-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrolebinding-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-rolebinding-kube-system.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:controller:kube-apiserver-check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-apiserver/rolebindings/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/delegated-incluster-authentication-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/authentication-reader-for-authenticated-users\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-apiserver-recovery\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/localhost-recovery-sa.yaml\" (string): serviceaccounts \"localhost-recovery-client\" is forbidden: User \"system:serviceaccount:openshift-kube-apiserver-operator:kube-apiserver-operator\" cannot get resource \"serviceaccounts\" in API group \"\" in the namespace \"openshift-kube-apiserver\"\nKubeAPIServerStaticResourcesDegraded: \nNodeKubeconfigControllerDegraded: \"secret/node-kubeconfigs\": secrets \"node-kubeconfigs\" is forbidden: User \"system:serviceaccount:openshift-kube-apiserver-operator:kube-apiserver-operator\" cannot get resource \"secrets\" in API group \"\" in the namespace \"openshift-kube-apiserver\"\nRevisionControllerDegraded: secrets \"encryption-config-7\" is forbidden: User \"system:serviceaccount:openshift-kube-apiserver-operator:kube-apiserver-operator\" cannot delete resource \"secrets\" in API group \"\" in the namespace \"openshift-kube-apiserver\""
2023-01-09T04:49:01.250382396Z I0109 04:49:01.250331       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:49:01.250661169Z I0109 04:49:01.250633       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:49:01.250977016Z I0109 04:49:01.250949       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:49:01.251327941Z I0109 04:49:01.251298       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:49:01.291598993Z I0109 04:49:01.291562       1 request.go:601] Waited for 2.581395497s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces?resourceVersion=22903
2023-01-09T04:49:01.457312973Z I0109 04:49:01.457275       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:49:01.459957993Z E0109 04:49:01.459921       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing PodIP in operand kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal]
2023-01-09T04:49:01.460157273Z I0109 04:49:01.460116       1 status_controller.go:211] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:44:16Z","message":"BackingResourceControllerDegraded: \"manifests/installer-sa.yaml\" (string): serviceaccounts \"installer-sa\" is forbidden: User \"system:serviceaccount:openshift-kube-apiserver-operator:kube-apiserver-operator\" cannot get resource \"serviceaccounts\" in API group \"\" in the namespace \"openshift-kube-apiserver\"\nBackingResourceControllerDegraded: \"manifests/installer-cluster-rolebinding.yaml\" (string): clusterrolebindings.rbac.authorization.k8s.io \"system:openshift:operator:openshift-kube-apiserver-installer\" is forbidden: User \"system:serviceaccount:openshift-kube-apiserver-operator:kube-apiserver-operator\" cannot get resource \"clusterrolebindings\" in API group \"rbac.authorization.k8s.io\" at the cluster scope\nBackingResourceControllerDegraded: \nGuardControllerDegraded: [Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing PodIP in operand kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal]\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrole-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrole-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrolebinding-auth-delegator.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-auth-delegator\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrolebinding-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrolebinding-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-rolebinding-kube-system.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:controller:kube-apiserver-check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-apiserver/rolebindings/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/delegated-incluster-authentication-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/authentication-reader-for-authenticated-users\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-apiserver-recovery\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/localhost-recovery-sa.yaml\" (string): serviceaccounts \"localhost-recovery-client\" is forbidden: User \"system:serviceaccount:openshift-kube-apiserver-operator:kube-apiserver-operator\" cannot get resource \"serviceaccounts\" in API group \"\" in the namespace \"openshift-kube-apiserver\"\nKubeAPIServerStaticResourcesDegraded: \nNodeKubeconfigControllerDegraded: \"secret/node-kubeconfigs\": secrets \"node-kubeconfigs\" is forbidden: User \"system:serviceaccount:openshift-kube-apiserver-operator:kube-apiserver-operator\" cannot get resource \"secrets\" in API group \"\" in the namespace \"openshift-kube-apiserver\"\nRevisionControllerDegraded: secrets \"encryption-config-7\" is forbidden: User \"system:serviceaccount:openshift-kube-apiserver-operator:kube-apiserver-operator\" cannot delete resource \"secrets\" in API group \"\" in the namespace \"openshift-kube-apiserver\"","reason":"BackingResourceController_SyncError::GuardController_SyncError::KubeAPIServerStaticResources_SyncError::NodeKubeconfigController_SyncError::RevisionController_ContentCreationError","status":"True","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:42:55Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 6","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:49:01.464534932Z E0109 04:49:01.464504       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:49:01.464562618Z E0109 04:49:01.464533       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:49:01.464562618Z E0109 04:49:01.464545       1 guard_controller.go:274] Missing PodIP in operand kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal on node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:49:01.482527346Z I0109 04:49:01.482460       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded message changed from "BackingResourceControllerDegraded: \"manifests/installer-sa.yaml\" (string): serviceaccounts \"installer-sa\" is forbidden: User \"system:serviceaccount:openshift-kube-apiserver-operator:kube-apiserver-operator\" cannot get resource \"serviceaccounts\" in API group \"\" in the namespace \"openshift-kube-apiserver\"\nBackingResourceControllerDegraded: \"manifests/installer-cluster-rolebinding.yaml\" (string): clusterrolebindings.rbac.authorization.k8s.io \"system:openshift:operator:openshift-kube-apiserver-installer\" is forbidden: User \"system:serviceaccount:openshift-kube-apiserver-operator:kube-apiserver-operator\" cannot get resource \"clusterrolebindings\" in API group \"rbac.authorization.k8s.io\" at the cluster scope\nBackingResourceControllerDegraded: \nGuardControllerDegraded: [Missing PodIP in operand kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrole-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrole-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrolebinding-auth-delegator.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-auth-delegator\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrolebinding-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrolebinding-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-rolebinding-kube-system.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:controller:kube-apiserver-check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-apiserver/rolebindings/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/delegated-incluster-authentication-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/authentication-reader-for-authenticated-users\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-apiserver-recovery\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/localhost-recovery-sa.yaml\" (string): serviceaccounts \"localhost-recovery-client\" is forbidden: User \"system:serviceaccount:openshift-kube-apiserver-operator:kube-apiserver-operator\" cannot get resource \"serviceaccounts\" in API group \"\" in the namespace \"openshift-kube-apiserver\"\nKubeAPIServerStaticResourcesDegraded: \nNodeKubeconfigControllerDegraded: \"secret/node-kubeconfigs\": secrets \"node-kubeconfigs\" is forbidden: User \"system:serviceaccount:openshift-kube-apiserver-operator:kube-apiserver-operator\" cannot get resource \"secrets\" in API group \"\" in the namespace \"openshift-kube-apiserver\"\nRevisionControllerDegraded: secrets \"encryption-config-7\" is forbidden: User \"system:serviceaccount:openshift-kube-apiserver-operator:kube-apiserver-operator\" cannot delete resource \"secrets\" in API group \"\" in the namespace \"openshift-kube-apiserver\"" to "BackingResourceControllerDegraded: \"manifests/installer-sa.yaml\" (string): serviceaccounts \"installer-sa\" is forbidden: User \"system:serviceaccount:openshift-kube-apiserver-operator:kube-apiserver-operator\" cannot get resource \"serviceaccounts\" in API group \"\" in the namespace \"openshift-kube-apiserver\"\nBackingResourceControllerDegraded: \"manifests/installer-cluster-rolebinding.yaml\" (string): clusterrolebindings.rbac.authorization.k8s.io \"system:openshift:operator:openshift-kube-apiserver-installer\" is forbidden: User \"system:serviceaccount:openshift-kube-apiserver-operator:kube-apiserver-operator\" cannot get resource \"clusterrolebindings\" in API group \"rbac.authorization.k8s.io\" at the cluster scope\nBackingResourceControllerDegraded: \nGuardControllerDegraded: [Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing PodIP in operand kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal]\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrole-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrole-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrolebinding-auth-delegator.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-auth-delegator\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrolebinding-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrolebinding-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-rolebinding-kube-system.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:controller:kube-apiserver-check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-apiserver/rolebindings/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/delegated-incluster-authentication-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/authentication-reader-for-authenticated-users\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-apiserver-recovery\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/localhost-recovery-sa.yaml\" (string): serviceaccounts \"localhost-recovery-client\" is forbidden: User \"system:serviceaccount:openshift-kube-apiserver-operator:kube-apiserver-operator\" cannot get resource \"serviceaccounts\" in API group \"\" in the namespace \"openshift-kube-apiserver\"\nKubeAPIServerStaticResourcesDegraded: \nNodeKubeconfigControllerDegraded: \"secret/node-kubeconfigs\": secrets \"node-kubeconfigs\" is forbidden: User \"system:serviceaccount:openshift-kube-apiserver-operator:kube-apiserver-operator\" cannot get resource \"secrets\" in API group \"\" in the namespace \"openshift-kube-apiserver\"\nRevisionControllerDegraded: secrets \"encryption-config-7\" is forbidden: User \"system:serviceaccount:openshift-kube-apiserver-operator:kube-apiserver-operator\" cannot delete resource \"secrets\" in API group \"\" in the namespace \"openshift-kube-apiserver\""
2023-01-09T04:49:01.654216789Z E0109 04:49:01.654172       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing PodIP in operand kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal on node ip-10-0-199-219.us-east-2.compute.internal]
2023-01-09T04:49:01.657065188Z I0109 04:49:01.657019       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:49:01.658396312Z I0109 04:49:01.658351       1 status_controller.go:211] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:44:16Z","message":"BackingResourceControllerDegraded: \"manifests/installer-sa.yaml\" (string): serviceaccounts \"installer-sa\" is forbidden: User \"system:serviceaccount:openshift-kube-apiserver-operator:kube-apiserver-operator\" cannot get resource \"serviceaccounts\" in API group \"\" in the namespace \"openshift-kube-apiserver\"\nBackingResourceControllerDegraded: \"manifests/installer-cluster-rolebinding.yaml\" (string): clusterrolebindings.rbac.authorization.k8s.io \"system:openshift:operator:openshift-kube-apiserver-installer\" is forbidden: User \"system:serviceaccount:openshift-kube-apiserver-operator:kube-apiserver-operator\" cannot get resource \"clusterrolebindings\" in API group \"rbac.authorization.k8s.io\" at the cluster scope\nBackingResourceControllerDegraded: \nGuardControllerDegraded: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing PodIP in operand kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal on node ip-10-0-199-219.us-east-2.compute.internal]\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrole-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrole-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrolebinding-auth-delegator.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-auth-delegator\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrolebinding-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrolebinding-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-rolebinding-kube-system.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:controller:kube-apiserver-check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-apiserver/rolebindings/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/delegated-incluster-authentication-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/authentication-reader-for-authenticated-users\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-apiserver-recovery\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/localhost-recovery-sa.yaml\" (string): serviceaccounts \"localhost-recovery-client\" is forbidden: User \"system:serviceaccount:openshift-kube-apiserver-operator:kube-apiserver-operator\" cannot get resource \"serviceaccounts\" in API group \"\" in the namespace \"openshift-kube-apiserver\"\nKubeAPIServerStaticResourcesDegraded: \nNodeKubeconfigControllerDegraded: \"secret/node-kubeconfigs\": secrets \"node-kubeconfigs\" is forbidden: User \"system:serviceaccount:openshift-kube-apiserver-operator:kube-apiserver-operator\" cannot get resource \"secrets\" in API group \"\" in the namespace \"openshift-kube-apiserver\"\nRevisionControllerDegraded: secrets \"encryption-config-7\" is forbidden: User \"system:serviceaccount:openshift-kube-apiserver-operator:kube-apiserver-operator\" cannot delete resource \"secrets\" in API group \"\" in the namespace \"openshift-kube-apiserver\"","reason":"BackingResourceController_SyncError::GuardController_SyncError::KubeAPIServerStaticResources_SyncError::NodeKubeconfigController_SyncError::RevisionController_ContentCreationError","status":"True","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:42:55Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 6","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:49:01.671065004Z I0109 04:49:01.667936       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded message changed from "BackingResourceControllerDegraded: \"manifests/installer-sa.yaml\" (string): serviceaccounts \"installer-sa\" is forbidden: User \"system:serviceaccount:openshift-kube-apiserver-operator:kube-apiserver-operator\" cannot get resource \"serviceaccounts\" in API group \"\" in the namespace \"openshift-kube-apiserver\"\nBackingResourceControllerDegraded: \"manifests/installer-cluster-rolebinding.yaml\" (string): clusterrolebindings.rbac.authorization.k8s.io \"system:openshift:operator:openshift-kube-apiserver-installer\" is forbidden: User \"system:serviceaccount:openshift-kube-apiserver-operator:kube-apiserver-operator\" cannot get resource \"clusterrolebindings\" in API group \"rbac.authorization.k8s.io\" at the cluster scope\nBackingResourceControllerDegraded: \nGuardControllerDegraded: [Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing PodIP in operand kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal]\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrole-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrole-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrolebinding-auth-delegator.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-auth-delegator\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrolebinding-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrolebinding-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-rolebinding-kube-system.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:controller:kube-apiserver-check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-apiserver/rolebindings/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/delegated-incluster-authentication-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/authentication-reader-for-authenticated-users\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-apiserver-recovery\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/localhost-recovery-sa.yaml\" (string): serviceaccounts \"localhost-recovery-client\" is forbidden: User \"system:serviceaccount:openshift-kube-apiserver-operator:kube-apiserver-operator\" cannot get resource \"serviceaccounts\" in API group \"\" in the namespace \"openshift-kube-apiserver\"\nKubeAPIServerStaticResourcesDegraded: \nNodeKubeconfigControllerDegraded: \"secret/node-kubeconfigs\": secrets \"node-kubeconfigs\" is forbidden: User \"system:serviceaccount:openshift-kube-apiserver-operator:kube-apiserver-operator\" cannot get resource \"secrets\" in API group \"\" in the namespace \"openshift-kube-apiserver\"\nRevisionControllerDegraded: secrets \"encryption-config-7\" is forbidden: User \"system:serviceaccount:openshift-kube-apiserver-operator:kube-apiserver-operator\" cannot delete resource \"secrets\" in API group \"\" in the namespace \"openshift-kube-apiserver\"" to "BackingResourceControllerDegraded: \"manifests/installer-sa.yaml\" (string): serviceaccounts \"installer-sa\" is forbidden: User \"system:serviceaccount:openshift-kube-apiserver-operator:kube-apiserver-operator\" cannot get resource \"serviceaccounts\" in API group \"\" in the namespace \"openshift-kube-apiserver\"\nBackingResourceControllerDegraded: \"manifests/installer-cluster-rolebinding.yaml\" (string): clusterrolebindings.rbac.authorization.k8s.io \"system:openshift:operator:openshift-kube-apiserver-installer\" is forbidden: User \"system:serviceaccount:openshift-kube-apiserver-operator:kube-apiserver-operator\" cannot get resource \"clusterrolebindings\" in API group \"rbac.authorization.k8s.io\" at the cluster scope\nBackingResourceControllerDegraded: \nGuardControllerDegraded: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing PodIP in operand kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal on node ip-10-0-199-219.us-east-2.compute.internal]\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrole-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrole-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrolebinding-auth-delegator.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-auth-delegator\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrolebinding-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrolebinding-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-rolebinding-kube-system.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:controller:kube-apiserver-check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-apiserver/rolebindings/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/delegated-incluster-authentication-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/authentication-reader-for-authenticated-users\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-apiserver-recovery\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/localhost-recovery-sa.yaml\" (string): serviceaccounts \"localhost-recovery-client\" is forbidden: User \"system:serviceaccount:openshift-kube-apiserver-operator:kube-apiserver-operator\" cannot get resource \"serviceaccounts\" in API group \"\" in the namespace \"openshift-kube-apiserver\"\nKubeAPIServerStaticResourcesDegraded: \nNodeKubeconfigControllerDegraded: \"secret/node-kubeconfigs\": secrets \"node-kubeconfigs\" is forbidden: User \"system:serviceaccount:openshift-kube-apiserver-operator:kube-apiserver-operator\" cannot get resource \"secrets\" in API group \"\" in the namespace \"openshift-kube-apiserver\"\nRevisionControllerDegraded: secrets \"encryption-config-7\" is forbidden: User \"system:serviceaccount:openshift-kube-apiserver-operator:kube-apiserver-operator\" cannot delete resource \"secrets\" in API group \"\" in the namespace \"openshift-kube-apiserver\""
2023-01-09T04:49:02.093736040Z E0109 04:49:02.093687       1 base_controller.go:272] PruneController reconciliation failed: configmaps "revision-status-1" not found
2023-01-09T04:49:02.491878848Z I0109 04:49:02.491833       1 request.go:601] Waited for 2.604200022s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver
2023-01-09T04:49:02.713628204Z I0109 04:49:02.713566       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'PodCreateFailed' Failed to create Pod/installer-6-ip-10-0-199-219.us-east-2.compute.internal -n openshift-kube-apiserver: etcdserver: request timed out
2023-01-09T04:49:02.713628204Z I0109 04:49:02.713599       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 6 count 0 on node "ip-10-0-199-219.us-east-2.compute.internal": etcdserver: request timed out
2023-01-09T04:49:02.723857280Z I0109 04:49:02.723437       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:49:02.728425149Z E0109 04:49:02.728379       1 base_controller.go:272] InstallerController reconciliation failed: etcdserver: request timed out
2023-01-09T04:49:02.730485239Z I0109 04:49:02.730448       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:49:02.731697881Z I0109 04:49:02.731639       1 status_controller.go:211] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:44:16Z","message":"BackingResourceControllerDegraded: \"manifests/installer-sa.yaml\" (string): serviceaccounts \"installer-sa\" is forbidden: User \"system:serviceaccount:openshift-kube-apiserver-operator:kube-apiserver-operator\" cannot get resource \"serviceaccounts\" in API group \"\" in the namespace \"openshift-kube-apiserver\"\nBackingResourceControllerDegraded: \"manifests/installer-cluster-rolebinding.yaml\" (string): clusterrolebindings.rbac.authorization.k8s.io \"system:openshift:operator:openshift-kube-apiserver-installer\" is forbidden: User \"system:serviceaccount:openshift-kube-apiserver-operator:kube-apiserver-operator\" cannot get resource \"clusterrolebindings\" in API group \"rbac.authorization.k8s.io\" at the cluster scope\nBackingResourceControllerDegraded: \nGuardControllerDegraded: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing PodIP in operand kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal on node ip-10-0-199-219.us-east-2.compute.internal]\nInstallerControllerDegraded: etcdserver: request timed out\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrole-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrole-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrolebinding-auth-delegator.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-auth-delegator\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrolebinding-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrolebinding-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-rolebinding-kube-system.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:controller:kube-apiserver-check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-apiserver/rolebindings/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/delegated-incluster-authentication-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/authentication-reader-for-authenticated-users\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-apiserver-recovery\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/localhost-recovery-sa.yaml\" (string): serviceaccounts \"localhost-recovery-client\" is forbidden: User \"system:serviceaccount:openshift-kube-apiserver-operator:kube-apiserver-operator\" cannot get resource \"serviceaccounts\" in API group \"\" in the namespace \"openshift-kube-apiserver\"\nKubeAPIServerStaticResourcesDegraded: \nNodeKubeconfigControllerDegraded: \"secret/node-kubeconfigs\": secrets \"node-kubeconfigs\" is forbidden: User \"system:serviceaccount:openshift-kube-apiserver-operator:kube-apiserver-operator\" cannot get resource \"secrets\" in API group \"\" in the namespace \"openshift-kube-apiserver\"\nRevisionControllerDegraded: secrets \"encryption-config-7\" is forbidden: User \"system:serviceaccount:openshift-kube-apiserver-operator:kube-apiserver-operator\" cannot delete resource \"secrets\" in API group \"\" in the namespace \"openshift-kube-apiserver\"","reason":"BackingResourceController_SyncError::GuardController_SyncError::InstallerController_Error::KubeAPIServerStaticResources_SyncError::NodeKubeconfigController_SyncError::RevisionController_ContentCreationError","status":"True","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:42:55Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 6","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:49:02.739946841Z I0109 04:49:02.739889       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded message changed from "BackingResourceControllerDegraded: \"manifests/installer-sa.yaml\" (string): serviceaccounts \"installer-sa\" is forbidden: User \"system:serviceaccount:openshift-kube-apiserver-operator:kube-apiserver-operator\" cannot get resource \"serviceaccounts\" in API group \"\" in the namespace \"openshift-kube-apiserver\"\nBackingResourceControllerDegraded: \"manifests/installer-cluster-rolebinding.yaml\" (string): clusterrolebindings.rbac.authorization.k8s.io \"system:openshift:operator:openshift-kube-apiserver-installer\" is forbidden: User \"system:serviceaccount:openshift-kube-apiserver-operator:kube-apiserver-operator\" cannot get resource \"clusterrolebindings\" in API group \"rbac.authorization.k8s.io\" at the cluster scope\nBackingResourceControllerDegraded: \nGuardControllerDegraded: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing PodIP in operand kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal on node ip-10-0-199-219.us-east-2.compute.internal]\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrole-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrole-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrolebinding-auth-delegator.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-auth-delegator\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrolebinding-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrolebinding-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-rolebinding-kube-system.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:controller:kube-apiserver-check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-apiserver/rolebindings/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/delegated-incluster-authentication-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/authentication-reader-for-authenticated-users\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-apiserver-recovery\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/localhost-recovery-sa.yaml\" (string): serviceaccounts \"localhost-recovery-client\" is forbidden: User \"system:serviceaccount:openshift-kube-apiserver-operator:kube-apiserver-operator\" cannot get resource \"serviceaccounts\" in API group \"\" in the namespace \"openshift-kube-apiserver\"\nKubeAPIServerStaticResourcesDegraded: \nNodeKubeconfigControllerDegraded: \"secret/node-kubeconfigs\": secrets \"node-kubeconfigs\" is forbidden: User \"system:serviceaccount:openshift-kube-apiserver-operator:kube-apiserver-operator\" cannot get resource \"secrets\" in API group \"\" in the namespace \"openshift-kube-apiserver\"\nRevisionControllerDegraded: secrets \"encryption-config-7\" is forbidden: User \"system:serviceaccount:openshift-kube-apiserver-operator:kube-apiserver-operator\" cannot delete resource \"secrets\" in API group \"\" in the namespace \"openshift-kube-apiserver\"" to "BackingResourceControllerDegraded: \"manifests/installer-sa.yaml\" (string): serviceaccounts \"installer-sa\" is forbidden: User \"system:serviceaccount:openshift-kube-apiserver-operator:kube-apiserver-operator\" cannot get resource \"serviceaccounts\" in API group \"\" in the namespace \"openshift-kube-apiserver\"\nBackingResourceControllerDegraded: \"manifests/installer-cluster-rolebinding.yaml\" (string): clusterrolebindings.rbac.authorization.k8s.io \"system:openshift:operator:openshift-kube-apiserver-installer\" is forbidden: User \"system:serviceaccount:openshift-kube-apiserver-operator:kube-apiserver-operator\" cannot get resource \"clusterrolebindings\" in API group \"rbac.authorization.k8s.io\" at the cluster scope\nBackingResourceControllerDegraded: \nGuardControllerDegraded: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing PodIP in operand kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal on node ip-10-0-199-219.us-east-2.compute.internal]\nInstallerControllerDegraded: etcdserver: request timed out\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrole-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrole-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrolebinding-auth-delegator.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-auth-delegator\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrolebinding-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrolebinding-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-rolebinding-kube-system.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:controller:kube-apiserver-check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-apiserver/rolebindings/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/delegated-incluster-authentication-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/authentication-reader-for-authenticated-users\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-apiserver-recovery\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/localhost-recovery-sa.yaml\" (string): serviceaccounts \"localhost-recovery-client\" is forbidden: User \"system:serviceaccount:openshift-kube-apiserver-operator:kube-apiserver-operator\" cannot get resource \"serviceaccounts\" in API group \"\" in the namespace \"openshift-kube-apiserver\"\nKubeAPIServerStaticResourcesDegraded: \nNodeKubeconfigControllerDegraded: \"secret/node-kubeconfigs\": secrets \"node-kubeconfigs\" is forbidden: User \"system:serviceaccount:openshift-kube-apiserver-operator:kube-apiserver-operator\" cannot get resource \"secrets\" in API group \"\" in the namespace \"openshift-kube-apiserver\"\nRevisionControllerDegraded: secrets \"encryption-config-7\" is forbidden: User \"system:serviceaccount:openshift-kube-apiserver-operator:kube-apiserver-operator\" cannot delete resource \"secrets\" in API group \"\" in the namespace \"openshift-kube-apiserver\""
2023-01-09T04:49:02.899667241Z I0109 04:49:02.899408       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapUpdated' Updated ConfigMap/config -n openshift-kube-apiserver:
2023-01-09T04:49:02.899667241Z cause by changes in data.config.yaml
2023-01-09T04:49:03.313127250Z I0109 04:49:03.313072       1 status_controller.go:211] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:44:16Z","message":"GuardControllerDegraded: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing PodIP in operand kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal on node ip-10-0-199-219.us-east-2.compute.internal]\nInstallerControllerDegraded: etcdserver: request timed out\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrole-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrole-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrolebinding-auth-delegator.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-auth-delegator\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrolebinding-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrolebinding-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-rolebinding-kube-system.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:controller:kube-apiserver-check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-apiserver/rolebindings/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/delegated-incluster-authentication-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/authentication-reader-for-authenticated-users\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-apiserver-recovery\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/localhost-recovery-sa.yaml\" (string): serviceaccounts \"localhost-recovery-client\" is forbidden: User \"system:serviceaccount:openshift-kube-apiserver-operator:kube-apiserver-operator\" cannot get resource \"serviceaccounts\" in API group \"\" in the namespace \"openshift-kube-apiserver\"\nKubeAPIServerStaticResourcesDegraded: \nNodeKubeconfigControllerDegraded: \"secret/node-kubeconfigs\": secrets \"node-kubeconfigs\" is forbidden: User \"system:serviceaccount:openshift-kube-apiserver-operator:kube-apiserver-operator\" cannot get resource \"secrets\" in API group \"\" in the namespace \"openshift-kube-apiserver\"\nRevisionControllerDegraded: secrets \"encryption-config-7\" is forbidden: User \"system:serviceaccount:openshift-kube-apiserver-operator:kube-apiserver-operator\" cannot delete resource \"secrets\" in API group \"\" in the namespace \"openshift-kube-apiserver\"","reason":"GuardController_SyncError::InstallerController_Error::KubeAPIServerStaticResources_SyncError::NodeKubeconfigController_SyncError::RevisionController_ContentCreationError","status":"True","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:42:55Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 6","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:49:03.313416025Z I0109 04:49:03.313388       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:49:03.324105047Z I0109 04:49:03.322620       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded message changed from "BackingResourceControllerDegraded: \"manifests/installer-sa.yaml\" (string): serviceaccounts \"installer-sa\" is forbidden: User \"system:serviceaccount:openshift-kube-apiserver-operator:kube-apiserver-operator\" cannot get resource \"serviceaccounts\" in API group \"\" in the namespace \"openshift-kube-apiserver\"\nBackingResourceControllerDegraded: \"manifests/installer-cluster-rolebinding.yaml\" (string): clusterrolebindings.rbac.authorization.k8s.io \"system:openshift:operator:openshift-kube-apiserver-installer\" is forbidden: User \"system:serviceaccount:openshift-kube-apiserver-operator:kube-apiserver-operator\" cannot get resource \"clusterrolebindings\" in API group \"rbac.authorization.k8s.io\" at the cluster scope\nBackingResourceControllerDegraded: \nGuardControllerDegraded: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing PodIP in operand kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal on node ip-10-0-199-219.us-east-2.compute.internal]\nInstallerControllerDegraded: etcdserver: request timed out\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrole-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrole-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrolebinding-auth-delegator.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-auth-delegator\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrolebinding-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrolebinding-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-rolebinding-kube-system.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:controller:kube-apiserver-check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-apiserver/rolebindings/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/delegated-incluster-authentication-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/authentication-reader-for-authenticated-users\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-apiserver-recovery\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/localhost-recovery-sa.yaml\" (string): serviceaccounts \"localhost-recovery-client\" is forbidden: User \"system:serviceaccount:openshift-kube-apiserver-operator:kube-apiserver-operator\" cannot get resource \"serviceaccounts\" in API group \"\" in the namespace \"openshift-kube-apiserver\"\nKubeAPIServerStaticResourcesDegraded: \nNodeKubeconfigControllerDegraded: \"secret/node-kubeconfigs\": secrets \"node-kubeconfigs\" is forbidden: User \"system:serviceaccount:openshift-kube-apiserver-operator:kube-apiserver-operator\" cannot get resource \"secrets\" in API group \"\" in the namespace \"openshift-kube-apiserver\"\nRevisionControllerDegraded: secrets \"encryption-config-7\" is forbidden: User \"system:serviceaccount:openshift-kube-apiserver-operator:kube-apiserver-operator\" cannot delete resource \"secrets\" in API group \"\" in the namespace \"openshift-kube-apiserver\"" to "GuardControllerDegraded: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing PodIP in operand kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal on node ip-10-0-199-219.us-east-2.compute.internal]\nInstallerControllerDegraded: etcdserver: request timed out\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrole-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrole-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrolebinding-auth-delegator.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-auth-delegator\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrolebinding-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrolebinding-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-rolebinding-kube-system.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:controller:kube-apiserver-check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-apiserver/rolebindings/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/delegated-incluster-authentication-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/authentication-reader-for-authenticated-users\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-apiserver-recovery\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/localhost-recovery-sa.yaml\" (string): serviceaccounts \"localhost-recovery-client\" is forbidden: User \"system:serviceaccount:openshift-kube-apiserver-operator:kube-apiserver-operator\" cannot get resource \"serviceaccounts\" in API group \"\" in the namespace \"openshift-kube-apiserver\"\nKubeAPIServerStaticResourcesDegraded: \nNodeKubeconfigControllerDegraded: \"secret/node-kubeconfigs\": secrets \"node-kubeconfigs\" is forbidden: User \"system:serviceaccount:openshift-kube-apiserver-operator:kube-apiserver-operator\" cannot get resource \"secrets\" in API group \"\" in the namespace \"openshift-kube-apiserver\"\nRevisionControllerDegraded: secrets \"encryption-config-7\" is forbidden: User \"system:serviceaccount:openshift-kube-apiserver-operator:kube-apiserver-operator\" cannot delete resource \"secrets\" in API group \"\" in the namespace \"openshift-kube-apiserver\""
2023-01-09T04:49:03.691351051Z I0109 04:49:03.691305       1 request.go:601] Waited for 2.636180515s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T04:49:03.714375561Z I0109 04:49:03.713064       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:49:03.714375561Z I0109 04:49:03.714315       1 status_controller.go:211] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:44:16Z","message":"GuardControllerDegraded: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing PodIP in operand kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal on node ip-10-0-199-219.us-east-2.compute.internal]\nInstallerControllerDegraded: etcdserver: request timed out\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrole-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrole-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrolebinding-auth-delegator.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-auth-delegator\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrolebinding-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrolebinding-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-rolebinding-kube-system.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:controller:kube-apiserver-check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-apiserver/rolebindings/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/delegated-incluster-authentication-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/authentication-reader-for-authenticated-users\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-apiserver-recovery\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/localhost-recovery-sa.yaml\" (string): serviceaccounts \"localhost-recovery-client\" is forbidden: User \"system:serviceaccount:openshift-kube-apiserver-operator:kube-apiserver-operator\" cannot get resource \"serviceaccounts\" in API group \"\" in the namespace \"openshift-kube-apiserver\"\nKubeAPIServerStaticResourcesDegraded: \nRevisionControllerDegraded: secrets \"encryption-config-7\" is forbidden: User \"system:serviceaccount:openshift-kube-apiserver-operator:kube-apiserver-operator\" cannot delete resource \"secrets\" in API group \"\" in the namespace \"openshift-kube-apiserver\"","reason":"GuardController_SyncError::InstallerController_Error::KubeAPIServerStaticResources_SyncError::RevisionController_ContentCreationError","status":"True","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:42:55Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 6","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:49:03.723851119Z I0109 04:49:03.723785       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded message changed from "GuardControllerDegraded: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing PodIP in operand kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal on node ip-10-0-199-219.us-east-2.compute.internal]\nInstallerControllerDegraded: etcdserver: request timed out\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrole-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrole-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrolebinding-auth-delegator.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-auth-delegator\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrolebinding-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrolebinding-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-rolebinding-kube-system.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:controller:kube-apiserver-check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-apiserver/rolebindings/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/delegated-incluster-authentication-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/authentication-reader-for-authenticated-users\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-apiserver-recovery\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/localhost-recovery-sa.yaml\" (string): serviceaccounts \"localhost-recovery-client\" is forbidden: User \"system:serviceaccount:openshift-kube-apiserver-operator:kube-apiserver-operator\" cannot get resource \"serviceaccounts\" in API group \"\" in the namespace \"openshift-kube-apiserver\"\nKubeAPIServerStaticResourcesDegraded: \nNodeKubeconfigControllerDegraded: \"secret/node-kubeconfigs\": secrets \"node-kubeconfigs\" is forbidden: User \"system:serviceaccount:openshift-kube-apiserver-operator:kube-apiserver-operator\" cannot get resource \"secrets\" in API group \"\" in the namespace \"openshift-kube-apiserver\"\nRevisionControllerDegraded: secrets \"encryption-config-7\" is forbidden: User \"system:serviceaccount:openshift-kube-apiserver-operator:kube-apiserver-operator\" cannot delete resource \"secrets\" in API group \"\" in the namespace \"openshift-kube-apiserver\"" to "GuardControllerDegraded: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing PodIP in operand kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal on node ip-10-0-199-219.us-east-2.compute.internal]\nInstallerControllerDegraded: etcdserver: request timed out\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrole-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrole-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrolebinding-auth-delegator.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-auth-delegator\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrolebinding-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrolebinding-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-rolebinding-kube-system.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:controller:kube-apiserver-check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-apiserver/rolebindings/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/delegated-incluster-authentication-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/authentication-reader-for-authenticated-users\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-apiserver-recovery\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/localhost-recovery-sa.yaml\" (string): serviceaccounts \"localhost-recovery-client\" is forbidden: User \"system:serviceaccount:openshift-kube-apiserver-operator:kube-apiserver-operator\" cannot get resource \"serviceaccounts\" in API group \"\" in the namespace \"openshift-kube-apiserver\"\nKubeAPIServerStaticResourcesDegraded: \nRevisionControllerDegraded: secrets \"encryption-config-7\" is forbidden: User \"system:serviceaccount:openshift-kube-apiserver-operator:kube-apiserver-operator\" cannot delete resource \"secrets\" in API group \"\" in the namespace \"openshift-kube-apiserver\""
2023-01-09T04:49:04.417447262Z E0109 04:49:04.417407       1 guard_controller.go:274] Missing PodIP in operand kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal on node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:49:04.417447262Z E0109 04:49:04.417432       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:49:04.417484160Z E0109 04:49:04.417443       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:49:04.434590658Z E0109 04:49:04.434539       1 base_controller.go:272] GuardController reconciliation failed: [Missing PodIP in operand kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:49:04.436239304Z I0109 04:49:04.436197       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:49:04.438979144Z I0109 04:49:04.438926       1 status_controller.go:211] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:44:16Z","message":"GuardControllerDegraded: [Missing PodIP in operand kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]\nInstallerControllerDegraded: etcdserver: request timed out\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrole-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrole-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrolebinding-auth-delegator.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-auth-delegator\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrolebinding-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrolebinding-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-rolebinding-kube-system.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:controller:kube-apiserver-check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-apiserver/rolebindings/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/delegated-incluster-authentication-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/authentication-reader-for-authenticated-users\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-apiserver-recovery\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/localhost-recovery-sa.yaml\" (string): serviceaccounts \"localhost-recovery-client\" is forbidden: User \"system:serviceaccount:openshift-kube-apiserver-operator:kube-apiserver-operator\" cannot get resource \"serviceaccounts\" in API group \"\" in the namespace \"openshift-kube-apiserver\"\nKubeAPIServerStaticResourcesDegraded: \nRevisionControllerDegraded: secrets \"encryption-config-7\" is forbidden: User \"system:serviceaccount:openshift-kube-apiserver-operator:kube-apiserver-operator\" cannot delete resource \"secrets\" in API group \"\" in the namespace \"openshift-kube-apiserver\"","reason":"GuardController_SyncError::InstallerController_Error::KubeAPIServerStaticResources_SyncError::RevisionController_ContentCreationError","status":"True","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:42:55Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 6","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:49:04.451018954Z I0109 04:49:04.447768       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded message changed from "GuardControllerDegraded: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing PodIP in operand kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal on node ip-10-0-199-219.us-east-2.compute.internal]\nInstallerControllerDegraded: etcdserver: request timed out\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrole-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrole-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrolebinding-auth-delegator.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-auth-delegator\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrolebinding-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrolebinding-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-rolebinding-kube-system.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:controller:kube-apiserver-check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-apiserver/rolebindings/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/delegated-incluster-authentication-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/authentication-reader-for-authenticated-users\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-apiserver-recovery\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/localhost-recovery-sa.yaml\" (string): serviceaccounts \"localhost-recovery-client\" is forbidden: User \"system:serviceaccount:openshift-kube-apiserver-operator:kube-apiserver-operator\" cannot get resource \"serviceaccounts\" in API group \"\" in the namespace \"openshift-kube-apiserver\"\nKubeAPIServerStaticResourcesDegraded: \nRevisionControllerDegraded: secrets \"encryption-config-7\" is forbidden: User \"system:serviceaccount:openshift-kube-apiserver-operator:kube-apiserver-operator\" cannot delete resource \"secrets\" in API group \"\" in the namespace \"openshift-kube-apiserver\"" to "GuardControllerDegraded: [Missing PodIP in operand kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]\nInstallerControllerDegraded: etcdserver: request timed out\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrole-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrole-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrolebinding-auth-delegator.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-auth-delegator\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrolebinding-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrolebinding-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-rolebinding-kube-system.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:controller:kube-apiserver-check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-apiserver/rolebindings/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/delegated-incluster-authentication-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/authentication-reader-for-authenticated-users\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-apiserver-recovery\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/localhost-recovery-sa.yaml\" (string): serviceaccounts \"localhost-recovery-client\" is forbidden: User \"system:serviceaccount:openshift-kube-apiserver-operator:kube-apiserver-operator\" cannot get resource \"serviceaccounts\" in API group \"\" in the namespace \"openshift-kube-apiserver\"\nKubeAPIServerStaticResourcesDegraded: \nRevisionControllerDegraded: secrets \"encryption-config-7\" is forbidden: User \"system:serviceaccount:openshift-kube-apiserver-operator:kube-apiserver-operator\" cannot delete resource \"secrets\" in API group \"\" in the namespace \"openshift-kube-apiserver\""
2023-01-09T04:49:04.496285472Z I0109 04:49:04.496226       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/webhook-authenticator-7 -n openshift-kube-apiserver because it was missing
2023-01-09T04:49:04.509937008Z I0109 04:49:04.509890       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionCreate' Revision 6 created because configmap/config has changed,configmap/oauth-metadata has changed
2023-01-09T04:49:04.510787569Z I0109 04:49:04.510754       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:49:04.511916583Z I0109 04:49:04.511881       1 status_controller.go:211] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:44:16Z","message":"GuardControllerDegraded: [Missing PodIP in operand kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]\nInstallerControllerDegraded: etcdserver: request timed out\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrole-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrole-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrolebinding-auth-delegator.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-auth-delegator\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrolebinding-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrolebinding-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-rolebinding-kube-system.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:controller:kube-apiserver-check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-apiserver/rolebindings/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/delegated-incluster-authentication-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/authentication-reader-for-authenticated-users\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-apiserver-recovery\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/localhost-recovery-sa.yaml\" (string): serviceaccounts \"localhost-recovery-client\" is forbidden: User \"system:serviceaccount:openshift-kube-apiserver-operator:kube-apiserver-operator\" cannot get resource \"serviceaccounts\" in API group \"\" in the namespace \"openshift-kube-apiserver\"\nKubeAPIServerStaticResourcesDegraded: ","reason":"GuardController_SyncError::InstallerController_Error::KubeAPIServerStaticResources_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:42:55Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 6","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:49:04.522134677Z I0109 04:49:04.521260       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded message changed from "GuardControllerDegraded: [Missing PodIP in operand kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]\nInstallerControllerDegraded: etcdserver: request timed out\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrole-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrole-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrolebinding-auth-delegator.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-auth-delegator\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrolebinding-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrolebinding-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-rolebinding-kube-system.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:controller:kube-apiserver-check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-apiserver/rolebindings/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/delegated-incluster-authentication-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/authentication-reader-for-authenticated-users\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-apiserver-recovery\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/localhost-recovery-sa.yaml\" (string): serviceaccounts \"localhost-recovery-client\" is forbidden: User \"system:serviceaccount:openshift-kube-apiserver-operator:kube-apiserver-operator\" cannot get resource \"serviceaccounts\" in API group \"\" in the namespace \"openshift-kube-apiserver\"\nKubeAPIServerStaticResourcesDegraded: \nRevisionControllerDegraded: secrets \"encryption-config-7\" is forbidden: User \"system:serviceaccount:openshift-kube-apiserver-operator:kube-apiserver-operator\" cannot delete resource \"secrets\" in API group \"\" in the namespace \"openshift-kube-apiserver\"" to "GuardControllerDegraded: [Missing PodIP in operand kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]\nInstallerControllerDegraded: etcdserver: request timed out\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrole-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrole-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrolebinding-auth-delegator.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-auth-delegator\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrolebinding-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrolebinding-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-rolebinding-kube-system.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:controller:kube-apiserver-check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-apiserver/rolebindings/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/delegated-incluster-authentication-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/authentication-reader-for-authenticated-users\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-apiserver-recovery\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/localhost-recovery-sa.yaml\" (string): serviceaccounts \"localhost-recovery-client\" is forbidden: User \"system:serviceaccount:openshift-kube-apiserver-operator:kube-apiserver-operator\" cannot get resource \"serviceaccounts\" in API group \"\" in the namespace \"openshift-kube-apiserver\"\nKubeAPIServerStaticResourcesDegraded: "
2023-01-09T04:49:04.532696631Z I0109 04:49:04.532660       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionTriggered' new revision 8 triggered by "configmap/config has changed"
2023-01-09T04:49:04.691808846Z I0109 04:49:04.691764       1 request.go:601] Waited for 2.597217286s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-6-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:49:05.656940274Z E0109 04:49:05.656898       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:49:05.656940274Z E0109 04:49:05.656922       1 guard_controller.go:274] Missing PodIP in operand kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal on node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:49:05.656940274Z E0109 04:49:05.656934       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:49:05.669413286Z E0109 04:49:05.669373       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing PodIP in operand kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal]
2023-01-09T04:49:05.670500408Z I0109 04:49:05.670472       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:49:05.672590002Z I0109 04:49:05.672549       1 status_controller.go:211] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:44:16Z","message":"GuardControllerDegraded: [Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing PodIP in operand kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal]\nInstallerControllerDegraded: etcdserver: request timed out\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrole-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrole-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrolebinding-auth-delegator.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-auth-delegator\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrolebinding-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrolebinding-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-rolebinding-kube-system.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:controller:kube-apiserver-check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-apiserver/rolebindings/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/delegated-incluster-authentication-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/authentication-reader-for-authenticated-users\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-apiserver-recovery\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/localhost-recovery-sa.yaml\" (string): serviceaccounts \"localhost-recovery-client\" is forbidden: User \"system:serviceaccount:openshift-kube-apiserver-operator:kube-apiserver-operator\" cannot get resource \"serviceaccounts\" in API group \"\" in the namespace \"openshift-kube-apiserver\"\nKubeAPIServerStaticResourcesDegraded: ","reason":"GuardController_SyncError::InstallerController_Error::KubeAPIServerStaticResources_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:42:55Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 6","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:49:05.681500031Z I0109 04:49:05.681453       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded message changed from "GuardControllerDegraded: [Missing PodIP in operand kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]\nInstallerControllerDegraded: etcdserver: request timed out\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrole-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrole-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrolebinding-auth-delegator.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-auth-delegator\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrolebinding-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrolebinding-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-rolebinding-kube-system.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:controller:kube-apiserver-check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-apiserver/rolebindings/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/delegated-incluster-authentication-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/authentication-reader-for-authenticated-users\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-apiserver-recovery\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/localhost-recovery-sa.yaml\" (string): serviceaccounts \"localhost-recovery-client\" is forbidden: User \"system:serviceaccount:openshift-kube-apiserver-operator:kube-apiserver-operator\" cannot get resource \"serviceaccounts\" in API group \"\" in the namespace \"openshift-kube-apiserver\"\nKubeAPIServerStaticResourcesDegraded: " to "GuardControllerDegraded: [Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing PodIP in operand kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal]\nInstallerControllerDegraded: etcdserver: request timed out\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrole-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrole-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrolebinding-auth-delegator.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-auth-delegator\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrolebinding-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrolebinding-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-rolebinding-kube-system.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:controller:kube-apiserver-check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-apiserver/rolebindings/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/delegated-incluster-authentication-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/authentication-reader-for-authenticated-users\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-apiserver-recovery\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/localhost-recovery-sa.yaml\" (string): serviceaccounts \"localhost-recovery-client\" is forbidden: User \"system:serviceaccount:openshift-kube-apiserver-operator:kube-apiserver-operator\" cannot get resource \"serviceaccounts\" in API group \"\" in the namespace \"openshift-kube-apiserver\"\nKubeAPIServerStaticResourcesDegraded: "
2023-01-09T04:49:05.891120009Z I0109 04:49:05.891063       1 request.go:601] Waited for 2.395968966s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T04:49:06.701834812Z I0109 04:49:06.701780       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/revision-status-8 -n openshift-kube-apiserver because it was missing
2023-01-09T04:49:06.891512063Z I0109 04:49:06.891459       1 request.go:601] Waited for 2.194809436s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-6-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:49:07.274449198Z I0109 04:49:07.274385       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:49:07.350890131Z I0109 04:49:07.350842       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:49:07.352969898Z I0109 04:49:07.352925       1 status_controller.go:211] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:44:16Z","message":"GuardControllerDegraded: [Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing PodIP in operand kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal]\nInstallerControllerDegraded: etcdserver: request timed out","reason":"GuardController_SyncError::InstallerController_Error","status":"True","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:42:55Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 6","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:49:07.361670479Z I0109 04:49:07.360969       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded message changed from "GuardControllerDegraded: [Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing PodIP in operand kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal]\nInstallerControllerDegraded: etcdserver: request timed out\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrole-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrole-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrolebinding-auth-delegator.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-auth-delegator\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrolebinding-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrolebinding-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-rolebinding-kube-system.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:controller:kube-apiserver-check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-apiserver/rolebindings/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/delegated-incluster-authentication-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/authentication-reader-for-authenticated-users\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-apiserver-recovery\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/localhost-recovery-sa.yaml\" (string): serviceaccounts \"localhost-recovery-client\" is forbidden: User \"system:serviceaccount:openshift-kube-apiserver-operator:kube-apiserver-operator\" cannot get resource \"serviceaccounts\" in API group \"\" in the namespace \"openshift-kube-apiserver\"\nKubeAPIServerStaticResourcesDegraded: " to "GuardControllerDegraded: [Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing PodIP in operand kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal]\nInstallerControllerDegraded: etcdserver: request timed out"
2023-01-09T04:49:07.665263480Z I0109 04:49:07.665224       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:49:07.670880409Z E0109 04:49:07.670845       1 guard_controller.go:274] Missing PodIP in operand kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal on node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:49:07.670906243Z E0109 04:49:07.670876       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:49:07.670906243Z E0109 04:49:07.670893       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:49:07.682322037Z E0109 04:49:07.682287       1 base_controller.go:272] GuardController reconciliation failed: [Missing PodIP in operand kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:49:07.683801097Z I0109 04:49:07.683768       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:49:07.686235054Z I0109 04:49:07.686201       1 status_controller.go:211] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:44:16Z","message":"GuardControllerDegraded: [Missing PodIP in operand kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]\nInstallerControllerDegraded: etcdserver: request timed out","reason":"GuardController_SyncError::InstallerController_Error","status":"True","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:42:55Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 6","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:49:07.696914351Z I0109 04:49:07.696678       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded message changed from "GuardControllerDegraded: [Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing PodIP in operand kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal]\nInstallerControllerDegraded: etcdserver: request timed out" to "GuardControllerDegraded: [Missing PodIP in operand kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]\nInstallerControllerDegraded: etcdserver: request timed out"
2023-01-09T04:49:08.090813193Z I0109 04:49:08.090771       1 request.go:601] Waited for 2.196536801s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T04:49:08.900162644Z I0109 04:49:08.900108       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-apiserver-pod-8 -n openshift-kube-apiserver because it was missing
2023-01-09T04:49:09.091277664Z I0109 04:49:09.091217       1 request.go:601] Waited for 2.196788584s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-6-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:49:10.091697035Z I0109 04:49:10.091645       1 request.go:601] Waited for 2.193054502s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2023-01-09T04:49:11.102175967Z I0109 04:49:11.102125       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/config-8 -n openshift-kube-apiserver because it was missing
2023-01-09T04:49:11.291212730Z I0109 04:49:11.291176       1 request.go:601] Waited for 2.19654191s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-7-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:49:12.053748677Z E0109 04:49:12.053706       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:49:12.291610384Z I0109 04:49:12.291572       1 request.go:601] Waited for 1.997270973s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T04:49:12.696135886Z I0109 04:49:12.696082       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-apiserver-cert-syncer-kubeconfig-8 -n openshift-kube-apiserver because it was missing
2023-01-09T04:49:12.896325080Z I0109 04:49:12.896271       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/revision-pruner-7-ip-10-0-199-219.us-east-2.compute.internal -n openshift-kube-apiserver because it was missing
2023-01-09T04:49:13.491374739Z I0109 04:49:13.491335       1 request.go:601] Waited for 1.59711137s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods
2023-01-09T04:49:13.497585044Z I0109 04:49:13.497536       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/installer-6-ip-10-0-199-219.us-east-2.compute.internal -n openshift-kube-apiserver because it was missing
2023-01-09T04:49:14.690828919Z I0109 04:49:14.690785       1 request.go:601] Waited for 2.191102834s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T04:49:14.896749830Z I0109 04:49:14.896692       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/oauth-metadata-8 -n openshift-kube-apiserver because it was missing
2023-01-09T04:49:15.691386102Z I0109 04:49:15.691343       1 request.go:601] Waited for 2.193840195s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/installer-6-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:49:15.694076282Z I0109 04:49:15.694039       1 installer_controller.go:512] "ip-10-0-199-219.us-east-2.compute.internal" is in transition to 6, but has not made progress because installer is not finished, but in Running phase
2023-01-09T04:49:15.709164218Z I0109 04:49:15.709117       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:49:15.710834020Z I0109 04:49:15.710796       1 status_controller.go:211] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:44:16Z","message":"GuardControllerDegraded: [Missing PodIP in operand kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]","reason":"GuardController_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:42:55Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 7","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 7","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:49:15.718222349Z I0109 04:49:15.718179       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded message changed from "GuardControllerDegraded: [Missing PodIP in operand kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]\nInstallerControllerDegraded: etcdserver: request timed out" to "GuardControllerDegraded: [Missing PodIP in operand kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]",Progressing message changed from "NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 6" to "NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 7",Available message changed from "StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 6" to "StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 7"
2023-01-09T04:49:16.294600305Z E0109 04:49:16.294563       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:49:16.307296976Z E0109 04:49:16.307260       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal]
2023-01-09T04:49:16.307962812Z I0109 04:49:16.307929       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:49:16.310153138Z I0109 04:49:16.310120       1 status_controller.go:211] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:44:16Z","message":"GuardControllerDegraded: [Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal]","reason":"GuardController_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:42:55Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 7","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 7","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:49:16.320017500Z I0109 04:49:16.319929       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded message changed from "GuardControllerDegraded: [Missing PodIP in operand kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]" to "GuardControllerDegraded: [Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal]"
2023-01-09T04:49:16.693982268Z I0109 04:49:16.693939       1 request.go:601] Waited for 2.199287058s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T04:49:17.096397103Z I0109 04:49:17.096340       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/bound-sa-token-signing-certs-8 -n openshift-kube-apiserver because it was missing
2023-01-09T04:49:17.297734740Z I0109 04:49:17.297674       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/revision-pruner-7-ip-10-0-160-211.us-east-2.compute.internal -n openshift-kube-apiserver because it was missing
2023-01-09T04:49:17.890905239Z I0109 04:49:17.890861       1 request.go:601] Waited for 2.181810683s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:49:18.891802520Z I0109 04:49:18.891760       1 request.go:601] Waited for 2.394304832s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/config
2023-01-09T04:49:19.514366581Z I0109 04:49:19.514255       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/etcd-serving-ca-8 -n openshift-kube-apiserver because it was missing
2023-01-09T04:49:20.091131056Z I0109 04:49:20.091087       1 request.go:601] Waited for 2.370742175s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2023-01-09T04:49:20.714676038Z I0109 04:49:20.714625       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:49:20.717468643Z I0109 04:49:20.717435       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:49:21.091752914Z I0109 04:49:21.091701       1 request.go:601] Waited for 2.398139131s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:49:21.094732947Z E0109 04:49:21.094691       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:49:21.094732947Z E0109 04:49:21.094721       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:49:21.107480310Z E0109 04:49:21.107400       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:49:21.108800189Z I0109 04:49:21.108763       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:49:21.108855022Z I0109 04:49:21.108835       1 status_controller.go:211] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:44:16Z","message":"GuardControllerDegraded: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]","reason":"GuardController_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:42:55Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 7","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 7","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:49:21.110386462Z E0109 04:49:21.110359       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:49:21.110425488Z E0109 04:49:21.110384       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:49:21.117527209Z I0109 04:49:21.117487       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded message changed from "GuardControllerDegraded: [Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal]" to "GuardControllerDegraded: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]"
2023-01-09T04:49:21.897006032Z I0109 04:49:21.896920       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-apiserver-server-ca-8 -n openshift-kube-apiserver because it was missing
2023-01-09T04:49:22.097465671Z I0109 04:49:22.097414       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/revision-pruner-7-ip-10-0-145-4.us-east-2.compute.internal -n openshift-kube-apiserver because it was missing
2023-01-09T04:49:22.291505858Z I0109 04:49:22.291458       1 request.go:601] Waited for 2.394098306s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:49:23.491680193Z I0109 04:49:23.491645       1 request.go:601] Waited for 2.380919766s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:49:24.297301274Z I0109 04:49:24.297248       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kubelet-serving-ca-8 -n openshift-kube-apiserver because it was missing
2023-01-09T04:49:24.691059727Z I0109 04:49:24.691017       1 request.go:601] Waited for 2.396777244s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:49:25.691709938Z I0109 04:49:25.691660       1 request.go:601] Waited for 2.197355649s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:49:25.694731371Z E0109 04:49:25.694686       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:49:25.761463744Z I0109 04:49:25.761416       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:49:25.767126637Z I0109 04:49:25.767086       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:49:25.814620731Z I0109 04:49:25.814558       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:49:25.814893346Z I0109 04:49:25.814843       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:49:26.497510591Z I0109 04:49:26.497447       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/sa-token-signing-certs-8 -n openshift-kube-apiserver because it was missing
2023-01-09T04:49:26.891471744Z I0109 04:49:26.891433       1 request.go:601] Waited for 2.197913465s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:49:28.091090536Z I0109 04:49:28.091043       1 request.go:601] Waited for 2.195887264s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/trusted-ca-bundle
2023-01-09T04:49:28.696264191Z I0109 04:49:28.696213       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-apiserver-audit-policies-8 -n openshift-kube-apiserver because it was missing
2023-01-09T04:49:29.291248052Z I0109 04:49:29.291200       1 request.go:601] Waited for 2.160139893s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver
2023-01-09T04:49:30.094511513Z E0109 04:49:30.094467       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:49:30.094511513Z E0109 04:49:30.094495       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:49:30.094841307Z E0109 04:49:30.094821       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:49:30.291523457Z I0109 04:49:30.291481       1 request.go:601] Waited for 2.191504625s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2023-01-09T04:49:30.897134532Z I0109 04:49:30.897080       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/etcd-client-8 -n openshift-kube-apiserver because it was missing
2023-01-09T04:49:31.291698268Z I0109 04:49:31.291659       1 request.go:601] Waited for 1.997661805s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver
2023-01-09T04:49:32.491237465Z I0109 04:49:32.491192       1 request.go:601] Waited for 1.594351549s due to client-side throttling, not priority and fairness, request: DELETE:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/encryption-config-8
2023-01-09T04:49:33.294603993Z E0109 04:49:33.294564       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:49:33.294603993Z E0109 04:49:33.294591       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:49:33.294951513Z E0109 04:49:33.294931       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:49:33.491448135Z I0109 04:49:33.491408       1 request.go:601] Waited for 1.59339475s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/config
2023-01-09T04:49:33.898972628Z I0109 04:49:33.898916       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/localhost-recovery-serving-certkey-8 -n openshift-kube-apiserver because it was missing
2023-01-09T04:49:34.578563205Z E0109 04:49:34.578518       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:49:34.699701995Z I0109 04:49:34.699652       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/localhost-recovery-client-token-8 -n openshift-kube-apiserver because it was missing
2023-01-09T04:49:35.697732896Z I0109 04:49:35.697680       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/webhook-authenticator-8 -n openshift-kube-apiserver because it was missing
2023-01-09T04:49:35.709166342Z I0109 04:49:35.709124       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionCreate' Revision 7 created because configmap/config has changed
2023-01-09T04:49:35.711253076Z I0109 04:49:35.711205       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:49:35.714886697Z I0109 04:49:35.714852       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionTriggered' new revision 8 triggered by "configmap/config has changed"
2023-01-09T04:49:36.494035863Z E0109 04:49:36.493980       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:49:36.505440464Z E0109 04:49:36.505409       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal]
2023-01-09T04:49:36.506249390Z I0109 04:49:36.506223       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:49:36.506883937Z I0109 04:49:36.506835       1 status_controller.go:211] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:44:16Z","message":"GuardControllerDegraded: [Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal]","reason":"GuardController_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:42:55Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 7","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 7","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:49:36.522473347Z I0109 04:49:36.520832       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded message changed from "GuardControllerDegraded: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]" to "GuardControllerDegraded: [Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal]"
2023-01-09T04:49:36.891475476Z I0109 04:49:36.891434       1 request.go:601] Waited for 1.180829496s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-8-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:49:37.699565554Z W0109 04:49:37.699516       1 staticpod.go:38] revision 8 is unexpectedly already the latest available revision. This is a possible race!
2023-01-09T04:49:37.711772825Z E0109 04:49:37.711734       1 base_controller.go:272] RevisionController reconciliation failed: conflicting latestAvailableRevision 8
2023-01-09T04:49:37.714323026Z I0109 04:49:37.714276       1 status_controller.go:211] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:44:16Z","message":"GuardControllerDegraded: [Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal]\nRevisionControllerDegraded: conflicting latestAvailableRevision 8","reason":"GuardController_SyncError::RevisionController_Error","status":"True","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:42:55Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 7","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 7","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:49:37.715071231Z I0109 04:49:37.715017       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:49:37.722589058Z I0109 04:49:37.722518       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded message changed from "GuardControllerDegraded: [Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal]" to "GuardControllerDegraded: [Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal]\nRevisionControllerDegraded: conflicting latestAvailableRevision 8"
2023-01-09T04:49:37.735881690Z I0109 04:49:37.735846       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:49:37.738907169Z I0109 04:49:37.738877       1 status_controller.go:211] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:44:16Z","message":"GuardControllerDegraded: [Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal]","reason":"GuardController_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:42:55Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 7","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 7","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:49:37.745800769Z I0109 04:49:37.745766       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded message changed from "GuardControllerDegraded: [Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal]\nRevisionControllerDegraded: conflicting latestAvailableRevision 8" to "GuardControllerDegraded: [Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal]"
2023-01-09T04:49:38.091078113Z I0109 04:49:38.091038       1 request.go:601] Waited for 1.950469628s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver
2023-01-09T04:49:38.699626605Z I0109 04:49:38.699570       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/revision-pruner-8-ip-10-0-199-219.us-east-2.compute.internal -n openshift-kube-apiserver because it was missing
2023-01-09T04:49:38.703642170Z E0109 04:49:38.703601       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:49:39.091795774Z I0109 04:49:39.091756       1 request.go:601] Waited for 1.794986691s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T04:49:40.291583307Z I0109 04:49:40.291529       1 request.go:601] Waited for 1.591510171s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-8-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:49:41.491552939Z I0109 04:49:41.491492       1 request.go:601] Waited for 2.196772974s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:49:42.097529497Z I0109 04:49:42.097475       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/revision-pruner-8-ip-10-0-160-211.us-east-2.compute.internal -n openshift-kube-apiserver because it was missing
2023-01-09T04:49:42.691787773Z I0109 04:49:42.691748       1 request.go:601] Waited for 1.797058895s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:49:42.694300663Z E0109 04:49:42.694268       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:49:42.694607929Z E0109 04:49:42.694589       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal]
2023-01-09T04:49:43.891460218Z I0109 04:49:43.891419       1 request.go:601] Waited for 1.595818094s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2023-01-09T04:49:45.091077186Z I0109 04:49:45.091039       1 request.go:601] Waited for 1.594069898s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-pod
2023-01-09T04:49:45.298562122Z I0109 04:49:45.298501       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/revision-pruner-8-ip-10-0-145-4.us-east-2.compute.internal -n openshift-kube-apiserver because it was missing
2023-01-09T04:49:45.894432331Z E0109 04:49:45.894391       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:49:45.894432331Z E0109 04:49:45.894427       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:49:45.911610376Z E0109 04:49:45.911571       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:49:45.917277353Z I0109 04:49:45.917237       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:49:45.918930474Z I0109 04:49:45.918898       1 status_controller.go:211] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:44:16Z","message":"GuardControllerDegraded: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]","reason":"GuardController_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:42:55Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 7","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 7","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:49:45.927859610Z I0109 04:49:45.926816       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded message changed from "GuardControllerDegraded: [Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal]" to "GuardControllerDegraded: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]"
2023-01-09T04:49:46.091263989Z I0109 04:49:46.091217       1 request.go:601] Waited for 1.596381739s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:49:47.291318515Z I0109 04:49:47.291281       1 request.go:601] Waited for 1.596412248s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver
2023-01-09T04:49:48.291577591Z I0109 04:49:48.291537       1 request.go:601] Waited for 2.197014649s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:49:49.291656414Z I0109 04:49:49.291620       1 request.go:601] Waited for 2.195662164s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2023-01-09T04:49:50.094165421Z E0109 04:49:50.094127       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:49:50.094165421Z E0109 04:49:50.094155       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:49:50.094538475Z E0109 04:49:50.094521       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:49:50.490822674Z I0109 04:49:50.490782       1 request.go:601] Waited for 1.996483822s due to client-side throttling, not priority and fairness, request: DELETE:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/installer-6-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:49:50.498158446Z I0109 04:49:50.498120       1 installer_controller.go:500] "ip-10-0-199-219.us-east-2.compute.internal" moving to (v1.NodeStatus) {
2023-01-09T04:49:50.498158446Z  NodeName: (string) (len=42) "ip-10-0-199-219.us-east-2.compute.internal",
2023-01-09T04:49:50.498158446Z  CurrentRevision: (int32) 0,
2023-01-09T04:49:50.498158446Z  TargetRevision: (int32) 8,
2023-01-09T04:49:50.498158446Z  LastFailedRevision: (int32) 0,
2023-01-09T04:49:50.498158446Z  LastFailedTime: (*v1.Time)(<nil>),
2023-01-09T04:49:50.498158446Z  LastFailedReason: (string) "",
2023-01-09T04:49:50.498158446Z  LastFailedCount: (int) 0,
2023-01-09T04:49:50.498158446Z  LastFallbackCount: (int) 0,
2023-01-09T04:49:50.498158446Z  LastFailedRevisionErrors: ([]string) <nil>
2023-01-09T04:49:50.498158446Z }
2023-01-09T04:49:50.498158446Z  because new revision pending
2023-01-09T04:49:50.514172358Z I0109 04:49:50.514133       1 status_controller.go:211] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:44:16Z","message":"GuardControllerDegraded: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]","reason":"GuardController_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:42:55Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 8","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 8","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:49:50.514699255Z I0109 04:49:50.514668       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:49:50.521766514Z I0109 04:49:50.521297       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Progressing message changed from "NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 7" to "NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 8",Available message changed from "StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 7" to "StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 8"
2023-01-09T04:49:51.491281811Z I0109 04:49:51.491248       1 request.go:601] Waited for 1.996151408s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver
2023-01-09T04:49:52.691803250Z I0109 04:49:52.691764       1 request.go:601] Waited for 2.157760392s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:49:53.891494470Z I0109 04:49:53.891449       1 request.go:601] Waited for 2.197756854s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:49:53.894046737Z E0109 04:49:53.894018       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:49:53.894046737Z E0109 04:49:53.894039       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:49:53.894366676Z E0109 04:49:53.894350       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:49:54.891533342Z I0109 04:49:54.891491       1 request.go:601] Waited for 1.593895537s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-8-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:49:56.090951443Z I0109 04:49:56.090913       1 request.go:601] Waited for 1.392921559s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/config
2023-01-09T04:49:56.494756855Z E0109 04:49:56.494724       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:49:56.494756855Z E0109 04:49:56.494749       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:49:56.495105312Z E0109 04:49:56.495089       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:49:57.091262172Z I0109 04:49:57.091219       1 request.go:601] Waited for 1.168948238s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2023-01-09T04:49:57.278056174Z I0109 04:49:57.278019       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:49:57.291939568Z I0109 04:49:57.291903       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:49:57.528916833Z E0109 04:49:57.528876       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:49:57.528916833Z E0109 04:49:57.528902       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:49:57.899448175Z I0109 04:49:57.899395       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/installer-8-ip-10-0-199-219.us-east-2.compute.internal -n openshift-kube-apiserver because it was missing
2023-01-09T04:49:58.466367420Z I0109 04:49:58.466323       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:49:58.558887414Z E0109 04:49:58.558852       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T04:49:58.691245096Z I0109 04:49:58.691195       1 request.go:601] Waited for 1.192113827s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver
2023-01-09T04:49:58.693408635Z I0109 04:49:58.693375       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:49:59.088794305Z I0109 04:49:59.088757       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:49:59.112618668Z I0109 04:49:59.112559       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:49:59.565121399Z E0109 04:49:59.565080       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T04:49:59.691315713Z I0109 04:49:59.691281       1 request.go:601] Waited for 1.996418526s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T04:49:59.894221928Z I0109 04:49:59.894188       1 installer_controller.go:512] "ip-10-0-199-219.us-east-2.compute.internal" is in transition to 8, but has not made progress because installer is not finished, but in Running phase
2023-01-09T04:50:00.891109680Z I0109 04:50:00.891063       1 request.go:601] Waited for 1.79025928s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:50:01.095117096Z E0109 04:50:01.095079       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:50:01.594959438Z I0109 04:50:01.594903       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:50:01.693496951Z I0109 04:50:01.693425       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:50:01.891460125Z I0109 04:50:01.891421       1 request.go:601] Waited for 1.796260677s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/trusted-ca-bundle
2023-01-09T04:50:02.891503718Z I0109 04:50:02.891459       1 request.go:601] Waited for 1.596278186s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver
2023-01-09T04:50:04.091753111Z I0109 04:50:04.091719       1 request.go:601] Waited for 2.192234957s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2023-01-09T04:50:04.695175213Z E0109 04:50:04.695135       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:50:04.695175213Z E0109 04:50:04.695165       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:50:04.695516468Z E0109 04:50:04.695500       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:50:05.291521579Z I0109 04:50:05.291475       1 request.go:601] Waited for 1.79687352s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-8-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:50:06.291582855Z I0109 04:50:06.291535       1 request.go:601] Waited for 1.797454929s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:50:07.491262500Z I0109 04:50:07.491214       1 request.go:601] Waited for 1.19694428s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:50:08.094605801Z I0109 04:50:08.094570       1 installer_controller.go:512] "ip-10-0-199-219.us-east-2.compute.internal" is in transition to 8, but has not made progress because installer is not finished, but in Running phase
2023-01-09T04:50:10.500808888Z I0109 04:50:10.500761       1 installer_controller.go:512] "ip-10-0-199-219.us-east-2.compute.internal" is in transition to 8, but has not made progress because installer is not finished, but in Running phase
2023-01-09T04:50:24.229843669Z I0109 04:50:24.229807       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:50:36.720345738Z I0109 04:50:36.720269       1 termination_observer.go:236] Observed event "TerminationPreShutdownHooksFinished" for API server pod "kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal" (last termination at 2023-01-09 04:48:54 +0000 UTC) at 0001-01-01 00:00:00 +0000 UTC
2023-01-09T04:50:38.725664183Z I0109 04:50:38.725617       1 request.go:601] Waited for 1.067359207s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:50:39.928441071Z E0109 04:50:39.928400       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:50:39.928441071Z E0109 04:50:39.928432       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:50:39.928763465Z E0109 04:50:39.928748       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:50:40.726165954Z I0109 04:50:40.726129       1 request.go:601] Waited for 1.056983158s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2023-01-09T04:50:41.928525764Z E0109 04:50:41.928485       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:50:41.928525764Z E0109 04:50:41.928510       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:50:41.928891451Z E0109 04:50:41.928867       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:50:42.928886924Z I0109 04:50:42.928845       1 installer_controller.go:512] "ip-10-0-199-219.us-east-2.compute.internal" is in transition to 8, but has not made progress because waiting for static pod of revision 8, found 5
2023-01-09T04:50:44.328787995Z I0109 04:50:44.328743       1 installer_controller.go:512] "ip-10-0-199-219.us-east-2.compute.internal" is in transition to 8, but has not made progress because waiting for static pod of revision 8, found 5
2023-01-09T04:50:44.686434063Z I0109 04:50:44.686388       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:50:44.688499936Z I0109 04:50:44.688461       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:50:48.698825363Z I0109 04:50:48.698768       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:50:48.708264195Z I0109 04:50:48.708221       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:50:48.736944361Z I0109 04:50:48.736906       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:50:48.739225891Z I0109 04:50:48.739178       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:51:39.961554420Z I0109 04:51:39.961510       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:51:40.361734147Z I0109 04:51:40.361688       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:51:57.577574130Z I0109 04:51:57.577538       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:52:16.461503903Z I0109 04:52:16.461464       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:52:16.461726837Z I0109 04:52:16.461709       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:52:21.482294573Z I0109 04:52:21.482252       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:52:24.101232816Z I0109 04:52:24.101194       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:52:24.500666900Z I0109 04:52:24.500622       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:52:46.390710460Z E0109 04:52:46.390666       1 base_controller.go:272] auditPolicyController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies": dial tcp 172.30.0.1:443: connect: connection refused
2023-01-09T04:52:46.398231503Z E0109 04:52:46.398201       1 base_controller.go:272] auditPolicyController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies": dial tcp 172.30.0.1:443: connect: connection refused
2023-01-09T04:52:46.410864109Z E0109 04:52:46.410839       1 base_controller.go:272] auditPolicyController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies": dial tcp 172.30.0.1:443: connect: connection refused
2023-01-09T04:52:46.433260466Z E0109 04:52:46.433236       1 base_controller.go:272] auditPolicyController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies": dial tcp 172.30.0.1:443: connect: connection refused
2023-01-09T04:52:46.477026725Z E0109 04:52:46.476972       1 base_controller.go:272] auditPolicyController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies": dial tcp 172.30.0.1:443: connect: connection refused
2023-01-09T04:52:46.559927913Z E0109 04:52:46.559893       1 base_controller.go:272] auditPolicyController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies": dial tcp 172.30.0.1:443: connect: connection refused
2023-01-09T04:52:46.722720939Z E0109 04:52:46.722681       1 base_controller.go:272] auditPolicyController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies": dial tcp 172.30.0.1:443: connect: connection refused
2023-01-09T04:52:47.046566067Z E0109 04:52:47.046532       1 base_controller.go:272] auditPolicyController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies": dial tcp 172.30.0.1:443: connect: connection refused
2023-01-09T04:52:47.689283435Z E0109 04:52:47.689245       1 base_controller.go:272] auditPolicyController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies": dial tcp 172.30.0.1:443: connect: connection refused
2023-01-09T04:52:47.733428119Z I0109 04:52:47.733359       1 termination_observer.go:236] Observed event "TerminationGracefulTerminationFinished" for API server pod "kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal" (last termination at 2023-01-09 04:48:54 +0000 UTC) at 0001-01-01 00:00:00 +0000 UTC
2023-01-09T04:52:48.972395431Z E0109 04:52:48.972358       1 base_controller.go:272] auditPolicyController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies": dial tcp 172.30.0.1:443: connect: connection refused
2023-01-09T04:52:51.535182695Z E0109 04:52:51.535135       1 base_controller.go:272] auditPolicyController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies": dial tcp 172.30.0.1:443: connect: connection refused
2023-01-09T04:52:57.874859638Z I0109 04:52:57.874800       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:52:57.875884340Z I0109 04:52:57.875852       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:52:58.189103288Z I0109 04:52:58.189061       1 request.go:601] Waited for 1.107082833s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config/configmaps?resourceVersion=26457
2023-01-09T04:52:59.007138506Z I0109 04:52:59.007091       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:52:59.189250303Z I0109 04:52:59.189207       1 request.go:601] Waited for 1.631006252s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-apiserver/endpoints?resourceVersion=26719
2023-01-09T04:52:59.298748839Z I0109 04:52:59.298708       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:52:59.716795810Z I0109 04:52:59.716480       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:52:59.753145378Z I0109 04:52:59.753107       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:53:00.189259215Z I0109 04:53:00.189208       1 request.go:601] Waited for 2.193000736s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-apiserver/secrets?resourceVersion=26454
2023-01-09T04:53:00.424120189Z I0109 04:53:00.424073       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:53:00.510981783Z E0109 04:53:00.510905       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T04:53:00.746876996Z I0109 04:53:00.746839       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:53:01.389319207Z I0109 04:53:01.389284       1 request.go:601] Waited for 2.938975842s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces?resourceVersion=26465
2023-01-09T04:53:01.516077860Z E0109 04:53:01.516039       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T04:53:01.589042168Z I0109 04:53:01.588970       1 externalloadbalancer.go:27] syncing external loadbalancer hostnames: api.sn-loggvls-jsm.qe.devcluster.openshift.com
2023-01-09T04:53:01.589483830Z I0109 04:53:01.589447       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:53:02.389492973Z I0109 04:53:02.389448       1 request.go:601] Waited for 2.948172594s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/trusted-ca-bundle
2023-01-09T04:53:02.595893121Z E0109 04:53:02.595852       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:53:02.595931004Z E0109 04:53:02.595890       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:53:02.596439173Z E0109 04:53:02.596408       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:53:02.605624136Z E0109 04:53:02.605592       1 guard_controller.go:274] Missing PodIP in operand kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal on node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:53:02.605624136Z E0109 04:53:02.605617       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:53:02.605664496Z E0109 04:53:02.605628       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:53:02.622709724Z E0109 04:53:02.622665       1 base_controller.go:272] GuardController reconciliation failed: [Missing PodIP in operand kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:53:03.057286293Z I0109 04:53:03.057243       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:53:03.131254026Z I0109 04:53:03.131187       1 servicehostname.go:40] syncing servicenetwork hostnames: [172.30.0.1 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local openshift openshift.default openshift.default.svc openshift.default.svc.cluster.local]
2023-01-09T04:53:03.154230768Z I0109 04:53:03.154192       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:53:03.389665613Z I0109 04:53:03.389627       1 request.go:601] Waited for 1.797339084s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:53:03.596047830Z I0109 04:53:03.595576       1 termination_observer.go:130] Observed termination of API server pod "kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal" at 2023-01-09 04:52:56 +0000 UTC
2023-01-09T04:53:03.938456046Z E0109 04:53:03.938415       1 base_controller.go:272] webhookSupportabilityController reconciliation failed: Operation cannot be fulfilled on kubeapiservers.operator.openshift.io "cluster": the object has been modified; please apply your changes to the latest version and try again
2023-01-09T04:53:03.973827949Z I0109 04:53:03.973788       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:53:04.337613640Z I0109 04:53:04.337558       1 status_controller.go:211] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:44:16Z","message":"GuardControllerDegraded: [Missing PodIP in operand kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]","reason":"GuardController_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:42:55Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 8","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 8","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:53:04.338568310Z I0109 04:53:04.338531       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:53:04.352198336Z I0109 04:53:04.351558       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded message changed from "GuardControllerDegraded: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]" to "GuardControllerDegraded: [Missing PodIP in operand kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]"
2023-01-09T04:53:04.389716489Z I0109 04:53:04.389682       1 request.go:601] Waited for 1.971381785s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2023-01-09T04:53:05.589547312Z I0109 04:53:05.589507       1 request.go:601] Waited for 1.78201891s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:53:06.589783832Z I0109 04:53:06.589740       1 request.go:601] Waited for 1.968250069s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2023-01-09T04:53:07.589979012Z I0109 04:53:07.589937       1 request.go:601] Waited for 1.4431432s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2023-01-09T04:53:08.590046459Z I0109 04:53:08.590010       1 request.go:601] Waited for 2.193259752s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/config
2023-01-09T04:53:09.593301509Z E0109 04:53:09.593266       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:53:09.593301509Z E0109 04:53:09.593289       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:53:09.607020915Z E0109 04:53:09.606965       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:53:09.608849378Z I0109 04:53:09.608818       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:53:09.610360496Z I0109 04:53:09.610331       1 status_controller.go:211] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:44:16Z","message":"GuardControllerDegraded: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]","reason":"GuardController_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:42:55Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 8","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 8","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:53:09.611268670Z E0109 04:53:09.611238       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:53:09.611298828Z E0109 04:53:09.611267       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:53:09.619099582Z I0109 04:53:09.619064       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded message changed from "GuardControllerDegraded: [Missing PodIP in operand kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]" to "GuardControllerDegraded: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]"
2023-01-09T04:53:09.790091684Z I0109 04:53:09.790047       1 request.go:601] Waited for 1.59223618s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-8-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:53:10.989572953Z I0109 04:53:10.989532       1 request.go:601] Waited for 1.380928456s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T04:53:11.993046532Z I0109 04:53:11.992978       1 installer_controller.go:500] "ip-10-0-199-219.us-east-2.compute.internal" moving to (v1.NodeStatus) {
2023-01-09T04:53:11.993046532Z  NodeName: (string) (len=42) "ip-10-0-199-219.us-east-2.compute.internal",
2023-01-09T04:53:11.993046532Z  CurrentRevision: (int32) 8,
2023-01-09T04:53:11.993046532Z  TargetRevision: (int32) 0,
2023-01-09T04:53:11.993046532Z  LastFailedRevision: (int32) 0,
2023-01-09T04:53:11.993046532Z  LastFailedTime: (*v1.Time)(<nil>),
2023-01-09T04:53:11.993046532Z  LastFailedReason: (string) "",
2023-01-09T04:53:11.993046532Z  LastFailedCount: (int) 0,
2023-01-09T04:53:11.993046532Z  LastFallbackCount: (int) 0,
2023-01-09T04:53:11.993046532Z  LastFailedRevisionErrors: ([]string) <nil>
2023-01-09T04:53:11.993046532Z }
2023-01-09T04:53:11.993046532Z  because static pod is ready
2023-01-09T04:53:12.005391719Z I0109 04:53:12.005348       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeCurrentRevisionChanged' Updated node "ip-10-0-199-219.us-east-2.compute.internal" from revision 0 to 8 because static pod is ready
2023-01-09T04:53:12.007605884Z I0109 04:53:12.007557       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:53:12.008323122Z I0109 04:53:12.008288       1 status_controller.go:211] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:44:16Z","message":"GuardControllerDegraded: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]","reason":"GuardController_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:42:55Z","message":"NodeInstallerProgressing: 2 nodes are at revision 0; 1 nodes are at revision 8","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:53:12Z","message":"StaticPodsAvailable: 1 nodes are active; 2 nodes are at revision 0; 1 nodes are at revision 8","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:53:12.019435463Z I0109 04:53:12.016895       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Progressing message changed from "NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 8" to "NodeInstallerProgressing: 2 nodes are at revision 0; 1 nodes are at revision 8",Available changed from False to True ("StaticPodsAvailable: 1 nodes are active; 2 nodes are at revision 0; 1 nodes are at revision 8")
2023-01-09T04:53:12.189332899Z I0109 04:53:12.189284       1 request.go:601] Waited for 1.794094932s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:53:12.993059793Z E0109 04:53:12.993018       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:53:13.189364169Z I0109 04:53:13.189308       1 request.go:601] Waited for 1.595431359s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-8-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:53:14.190024232Z I0109 04:53:14.189974       1 request.go:601] Waited for 2.182705834s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T04:53:15.389946582Z I0109 04:53:15.389903       1 request.go:601] Waited for 2.196390594s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-8-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:53:16.394536851Z E0109 04:53:16.394493       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:53:16.394536851Z E0109 04:53:16.394527       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:53:16.394874181Z E0109 04:53:16.394857       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:53:16.589571766Z I0109 04:53:16.589534       1 request.go:601] Waited for 1.194958157s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-8-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:53:17.789958955Z I0109 04:53:17.789922       1 request.go:601] Waited for 1.400047215s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T04:53:18.989467186Z I0109 04:53:18.989422       1 request.go:601] Waited for 1.229623424s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver
2023-01-09T04:53:20.189103607Z I0109 04:53:20.189056       1 request.go:601] Waited for 1.189065001s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:53:21.192949193Z E0109 04:53:21.192911       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:53:21.192949193Z E0109 04:53:21.192935       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:53:21.193306979Z E0109 04:53:21.193285       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:53:24.232808058Z I0109 04:53:24.232755       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:53:42.420062296Z I0109 04:53:42.420022       1 installer_controller.go:524] node ip-10-0-160-211.us-east-2.compute.internal static pod not found and needs new revision 8
2023-01-09T04:53:42.420104426Z I0109 04:53:42.420070       1 installer_controller.go:532] "ip-10-0-160-211.us-east-2.compute.internal" moving to (v1.NodeStatus) {
2023-01-09T04:53:42.420104426Z  NodeName: (string) (len=42) "ip-10-0-160-211.us-east-2.compute.internal",
2023-01-09T04:53:42.420104426Z  CurrentRevision: (int32) 0,
2023-01-09T04:53:42.420104426Z  TargetRevision: (int32) 8,
2023-01-09T04:53:42.420104426Z  LastFailedRevision: (int32) 0,
2023-01-09T04:53:42.420104426Z  LastFailedTime: (*v1.Time)(<nil>),
2023-01-09T04:53:42.420104426Z  LastFailedReason: (string) "",
2023-01-09T04:53:42.420104426Z  LastFailedCount: (int) 0,
2023-01-09T04:53:42.420104426Z  LastFallbackCount: (int) 0,
2023-01-09T04:53:42.420104426Z  LastFailedRevisionErrors: ([]string) <nil>
2023-01-09T04:53:42.420104426Z }
2023-01-09T04:53:42.433539249Z I0109 04:53:42.433495       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeTargetRevisionChanged' Updating node "ip-10-0-160-211.us-east-2.compute.internal" from revision 0 to 8 because node ip-10-0-160-211.us-east-2.compute.internal static pod not found
2023-01-09T04:53:42.435576545Z I0109 04:53:42.435516       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:53:45.616049785Z I0109 04:53:45.615971       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/installer-8-ip-10-0-160-211.us-east-2.compute.internal -n openshift-kube-apiserver because it was missing
2023-01-09T04:53:46.007118956Z I0109 04:53:46.007052       1 installer_controller.go:512] "ip-10-0-160-211.us-east-2.compute.internal" is in transition to 8, but has not made progress because installer is not finished, but in Pending phase
2023-01-09T04:53:46.802888851Z I0109 04:53:46.802852       1 request.go:601] Waited for 1.182461834s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:53:48.002545538Z I0109 04:53:48.002503       1 request.go:601] Waited for 1.393211755s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver
2023-01-09T04:53:48.206470172Z E0109 04:53:48.206431       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:53:48.206470172Z E0109 04:53:48.206455       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:53:48.206835303Z E0109 04:53:48.206819       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:53:49.002546549Z I0109 04:53:49.002507       1 request.go:601] Waited for 1.196157115s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:53:50.005980636Z E0109 04:53:50.005936       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:53:50.005980636Z E0109 04:53:50.005964       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:53:50.006342921Z E0109 04:53:50.006325       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:53:50.606385939Z I0109 04:53:50.606345       1 installer_controller.go:512] "ip-10-0-160-211.us-east-2.compute.internal" is in transition to 8, but has not made progress because installer is not finished, but in Running phase
2023-01-09T04:53:51.806764363Z I0109 04:53:51.806716       1 installer_controller.go:512] "ip-10-0-160-211.us-east-2.compute.internal" is in transition to 8, but has not made progress because installer is not finished, but in Running phase
2023-01-09T04:54:05.939020776Z E0109 04:54:05.938945       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:54:05.939020776Z E0109 04:54:05.938979       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:54:05.947939598Z E0109 04:54:05.947879       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:54:06.709949627Z E0109 04:54:06.709909       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:54:06.709949627Z E0109 04:54:06.709938       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:54:06.710314634Z E0109 04:54:06.710298       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:54:07.336486611Z E0109 04:54:07.336445       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:54:07.336600134Z E0109 04:54:07.336571       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:54:07.346249442Z E0109 04:54:07.346216       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:54:25.968075657Z E0109 04:54:25.965399       1 guard_controller.go:274] Missing PodIP in operand kube-apiserver-ip-10-0-160-211.us-east-2.compute.internal on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:54:25.968075657Z E0109 04:54:25.965433       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:54:25.979787061Z E0109 04:54:25.979744       1 base_controller.go:272] GuardController reconciliation failed: [Missing PodIP in operand kube-apiserver-ip-10-0-160-211.us-east-2.compute.internal on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:54:25.982379813Z E0109 04:54:25.982343       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:54:25.989880345Z I0109 04:54:25.989838       1 status_controller.go:211] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:44:16Z","message":"GuardControllerDegraded: [Missing PodIP in operand kube-apiserver-ip-10-0-160-211.us-east-2.compute.internal on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]","reason":"GuardController_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:42:55Z","message":"NodeInstallerProgressing: 2 nodes are at revision 0; 1 nodes are at revision 8","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:53:12Z","message":"StaticPodsAvailable: 1 nodes are active; 2 nodes are at revision 0; 1 nodes are at revision 8","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:54:25.993031197Z I0109 04:54:25.992963       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:54:26.002888255Z I0109 04:54:26.002287       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded message changed from "GuardControllerDegraded: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]" to "GuardControllerDegraded: [Missing PodIP in operand kube-apiserver-ip-10-0-160-211.us-east-2.compute.internal on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]"
2023-01-09T04:54:27.161692208Z I0109 04:54:27.161654       1 request.go:601] Waited for 1.178594321s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:54:28.162330073Z I0109 04:54:28.162286       1 request.go:601] Waited for 2.169023386s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T04:54:29.169233820Z I0109 04:54:29.169189       1 request.go:601] Waited for 2.005180782s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:54:30.361634666Z I0109 04:54:30.361587       1 request.go:601] Waited for 1.79471053s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:54:30.364211736Z I0109 04:54:30.364175       1 installer_controller.go:512] "ip-10-0-160-211.us-east-2.compute.internal" is in transition to 8, but has not made progress because static pod is pending
2023-01-09T04:54:31.364234306Z I0109 04:54:31.364195       1 request.go:601] Waited for 1.775711717s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2023-01-09T04:54:32.968537310Z I0109 04:54:32.968429       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/kube-apiserver-guard-ip-10-0-160-211.us-east-2.compute.internal -n openshift-kube-apiserver because it was missing
2023-01-09T04:54:32.982269868Z E0109 04:54:32.982228       1 base_controller.go:272] GuardController reconciliation failed: Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:54:32.992225146Z I0109 04:54:32.987343       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:54:33.004329526Z I0109 04:54:33.003764       1 status_controller.go:211] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:44:16Z","message":"GuardControllerDegraded: Missing operand on node ip-10-0-145-4.us-east-2.compute.internal","reason":"GuardController_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:42:55Z","message":"NodeInstallerProgressing: 2 nodes are at revision 0; 1 nodes are at revision 8","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:53:12Z","message":"StaticPodsAvailable: 1 nodes are active; 2 nodes are at revision 0; 1 nodes are at revision 8","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:54:33.022064255Z I0109 04:54:33.013347       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded message changed from "GuardControllerDegraded: [Missing PodIP in operand kube-apiserver-ip-10-0-160-211.us-east-2.compute.internal on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]" to "GuardControllerDegraded: Missing operand on node ip-10-0-145-4.us-east-2.compute.internal"
2023-01-09T04:54:34.162090825Z I0109 04:54:34.162046       1 request.go:601] Waited for 1.175732827s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-8-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:54:35.162318138Z I0109 04:54:35.162277       1 request.go:601] Waited for 2.162366026s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver
2023-01-09T04:54:36.361672629Z I0109 04:54:36.361636       1 request.go:601] Waited for 2.19669191s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-8-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:54:37.561948933Z I0109 04:54:37.561909       1 request.go:601] Waited for 1.596116299s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2023-01-09T04:54:38.761422376Z I0109 04:54:38.761379       1 request.go:601] Waited for 1.793681378s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/config
2023-01-09T04:54:39.165208152Z I0109 04:54:39.165153       1 installer_controller.go:512] "ip-10-0-160-211.us-east-2.compute.internal" is in transition to 8, but has not made progress because static pod is pending
2023-01-09T04:54:39.364405109Z E0109 04:54:39.364364       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:54:39.364775766Z E0109 04:54:39.364748       1 base_controller.go:272] GuardController reconciliation failed: Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:54:39.367065007Z E0109 04:54:39.367038       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:54:41.964684091Z E0109 04:54:41.964644       1 base_controller.go:272] GuardController reconciliation failed: Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:54:42.963802455Z I0109 04:54:42.963762       1 installer_controller.go:512] "ip-10-0-160-211.us-east-2.compute.internal" is in transition to 8, but has not made progress because static pod is pending
2023-01-09T04:54:43.563737157Z E0109 04:54:43.563697       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:54:43.564067055Z E0109 04:54:43.564050       1 base_controller.go:272] GuardController reconciliation failed: Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:54:45.561617446Z I0109 04:54:45.561575       1 request.go:601] Waited for 1.094976355s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:54:46.761879874Z I0109 04:54:46.761839       1 request.go:601] Waited for 1.39584959s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2023-01-09T04:54:47.761967991Z I0109 04:54:47.761920       1 request.go:601] Waited for 1.396687142s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:54:48.961692214Z I0109 04:54:48.961648       1 request.go:601] Waited for 1.196996692s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:54:49.365318398Z E0109 04:54:49.365281       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:54:49.365828023Z E0109 04:54:49.365812       1 base_controller.go:272] GuardController reconciliation failed: Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:54:51.964489165Z E0109 04:54:51.964442       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:54:51.964797664Z E0109 04:54:51.964781       1 base_controller.go:272] GuardController reconciliation failed: Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:54:54.988846752Z E0109 04:54:54.988802       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:54:54.989259918Z E0109 04:54:54.989226       1 base_controller.go:272] GuardController reconciliation failed: Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:54:56.725439752Z I0109 04:54:56.725395       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:54:57.116850401Z I0109 04:54:57.116793       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:55:15.019739386Z I0109 04:55:15.019700       1 installer_controller.go:500] "ip-10-0-160-211.us-east-2.compute.internal" moving to (v1.NodeStatus) {
2023-01-09T04:55:15.019739386Z  NodeName: (string) (len=42) "ip-10-0-160-211.us-east-2.compute.internal",
2023-01-09T04:55:15.019739386Z  CurrentRevision: (int32) 8,
2023-01-09T04:55:15.019739386Z  TargetRevision: (int32) 0,
2023-01-09T04:55:15.019739386Z  LastFailedRevision: (int32) 0,
2023-01-09T04:55:15.019739386Z  LastFailedTime: (*v1.Time)(<nil>),
2023-01-09T04:55:15.019739386Z  LastFailedReason: (string) "",
2023-01-09T04:55:15.019739386Z  LastFailedCount: (int) 0,
2023-01-09T04:55:15.019739386Z  LastFallbackCount: (int) 0,
2023-01-09T04:55:15.019739386Z  LastFailedRevisionErrors: ([]string) <nil>
2023-01-09T04:55:15.019739386Z }
2023-01-09T04:55:15.019739386Z  because static pod is ready
2023-01-09T04:55:15.034505139Z I0109 04:55:15.034456       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeCurrentRevisionChanged' Updated node "ip-10-0-160-211.us-east-2.compute.internal" from revision 0 to 8 because static pod is ready
2023-01-09T04:55:15.036777085Z I0109 04:55:15.036742       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:55:15.038304805Z I0109 04:55:15.038272       1 status_controller.go:211] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:44:16Z","message":"GuardControllerDegraded: Missing operand on node ip-10-0-145-4.us-east-2.compute.internal","reason":"GuardController_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:42:55Z","message":"NodeInstallerProgressing: 1 nodes are at revision 0; 2 nodes are at revision 8","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:53:12Z","message":"StaticPodsAvailable: 2 nodes are active; 1 nodes are at revision 0; 2 nodes are at revision 8","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:55:15.050008404Z I0109 04:55:15.049949       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Progressing message changed from "NodeInstallerProgressing: 2 nodes are at revision 0; 1 nodes are at revision 8" to "NodeInstallerProgressing: 1 nodes are at revision 0; 2 nodes are at revision 8",Available message changed from "StaticPodsAvailable: 1 nodes are active; 2 nodes are at revision 0; 1 nodes are at revision 8" to "StaticPodsAvailable: 2 nodes are active; 1 nodes are at revision 0; 2 nodes are at revision 8"
2023-01-09T04:55:16.200895359Z I0109 04:55:16.200852       1 request.go:601] Waited for 1.159320474s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-8-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:55:17.400004229Z I0109 04:55:17.399950       1 request.go:601] Waited for 1.394520262s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-pod
2023-01-09T04:55:18.400693608Z I0109 04:55:18.400647       1 request.go:601] Waited for 1.397069196s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:55:20.805392169Z I0109 04:55:20.805352       1 installer_controller.go:524] node ip-10-0-145-4.us-east-2.compute.internal static pod not found and needs new revision 8
2023-01-09T04:55:20.805435398Z I0109 04:55:20.805392       1 installer_controller.go:532] "ip-10-0-145-4.us-east-2.compute.internal" moving to (v1.NodeStatus) {
2023-01-09T04:55:20.805435398Z  NodeName: (string) (len=40) "ip-10-0-145-4.us-east-2.compute.internal",
2023-01-09T04:55:20.805435398Z  CurrentRevision: (int32) 0,
2023-01-09T04:55:20.805435398Z  TargetRevision: (int32) 8,
2023-01-09T04:55:20.805435398Z  LastFailedRevision: (int32) 0,
2023-01-09T04:55:20.805435398Z  LastFailedTime: (*v1.Time)(<nil>),
2023-01-09T04:55:20.805435398Z  LastFailedReason: (string) "",
2023-01-09T04:55:20.805435398Z  LastFailedCount: (int) 0,
2023-01-09T04:55:20.805435398Z  LastFallbackCount: (int) 0,
2023-01-09T04:55:20.805435398Z  LastFailedRevisionErrors: ([]string) <nil>
2023-01-09T04:55:20.805435398Z }
2023-01-09T04:55:20.817305440Z I0109 04:55:20.817256       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeTargetRevisionChanged' Updating node "ip-10-0-145-4.us-east-2.compute.internal" from revision 0 to 8 because node ip-10-0-145-4.us-east-2.compute.internal static pod not found
2023-01-09T04:55:20.819829083Z I0109 04:55:20.819773       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:55:22.000384150Z I0109 04:55:22.000343       1 request.go:601] Waited for 1.180651883s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:55:25.214265463Z I0109 04:55:25.214199       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/installer-8-ip-10-0-145-4.us-east-2.compute.internal -n openshift-kube-apiserver because it was missing
2023-01-09T04:55:26.202481829Z I0109 04:55:26.202434       1 installer_controller.go:512] "ip-10-0-145-4.us-east-2.compute.internal" is in transition to 8, but has not made progress because installer is not finished, but in Pending phase
2023-01-09T04:55:26.400858956Z I0109 04:55:26.400821       1 request.go:601] Waited for 1.184765847s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:55:27.600781069Z I0109 04:55:27.600741       1 request.go:601] Waited for 1.202615607s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T04:55:28.800926511Z I0109 04:55:28.800884       1 request.go:601] Waited for 1.398185411s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:55:29.802855144Z E0109 04:55:29.802809       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:55:29.803221325Z E0109 04:55:29.803191       1 base_controller.go:272] GuardController reconciliation failed: Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:55:30.803607321Z I0109 04:55:30.803567       1 installer_controller.go:512] "ip-10-0-145-4.us-east-2.compute.internal" is in transition to 8, but has not made progress because installer is not finished, but in Running phase
2023-01-09T04:55:31.003551952Z E0109 04:55:31.003512       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:55:31.805213786Z E0109 04:55:31.805169       1 base_controller.go:272] GuardController reconciliation failed: Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:55:32.402580412Z I0109 04:55:32.402535       1 installer_controller.go:512] "ip-10-0-145-4.us-east-2.compute.internal" is in transition to 8, but has not made progress because installer is not finished, but in Running phase
2023-01-09T04:55:40.873828149Z I0109 04:55:40.873783       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:55:41.274261866Z I0109 04:55:41.274211       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:55:48.861094872Z I0109 04:55:48.861056       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:55:48.872677424Z I0109 04:55:48.872638       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:55:51.301577027Z I0109 04:55:51.301528       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:55:51.384420494Z E0109 04:55:51.384386       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T04:55:51.530126395Z I0109 04:55:51.530088       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:55:51.867619122Z I0109 04:55:51.867560       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:55:51.884564551Z I0109 04:55:51.882865       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:55:52.389631575Z E0109 04:55:52.389591       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T04:55:54.431912041Z I0109 04:55:54.431860       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:55:54.539425243Z I0109 04:55:54.539386       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:55:55.622160373Z I0109 04:55:55.622117       1 request.go:601] Waited for 1.182555331s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-pod
2023-01-09T04:55:56.822041547Z I0109 04:55:56.822003       1 request.go:601] Waited for 1.595668448s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:55:57.024152140Z I0109 04:55:57.024110       1 installer_controller.go:512] "ip-10-0-145-4.us-east-2.compute.internal" is in transition to 8, but has not made progress because installer is not finished, but in Running phase
2023-01-09T04:55:58.022256352Z I0109 04:55:58.022212       1 request.go:601] Waited for 1.195829353s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:56:00.823610934Z I0109 04:56:00.823569       1 installer_controller.go:512] "ip-10-0-145-4.us-east-2.compute.internal" is in transition to 8, but has not made progress because installer is not finished, but in Running phase
2023-01-09T04:56:04.822268233Z I0109 04:56:04.822226       1 request.go:601] Waited for 1.11279847s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:56:06.021279820Z I0109 04:56:06.021237       1 request.go:601] Waited for 1.093375466s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2023-01-09T04:56:07.021959689Z I0109 04:56:07.021912       1 request.go:601] Waited for 1.39741497s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:56:08.022247081Z I0109 04:56:08.022198       1 request.go:601] Waited for 1.597397762s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:56:09.221872637Z I0109 04:56:09.221822       1 request.go:601] Waited for 1.592913379s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver
2023-01-09T04:56:09.425328596Z E0109 04:56:09.425289       1 guard_controller.go:274] Missing PodIP in operand kube-apiserver-ip-10-0-145-4.us-east-2.compute.internal on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:56:09.436580814Z E0109 04:56:09.436539       1 base_controller.go:272] GuardController reconciliation failed: Missing PodIP in operand kube-apiserver-ip-10-0-145-4.us-east-2.compute.internal on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:56:09.437352669Z I0109 04:56:09.437323       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:56:09.438592854Z I0109 04:56:09.438563       1 status_controller.go:211] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:44:16Z","message":"GuardControllerDegraded: Missing PodIP in operand kube-apiserver-ip-10-0-145-4.us-east-2.compute.internal on node ip-10-0-145-4.us-east-2.compute.internal","reason":"GuardController_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:42:55Z","message":"NodeInstallerProgressing: 1 nodes are at revision 0; 2 nodes are at revision 8","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:53:12Z","message":"StaticPodsAvailable: 2 nodes are active; 1 nodes are at revision 0; 2 nodes are at revision 8","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:56:09.449971064Z I0109 04:56:09.449362       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded message changed from "GuardControllerDegraded: Missing operand on node ip-10-0-145-4.us-east-2.compute.internal" to "GuardControllerDegraded: Missing PodIP in operand kube-apiserver-ip-10-0-145-4.us-east-2.compute.internal on node ip-10-0-145-4.us-east-2.compute.internal"
2023-01-09T04:56:10.621454259Z I0109 04:56:10.621405       1 request.go:601] Waited for 1.183021736s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T04:56:11.622234308Z I0109 04:56:11.622186       1 request.go:601] Waited for 1.798074804s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:56:11.627917954Z I0109 04:56:11.627874       1 installer_controller.go:512] "ip-10-0-145-4.us-east-2.compute.internal" is in transition to 8, but has not made progress because static pod is pending
2023-01-09T04:56:12.622279791Z I0109 04:56:12.622237       1 request.go:601] Waited for 1.193523239s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-pod
2023-01-09T04:56:13.821318432Z I0109 04:56:13.821278       1 request.go:601] Waited for 1.195874075s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/client-ca
2023-01-09T04:56:16.426959682Z I0109 04:56:16.426901       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/kube-apiserver-guard-ip-10-0-145-4.us-east-2.compute.internal -n openshift-kube-apiserver because it was missing
2023-01-09T04:56:16.445843814Z I0109 04:56:16.445267       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:56:16.448964529Z I0109 04:56:16.448924       1 status_controller.go:211] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:56:16Z","message":"NodeControllerDegraded: All master nodes are ready","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:42:55Z","message":"NodeInstallerProgressing: 1 nodes are at revision 0; 2 nodes are at revision 8","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:53:12Z","message":"StaticPodsAvailable: 2 nodes are active; 1 nodes are at revision 0; 2 nodes are at revision 8","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:56:16.457500841Z I0109 04:56:16.457450       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded changed from True to False ("NodeControllerDegraded: All master nodes are ready")
2023-01-09T04:56:17.226027976Z I0109 04:56:17.225974       1 installer_controller.go:512] "ip-10-0-145-4.us-east-2.compute.internal" is in transition to 8, but has not made progress because static pod is pending
2023-01-09T04:56:17.422272436Z I0109 04:56:17.422209       1 request.go:601] Waited for 1.021654898s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T04:56:18.621654645Z I0109 04:56:18.621612       1 request.go:601] Waited for 2.170831901s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-8-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:56:19.621693153Z I0109 04:56:19.621642       1 request.go:601] Waited for 2.194445107s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T04:56:20.622277088Z I0109 04:56:20.622226       1 request.go:601] Waited for 1.996901932s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-8-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:56:21.821790763Z I0109 04:56:21.821751       1 request.go:601] Waited for 1.595304286s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:56:23.021508555Z I0109 04:56:23.021468       1 request.go:601] Waited for 1.595032401s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:56:25.221800055Z I0109 04:56:25.221756       1 request.go:601] Waited for 1.190866598s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2023-01-09T04:56:26.421807021Z I0109 04:56:26.421767       1 request.go:601] Waited for 1.395267833s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:56:26.426673706Z I0109 04:56:26.426637       1 installer_controller.go:500] "ip-10-0-145-4.us-east-2.compute.internal" moving to (v1.NodeStatus) {
2023-01-09T04:56:26.426673706Z  NodeName: (string) (len=40) "ip-10-0-145-4.us-east-2.compute.internal",
2023-01-09T04:56:26.426673706Z  CurrentRevision: (int32) 8,
2023-01-09T04:56:26.426673706Z  TargetRevision: (int32) 0,
2023-01-09T04:56:26.426673706Z  LastFailedRevision: (int32) 0,
2023-01-09T04:56:26.426673706Z  LastFailedTime: (*v1.Time)(<nil>),
2023-01-09T04:56:26.426673706Z  LastFailedReason: (string) "",
2023-01-09T04:56:26.426673706Z  LastFailedCount: (int) 0,
2023-01-09T04:56:26.426673706Z  LastFallbackCount: (int) 0,
2023-01-09T04:56:26.426673706Z  LastFailedRevisionErrors: ([]string) <nil>
2023-01-09T04:56:26.426673706Z }
2023-01-09T04:56:26.426673706Z  because static pod is ready
2023-01-09T04:56:26.442443353Z I0109 04:56:26.442386       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeCurrentRevisionChanged' Updated node "ip-10-0-145-4.us-east-2.compute.internal" from revision 0 to 8 because static pod is ready
2023-01-09T04:56:26.444620351Z I0109 04:56:26.444586       1 status_controller.go:211] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:56:16Z","message":"NodeControllerDegraded: All master nodes are ready","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:56:26Z","message":"NodeInstallerProgressing: 3 nodes are at revision 8","reason":"AsExpected","status":"False","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:53:12Z","message":"StaticPodsAvailable: 3 nodes are active; 3 nodes are at revision 8","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:56:26.446535179Z I0109 04:56:26.446499       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:56:26.457636947Z I0109 04:56:26.457598       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Progressing changed from True to False ("NodeInstallerProgressing: 3 nodes are at revision 8"),Available message changed from "StaticPodsAvailable: 2 nodes are active; 1 nodes are at revision 0; 2 nodes are at revision 8" to "StaticPodsAvailable: 3 nodes are active; 3 nodes are at revision 8"
2023-01-09T04:56:27.422092058Z I0109 04:56:27.422048       1 request.go:601] Waited for 1.19793441s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/localhost-recovery-client-token
2023-01-09T04:56:28.422139194Z I0109 04:56:28.422100       1 request.go:601] Waited for 1.975930367s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T04:56:29.622147789Z I0109 04:56:29.622110       1 request.go:601] Waited for 1.797354103s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:56:30.822175508Z I0109 04:56:30.822127       1 request.go:601] Waited for 1.594985261s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-pod
2023-01-09T04:56:32.022277528Z I0109 04:56:32.022235       1 request.go:601] Waited for 1.396046787s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:58:13.511596990Z I0109 04:58:13.511558       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:58:13.909420793Z I0109 04:58:13.909362       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:58:55.122095706Z I0109 04:58:55.122036       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:58:55.135791914Z I0109 04:58:55.135749       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:58:57.667498684Z I0109 04:58:57.667439       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:58:57.873309556Z I0109 04:58:57.873269       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:58:57.961692829Z E0109 04:58:57.961657       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T04:58:58.103835381Z I0109 04:58:58.103797       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:58:58.104137122Z I0109 04:58:58.104117       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:58:58.376296328Z I0109 04:58:58.376252       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:58:58.399400690Z I0109 04:58:58.399363       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:58:58.968195248Z E0109 04:58:58.968160       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T04:59:01.000586459Z I0109 04:59:01.000542       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:59:01.106769896Z I0109 04:59:01.106725       1 connectivity_check_controller.go:138] ConnectivityCheckController is waiting for transition to desired version (4.12.0-0.nightly-2023-01-08-142418) to be completed.
2023-01-09T04:59:02.200505242Z I0109 04:59:02.200454       1 request.go:601] Waited for 1.093684675s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T04:59:03.200966489Z I0109 04:59:03.200929       1 request.go:601] Waited for 1.595563828s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/client-ca
2023-01-09T04:59:05.600001002Z I0109 04:59:05.599944       1 request.go:601] Waited for 1.02894673s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T04:59:06.600038997Z I0109 04:59:06.600003       1 request.go:601] Waited for 1.389603892s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2023-01-09T04:59:24.256243675Z E0109 04:59:24.256205       1 base_controller.go:272] ConnectivityCheckController reconciliation failed: customresourcedefinitions.apiextensions.k8s.io "podnetworkconnectivitychecks.controlplane.operator.openshift.io" already exists
2023-01-09T04:59:24.256286211Z I0109 04:59:24.256250       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"8d9ef2be-f544-42a7-a35e-748118a0b1ff", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'CustomResourceDefinitionCreateFailed' Failed to create CustomResourceDefinition.apiextensions.k8s.io/podnetworkconnectivitychecks.controlplane.operator.openshift.io: customresourcedefinitions.apiextensions.k8s.io "podnetworkconnectivitychecks.controlplane.operator.openshift.io" already exists
2023-01-09T05:02:01.948149506Z E0109 05:02:01.948112       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T05:02:02.954173478Z E0109 05:02:02.954134       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T05:02:06.179760642Z I0109 05:02:06.179720       1 request.go:601] Waited for 1.084560298s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T05:02:07.179893335Z I0109 05:02:07.179848       1 request.go:601] Waited for 1.598054718s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T05:02:08.379698139Z I0109 05:02:08.379657       1 request.go:601] Waited for 1.39634998s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T05:02:09.579807290Z I0109 05:02:09.579762       1 request.go:601] Waited for 1.195208036s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T05:03:00.122194400Z I0109 05:03:00.122141       1 request.go:601] Waited for 1.186347734s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2023-01-09T05:03:01.590042268Z I0109 05:03:01.589971       1 externalloadbalancer.go:27] syncing external loadbalancer hostnames: api.sn-loggvls-jsm.qe.devcluster.openshift.com
2023-01-09T05:03:02.522699858Z I0109 05:03:02.522660       1 request.go:601] Waited for 1.113657773s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T05:03:03.132247173Z I0109 05:03:03.132173       1 servicehostname.go:40] syncing servicenetwork hostnames: [172.30.0.1 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local openshift openshift.default openshift.default.svc openshift.default.svc.cluster.local]
2023-01-09T05:03:03.722918405Z I0109 05:03:03.722876       1 request.go:601] Waited for 1.961652647s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2023-01-09T05:03:04.723015824Z I0109 05:03:04.722958       1 request.go:601] Waited for 1.594654838s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver
2023-01-09T05:03:05.922517706Z I0109 05:03:05.922477       1 request.go:601] Waited for 1.591724357s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/config
2023-01-09T05:03:07.523078127Z I0109 05:03:07.523035       1 request.go:601] Waited for 1.09647878s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T05:04:54.198248850Z E0109 05:04:54.198203       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T05:04:55.204392612Z E0109 05:04:55.204353       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T05:04:58.436455796Z I0109 05:04:58.436416       1 request.go:601] Waited for 1.095712323s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2023-01-09T05:04:59.436499798Z I0109 05:04:59.436442       1 request.go:601] Waited for 1.598064796s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T05:07:46.431285895Z E0109 05:07:46.431248       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T05:07:47.437631509Z E0109 05:07:47.437585       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T05:07:50.757682522Z I0109 05:07:50.757641       1 request.go:601] Waited for 1.175888301s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T05:07:51.956577712Z I0109 05:07:51.956536       1 request.go:601] Waited for 1.796600825s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T05:07:52.957259525Z I0109 05:07:52.957220       1 request.go:601] Waited for 1.395335325s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/client-ca
2023-01-09T05:10:38.676416025Z E0109 05:10:38.676377       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T05:10:39.682473014Z E0109 05:10:39.682427       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T05:10:42.925265017Z I0109 05:10:42.925226       1 request.go:601] Waited for 1.090641692s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T05:10:43.926013543Z I0109 05:10:43.925959       1 request.go:601] Waited for 1.594205723s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-8-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T05:12:59.722845572Z I0109 05:12:59.722804       1 request.go:601] Waited for 1.105286431s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T05:13:00.923240635Z I0109 05:13:00.923204       1 request.go:601] Waited for 1.197442875s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T05:13:01.590342146Z I0109 05:13:01.590297       1 externalloadbalancer.go:27] syncing external loadbalancer hostnames: api.sn-loggvls-jsm.qe.devcluster.openshift.com
2023-01-09T05:13:02.523045537Z I0109 05:13:02.522971       1 request.go:601] Waited for 1.113141273s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T05:13:03.133240585Z I0109 05:13:03.133175       1 servicehostname.go:40] syncing servicenetwork hostnames: [172.30.0.1 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local openshift openshift.default openshift.default.svc openshift.default.svc.cluster.local]
2023-01-09T05:13:03.722842062Z I0109 05:13:03.722800       1 request.go:601] Waited for 1.990136882s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T05:13:04.723033268Z I0109 05:13:04.722979       1 request.go:601] Waited for 1.795609494s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2023-01-09T05:13:05.922845026Z I0109 05:13:05.922811       1 request.go:601] Waited for 1.524100253s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver
2023-01-09T05:13:07.523163171Z I0109 05:13:07.523122       1 request.go:601] Waited for 1.04216531s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T05:13:31.000550305Z E0109 05:13:31.000514       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T05:13:32.007632817Z E0109 05:13:32.007580       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T05:13:35.237700326Z I0109 05:13:35.237658       1 request.go:601] Waited for 1.097033135s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T05:13:36.238579168Z I0109 05:13:36.238535       1 request.go:601] Waited for 1.60889229s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T05:13:37.437762289Z I0109 05:13:37.437723       1 request.go:601] Waited for 1.196333272s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T05:13:38.438211639Z I0109 05:13:38.438173       1 request.go:601] Waited for 1.397395662s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver
2023-01-09T05:13:39.638091560Z I0109 05:13:39.638043       1 request.go:601] Waited for 1.167164279s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2023-01-09T05:16:23.174575507Z E0109 05:16:23.174537       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T05:16:24.180753889Z E0109 05:16:24.180716       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T05:16:27.369422926Z I0109 05:16:27.369378       1 request.go:601] Waited for 1.165940734s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T05:16:28.569650457Z I0109 05:16:28.569605       1 request.go:601] Waited for 1.398378686s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T05:16:29.769780815Z I0109 05:16:29.769735       1 request.go:601] Waited for 1.19743318s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T05:16:31.768824292Z I0109 05:16:31.768784       1 request.go:601] Waited for 1.127063888s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T05:16:32.769540113Z I0109 05:16:32.769499       1 request.go:601] Waited for 1.198052887s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/localhost-recovery-client-token
2023-01-09T05:19:15.557417570Z E0109 05:19:15.557369       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T05:19:16.562684739Z E0109 05:19:16.562645       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T05:19:19.773347960Z I0109 05:19:19.773306       1 request.go:601] Waited for 1.175037168s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/config
2023-01-09T05:19:20.973510738Z I0109 05:19:20.973472       1 request.go:601] Waited for 1.597098256s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T05:22:07.835843099Z E0109 05:22:07.835804       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T05:22:08.841721457Z E0109 05:22:08.841678       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T05:22:12.073208087Z I0109 05:22:12.073159       1 request.go:601] Waited for 1.091257609s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T05:22:13.273165867Z I0109 05:22:13.273119       1 request.go:601] Waited for 1.598491119s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/client-ca
2023-01-09T05:22:18.873095139Z I0109 05:22:18.873044       1 request.go:601] Waited for 1.064751369s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver
2023-01-09T05:22:59.649148500Z I0109 05:22:59.649109       1 request.go:601] Waited for 1.028936917s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T05:23:00.849249303Z I0109 05:23:00.849207       1 request.go:601] Waited for 1.196364956s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T05:23:01.591360599Z I0109 05:23:01.591313       1 externalloadbalancer.go:27] syncing external loadbalancer hostnames: api.sn-loggvls-jsm.qe.devcluster.openshift.com
2023-01-09T05:23:02.448786152Z I0109 05:23:02.448748       1 request.go:601] Waited for 1.039043005s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T05:23:03.133694038Z I0109 05:23:03.133627       1 servicehostname.go:40] syncing servicenetwork hostnames: [172.30.0.1 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local openshift openshift.default openshift.default.svc openshift.default.svc.cluster.local]
2023-01-09T05:23:03.649154134Z I0109 05:23:03.649111       1 request.go:601] Waited for 1.99012346s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T05:23:04.848786427Z I0109 05:23:04.848747       1 request.go:601] Waited for 1.792225321s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver
2023-01-09T05:23:05.849171583Z I0109 05:23:05.849131       1 request.go:601] Waited for 1.380488127s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T05:23:07.649313158Z I0109 05:23:07.649271       1 request.go:601] Waited for 1.133112934s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T05:23:08.649369389Z I0109 05:23:08.649329       1 request.go:601] Waited for 1.198579324s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/localhost-recovery-client-token
2023-01-09T05:24:59.988663951Z E0109 05:24:59.988629       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T05:25:00.995031834Z E0109 05:25:00.994961       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T05:25:04.227509308Z I0109 05:25:04.227468       1 request.go:601] Waited for 1.058630992s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T05:25:05.227696771Z I0109 05:25:05.227652       1 request.go:601] Waited for 1.596518368s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T05:25:06.827830628Z I0109 05:25:06.827789       1 request.go:601] Waited for 1.094151637s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T05:25:07.827928782Z I0109 05:25:07.827890       1 request.go:601] Waited for 1.395785614s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/trusted-ca-bundle
2023-01-09T05:25:09.028254522Z I0109 05:25:09.028204       1 request.go:601] Waited for 1.192985868s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2023-01-09T05:27:33.549115894Z E0109 05:27:33.549076       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T05:27:34.553911096Z E0109 05:27:34.553874       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T05:27:37.733115744Z I0109 05:27:37.733070       1 request.go:601] Waited for 1.047376689s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2023-01-09T05:27:38.933011261Z I0109 05:27:38.932949       1 request.go:601] Waited for 1.595061727s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-8-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T05:27:52.252399586Z E0109 05:27:52.252345       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T05:27:53.258045029Z E0109 05:27:53.258004       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T05:27:56.497955918Z I0109 05:27:56.497919       1 request.go:601] Waited for 1.095050157s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2023-01-09T05:27:57.697286733Z I0109 05:27:57.697234       1 request.go:601] Waited for 1.591651541s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/client-ca
2023-01-09T05:27:58.697423739Z I0109 05:27:58.697381       1 request.go:601] Waited for 1.197003119s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T05:30:44.585911178Z E0109 05:30:44.585872       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T05:30:45.592491968Z E0109 05:30:45.592449       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T05:30:48.655397087Z I0109 05:30:48.655355       1 request.go:601] Waited for 1.031800622s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-8-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T05:30:49.855569446Z I0109 05:30:49.855525       1 request.go:601] Waited for 1.797074587s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/localhost-recovery-client-token
2023-01-09T05:30:50.855673983Z I0109 05:30:50.855632       1 request.go:601] Waited for 1.796753621s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T05:30:52.055730227Z I0109 05:30:52.055684       1 request.go:601] Waited for 1.597162361s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-8-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T05:30:53.255177185Z I0109 05:30:53.255125       1 request.go:601] Waited for 1.395340503s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T05:30:54.455536655Z I0109 05:30:54.455497       1 request.go:601] Waited for 1.197116645s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T05:30:55.655704117Z I0109 05:30:55.655664       1 request.go:601] Waited for 1.197024274s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T05:30:56.855482058Z I0109 05:30:56.855439       1 request.go:601] Waited for 1.197211916s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T05:32:18.653700918Z E0109 05:32:18.653659       1 degraded_webhook.go:128] dial tcp 172.30.221.94:443: connect: connection refused
2023-01-09T05:32:19.662048037Z E0109 05:32:19.661950       1 degraded_webhook.go:128] dial tcp 172.30.221.94:443: connect: connection refused
2023-01-09T05:32:21.724792616Z E0109 05:32:21.724752       1 degraded_webhook.go:128] dial tcp 172.30.51.101:443: connect: connection refused
2023-01-09T05:32:22.727895900Z E0109 05:32:22.727845       1 degraded_webhook.go:128] dial tcp 172.30.51.101:443: connect: connection refused
2023-01-09T05:32:22.880097079Z I0109 05:32:22.880051       1 request.go:601] Waited for 1.195735951s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/config
2023-01-09T05:32:24.080558958Z I0109 05:32:24.080519       1 request.go:601] Waited for 1.196185218s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-pod
2023-01-09T05:32:24.769709563Z E0109 05:32:24.769634       1 degraded_webhook.go:128] dial tcp 172.30.51.101:443: connect: connection refused
2023-01-09T05:32:25.280494971Z I0109 05:32:25.280443       1 request.go:601] Waited for 1.196657867s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/client-ca
2023-01-09T05:32:25.772410616Z E0109 05:32:25.772366       1 degraded_webhook.go:128] dial tcp 172.30.51.101:443: connect: connection refused
2023-01-09T05:32:27.777657432Z E0109 05:32:27.777615       1 degraded_webhook.go:128] dial tcp 172.30.51.101:443: connect: connection refused
2023-01-09T05:32:28.780892279Z E0109 05:32:28.780837       1 degraded_webhook.go:128] dial tcp 172.30.51.101:443: connect: connection refused
2023-01-09T05:32:29.080101039Z I0109 05:32:29.080058       1 request.go:601] Waited for 1.02855335s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T05:32:30.802798304Z E0109 05:32:30.802757       1 degraded_webhook.go:128] dial tcp 172.30.51.101:443: connect: connection refused
2023-01-09T05:32:31.805271843Z E0109 05:32:31.805229       1 degraded_webhook.go:128] dial tcp 172.30.51.101:443: connect: connection refused
2023-01-09T05:32:34.879922910Z I0109 05:32:34.879882       1 request.go:601] Waited for 1.057174108s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T05:32:35.879979534Z I0109 05:32:35.879936       1 request.go:601] Waited for 1.195340856s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T05:32:37.680182655Z I0109 05:32:37.680131       1 request.go:601] Waited for 1.131268175s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T05:32:54.960963482Z E0109 05:32:54.960922       1 degraded_webhook.go:128] dial tcp 172.30.51.101:443: connect: connection refused
2023-01-09T05:32:55.963579480Z E0109 05:32:55.963534       1 degraded_webhook.go:128] dial tcp 172.30.51.101:443: connect: connection refused
2023-01-09T05:32:58.011395827Z E0109 05:32:58.011357       1 degraded_webhook.go:128] dial tcp 172.30.51.101:443: connect: connection refused
2023-01-09T05:32:59.014675032Z E0109 05:32:59.014634       1 degraded_webhook.go:128] dial tcp 172.30.51.101:443: connect: connection refused
2023-01-09T05:32:59.667979760Z I0109 05:32:59.667937       1 request.go:601] Waited for 1.044996933s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T05:33:00.868481374Z I0109 05:33:00.868438       1 request.go:601] Waited for 1.197560052s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T05:33:01.019058939Z E0109 05:33:01.019012       1 degraded_webhook.go:128] dial tcp 172.30.51.101:443: connect: connection refused
2023-01-09T05:33:01.591865634Z I0109 05:33:01.591820       1 externalloadbalancer.go:27] syncing external loadbalancer hostnames: api.sn-loggvls-jsm.qe.devcluster.openshift.com
2023-01-09T05:33:02.021976928Z E0109 05:33:02.021935       1 degraded_webhook.go:128] dial tcp 172.30.51.101:443: connect: connection refused
2023-01-09T05:33:02.468671253Z I0109 05:33:02.468628       1 request.go:601] Waited for 1.058797801s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T05:33:03.134088761Z I0109 05:33:03.134018       1 servicehostname.go:40] syncing servicenetwork hostnames: [172.30.0.1 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local openshift openshift.default openshift.default.svc openshift.default.svc.cluster.local]
2023-01-09T05:33:03.668301658Z I0109 05:33:03.668256       1 request.go:601] Waited for 1.988303888s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T05:33:04.047713424Z E0109 05:33:04.047663       1 degraded_webhook.go:128] dial tcp 172.30.51.101:443: connect: connection refused
2023-01-09T05:33:04.668333164Z I0109 05:33:04.668279       1 request.go:601] Waited for 1.795735035s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2023-01-09T05:33:05.050391361Z E0109 05:33:05.050346       1 degraded_webhook.go:128] dial tcp 172.30.51.101:443: connect: connection refused
2023-01-09T05:33:05.867826436Z I0109 05:33:05.867780       1 request.go:601] Waited for 1.39240676s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver
2023-01-09T05:33:07.087351962Z E0109 05:33:07.087313       1 degraded_webhook.go:128] dial tcp 172.30.51.101:443: connect: connection refused
2023-01-09T05:33:07.668088074Z I0109 05:33:07.668048       1 request.go:601] Waited for 1.118184393s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T05:33:08.089795212Z E0109 05:33:08.089752       1 degraded_webhook.go:128] dial tcp 172.30.51.101:443: connect: connection refused
2023-01-09T05:33:10.134810811Z E0109 05:33:10.134771       1 degraded_webhook.go:128] dial tcp 172.30.51.101:443: connect: connection refused
2023-01-09T05:33:11.136906950Z E0109 05:33:11.136865       1 degraded_webhook.go:128] dial tcp 172.30.51.101:443: connect: connection refused
2023-01-09T05:33:13.141676239Z E0109 05:33:13.141625       1 degraded_webhook.go:128] dial tcp 172.30.51.101:443: connect: connection refused
2023-01-09T05:33:14.143962939Z E0109 05:33:14.143917       1 degraded_webhook.go:128] dial tcp 172.30.51.101:443: connect: connection refused
2023-01-09T05:33:16.179287437Z E0109 05:33:16.179233       1 degraded_webhook.go:128] dial tcp 172.30.51.101:443: connect: connection refused
2023-01-09T05:33:17.182146732Z E0109 05:33:17.182103       1 degraded_webhook.go:128] dial tcp 172.30.51.101:443: connect: connection refused
2023-01-09T05:33:19.206543774Z E0109 05:33:19.206504       1 degraded_webhook.go:128] dial tcp 172.30.51.101:443: connect: connection refused
2023-01-09T05:33:20.209710612Z E0109 05:33:20.209658       1 degraded_webhook.go:128] dial tcp 172.30.51.101:443: connect: connection refused
2023-01-09T05:33:22.247925206Z E0109 05:33:22.247884       1 degraded_webhook.go:128] dial tcp 172.30.51.101:443: connect: connection refused
2023-01-09T05:33:23.250417317Z E0109 05:33:23.250376       1 degraded_webhook.go:128] dial tcp 172.30.51.101:443: connect: connection refused
2023-01-09T05:33:25.254851244Z E0109 05:33:25.254814       1 degraded_webhook.go:128] dial tcp 172.30.51.101:443: connect: connection refused
2023-01-09T05:33:26.257982475Z E0109 05:33:26.257931       1 degraded_webhook.go:128] dial tcp 172.30.51.101:443: connect: connection refused
2023-01-09T05:33:28.310638741Z E0109 05:33:28.310601       1 degraded_webhook.go:128] dial tcp 172.30.51.101:443: connect: connection refused
2023-01-09T05:33:29.313694025Z E0109 05:33:29.313643       1 degraded_webhook.go:128] dial tcp 172.30.51.101:443: connect: connection refused
2023-01-09T05:33:31.337809077Z E0109 05:33:31.337767       1 degraded_webhook.go:128] dial tcp 172.30.51.101:443: connect: connection refused
2023-01-09T05:33:32.340582901Z E0109 05:33:32.340538       1 degraded_webhook.go:128] dial tcp 172.30.51.101:443: connect: connection refused
2023-01-09T05:33:34.379262934Z E0109 05:33:34.379221       1 degraded_webhook.go:128] dial tcp 172.30.51.101:443: connect: connection refused
2023-01-09T05:33:35.382014644Z E0109 05:33:35.381953       1 degraded_webhook.go:128] dial tcp 172.30.51.101:443: connect: connection refused
2023-01-09T05:33:37.386900046Z E0109 05:33:37.386860       1 degraded_webhook.go:128] dial tcp 172.30.51.101:443: connect: connection refused
2023-01-09T05:33:38.389829771Z E0109 05:33:38.389787       1 degraded_webhook.go:128] dial tcp 172.30.51.101:443: connect: connection refused
2023-01-09T05:33:40.448504541Z E0109 05:33:40.448449       1 degraded_webhook.go:128] dial tcp 172.30.51.101:443: connect: connection refused
2023-01-09T05:33:41.451220319Z E0109 05:33:41.451179       1 degraded_webhook.go:128] dial tcp 172.30.51.101:443: connect: connection refused
2023-01-09T05:33:43.494241853Z E0109 05:33:43.494177       1 degraded_webhook.go:128] dial tcp 172.30.51.101:443: connect: connection refused
2023-01-09T05:33:44.497191855Z E0109 05:33:44.497143       1 degraded_webhook.go:128] dial tcp 172.30.51.101:443: connect: connection refused
2023-01-09T05:33:46.544266085Z E0109 05:33:46.544223       1 degraded_webhook.go:128] dial tcp 172.30.51.101:443: connect: connection refused
2023-01-09T05:33:47.546910072Z E0109 05:33:47.546865       1 degraded_webhook.go:128] dial tcp 172.30.51.101:443: connect: connection refused
2023-01-09T05:33:49.552046694Z E0109 05:33:49.552002       1 degraded_webhook.go:128] dial tcp 172.30.51.101:443: connect: connection refused
2023-01-09T05:33:50.554268908Z E0109 05:33:50.554224       1 degraded_webhook.go:128] dial tcp 172.30.51.101:443: connect: connection refused
2023-01-09T05:33:52.570750329Z E0109 05:33:52.570707       1 degraded_webhook.go:128] dial tcp 172.30.51.101:443: connect: connection refused
2023-01-09T05:33:53.572812638Z E0109 05:33:53.572768       1 degraded_webhook.go:128] dial tcp 172.30.51.101:443: connect: connection refused
2023-01-09T05:34:17.958262285Z E0109 05:34:17.958215       1 degraded_webhook.go:128] dial tcp 172.30.51.101:443: connect: connection refused
2023-01-09T05:34:18.962633566Z E0109 05:34:18.962587       1 degraded_webhook.go:128] dial tcp 172.30.51.101:443: connect: connection refused
2023-01-09T05:34:22.165123497Z I0109 05:34:22.165079       1 request.go:601] Waited for 1.08976517s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T05:34:23.364892083Z I0109 05:34:23.364842       1 request.go:601] Waited for 1.390974704s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-8-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T05:36:29.032926945Z E0109 05:36:29.032883       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T05:36:30.039484488Z E0109 05:36:30.039439       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T05:36:33.275108552Z I0109 05:36:33.275059       1 request.go:601] Waited for 1.071321941s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T05:36:34.276720931Z I0109 05:36:34.276674       1 request.go:601] Waited for 1.596858891s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T05:36:37.674635666Z I0109 05:36:37.674591       1 request.go:601] Waited for 1.113667761s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T05:39:21.287675235Z E0109 05:39:21.287638       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T05:39:22.293389697Z E0109 05:39:22.293349       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T05:39:25.529159784Z I0109 05:39:25.529117       1 request.go:601] Waited for 1.106916525s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T05:39:26.729067070Z I0109 05:39:26.729028       1 request.go:601] Waited for 1.596923127s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-8-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T05:39:27.931424382Z I0109 05:39:27.931132       1 request.go:601] Waited for 1.398478797s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T05:39:29.128528683Z I0109 05:39:29.128483       1 request.go:601] Waited for 1.187319601s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T05:42:13.465899078Z E0109 05:42:13.465859       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T05:42:14.471969096Z E0109 05:42:14.471929       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T05:42:17.590555501Z I0109 05:42:17.590517       1 request.go:601] Waited for 1.011901994s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T05:42:18.790157686Z I0109 05:42:18.790119       1 request.go:601] Waited for 1.56815632s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2023-01-09T05:42:19.790319139Z I0109 05:42:19.790275       1 request.go:601] Waited for 1.592539336s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T05:42:20.795121229Z I0109 05:42:20.795076       1 request.go:601] Waited for 1.402734165s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T05:42:59.803272907Z I0109 05:42:59.803230       1 request.go:601] Waited for 1.056232371s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2023-01-09T05:43:00.803837305Z I0109 05:43:00.803796       1 request.go:601] Waited for 1.197128216s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T05:43:01.592336906Z I0109 05:43:01.592295       1 externalloadbalancer.go:27] syncing external loadbalancer hostnames: api.sn-loggvls-jsm.qe.devcluster.openshift.com
2023-01-09T05:43:02.603717247Z I0109 05:43:02.603676       1 request.go:601] Waited for 1.193731768s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T05:43:03.135039803Z I0109 05:43:03.134952       1 servicehostname.go:40] syncing servicenetwork hostnames: [172.30.0.1 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local openshift openshift.default openshift.default.svc openshift.default.svc.cluster.local]
2023-01-09T05:43:03.603769455Z I0109 05:43:03.603725       1 request.go:601] Waited for 1.988911948s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T05:43:04.803984562Z I0109 05:43:04.803937       1 request.go:601] Waited for 1.797482159s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T05:43:06.004018793Z I0109 05:43:06.003976       1 request.go:601] Waited for 1.195242777s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T05:43:07.604297930Z I0109 05:43:07.604245       1 request.go:601] Waited for 1.021884206s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T05:45:05.745327058Z E0109 05:45:05.745287       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T05:45:06.751353835Z E0109 05:45:06.751310       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T05:45:09.896981993Z I0109 05:45:09.896941       1 request.go:601] Waited for 1.10968331s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T05:45:10.897036612Z I0109 05:45:10.896970       1 request.go:601] Waited for 1.791266205s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2023-01-09T05:45:11.897059060Z I0109 05:45:11.897017       1 request.go:601] Waited for 1.795812161s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T05:45:13.096906640Z I0109 05:45:13.096860       1 request.go:601] Waited for 1.197064722s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T05:47:58.081302715Z E0109 05:47:58.081266       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T05:47:59.087656927Z E0109 05:47:59.087606       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T05:48:02.323569651Z I0109 05:48:02.323529       1 request.go:601] Waited for 1.080222342s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2023-01-09T05:48:03.522960574Z I0109 05:48:03.522916       1 request.go:601] Waited for 1.59685902s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-8-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T05:48:05.923598828Z I0109 05:48:05.923556       1 request.go:601] Waited for 1.084736632s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T05:50:50.177250548Z E0109 05:50:50.177209       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T05:50:51.183471471Z E0109 05:50:51.183432       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T05:50:54.419848074Z I0109 05:50:54.419806       1 request.go:601] Waited for 1.072331577s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T05:50:55.420251227Z I0109 05:50:55.420200       1 request.go:601] Waited for 1.595448009s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T05:50:57.619976035Z I0109 05:50:57.619934       1 request.go:601] Waited for 1.013163687s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T05:52:59.816306895Z I0109 05:52:59.816272       1 request.go:601] Waited for 1.196224069s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T05:53:00.816373222Z I0109 05:53:00.816328       1 request.go:601] Waited for 1.191428151s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T05:53:01.593150808Z I0109 05:53:01.593099       1 externalloadbalancer.go:27] syncing external loadbalancer hostnames: api.sn-loggvls-jsm.qe.devcluster.openshift.com
2023-01-09T05:53:02.016292295Z I0109 05:53:02.016245       1 request.go:601] Waited for 1.021366478s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2023-01-09T05:53:03.017237334Z I0109 05:53:03.017191       1 request.go:601] Waited for 1.422881007s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T05:53:03.135331198Z I0109 05:53:03.135261       1 servicehostname.go:40] syncing servicenetwork hostnames: [172.30.0.1 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local openshift openshift.default openshift.default.svc openshift.default.svc.cluster.local]
2023-01-09T05:53:04.216286147Z I0109 05:53:04.216237       1 request.go:601] Waited for 1.972012534s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2023-01-09T05:53:05.216861894Z I0109 05:53:05.216821       1 request.go:601] Waited for 1.794961816s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2023-01-09T05:53:07.616846845Z I0109 05:53:07.616802       1 request.go:601] Waited for 1.000955828s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T05:53:08.616867005Z I0109 05:53:08.616823       1 request.go:601] Waited for 1.196968214s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/trusted-ca-bundle
2023-01-09T05:53:42.473384401Z E0109 05:53:42.473300       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T05:53:43.478929711Z E0109 05:53:43.478888       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T05:53:46.694172606Z I0109 05:53:46.694137       1 request.go:601] Waited for 1.169726527s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T05:53:47.694764996Z I0109 05:53:47.694719       1 request.go:601] Waited for 1.597810908s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-8-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T05:53:48.694799471Z I0109 05:53:48.694755       1 request.go:601] Waited for 1.597750099s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver
2023-01-09T05:53:49.894513483Z I0109 05:53:49.894472       1 request.go:601] Waited for 1.392897293s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/client-ca
2023-01-09T05:56:34.766560954Z E0109 05:56:34.766514       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T05:56:35.773401404Z E0109 05:56:35.773356       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T05:56:39.009096958Z I0109 05:56:39.009057       1 request.go:601] Waited for 1.074548605s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T05:56:40.208583165Z I0109 05:56:40.208526       1 request.go:601] Waited for 1.596422807s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/client-ca
2023-01-09T05:56:41.408335453Z I0109 05:56:41.408295       1 request.go:601] Waited for 1.196526763s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-server-ca
2023-01-09T05:56:42.408393567Z I0109 05:56:42.408344       1 request.go:601] Waited for 1.197392889s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T05:56:43.408484379Z I0109 05:56:43.408437       1 request.go:601] Waited for 1.196054338s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-8-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T05:56:46.408913172Z I0109 05:56:46.408870       1 request.go:601] Waited for 1.171262967s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T05:59:27.095109202Z E0109 05:59:27.095062       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T05:59:28.102099556Z E0109 05:59:28.102042       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T05:59:31.338021191Z I0109 05:59:31.337975       1 request.go:601] Waited for 1.078447605s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T05:59:32.338065736Z I0109 05:59:32.338026       1 request.go:601] Waited for 1.598540685s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T06:02:59.853694059Z I0109 06:02:59.853659       1 request.go:601] Waited for 1.105726364s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2023-01-09T06:03:00.854011359Z I0109 06:03:00.853948       1 request.go:601] Waited for 1.197637651s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/client-ca
2023-01-09T06:03:01.594250227Z I0109 06:03:01.594192       1 externalloadbalancer.go:27] syncing external loadbalancer hostnames: api.sn-loggvls-jsm.qe.devcluster.openshift.com
2023-01-09T06:03:02.454005572Z I0109 06:03:02.453951       1 request.go:601] Waited for 1.043172971s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T06:03:03.135820039Z I0109 06:03:03.135741       1 servicehostname.go:40] syncing servicenetwork hostnames: [172.30.0.1 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local openshift openshift.default openshift.default.svc openshift.default.svc.cluster.local]
2023-01-09T06:03:03.454444606Z I0109 06:03:03.454402       1 request.go:601] Waited for 1.857992436s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T06:03:04.653980418Z I0109 06:03:04.653931       1 request.go:601] Waited for 1.79518851s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver
2023-01-09T06:03:05.854172403Z I0109 06:03:05.854126       1 request.go:601] Waited for 1.395786816s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T06:03:07.853897114Z I0109 06:03:07.853856       1 request.go:601] Waited for 1.195162755s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T06:05:11.600166440Z E0109 06:05:11.600125       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T06:05:12.606313116Z E0109 06:05:12.606271       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T06:05:15.838920166Z I0109 06:05:15.838881       1 request.go:601] Waited for 1.074620232s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T06:05:16.839207858Z I0109 06:05:16.839171       1 request.go:601] Waited for 1.597651136s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T06:05:18.039295488Z I0109 06:05:18.039252       1 request.go:601] Waited for 1.378906622s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T06:05:19.238296376Z I0109 06:05:19.238253       1 request.go:601] Waited for 1.397054689s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T06:08:04.003954748Z E0109 06:08:04.003916       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T06:08:05.010244261Z E0109 06:08:05.010205       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T06:08:08.246399657Z I0109 06:08:08.246362       1 request.go:601] Waited for 1.076182991s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2023-01-09T06:08:09.446099651Z I0109 06:08:09.446056       1 request.go:601] Waited for 1.59540247s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/client-ca
2023-01-09T06:08:10.646502662Z I0109 06:08:10.646456       1 request.go:601] Waited for 1.197871081s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-server-ca
2023-01-09T06:10:56.260277574Z E0109 06:10:56.260236       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T06:10:57.266764886Z E0109 06:10:57.266718       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T06:11:00.499674250Z I0109 06:11:00.499633       1 request.go:601] Waited for 1.055351344s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T06:11:01.500252278Z I0109 06:11:01.500214       1 request.go:601] Waited for 1.594963608s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-pod
2023-01-09T06:12:59.730106102Z I0109 06:12:59.730063       1 request.go:601] Waited for 1.108310251s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T06:13:00.730332563Z I0109 06:13:00.730282       1 request.go:601] Waited for 1.190443102s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T06:13:01.595291168Z I0109 06:13:01.595244       1 externalloadbalancer.go:27] syncing external loadbalancer hostnames: api.sn-loggvls-jsm.qe.devcluster.openshift.com
2023-01-09T06:13:02.530376444Z I0109 06:13:02.530333       1 request.go:601] Waited for 1.118938989s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T06:13:03.136727564Z I0109 06:13:03.136651       1 servicehostname.go:40] syncing servicenetwork hostnames: [172.30.0.1 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local openshift openshift.default openshift.default.svc openshift.default.svc.cluster.local]
2023-01-09T06:13:03.730405618Z I0109 06:13:03.730362       1 request.go:601] Waited for 1.991812749s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T06:13:04.929649378Z I0109 06:13:04.929605       1 request.go:601] Waited for 1.793894868s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T06:13:06.129700922Z I0109 06:13:06.129657       1 request.go:601] Waited for 1.395561521s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T06:13:07.730395281Z I0109 06:13:07.730350       1 request.go:601] Waited for 1.047315855s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T06:13:18.530165519Z I0109 06:13:18.530127       1 request.go:601] Waited for 1.122365381s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2023-01-09T06:13:48.441630233Z E0109 06:13:48.441591       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T06:13:49.447451961Z E0109 06:13:49.447411       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T06:13:52.683900916Z I0109 06:13:52.683863       1 request.go:601] Waited for 1.082198371s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T06:13:53.684021258Z I0109 06:13:53.683976       1 request.go:601] Waited for 1.595294923s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T06:16:40.651240741Z E0109 06:16:40.651200       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T06:16:41.657488051Z E0109 06:16:41.657445       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T06:16:44.870173398Z I0109 06:16:44.870135       1 request.go:601] Waited for 1.176902671s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T06:16:45.870344196Z I0109 06:16:45.870299       1 request.go:601] Waited for 1.586672015s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2023-01-09T06:16:46.870752462Z I0109 06:16:46.870710       1 request.go:601] Waited for 1.595751435s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/localhost-recovery-client-token
2023-01-09T06:16:48.070760208Z I0109 06:16:48.070713       1 request.go:601] Waited for 1.193936171s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/config
2023-01-09T06:16:49.270088220Z I0109 06:16:49.270051       1 request.go:601] Waited for 1.19498419s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-pod
2023-01-09T06:19:32.878793795Z E0109 06:19:32.878756       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T06:19:33.884756660Z E0109 06:19:33.884712       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T06:19:37.121590442Z I0109 06:19:37.121546       1 request.go:601] Waited for 1.071544818s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2023-01-09T06:19:38.321735828Z I0109 06:19:38.321694       1 request.go:601] Waited for 1.594491368s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T06:19:39.521487543Z I0109 06:19:39.521434       1 request.go:601] Waited for 1.19691717s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T06:22:25.257138801Z E0109 06:22:25.257093       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T06:22:26.263311100Z E0109 06:22:26.263269       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T06:22:29.500396460Z I0109 06:22:29.500347       1 request.go:601] Waited for 1.061714738s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T06:22:30.699643032Z I0109 06:22:30.699600       1 request.go:601] Waited for 1.595928933s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-8-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T06:22:59.716184159Z I0109 06:22:59.716141       1 request.go:601] Waited for 1.091467791s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T06:23:00.916314428Z I0109 06:23:00.916274       1 request.go:601] Waited for 1.197169587s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T06:23:01.596232205Z I0109 06:23:01.596183       1 externalloadbalancer.go:27] syncing external loadbalancer hostnames: api.sn-loggvls-jsm.qe.devcluster.openshift.com
2023-01-09T06:23:02.515726536Z I0109 06:23:02.515678       1 request.go:601] Waited for 1.103817564s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T06:23:03.137374027Z I0109 06:23:03.137306       1 servicehostname.go:40] syncing servicenetwork hostnames: [172.30.0.1 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local openshift openshift.default openshift.default.svc openshift.default.svc.cluster.local]
2023-01-09T06:23:03.715691723Z I0109 06:23:03.715651       1 request.go:601] Waited for 1.991221766s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T06:23:04.715895535Z I0109 06:23:04.715857       1 request.go:601] Waited for 1.794708458s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2023-01-09T06:23:05.715956925Z I0109 06:23:05.715915       1 request.go:601] Waited for 1.395588992s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/localhost-recovery-client-token
2023-01-09T06:23:07.916541734Z I0109 06:23:07.916504       1 request.go:601] Waited for 1.196061125s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-pod
2023-01-09T06:23:13.516325743Z I0109 06:23:13.516282       1 request.go:601] Waited for 1.178976046s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/config
2023-01-09T06:23:18.915932997Z I0109 06:23:18.915892       1 request.go:601] Waited for 1.010729216s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T06:25:17.567673692Z E0109 06:25:17.567626       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T06:25:18.574334802Z E0109 06:25:18.574291       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T06:25:21.809564243Z I0109 06:25:21.809518       1 request.go:601] Waited for 1.081613806s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T06:25:22.809690613Z I0109 06:25:22.809652       1 request.go:601] Waited for 1.59737285s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T06:25:23.809885116Z I0109 06:25:23.809820       1 request.go:601] Waited for 1.355912854s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver
2023-01-09T06:28:09.751869971Z E0109 06:28:09.751813       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T06:28:10.758747491Z E0109 06:28:10.758707       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T06:28:13.992884541Z I0109 06:28:13.992846       1 request.go:601] Waited for 1.079348s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T06:28:14.992976845Z I0109 06:28:14.992932       1 request.go:601] Waited for 1.595981135s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T06:28:17.192106982Z I0109 06:28:17.192052       1 request.go:601] Waited for 1.179620857s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2023-01-09T06:28:18.192354427Z I0109 06:28:18.192308       1 request.go:601] Waited for 1.396947883s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T06:28:19.192686403Z I0109 06:28:19.192645       1 request.go:601] Waited for 1.340639171s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver
2023-01-09T06:28:25.592785206Z I0109 06:28:25.592732       1 request.go:601] Waited for 1.042811295s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T06:30:44.548927949Z E0109 06:30:44.548890       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T06:30:45.553499350Z E0109 06:30:45.553460       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T06:30:48.812306639Z I0109 06:30:48.812265       1 request.go:601] Waited for 1.073698765s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2023-01-09T06:30:50.012243418Z I0109 06:30:50.012201       1 request.go:601] Waited for 1.59604594s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-8-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T06:31:02.002007507Z E0109 06:31:02.001952       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T06:31:03.008089553Z E0109 06:31:03.008050       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T06:31:06.060102268Z I0109 06:31:06.060059       1 request.go:601] Waited for 1.006494157s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/config
2023-01-09T06:31:07.260089357Z I0109 06:31:07.260046       1 request.go:601] Waited for 1.595509114s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T06:31:08.459561334Z I0109 06:31:08.459518       1 request.go:601] Waited for 1.391602781s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T06:31:09.460153159Z I0109 06:31:09.460108       1 request.go:601] Waited for 1.196496611s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-8-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T06:32:59.927614606Z I0109 06:32:59.927574       1 request.go:601] Waited for 1.188478306s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2023-01-09T06:33:00.928396569Z I0109 06:33:00.928350       1 request.go:601] Waited for 1.197961855s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-server-ca
2023-01-09T06:33:01.597211831Z I0109 06:33:01.597162       1 externalloadbalancer.go:27] syncing external loadbalancer hostnames: api.sn-loggvls-jsm.qe.devcluster.openshift.com
2023-01-09T06:33:02.528619352Z I0109 06:33:02.528576       1 request.go:601] Waited for 1.115653899s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T06:33:03.138338035Z I0109 06:33:03.138260       1 servicehostname.go:40] syncing servicenetwork hostnames: [172.30.0.1 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local openshift openshift.default openshift.default.svc openshift.default.svc.cluster.local]
2023-01-09T06:33:03.727884105Z I0109 06:33:03.727818       1 request.go:601] Waited for 1.990004038s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2023-01-09T06:33:04.928419678Z I0109 06:33:04.928376       1 request.go:601] Waited for 1.794982358s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T06:33:05.928556650Z I0109 06:33:05.928497       1 request.go:601] Waited for 1.395058797s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T06:33:07.927970136Z I0109 06:33:07.927927       1 request.go:601] Waited for 1.175099896s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T06:33:54.192359040Z E0109 06:33:54.192321       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T06:33:55.198303668Z E0109 06:33:55.198267       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T06:33:58.414396577Z I0109 06:33:58.414360       1 request.go:601] Waited for 1.054219242s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T06:33:59.613438625Z I0109 06:33:59.613392       1 request.go:601] Waited for 1.187437728s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2023-01-09T06:36:46.503259040Z E0109 06:36:46.503223       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T06:36:47.508863761Z E0109 06:36:47.508824       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T06:36:50.742532677Z I0109 06:36:50.742492       1 request.go:601] Waited for 1.069704036s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-8-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T06:36:51.942721455Z I0109 06:36:51.942678       1 request.go:601] Waited for 1.197379773s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-8-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T06:42:30.858316260Z E0109 06:42:30.858275       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T06:42:31.864749494Z E0109 06:42:31.864710       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T06:42:35.108741848Z I0109 06:42:35.108700       1 request.go:601] Waited for 1.095902211s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2023-01-09T06:42:36.109560092Z I0109 06:42:36.109513       1 request.go:601] Waited for 1.57176765s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2023-01-09T06:42:37.909086680Z I0109 06:42:37.909038       1 request.go:601] Waited for 1.122651815s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T06:42:59.928218996Z I0109 06:42:59.928178       1 request.go:601] Waited for 1.189101469s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2023-01-09T06:43:00.928864862Z I0109 06:43:00.928826       1 request.go:601] Waited for 1.198495444s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-server-ca
2023-01-09T06:43:01.597945171Z I0109 06:43:01.597893       1 externalloadbalancer.go:27] syncing external loadbalancer hostnames: api.sn-loggvls-jsm.qe.devcluster.openshift.com
2023-01-09T06:43:02.528966350Z I0109 06:43:02.528924       1 request.go:601] Waited for 1.115382274s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T06:43:03.138975610Z I0109 06:43:03.138909       1 servicehostname.go:40] syncing servicenetwork hostnames: [172.30.0.1 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local openshift openshift.default openshift.default.svc openshift.default.svc.cluster.local]
2023-01-09T06:43:03.728199092Z I0109 06:43:03.728135       1 request.go:601] Waited for 1.992909046s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2023-01-09T06:43:04.728385292Z I0109 06:43:04.728338       1 request.go:601] Waited for 1.792169886s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2023-01-09T06:43:05.728813062Z I0109 06:43:05.728769       1 request.go:601] Waited for 1.498944269s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver
2023-01-09T06:43:07.928224099Z I0109 06:43:07.928175       1 request.go:601] Waited for 1.140575343s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T06:43:10.328462982Z I0109 06:43:10.328421       1 request.go:601] Waited for 1.176922294s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T06:45:23.167843976Z E0109 06:45:23.167797       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T06:45:24.174297265Z E0109 06:45:24.174256       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T06:45:27.360646615Z I0109 06:45:27.360600       1 request.go:601] Waited for 1.025917839s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2023-01-09T06:45:28.559672311Z I0109 06:45:28.559631       1 request.go:601] Waited for 1.569799571s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2023-01-09T06:45:29.560308386Z I0109 06:45:29.560266       1 request.go:601] Waited for 1.19710568s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T06:48:15.507917313Z E0109 06:48:15.507870       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T06:48:16.513786653Z E0109 06:48:16.513750       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T06:48:19.649969125Z I0109 06:48:19.649928       1 request.go:601] Waited for 1.092415668s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/config
2023-01-09T06:48:20.650617760Z I0109 06:48:20.650577       1 request.go:601] Waited for 1.596022324s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver
2023-01-09T06:48:22.450563397Z I0109 06:48:22.450524       1 request.go:601] Waited for 1.076626732s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T06:48:23.650311264Z I0109 06:48:23.650268       1 request.go:601] Waited for 1.397932674s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-server-ca
2023-01-09T06:51:07.641119453Z E0109 06:51:07.641076       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T06:51:08.647508244Z E0109 06:51:08.647470       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T06:51:11.882815611Z I0109 06:51:11.882777       1 request.go:601] Waited for 1.06587001s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T06:51:13.082718638Z I0109 06:51:13.082678       1 request.go:601] Waited for 1.596598424s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-8-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T06:52:59.729448011Z I0109 06:52:59.729405       1 request.go:601] Waited for 1.103042238s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T06:53:00.928601453Z I0109 06:53:00.928563       1 request.go:601] Waited for 1.194067714s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T06:53:01.598359691Z I0109 06:53:01.598307       1 externalloadbalancer.go:27] syncing external loadbalancer hostnames: api.sn-loggvls-jsm.qe.devcluster.openshift.com
2023-01-09T06:53:02.529374604Z I0109 06:53:02.529336       1 request.go:601] Waited for 1.11520345s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T06:53:03.139473579Z I0109 06:53:03.139401       1 servicehostname.go:40] syncing servicenetwork hostnames: [172.30.0.1 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local openshift openshift.default openshift.default.svc openshift.default.svc.cluster.local]
2023-01-09T06:53:03.728899939Z I0109 06:53:03.728848       1 request.go:601] Waited for 1.991994158s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T06:53:04.929152165Z I0109 06:53:04.929108       1 request.go:601] Waited for 1.796493747s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T06:53:05.929234475Z I0109 06:53:05.929189       1 request.go:601] Waited for 1.393739183s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T06:53:07.928757974Z I0109 06:53:07.928717       1 request.go:601] Waited for 1.101771854s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T06:53:08.928784292Z I0109 06:53:08.928743       1 request.go:601] Waited for 1.316004089s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T06:53:10.129106252Z I0109 06:53:10.129066       1 request.go:601] Waited for 1.395902945s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver
2023-01-09T06:53:59.907672604Z E0109 06:53:59.907635       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T06:54:00.913665085Z E0109 06:54:00.913626       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T06:54:04.254860078Z I0109 06:54:04.254813       1 request.go:601] Waited for 1.191561739s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2023-01-09T06:54:05.454097193Z I0109 06:54:05.454053       1 request.go:601] Waited for 1.596071612s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-8-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T06:54:06.454429031Z I0109 06:54:06.454387       1 request.go:601] Waited for 1.092397424s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T06:54:07.854750737Z I0109 06:54:07.854707       1 request.go:601] Waited for 1.018850781s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T06:56:34.675762785Z E0109 06:56:34.675726       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T06:56:35.681600630Z E0109 06:56:35.681541       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T06:56:38.973417494Z I0109 06:56:38.973382       1 request.go:601] Waited for 1.183054843s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-8-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T06:56:39.973523170Z I0109 06:56:39.973473       1 request.go:601] Waited for 1.595226588s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2023-01-09T06:56:41.173283899Z I0109 06:56:41.173233       1 request.go:601] Waited for 1.594358171s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/config
2023-01-09T06:56:42.573147712Z I0109 06:56:42.573113       1 request.go:601] Waited for 1.092211098s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T06:56:52.165073611Z E0109 06:56:52.165034       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T06:56:53.171411720Z E0109 06:56:53.171371       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T06:56:56.408956917Z I0109 06:56:56.408918       1 request.go:601] Waited for 1.077684324s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T06:56:57.409252230Z I0109 06:56:57.409206       1 request.go:601] Waited for 1.597053723s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T06:56:58.608813810Z I0109 06:56:58.608768       1 request.go:601] Waited for 1.196413607s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T06:59:44.402967976Z E0109 06:59:44.402909       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T06:59:45.409245925Z E0109 06:59:45.409199       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T06:59:48.644711301Z I0109 06:59:48.644671       1 request.go:601] Waited for 1.077593929s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2023-01-09T06:59:49.843972992Z I0109 06:59:49.843934       1 request.go:601] Waited for 1.594568784s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-8-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T07:02:36.621157480Z E0109 07:02:36.621114       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T07:02:37.628252728Z E0109 07:02:37.628215       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T07:02:40.849344898Z I0109 07:02:40.849303       1 request.go:601] Waited for 1.08081297s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2023-01-09T07:02:41.849708874Z I0109 07:02:41.849662       1 request.go:601] Waited for 1.566686565s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2023-01-09T07:02:43.049738715Z I0109 07:02:43.049690       1 request.go:601] Waited for 1.393146265s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T07:02:59.664390996Z I0109 07:02:59.664348       1 request.go:601] Waited for 1.035590208s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T07:03:00.864457425Z I0109 07:03:00.864406       1 request.go:601] Waited for 1.197147966s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T07:03:01.599021410Z I0109 07:03:01.598935       1 externalloadbalancer.go:27] syncing external loadbalancer hostnames: api.sn-loggvls-jsm.qe.devcluster.openshift.com
2023-01-09T07:03:02.464045561Z I0109 07:03:02.464003       1 request.go:601] Waited for 1.048814989s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T07:03:03.139618582Z I0109 07:03:03.139533       1 servicehostname.go:40] syncing servicenetwork hostnames: [172.30.0.1 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local openshift openshift.default openshift.default.svc openshift.default.svc.cluster.local]
2023-01-09T07:03:03.464319829Z I0109 07:03:03.464276       1 request.go:601] Waited for 1.863304721s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T07:03:04.664397410Z I0109 07:03:04.664354       1 request.go:601] Waited for 1.796489368s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T07:03:05.664628866Z I0109 07:03:05.664555       1 request.go:601] Waited for 1.335335661s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver
2023-01-09T07:03:07.064597936Z I0109 07:03:07.064554       1 request.go:601] Waited for 1.017857497s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T07:03:08.064612647Z I0109 07:03:08.064562       1 request.go:601] Waited for 1.372605112s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2023-01-09T07:03:09.064611296Z I0109 07:03:09.064566       1 request.go:601] Waited for 1.196880644s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/trusted-ca-bundle
2023-01-09T07:05:28.969235283Z E0109 07:05:28.969194       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T07:05:29.975102939Z E0109 07:05:29.975059       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T07:05:33.200886008Z I0109 07:05:33.200843       1 request.go:601] Waited for 1.074640082s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T07:05:34.201153605Z I0109 07:05:34.201112       1 request.go:601] Waited for 1.594752405s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-8-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T07:08:21.235065508Z E0109 07:08:21.234967       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T07:08:22.241614309Z E0109 07:08:22.241574       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T07:08:25.460561894Z I0109 07:08:25.460525       1 request.go:601] Waited for 1.182560272s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver
2023-01-09T07:08:26.660301139Z I0109 07:08:26.660260       1 request.go:601] Waited for 1.596426209s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T07:08:27.660693678Z I0109 07:08:27.660650       1 request.go:601] Waited for 1.593422942s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2023-01-09T07:08:28.859696432Z I0109 07:08:28.859652       1 request.go:601] Waited for 1.196837472s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/localhost-recovery-client-token
2023-01-09T07:11:13.474127704Z E0109 07:11:13.474083       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T07:11:14.480799379Z E0109 07:11:14.480759       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T07:11:17.636787531Z I0109 07:11:17.636751       1 request.go:601] Waited for 1.009199895s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2023-01-09T07:11:18.836553271Z I0109 07:11:18.836505       1 request.go:601] Waited for 1.595698785s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T07:11:20.036128597Z I0109 07:11:20.036084       1 request.go:601] Waited for 1.356369663s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver
2023-01-09T07:11:21.638095141Z I0109 07:11:21.638039       1 request.go:601] Waited for 1.196224642s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T07:12:59.730522442Z I0109 07:12:59.730478       1 request.go:601] Waited for 1.105036074s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T07:13:00.931072948Z I0109 07:13:00.931030       1 request.go:601] Waited for 1.192461317s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T07:13:01.599793318Z I0109 07:13:01.599742       1 externalloadbalancer.go:27] syncing external loadbalancer hostnames: api.sn-loggvls-jsm.qe.devcluster.openshift.com
2023-01-09T07:13:02.530398510Z I0109 07:13:02.530344       1 request.go:601] Waited for 1.114223733s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T07:13:03.140217762Z I0109 07:13:03.140144       1 servicehostname.go:40] syncing servicenetwork hostnames: [172.30.0.1 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local openshift openshift.default openshift.default.svc openshift.default.svc.cluster.local]
2023-01-09T07:13:03.530679018Z I0109 07:13:03.530636       1 request.go:601] Waited for 1.927762428s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver
2023-01-09T07:13:04.530707424Z I0109 07:13:04.530670       1 request.go:601] Waited for 1.797443723s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T07:13:05.531121009Z I0109 07:13:05.531072       1 request.go:601] Waited for 1.333641792s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver
2023-01-09T07:13:06.730099583Z I0109 07:13:06.730057       1 request.go:601] Waited for 1.596509717s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T07:13:07.930242088Z I0109 07:13:07.930199       1 request.go:601] Waited for 1.039252154s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T07:13:08.930397506Z I0109 07:13:08.930344       1 request.go:601] Waited for 1.196759746s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T07:14:05.786040522Z E0109 07:14:05.785971       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T07:14:06.792334841Z E0109 07:14:06.792297       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T07:14:10.023660957Z I0109 07:14:10.023618       1 request.go:601] Waited for 1.081108177s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2023-01-09T07:14:11.023923818Z I0109 07:14:11.023879       1 request.go:601] Waited for 1.597355786s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T07:14:13.823468137Z I0109 07:14:13.823426       1 request.go:601] Waited for 1.015930545s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T07:14:18.623485768Z I0109 07:14:18.623445       1 request.go:601] Waited for 1.179679565s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2023-01-09T07:14:19.623786641Z I0109 07:14:19.623739       1 request.go:601] Waited for 1.19782188s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/trusted-ca-bundle
2023-01-09T07:16:58.184300406Z E0109 07:16:58.184257       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T07:16:59.190916513Z E0109 07:16:59.190877       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T07:17:02.289437068Z I0109 07:17:02.289396       1 request.go:601] Waited for 1.060570239s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver
2023-01-09T07:17:03.489630955Z I0109 07:17:03.489587       1 request.go:601] Waited for 1.594192706s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T07:17:05.490040829Z I0109 07:17:05.489980       1 request.go:601] Waited for 1.058859834s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T07:17:08.090031194Z I0109 07:17:08.089967       1 request.go:601] Waited for 1.183464121s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T07:19:50.304793506Z E0109 07:19:50.304757       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T07:19:51.311253795Z E0109 07:19:51.311215       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T07:19:54.533505235Z I0109 07:19:54.533467       1 request.go:601] Waited for 1.070807407s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T07:19:55.733155374Z I0109 07:19:55.733116       1 request.go:601] Waited for 1.595326194s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/client-ca
2023-01-09T07:19:57.933446018Z I0109 07:19:57.933408       1 request.go:601] Waited for 1.01586217s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T07:22:42.525325479Z E0109 07:22:42.525283       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T07:22:43.530980021Z E0109 07:22:43.530939       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T07:22:46.761614530Z I0109 07:22:46.761576       1 request.go:601] Waited for 1.072631738s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-8-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T07:22:47.762579011Z I0109 07:22:47.762535       1 request.go:601] Waited for 1.569095772s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2023-01-09T07:22:48.962549283Z I0109 07:22:48.962510       1 request.go:601] Waited for 1.152638188s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver
2023-01-09T07:22:59.762333270Z I0109 07:22:59.762289       1 request.go:601] Waited for 1.135828294s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T07:23:00.962303602Z I0109 07:23:00.962255       1 request.go:601] Waited for 1.196560474s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T07:23:01.600254644Z I0109 07:23:01.600198       1 externalloadbalancer.go:27] syncing external loadbalancer hostnames: api.sn-loggvls-jsm.qe.devcluster.openshift.com
2023-01-09T07:23:02.562472096Z I0109 07:23:02.562428       1 request.go:601] Waited for 1.145498905s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T07:23:03.141201435Z I0109 07:23:03.141122       1 servicehostname.go:40] syncing servicenetwork hostnames: [172.30.0.1 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local openshift openshift.default openshift.default.svc openshift.default.svc.cluster.local]
2023-01-09T07:23:03.761789378Z I0109 07:23:03.761740       1 request.go:601] Waited for 1.989332778s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T07:23:04.762170451Z I0109 07:23:04.762121       1 request.go:601] Waited for 1.811104217s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T07:23:05.962505010Z I0109 07:23:05.962448       1 request.go:601] Waited for 1.791975933s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2023-01-09T07:23:07.962500489Z I0109 07:23:07.962460       1 request.go:601] Waited for 1.03290252s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T07:25:34.898056657Z E0109 07:25:34.898017       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T07:25:35.905268441Z E0109 07:25:35.905224       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T07:25:39.141168813Z I0109 07:25:39.141125       1 request.go:601] Waited for 1.074708247s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T07:25:40.341166028Z I0109 07:25:40.341123       1 request.go:601] Waited for 1.59647451s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T07:25:41.541589597Z I0109 07:25:41.541551       1 request.go:601] Waited for 1.397505793s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-server-ca
2023-01-09T07:28:27.073565440Z E0109 07:28:27.073525       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T07:28:28.080233073Z E0109 07:28:28.080190       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T07:28:31.316088576Z I0109 07:28:31.316046       1 request.go:601] Waited for 1.084183332s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T07:28:32.515562400Z I0109 07:28:32.515518       1 request.go:601] Waited for 1.594927086s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-pod
2023-01-09T07:31:00.816067603Z E0109 07:31:00.816027       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T07:31:01.822071189Z E0109 07:31:01.822026       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T07:31:05.057648352Z I0109 07:31:05.057605       1 request.go:601] Waited for 1.076474403s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T07:31:06.058021367Z I0109 07:31:06.057971       1 request.go:601] Waited for 1.594991737s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-8-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T07:31:08.058630114Z I0109 07:31:08.058586       1 request.go:601] Waited for 1.103268156s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T07:32:59.732100547Z I0109 07:32:59.732053       1 request.go:601] Waited for 1.104697031s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T07:33:00.931392744Z I0109 07:33:00.931348       1 request.go:601] Waited for 1.194394519s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T07:33:01.600729476Z I0109 07:33:01.600677       1 externalloadbalancer.go:27] syncing external loadbalancer hostnames: api.sn-loggvls-jsm.qe.devcluster.openshift.com
2023-01-09T07:33:02.532292185Z I0109 07:33:02.532244       1 request.go:601] Waited for 1.181110764s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T07:33:03.141709477Z I0109 07:33:03.141624       1 servicehostname.go:40] syncing servicenetwork hostnames: [172.30.0.1 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local openshift openshift.default openshift.default.svc openshift.default.svc.cluster.local]
2023-01-09T07:33:03.731855391Z I0109 07:33:03.731813       1 request.go:601] Waited for 1.991984878s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T07:33:04.931882878Z I0109 07:33:04.931840       1 request.go:601] Waited for 1.995963446s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2023-01-09T07:33:05.932057317Z I0109 07:33:05.931981       1 request.go:601] Waited for 1.593024089s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/config
2023-01-09T07:33:08.131698894Z I0109 07:33:08.131655       1 request.go:601] Waited for 1.17066702s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T07:34:11.688600116Z E0109 07:34:11.688544       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T07:34:12.694894137Z E0109 07:34:12.694854       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T07:34:15.931929326Z I0109 07:34:15.931888       1 request.go:601] Waited for 1.06576678s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T07:34:17.131756332Z I0109 07:34:17.131717       1 request.go:601] Waited for 1.596214159s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-8-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T07:34:18.132090956Z I0109 07:34:18.132048       1 request.go:601] Waited for 1.197941493s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T07:34:19.332167832Z I0109 07:34:19.332125       1 request.go:601] Waited for 1.397608549s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-server-ca
2023-01-09T07:34:20.531523985Z I0109 07:34:20.531472       1 request.go:601] Waited for 1.12156659s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T07:37:03.967299269Z E0109 07:37:03.967258       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T07:37:04.972958188Z E0109 07:37:04.972919       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T07:37:08.172699464Z I0109 07:37:08.172656       1 request.go:601] Waited for 1.026117079s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2023-01-09T07:37:09.172778587Z I0109 07:37:09.172736       1 request.go:601] Waited for 1.597992435s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T07:39:56.247115381Z E0109 07:39:56.247073       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T07:39:57.254111864Z E0109 07:39:57.254072       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T07:40:00.321899757Z I0109 07:40:00.321860       1 request.go:601] Waited for 1.036947267s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-8-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T07:40:01.521272586Z I0109 07:40:01.521222       1 request.go:601] Waited for 1.587473184s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2023-01-09T07:40:04.721608255Z I0109 07:40:04.721565       1 request.go:601] Waited for 1.165554583s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2023-01-09T07:42:59.933257612Z I0109 07:42:59.933211       1 request.go:601] Waited for 1.193640983s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-pod
2023-01-09T07:43:00.933547500Z I0109 07:43:00.933504       1 request.go:601] Waited for 1.151927006s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver
2023-01-09T07:43:01.601366346Z I0109 07:43:01.601319       1 externalloadbalancer.go:27] syncing external loadbalancer hostnames: api.sn-loggvls-jsm.qe.devcluster.openshift.com
2023-01-09T07:43:02.133610518Z I0109 07:43:02.133558       1 request.go:601] Waited for 1.13234081s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2023-01-09T07:43:03.142384574Z I0109 07:43:03.142319       1 servicehostname.go:40] syncing servicenetwork hostnames: [172.30.0.1 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local openshift openshift.default openshift.default.svc openshift.default.svc.cluster.local]
2023-01-09T07:43:03.333632400Z I0109 07:43:03.333583       1 request.go:601] Waited for 1.73103603s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T07:43:04.533550267Z I0109 07:43:04.533505       1 request.go:601] Waited for 1.997232963s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T07:43:05.733164864Z I0109 07:43:05.733114       1 request.go:601] Waited for 1.711660487s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver
2023-01-09T07:43:06.933527279Z I0109 07:43:06.933475       1 request.go:601] Waited for 1.19548355s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver
2023-01-09T07:43:08.132907833Z I0109 07:43:08.132867       1 request.go:601] Waited for 1.141503145s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T07:48:32.839975312Z E0109 07:48:32.839937       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T07:48:33.846283176Z E0109 07:48:33.846245       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T07:48:37.080408834Z I0109 07:48:37.080365       1 request.go:601] Waited for 1.0803077s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T07:48:38.280084158Z I0109 07:48:38.280043       1 request.go:601] Waited for 1.595786527s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T07:48:39.280759375Z I0109 07:48:39.280717       1 request.go:601] Waited for 1.181799727s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T07:48:40.480090289Z I0109 07:48:40.480047       1 request.go:601] Waited for 1.397561544s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-server-ca
2023-01-09T07:51:25.155194108Z E0109 07:51:25.155159       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T07:51:26.161798806Z E0109 07:51:26.161759       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T07:51:29.394880775Z I0109 07:51:29.394835       1 request.go:601] Waited for 1.074587309s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T07:51:30.395183532Z I0109 07:51:30.395137       1 request.go:601] Waited for 1.596180765s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-8-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T07:52:59.533971438Z I0109 07:52:59.533934       1 request.go:601] Waited for 1.130695428s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T07:53:00.734293128Z I0109 07:53:00.734252       1 request.go:601] Waited for 1.197170844s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T07:53:01.601922269Z I0109 07:53:01.601875       1 externalloadbalancer.go:27] syncing external loadbalancer hostnames: api.sn-loggvls-jsm.qe.devcluster.openshift.com
2023-01-09T07:53:02.533465231Z I0109 07:53:02.533425       1 request.go:601] Waited for 1.114758551s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T07:53:03.143225803Z I0109 07:53:03.143159       1 servicehostname.go:40] syncing servicenetwork hostnames: [172.30.0.1 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local openshift openshift.default openshift.default.svc openshift.default.svc.cluster.local]
2023-01-09T07:53:03.533775242Z I0109 07:53:03.533732       1 request.go:601] Waited for 1.930752831s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T07:53:04.733831703Z I0109 07:53:04.733791       1 request.go:601] Waited for 1.79281771s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver
2023-01-09T07:53:05.734170821Z I0109 07:53:05.734122       1 request.go:601] Waited for 1.488667393s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver
2023-01-09T07:53:06.933727632Z I0109 07:53:06.933689       1 request.go:601] Waited for 1.195135678s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver
2023-01-09T07:53:08.134124300Z I0109 07:53:08.134078       1 request.go:601] Waited for 1.105229556s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T07:54:17.528536982Z E0109 07:54:17.528497       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T07:54:18.535396336Z E0109 07:54:18.535356       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T07:54:21.657169095Z I0109 07:54:21.657129       1 request.go:601] Waited for 1.084985309s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T07:54:22.657739868Z I0109 07:54:22.657697       1 request.go:601] Waited for 1.597708824s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-8-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T07:54:23.857119941Z I0109 07:54:23.857078       1 request.go:601] Waited for 1.554144245s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver
2023-01-09T07:54:25.057551669Z I0109 07:54:25.057503       1 request.go:601] Waited for 1.197034854s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver
2023-01-09T07:57:09.561226688Z E0109 07:57:09.561188       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T07:57:10.567404437Z E0109 07:57:10.567361       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T07:57:13.801982295Z I0109 07:57:13.801940       1 request.go:601] Waited for 1.068868119s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2023-01-09T07:57:15.002428826Z I0109 07:57:15.002374       1 request.go:601] Waited for 1.558981175s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2023-01-09T07:57:17.202216951Z I0109 07:57:17.202167       1 request.go:601] Waited for 1.143389235s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2023-01-09T07:57:18.202694818Z I0109 07:57:18.202655       1 request.go:601] Waited for 1.15942756s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T07:57:19.401896515Z I0109 07:57:19.401854       1 request.go:601] Waited for 1.356359623s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver
2023-01-09T07:57:20.402549956Z I0109 07:57:20.402510       1 request.go:601] Waited for 1.196853288s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T08:00:01.815396536Z E0109 08:00:01.815357       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T08:00:02.822069609Z E0109 08:00:02.822024       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T08:00:06.059759370Z I0109 08:00:06.059710       1 request.go:601] Waited for 1.061324035s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T08:00:07.059844982Z I0109 08:00:07.059802       1 request.go:601] Waited for 1.593903739s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-8-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T08:00:08.259376307Z I0109 08:00:08.259329       1 request.go:601] Waited for 1.196468564s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-8-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T08:00:09.459540463Z I0109 08:00:09.459498       1 request.go:601] Waited for 1.140966207s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T08:02:54.102287661Z E0109 08:02:54.102245       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T08:02:55.108268468Z E0109 08:02:55.108226       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T08:02:58.334500651Z I0109 08:02:58.334436       1 request.go:601] Waited for 1.18229441s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T08:02:59.334619018Z I0109 08:02:59.334579       1 request.go:601] Waited for 1.593923407s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/config
2023-01-09T08:03:00.335388301Z I0109 08:03:00.335350       1 request.go:601] Waited for 1.795775356s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T08:03:01.534773112Z I0109 08:03:01.534725       1 request.go:601] Waited for 1.790373705s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T08:03:01.602455076Z I0109 08:03:01.602409       1 externalloadbalancer.go:27] syncing external loadbalancer hostnames: api.sn-loggvls-jsm.qe.devcluster.openshift.com
2023-01-09T08:03:02.535272739Z I0109 08:03:02.535226       1 request.go:601] Waited for 1.771453177s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2023-01-09T08:03:03.144280713Z I0109 08:03:03.144211       1 servicehostname.go:40] syncing servicenetwork hostnames: [172.30.0.1 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local openshift openshift.default openshift.default.svc openshift.default.svc.cluster.local]
2023-01-09T08:03:03.734695330Z I0109 08:03:03.734652       1 request.go:601] Waited for 2.130675884s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2023-01-09T08:03:04.735029021Z I0109 08:03:04.734966       1 request.go:601] Waited for 2.154289011s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver
2023-01-09T08:03:05.735083340Z I0109 08:03:05.735042       1 request.go:601] Waited for 1.995852848s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2023-01-09T08:03:06.735176943Z I0109 08:03:06.735121       1 request.go:601] Waited for 1.796946112s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/trusted-ca-bundle
2023-01-09T08:03:07.934652362Z I0109 08:03:07.934596       1 request.go:601] Waited for 1.191844154s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2023-01-09T08:05:46.365697204Z E0109 08:05:46.365664       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T08:05:47.373026240Z E0109 08:05:47.372976       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T08:05:50.607786343Z I0109 08:05:50.607738       1 request.go:601] Waited for 1.076053161s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T08:05:51.807421741Z I0109 08:05:51.807377       1 request.go:601] Waited for 1.596269213s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/client-ca
2023-01-09T08:08:38.599820500Z E0109 08:08:38.599782       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T08:08:39.606440633Z E0109 08:08:39.606400       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T08:08:42.790083417Z I0109 08:08:42.790044       1 request.go:601] Waited for 1.017743622s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2023-01-09T08:08:43.790154965Z I0109 08:08:43.790116       1 request.go:601] Waited for 1.595739127s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-pod
2023-01-09T08:11:30.905298381Z E0109 08:11:30.905255       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T08:11:31.911559575Z E0109 08:11:31.911519       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T08:11:35.137165977Z I0109 08:11:35.137126       1 request.go:601] Waited for 1.080734216s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2023-01-09T08:11:36.137748190Z I0109 08:11:36.137703       1 request.go:601] Waited for 1.595374243s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-8-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T08:11:38.137088203Z I0109 08:11:38.137048       1 request.go:601] Waited for 1.031390063s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T08:11:39.137212652Z I0109 08:11:39.137166       1 request.go:601] Waited for 1.395685926s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T08:12:59.659685270Z I0109 08:12:59.659643       1 request.go:601] Waited for 1.030084856s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T08:13:00.860512876Z I0109 08:13:00.860459       1 request.go:601] Waited for 1.197881793s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T08:13:01.602534753Z I0109 08:13:01.602485       1 externalloadbalancer.go:27] syncing external loadbalancer hostnames: api.sn-loggvls-jsm.qe.devcluster.openshift.com
2023-01-09T08:13:02.460056313Z I0109 08:13:02.459959       1 request.go:601] Waited for 1.04006422s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T08:13:03.144614140Z I0109 08:13:03.144539       1 servicehostname.go:40] syncing servicenetwork hostnames: [172.30.0.1 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local openshift openshift.default openshift.default.svc openshift.default.svc.cluster.local]
2023-01-09T08:13:03.659903127Z I0109 08:13:03.659856       1 request.go:601] Waited for 1.991362633s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T08:13:04.859740661Z I0109 08:13:04.859699       1 request.go:601] Waited for 1.792135859s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver
2023-01-09T08:13:05.860531462Z I0109 08:13:05.860487       1 request.go:601] Waited for 1.379943207s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T08:13:08.259977821Z I0109 08:13:08.259934       1 request.go:601] Waited for 1.149461565s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T08:13:09.260025465Z I0109 08:13:09.259965       1 request.go:601] Waited for 1.196420705s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T08:14:23.231091222Z E0109 08:14:23.231050       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T08:14:24.238002326Z E0109 08:14:24.237942       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T08:14:27.472957730Z I0109 08:14:27.472917       1 request.go:601] Waited for 1.075877259s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T08:14:28.473698285Z I0109 08:14:28.473651       1 request.go:601] Waited for 1.597323519s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-8-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T08:14:29.673062730Z I0109 08:14:29.673006       1 request.go:601] Waited for 1.195440613s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-8-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T08:20:07.745391404Z E0109 08:20:07.745347       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T08:20:08.752058232Z E0109 08:20:08.751977       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T08:20:11.983300294Z I0109 08:20:11.983260       1 request.go:601] Waited for 1.075737439s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2023-01-09T08:20:13.183649576Z I0109 08:20:13.183607       1 request.go:601] Waited for 1.595724241s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-8-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T08:20:18.583262800Z I0109 08:20:18.583215       1 request.go:601] Waited for 1.002679355s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver
2023-01-09T08:22:59.687985813Z I0109 08:22:59.687951       1 request.go:601] Waited for 1.057506972s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T08:23:00.887781845Z I0109 08:23:00.887743       1 request.go:601] Waited for 1.194824002s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T08:23:01.604275404Z I0109 08:23:01.604228       1 externalloadbalancer.go:27] syncing external loadbalancer hostnames: api.sn-loggvls-jsm.qe.devcluster.openshift.com
2023-01-09T08:23:02.487166693Z I0109 08:23:02.487124       1 request.go:601] Waited for 1.066350863s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T08:23:03.145543949Z I0109 08:23:03.145470       1 servicehostname.go:40] syncing servicenetwork hostnames: [172.30.0.1 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local openshift openshift.default openshift.default.svc openshift.default.svc.cluster.local]
2023-01-09T08:23:03.488008606Z I0109 08:23:03.487942       1 request.go:601] Waited for 1.882424391s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver
2023-01-09T08:23:04.687403932Z I0109 08:23:04.687359       1 request.go:601] Waited for 1.796800196s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T08:23:05.687840326Z I0109 08:23:05.687788       1 request.go:601] Waited for 1.381867037s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T08:23:08.287469180Z I0109 08:23:08.287427       1 request.go:601] Waited for 1.13821874s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T08:23:09.287487231Z I0109 08:23:09.287447       1 request.go:601] Waited for 1.197175008s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T08:25:52.240654779Z E0109 08:25:52.240615       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T08:25:53.246735716Z E0109 08:25:53.246695       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T08:25:56.483206363Z I0109 08:25:56.483158       1 request.go:601] Waited for 1.079222669s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T08:25:57.682462866Z I0109 08:25:57.682413       1 request.go:601] Waited for 1.597274857s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/client-ca
2023-01-09T08:25:58.682499762Z I0109 08:25:58.682455       1 request.go:601] Waited for 1.396861365s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T08:25:59.683406145Z I0109 08:25:59.683360       1 request.go:601] Waited for 1.196941656s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver
2023-01-09T08:28:44.539080812Z E0109 08:28:44.530391       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T08:28:45.545906954Z E0109 08:28:45.545864       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T08:28:48.782181337Z I0109 08:28:48.782133       1 request.go:601] Waited for 1.07294326s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T08:28:49.982222457Z I0109 08:28:49.982178       1 request.go:601] Waited for 1.597165563s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-8-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T08:32:59.736902462Z I0109 08:32:59.736861       1 request.go:601] Waited for 1.105666324s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T08:33:00.936300070Z I0109 08:33:00.936255       1 request.go:601] Waited for 1.196515638s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T08:33:01.604822032Z I0109 08:33:01.604775       1 externalloadbalancer.go:27] syncing external loadbalancer hostnames: api.sn-loggvls-jsm.qe.devcluster.openshift.com
2023-01-09T08:33:02.536643387Z I0109 08:33:02.536593       1 request.go:601] Waited for 1.115074377s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T08:33:03.146281550Z I0109 08:33:03.146209       1 servicehostname.go:40] syncing servicenetwork hostnames: [172.30.0.1 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local openshift openshift.default openshift.default.svc openshift.default.svc.cluster.local]
2023-01-09T08:33:03.536757840Z I0109 08:33:03.536718       1 request.go:601] Waited for 1.930617912s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T08:33:04.736474359Z I0109 08:33:04.736430       1 request.go:601] Waited for 1.797532907s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T08:33:05.737094635Z I0109 08:33:05.737046       1 request.go:601] Waited for 1.597263709s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T08:33:08.336960737Z I0109 08:33:08.336918       1 request.go:601] Waited for 1.15249535s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T08:34:28.967370632Z E0109 08:34:28.967332       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T08:34:29.973354556Z E0109 08:34:29.973315       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T08:34:33.207695281Z I0109 08:34:33.207657       1 request.go:601] Waited for 1.080194262s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2023-01-09T08:34:34.407421605Z I0109 08:34:34.407372       1 request.go:601] Waited for 1.596883021s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/client-ca
2023-01-09T08:34:37.407924383Z I0109 08:34:37.407879       1 request.go:601] Waited for 1.176775574s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T08:40:13.655797439Z E0109 08:40:13.655756       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T08:40:14.661684366Z E0109 08:40:14.661632       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T08:40:17.874816430Z I0109 08:40:17.874777       1 request.go:601] Waited for 1.178186307s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T08:40:19.074831058Z I0109 08:40:19.074780       1 request.go:601] Waited for 1.593169183s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2023-01-09T08:40:20.075197007Z I0109 08:40:20.075155       1 request.go:601] Waited for 1.594019128s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/config
2023-01-09T08:40:21.275081955Z I0109 08:40:21.275036       1 request.go:601] Waited for 1.195548712s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-pod
2023-01-09T08:40:22.474763407Z I0109 08:40:22.474718       1 request.go:601] Waited for 1.197119262s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/client-ca
2023-01-09T08:42:59.824739239Z I0109 08:42:59.824697       1 request.go:601] Waited for 1.192444757s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T08:43:01.024150617Z I0109 08:43:01.024106       1 request.go:601] Waited for 1.196216482s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T08:43:01.605847368Z I0109 08:43:01.605790       1 externalloadbalancer.go:27] syncing external loadbalancer hostnames: api.sn-loggvls-jsm.qe.devcluster.openshift.com
2023-01-09T08:43:02.024275092Z I0109 08:43:02.024238       1 request.go:601] Waited for 1.019783712s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2023-01-09T08:43:03.147167752Z I0109 08:43:03.147098       1 servicehostname.go:40] syncing servicenetwork hostnames: [172.30.0.1 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local openshift openshift.default openshift.default.svc openshift.default.svc.cluster.local]
2023-01-09T08:43:03.224339019Z I0109 08:43:03.224294       1 request.go:601] Waited for 1.617791496s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T08:43:04.424105004Z I0109 08:43:04.424054       1 request.go:601] Waited for 1.764841182s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2023-01-09T08:43:05.624702387Z I0109 08:43:05.624653       1 request.go:601] Waited for 1.391078365s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-pod
2023-01-09T08:43:05.797509986Z E0109 08:43:05.797471       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T08:43:06.803365279Z E0109 08:43:06.803318       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T08:43:08.224152811Z I0109 08:43:08.224111       1 request.go:601] Waited for 1.002516297s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T08:43:10.024353185Z I0109 08:43:10.024309       1 request.go:601] Waited for 1.184234647s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T08:43:11.024578701Z I0109 08:43:11.024532       1 request.go:601] Waited for 1.79545994s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T08:43:12.224479767Z I0109 08:43:12.224442       1 request.go:601] Waited for 1.797154438s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-8-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T08:43:13.424491227Z I0109 08:43:13.424447       1 request.go:601] Waited for 1.197297081s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-8-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T08:43:17.624697235Z I0109 08:43:17.624655       1 request.go:601] Waited for 1.019073947s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T08:43:18.823764307Z I0109 08:43:18.823712       1 request.go:601] Waited for 1.333166776s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2023-01-09T08:43:19.824452814Z I0109 08:43:19.824411       1 request.go:601] Waited for 1.171819549s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2023-01-09T08:45:58.207258153Z E0109 08:45:58.206249       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T08:45:59.212922411Z E0109 08:45:59.212884       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T08:46:02.434637572Z I0109 08:46:02.434591       1 request.go:601] Waited for 1.07581629s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T08:46:03.634486688Z I0109 08:46:03.634435       1 request.go:601] Waited for 1.753801862s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T08:46:04.634905448Z I0109 08:46:04.634863       1 request.go:601] Waited for 1.197787375s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T08:46:05.834317544Z I0109 08:46:05.834275       1 request.go:601] Waited for 1.196203138s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T08:46:06.834960167Z I0109 08:46:06.834915       1 request.go:601] Waited for 1.197453521s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-8-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T08:48:50.329330293Z E0109 08:48:50.329284       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T08:48:51.335584486Z E0109 08:48:51.335541       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T08:48:54.562688050Z I0109 08:48:54.562649       1 request.go:601] Waited for 1.07332116s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2023-01-09T08:48:55.563399295Z I0109 08:48:55.563355       1 request.go:601] Waited for 1.597505313s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-8-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T08:48:56.563540411Z I0109 08:48:56.563496       1 request.go:601] Waited for 1.397174765s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T08:48:58.363305235Z I0109 08:48:58.363261       1 request.go:601] Waited for 1.120750829s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T08:51:42.580821998Z E0109 08:51:42.580783       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T08:51:43.586722761Z E0109 08:51:43.586685       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T08:51:46.821289412Z I0109 08:51:46.821251       1 request.go:601] Waited for 1.074255895s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T08:51:47.821943651Z I0109 08:51:47.821898       1 request.go:601] Waited for 1.596820241s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T08:51:49.022080404Z I0109 08:51:49.022040       1 request.go:601] Waited for 1.194888795s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T08:52:59.762925167Z I0109 08:52:59.762883       1 request.go:601] Waited for 1.129610711s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T08:53:00.763346406Z I0109 08:53:00.763307       1 request.go:601] Waited for 1.197687216s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T08:53:01.606757436Z I0109 08:53:01.606692       1 externalloadbalancer.go:27] syncing external loadbalancer hostnames: api.sn-loggvls-jsm.qe.devcluster.openshift.com
2023-01-09T08:53:02.563020263Z I0109 08:53:02.562962       1 request.go:601] Waited for 1.136919716s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T08:53:03.147773921Z I0109 08:53:03.147688       1 servicehostname.go:40] syncing servicenetwork hostnames: [172.30.0.1 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local openshift openshift.default openshift.default.svc openshift.default.svc.cluster.local]
2023-01-09T08:53:03.563176483Z I0109 08:53:03.563129       1 request.go:601] Waited for 1.955068417s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T08:53:04.763191623Z I0109 08:53:04.763144       1 request.go:601] Waited for 1.795851055s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T08:53:05.763349869Z I0109 08:53:05.763308       1 request.go:601] Waited for 1.333824684s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver
2023-01-09T08:53:08.363264831Z I0109 08:53:08.363223       1 request.go:601] Waited for 1.103692298s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T08:54:34.761473556Z E0109 08:54:34.761424       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T08:54:35.768292795Z E0109 08:54:35.768239       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T08:54:39.009187255Z I0109 08:54:39.009135       1 request.go:601] Waited for 1.064825779s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T08:54:40.209166529Z I0109 08:54:40.209125       1 request.go:601] Waited for 1.594754418s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/client-ca
2023-01-09T08:54:41.209349090Z I0109 08:54:41.209304       1 request.go:601] Waited for 1.196587809s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-8-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T08:57:27.048761183Z E0109 08:57:27.048719       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T08:57:28.055548350Z E0109 08:57:28.055506       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T08:57:31.291143652Z I0109 08:57:31.291107       1 request.go:601] Waited for 1.082150575s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2023-01-09T08:57:32.490486724Z I0109 08:57:32.490441       1 request.go:601] Waited for 1.593927848s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T09:00:19.357960797Z E0109 09:00:19.357920       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T09:00:20.364391968Z E0109 09:00:20.364350       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T09:00:23.600457453Z I0109 09:00:23.600410       1 request.go:601] Waited for 1.068124034s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T09:00:24.799751505Z I0109 09:00:24.799708       1 request.go:601] Waited for 1.596572014s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/client-ca
2023-01-09T09:00:27.600098675Z I0109 09:00:27.600047       1 request.go:601] Waited for 1.097045314s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T09:02:59.938115704Z I0109 09:02:59.938072       1 request.go:601] Waited for 1.189711158s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2023-01-09T09:03:00.939149619Z I0109 09:03:00.939107       1 request.go:601] Waited for 1.19770678s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T09:03:01.607555440Z I0109 09:03:01.607505       1 externalloadbalancer.go:27] syncing external loadbalancer hostnames: api.sn-loggvls-jsm.qe.devcluster.openshift.com
2023-01-09T09:03:02.539019728Z I0109 09:03:02.538962       1 request.go:601] Waited for 1.114169311s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T09:03:03.148210706Z I0109 09:03:03.148139       1 servicehostname.go:40] syncing servicenetwork hostnames: [172.30.0.1 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local openshift openshift.default openshift.default.svc openshift.default.svc.cluster.local]
2023-01-09T09:03:03.738589766Z I0109 09:03:03.738549       1 request.go:601] Waited for 1.996995593s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T09:03:04.738701538Z I0109 09:03:04.738652       1 request.go:601] Waited for 1.795728976s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2023-01-09T09:03:05.938500536Z I0109 09:03:05.938462       1 request.go:601] Waited for 1.596530559s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/localhost-recovery-client-token
2023-01-09T09:03:08.338794525Z I0109 09:03:08.338751       1 request.go:601] Waited for 1.044593786s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T09:03:11.580643342Z E0109 09:03:11.580600       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T09:03:12.587490266Z E0109 09:03:12.587453       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T09:03:15.738629050Z I0109 09:03:15.738585       1 request.go:601] Waited for 1.109373758s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T09:03:16.939016523Z I0109 09:03:16.938951       1 request.go:601] Waited for 1.59796307s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-8-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T09:03:18.138778095Z I0109 09:03:18.138736       1 request.go:601] Waited for 1.76357026s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2023-01-09T09:03:19.338931622Z I0109 09:03:19.338892       1 request.go:601] Waited for 1.395276091s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T09:03:20.738891716Z I0109 09:03:20.738843       1 request.go:601] Waited for 1.064159044s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T09:03:21.739101200Z I0109 09:03:21.739056       1 request.go:601] Waited for 1.168966548s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2023-01-09T09:08:56.099942806Z E0109 09:08:56.099901       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T09:08:57.106333455Z E0109 09:08:57.106290       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T09:09:00.342720060Z I0109 09:09:00.342682       1 request.go:601] Waited for 1.062616793s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2023-01-09T09:09:01.343171908Z I0109 09:09:01.343134       1 request.go:601] Waited for 1.594461862s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-pod
2023-01-09T09:11:48.267590248Z E0109 09:11:48.267536       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T09:11:49.273452375Z E0109 09:11:49.273412       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T09:11:52.508417462Z I0109 09:11:52.508377       1 request.go:601] Waited for 1.080271293s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T09:11:53.707960240Z I0109 09:11:53.707881       1 request.go:601] Waited for 1.596223014s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T09:11:54.908415008Z I0109 09:11:54.908375       1 request.go:601] Waited for 1.090070456s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T09:11:56.107790393Z I0109 09:11:56.107745       1 request.go:601] Waited for 1.394689897s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T09:12:59.739220654Z I0109 09:12:59.739180       1 request.go:601] Waited for 1.104354124s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T09:13:00.739781876Z I0109 09:13:00.739736       1 request.go:601] Waited for 1.191005981s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T09:13:01.608298294Z I0109 09:13:01.608252       1 externalloadbalancer.go:27] syncing external loadbalancer hostnames: api.sn-loggvls-jsm.qe.devcluster.openshift.com
2023-01-09T09:13:02.539659252Z I0109 09:13:02.539618       1 request.go:601] Waited for 1.114244178s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T09:13:03.148410090Z I0109 09:13:03.148336       1 servicehostname.go:40] syncing servicenetwork hostnames: [172.30.0.1 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local openshift openshift.default openshift.default.svc openshift.default.svc.cluster.local]
2023-01-09T09:13:03.739480115Z I0109 09:13:03.739428       1 request.go:601] Waited for 1.992246627s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T09:13:04.939447680Z I0109 09:13:04.939404       1 request.go:601] Waited for 1.796921963s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T09:13:05.939806644Z I0109 09:13:05.939764       1 request.go:601] Waited for 1.394145753s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T09:13:08.339166079Z I0109 09:13:08.339122       1 request.go:601] Waited for 1.007062849s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T09:14:40.578023621Z E0109 09:14:40.577961       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T09:14:41.584006968Z E0109 09:14:41.583944       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T09:14:44.819768819Z I0109 09:14:44.819714       1 request.go:601] Waited for 1.080955545s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T09:14:46.019254711Z I0109 09:14:46.019205       1 request.go:601] Waited for 1.597260278s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T09:14:48.418937242Z I0109 09:14:48.418897       1 request.go:601] Waited for 1.08216149s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T09:17:32.935066091Z E0109 09:17:32.935024       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T09:17:33.941634869Z E0109 09:17:33.941594       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T09:17:37.243935735Z I0109 09:17:37.243899       1 request.go:601] Waited for 1.132601619s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T09:17:38.443272429Z I0109 09:17:38.443230       1 request.go:601] Waited for 1.596382141s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T09:17:39.443381047Z I0109 09:17:39.443343       1 request.go:601] Waited for 1.196406541s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T09:17:40.444052121Z I0109 09:17:40.444008       1 request.go:601] Waited for 1.19703943s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-8-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T09:20:25.101282592Z E0109 09:20:25.101241       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T09:20:26.107284588Z E0109 09:20:26.107242       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T09:20:29.333652170Z I0109 09:20:29.333601       1 request.go:601] Waited for 1.078265608s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2023-01-09T09:20:30.533270321Z I0109 09:20:30.533229       1 request.go:601] Waited for 1.597785703s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T09:22:59.939685039Z I0109 09:22:59.939652       1 request.go:601] Waited for 1.096798792s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2023-01-09T09:23:01.140486945Z I0109 09:23:01.140450       1 request.go:601] Waited for 1.150869952s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver
2023-01-09T09:23:01.609142624Z I0109 09:23:01.609098       1 externalloadbalancer.go:27] syncing external loadbalancer hostnames: api.sn-loggvls-jsm.qe.devcluster.openshift.com
2023-01-09T09:23:02.539904535Z I0109 09:23:02.539854       1 request.go:601] Waited for 1.113561813s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T09:23:03.148449884Z I0109 09:23:03.148379       1 servicehostname.go:40] syncing servicenetwork hostnames: [172.30.0.1 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local openshift openshift.default openshift.default.svc openshift.default.svc.cluster.local]
2023-01-09T09:23:03.540171106Z I0109 09:23:03.540118       1 request.go:601] Waited for 1.929135372s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver
2023-01-09T09:23:04.740554475Z I0109 09:23:04.740503       1 request.go:601] Waited for 1.797151752s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T09:23:05.740602684Z I0109 09:23:05.740559       1 request.go:601] Waited for 1.523693846s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver
2023-01-09T09:23:08.540291816Z I0109 09:23:08.540253       1 request.go:601] Waited for 1.175670035s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T09:23:11.340091011Z I0109 09:23:11.340052       1 request.go:601] Waited for 1.063987324s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T09:23:17.501910117Z E0109 09:23:17.501872       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T09:23:18.507889032Z E0109 09:23:18.507847       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T09:23:18.939774176Z I0109 09:23:18.939724       1 request.go:601] Waited for 1.000556763s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver
2023-01-09T09:23:21.740585253Z I0109 09:23:21.740544       1 request.go:601] Waited for 1.181688928s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T09:23:22.939649653Z I0109 09:23:22.939608       1 request.go:601] Waited for 1.594042932s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-8-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T09:23:24.139963628Z I0109 09:23:24.139922       1 request.go:601] Waited for 1.197410878s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-8-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T09:26:09.581977676Z E0109 09:26:09.581935       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T09:26:10.588316363Z E0109 09:26:10.588275       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T09:26:13.805402413Z I0109 09:26:13.805358       1 request.go:601] Waited for 1.182110356s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T09:26:14.805688426Z I0109 09:26:14.805644       1 request.go:601] Waited for 1.593701431s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2023-01-09T09:26:15.806090554Z I0109 09:26:15.806049       1 request.go:601] Waited for 1.590288039s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T09:26:16.806210459Z I0109 09:26:16.806166       1 request.go:601] Waited for 1.197813834s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-8-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T09:26:18.005583329Z I0109 09:26:18.005503       1 request.go:601] Waited for 1.195210262s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-8-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T09:26:19.005569118Z I0109 09:26:19.005526       1 request.go:601] Waited for 1.19463285s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T09:26:20.006245396Z I0109 09:26:20.006204       1 request.go:601] Waited for 1.173863621s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T09:29:01.985870431Z E0109 09:29:01.985818       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T09:29:02.991843576Z E0109 09:29:02.991799       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T09:29:06.228328880Z I0109 09:29:06.228284       1 request.go:601] Waited for 1.080132212s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2023-01-09T09:29:07.228721422Z I0109 09:29:07.228676       1 request.go:601] Waited for 1.568799308s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2023-01-09T09:29:08.427971429Z I0109 09:29:08.427906       1 request.go:601] Waited for 1.038357982s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T09:29:09.428231386Z I0109 09:29:09.428192       1 request.go:601] Waited for 1.196980424s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver
2023-01-09T09:31:54.259036482Z E0109 09:31:54.257916       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T09:31:55.264275237Z E0109 09:31:55.264238       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T09:31:58.305888172Z I0109 09:31:58.305851       1 request.go:601] Waited for 1.001360842s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-8-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T09:31:59.505563801Z I0109 09:31:59.505520       1 request.go:601] Waited for 1.59662687s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T09:32:03.505462079Z I0109 09:32:03.505420       1 request.go:601] Waited for 1.041567706s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T09:32:59.940573655Z I0109 09:32:59.940538       1 request.go:601] Waited for 1.185744169s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2023-01-09T09:33:00.941188313Z I0109 09:33:00.941145       1 request.go:601] Waited for 1.197862132s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T09:33:01.609876169Z I0109 09:33:01.609837       1 externalloadbalancer.go:27] syncing external loadbalancer hostnames: api.sn-loggvls-jsm.qe.devcluster.openshift.com
2023-01-09T09:33:02.541553441Z I0109 09:33:02.541512       1 request.go:601] Waited for 1.114579372s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T09:33:03.148853599Z I0109 09:33:03.148785       1 servicehostname.go:40] syncing servicenetwork hostnames: [172.30.0.1 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local openshift openshift.default openshift.default.svc openshift.default.svc.cluster.local]
2023-01-09T09:33:03.741009363Z I0109 09:33:03.740955       1 request.go:601] Waited for 1.996303633s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T09:33:04.741626678Z I0109 09:33:04.741580       1 request.go:601] Waited for 1.797289397s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T09:33:05.940892583Z I0109 09:33:05.940847       1 request.go:601] Waited for 1.19594758s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T09:33:08.541512974Z I0109 09:33:08.541460       1 request.go:601] Waited for 1.140333797s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T09:33:09.741598454Z I0109 09:33:09.741552       1 request.go:601] Waited for 1.035000879s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T09:37:38.656351635Z E0109 09:37:38.656314       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T09:37:39.662747045Z E0109 09:37:39.662707       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T09:37:42.900200336Z I0109 09:37:42.900160       1 request.go:601] Waited for 1.062489867s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2023-01-09T09:37:43.900554021Z I0109 09:37:43.900517       1 request.go:601] Waited for 1.59772666s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T09:40:30.947717332Z E0109 09:40:30.947675       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T09:40:31.954299747Z E0109 09:40:31.954255       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T09:40:35.006355296Z I0109 09:40:35.006309       1 request.go:601] Waited for 1.009577827s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T09:40:36.206589142Z I0109 09:40:36.206533       1 request.go:601] Waited for 1.595722771s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T09:40:38.606800482Z I0109 09:40:38.606757       1 request.go:601] Waited for 1.180902628s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T09:40:39.806487506Z I0109 09:40:39.806449       1 request.go:601] Waited for 1.397579728s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T09:42:59.741090838Z I0109 09:42:59.741040       1 request.go:601] Waited for 1.104609185s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T09:43:00.941562266Z I0109 09:43:00.941520       1 request.go:601] Waited for 1.192715708s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T09:43:01.610494284Z I0109 09:43:01.610438       1 externalloadbalancer.go:27] syncing external loadbalancer hostnames: api.sn-loggvls-jsm.qe.devcluster.openshift.com
2023-01-09T09:43:02.541109552Z I0109 09:43:02.541061       1 request.go:601] Waited for 1.113307452s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T09:43:03.149042474Z I0109 09:43:03.148955       1 servicehostname.go:40] syncing servicenetwork hostnames: [172.30.0.1 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local openshift openshift.default openshift.default.svc openshift.default.svc.cluster.local]
2023-01-09T09:43:03.541598632Z I0109 09:43:03.541553       1 request.go:601] Waited for 1.928212481s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver
2023-01-09T09:43:04.741686083Z I0109 09:43:04.741639       1 request.go:601] Waited for 1.795322744s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2023-01-09T09:43:05.941855958Z I0109 09:43:05.941810       1 request.go:601] Waited for 1.37282186s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T09:43:08.141382604Z I0109 09:43:08.141339       1 request.go:601] Waited for 1.026200491s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T09:43:09.341160905Z I0109 09:43:09.341116       1 request.go:601] Waited for 1.397235552s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T09:43:10.341820614Z I0109 09:43:10.341781       1 request.go:601] Waited for 1.198224389s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-server-ca
2023-01-09T09:43:23.246543348Z E0109 09:43:23.246487       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T09:43:24.253341088Z E0109 09:43:24.253300       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T09:43:27.490672563Z I0109 09:43:27.490631       1 request.go:601] Waited for 1.079920289s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2023-01-09T09:43:28.690744383Z I0109 09:43:28.690698       1 request.go:601] Waited for 1.597028664s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T09:43:29.890735297Z I0109 09:43:29.890687       1 request.go:601] Waited for 1.197205189s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T09:43:34.289809873Z I0109 09:43:34.289767       1 request.go:601] Waited for 1.151862907s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T09:46:15.404843108Z E0109 09:46:15.404800       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T09:46:16.411208521Z E0109 09:46:16.411167       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T09:46:19.580548732Z I0109 09:46:19.580507       1 request.go:601] Waited for 1.133569606s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T09:46:20.580900600Z I0109 09:46:20.580856       1 request.go:601] Waited for 1.596902072s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T09:46:21.780572956Z I0109 09:46:21.780530       1 request.go:601] Waited for 1.59318809s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-pod
2023-01-09T09:46:22.780655271Z I0109 09:46:22.780611       1 request.go:601] Waited for 1.197909788s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T09:46:23.980553204Z I0109 09:46:23.980508       1 request.go:601] Waited for 1.196631472s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T09:46:24.980610071Z I0109 09:46:24.980564       1 request.go:601] Waited for 1.196665552s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-8-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T09:46:26.180093428Z I0109 09:46:26.180049       1 request.go:601] Waited for 1.196185368s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-8-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T09:49:07.620861501Z E0109 09:49:07.620827       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T09:49:08.627506138Z E0109 09:49:08.627467       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T09:49:11.861661263Z I0109 09:49:11.861624       1 request.go:601] Waited for 1.070718397s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T09:49:13.061415742Z I0109 09:49:13.061370       1 request.go:601] Waited for 1.59585982s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-pod
2023-01-09T09:49:14.260948727Z I0109 09:49:14.260907       1 request.go:601] Waited for 1.394292798s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-8-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T09:49:19.061357489Z I0109 09:49:19.061314       1 request.go:601] Waited for 1.138618936s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T09:51:59.851377264Z E0109 09:51:59.851328       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T09:52:00.857938965Z E0109 09:52:00.857901       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T09:52:04.091757000Z I0109 09:52:04.091712       1 request.go:601] Waited for 1.079428704s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T09:52:05.091828256Z I0109 09:52:05.091789       1 request.go:601] Waited for 1.596492291s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T09:52:08.491241519Z I0109 09:52:08.491200       1 request.go:601] Waited for 1.030092737s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T09:52:59.742971199Z I0109 09:52:59.742929       1 request.go:601] Waited for 1.106179754s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T09:53:00.942912580Z I0109 09:53:00.942872       1 request.go:601] Waited for 1.191316733s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T09:53:01.611204192Z I0109 09:53:01.611151       1 externalloadbalancer.go:27] syncing external loadbalancer hostnames: api.sn-loggvls-jsm.qe.devcluster.openshift.com
2023-01-09T09:53:02.543188237Z I0109 09:53:02.543134       1 request.go:601] Waited for 1.114301467s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T09:53:03.149749018Z I0109 09:53:03.149681       1 servicehostname.go:40] syncing servicenetwork hostnames: [172.30.0.1 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local openshift openshift.default openshift.default.svc openshift.default.svc.cluster.local]
2023-01-09T09:53:03.742870211Z I0109 09:53:03.742820       1 request.go:601] Waited for 1.991779675s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T09:53:04.943184289Z I0109 09:53:04.943129       1 request.go:601] Waited for 1.79578056s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2023-01-09T09:53:06.142391018Z I0109 09:53:06.142354       1 request.go:601] Waited for 1.397420041s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T09:53:07.342852448Z I0109 09:53:07.342809       1 request.go:601] Waited for 1.396065981s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/client-ca
2023-01-09T09:53:08.542530789Z I0109 09:53:08.542488       1 request.go:601] Waited for 1.076692306s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T09:53:09.542915853Z I0109 09:53:09.542877       1 request.go:601] Waited for 1.198370869s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/trusted-ca-bundle
2023-01-09T09:57:44.385703494Z E0109 09:57:44.385660       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T09:57:45.392590383Z E0109 09:57:45.392545       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T09:57:48.625110299Z I0109 09:57:48.625068       1 request.go:601] Waited for 1.079273094s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2023-01-09T09:57:49.825059559Z I0109 09:57:49.825019       1 request.go:601] Waited for 1.594737444s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-pod
2023-01-09T09:57:50.825175631Z I0109 09:57:50.825131       1 request.go:601] Waited for 1.194457079s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-8-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T09:57:52.825595579Z I0109 09:57:52.825556       1 request.go:601] Waited for 1.08618553s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T10:00:36.590472416Z E0109 10:00:36.590429       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T10:00:37.596706533Z E0109 10:00:37.596663       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T10:00:40.834095523Z I0109 10:00:40.834043       1 request.go:601] Waited for 1.068610737s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2023-01-09T10:00:41.834513798Z I0109 10:00:41.834471       1 request.go:601] Waited for 1.596802518s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-8-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T10:02:59.943676827Z I0109 10:02:59.943633       1 request.go:601] Waited for 1.183467822s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2023-01-09T10:03:00.944055014Z I0109 10:03:00.943981       1 request.go:601] Waited for 1.195733145s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T10:03:01.611572600Z I0109 10:03:01.611520       1 externalloadbalancer.go:27] syncing external loadbalancer hostnames: api.sn-loggvls-jsm.qe.devcluster.openshift.com
2023-01-09T10:03:02.543742663Z I0109 10:03:02.543698       1 request.go:601] Waited for 1.114285127s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T10:03:03.150262776Z I0109 10:03:03.150183       1 servicehostname.go:40] syncing servicenetwork hostnames: [172.30.0.1 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local openshift openshift.default openshift.default.svc openshift.default.svc.cluster.local]
2023-01-09T10:03:03.743976417Z I0109 10:03:03.743932       1 request.go:601] Waited for 1.997356328s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T10:03:04.943354713Z I0109 10:03:04.943310       1 request.go:601] Waited for 1.595988455s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver
2023-01-09T10:03:06.143309177Z I0109 10:03:06.143271       1 request.go:601] Waited for 1.797633354s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/localhost-recovery-client-token
2023-01-09T10:03:08.543690310Z I0109 10:03:08.543648       1 request.go:601] Waited for 1.048129601s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T10:03:28.856168678Z E0109 10:03:28.856120       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T10:03:29.862036509Z E0109 10:03:29.861981       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T10:03:33.022110303Z I0109 10:03:33.022054       1 request.go:601] Waited for 1.121287046s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T10:03:34.022542635Z I0109 10:03:34.022496       1 request.go:601] Waited for 1.589879203s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T10:03:35.222264605Z I0109 10:03:35.222224       1 request.go:601] Waited for 1.554308804s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver
2023-01-09T10:03:37.822188212Z I0109 10:03:37.822142       1 request.go:601] Waited for 1.194034345s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T10:03:38.822652475Z I0109 10:03:38.822607       1 request.go:601] Waited for 1.196415942s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T10:06:21.132531700Z E0109 10:06:21.132494       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T10:06:22.138093670Z E0109 10:06:22.138055       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T10:06:25.373717825Z I0109 10:06:25.373668       1 request.go:601] Waited for 1.079611713s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T10:06:26.573919079Z I0109 10:06:26.573870       1 request.go:601] Waited for 1.597877495s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T10:06:28.573096792Z I0109 10:06:28.573054       1 request.go:601] Waited for 1.065969979s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T10:06:29.573709574Z I0109 10:06:29.573666       1 request.go:601] Waited for 1.191737596s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2023-01-09T10:09:13.335542806Z E0109 10:09:13.335487       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T10:09:14.341771667Z E0109 10:09:14.341719       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T10:09:17.493828793Z I0109 10:09:17.493783       1 request.go:601] Waited for 1.098154526s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-pod
2023-01-09T10:09:18.693588237Z I0109 10:09:18.693546       1 request.go:601] Waited for 1.569088821s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2023-01-09T10:09:19.893166980Z I0109 10:09:19.893118       1 request.go:601] Waited for 1.396882257s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T10:12:05.588143116Z E0109 10:12:05.588095       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T10:12:06.594870850Z E0109 10:12:06.594829       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T10:12:09.830246767Z I0109 10:12:09.830205       1 request.go:601] Waited for 1.079770412s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2023-01-09T10:12:10.830339930Z I0109 10:12:10.830292       1 request.go:601] Waited for 1.596421385s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T10:12:12.029954613Z I0109 10:12:12.029907       1 request.go:601] Waited for 1.35730975s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver
2023-01-09T10:12:18.630055935Z I0109 10:12:18.630011       1 request.go:601] Waited for 1.088885637s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2023-01-09T10:12:59.744588948Z I0109 10:12:59.744537       1 request.go:601] Waited for 1.106196839s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T10:13:00.745170760Z I0109 10:13:00.745132       1 request.go:601] Waited for 1.196934089s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T10:13:01.612516905Z I0109 10:13:01.612470       1 externalloadbalancer.go:27] syncing external loadbalancer hostnames: api.sn-loggvls-jsm.qe.devcluster.openshift.com
2023-01-09T10:13:02.544573323Z I0109 10:13:02.544527       1 request.go:601] Waited for 1.112791486s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T10:13:03.151000944Z I0109 10:13:03.150922       1 servicehostname.go:40] syncing servicenetwork hostnames: [172.30.0.1 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local openshift openshift.default openshift.default.svc openshift.default.svc.cluster.local]
2023-01-09T10:13:03.545010556Z I0109 10:13:03.544951       1 request.go:601] Waited for 1.931876842s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver
2023-01-09T10:13:04.744295069Z I0109 10:13:04.744249       1 request.go:601] Waited for 1.997315932s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T10:13:05.744920375Z I0109 10:13:05.744869       1 request.go:601] Waited for 1.990982206s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T10:13:08.544618838Z I0109 10:13:08.544577       1 request.go:601] Waited for 1.014951696s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T10:17:50.066415640Z E0109 10:17:50.066367       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T10:17:51.072901050Z E0109 10:17:51.072858       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T10:17:54.235575127Z I0109 10:17:54.235539       1 request.go:601] Waited for 1.008072703s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2023-01-09T10:17:55.435096928Z I0109 10:17:55.435058       1 request.go:601] Waited for 1.592806301s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-pod
2023-01-09T10:17:56.435290462Z I0109 10:17:56.435251       1 request.go:601] Waited for 1.110637751s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T10:17:58.635292699Z I0109 10:17:58.635252       1 request.go:601] Waited for 1.09107389s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T10:17:59.635582410Z I0109 10:17:59.635536       1 request.go:601] Waited for 1.369591637s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2023-01-09T10:22:59.744664038Z I0109 10:22:59.744620       1 request.go:601] Waited for 1.106112354s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T10:23:00.744949477Z I0109 10:23:00.744907       1 request.go:601] Waited for 1.197115173s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T10:23:01.612854664Z I0109 10:23:01.612802       1 externalloadbalancer.go:27] syncing external loadbalancer hostnames: api.sn-loggvls-jsm.qe.devcluster.openshift.com
2023-01-09T10:23:02.144832709Z I0109 10:23:02.144789       1 request.go:601] Waited for 1.134771393s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2023-01-09T10:23:03.151361827Z I0109 10:23:03.151299       1 servicehostname.go:40] syncing servicenetwork hostnames: [172.30.0.1 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local openshift openshift.default openshift.default.svc openshift.default.svc.cluster.local]
2023-01-09T10:23:03.344710329Z I0109 10:23:03.344669       1 request.go:601] Waited for 1.730578871s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2023-01-09T10:23:04.344907617Z I0109 10:23:04.344866       1 request.go:601] Waited for 1.967831002s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2023-01-09T10:23:05.545285083Z I0109 10:23:05.545235       1 request.go:601] Waited for 1.992288759s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver
2023-01-09T10:23:06.545428607Z I0109 10:23:06.545384       1 request.go:601] Waited for 1.396905836s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T10:23:08.745088196Z I0109 10:23:08.745043       1 request.go:601] Waited for 1.186315847s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T10:23:34.627937468Z E0109 10:23:34.627900       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T10:23:35.633733152Z E0109 10:23:35.633688       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T10:23:38.961737132Z I0109 10:23:38.961703       1 request.go:601] Waited for 1.149688245s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T10:23:40.161823637Z I0109 10:23:40.161775       1 request.go:601] Waited for 1.596244383s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-pod
2023-01-09T10:29:19.345022393Z E0109 10:29:19.344972       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T10:29:20.351784662Z E0109 10:29:20.351746       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T10:29:23.586562128Z I0109 10:29:23.586520       1 request.go:601] Waited for 1.068622308s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T10:29:24.786017537Z I0109 10:29:24.785974       1 request.go:601] Waited for 1.596814011s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-8-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T10:29:25.986977804Z I0109 10:29:25.986937       1 request.go:601] Waited for 1.130382717s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T10:29:27.186591795Z I0109 10:29:27.186546       1 request.go:601] Waited for 1.197171586s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T10:32:11.409425486Z E0109 10:32:11.409379       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T10:32:12.415658030Z E0109 10:32:12.415616       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T10:32:15.607256211Z I0109 10:32:15.607219       1 request.go:601] Waited for 1.150310282s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-8-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T10:32:16.806578558Z I0109 10:32:16.806528       1 request.go:601] Waited for 1.597083414s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T10:32:17.806928070Z I0109 10:32:17.806877       1 request.go:601] Waited for 1.196530569s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T10:32:19.006986278Z I0109 10:32:19.006925       1 request.go:601] Waited for 1.418183838s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T10:32:20.007157493Z I0109 10:32:20.007114       1 request.go:601] Waited for 1.79755268s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T10:32:21.007325394Z I0109 10:32:21.007279       1 request.go:601] Waited for 1.196885032s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T10:32:22.007395186Z I0109 10:32:22.007346       1 request.go:601] Waited for 1.197959302s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T10:32:23.207161477Z I0109 10:32:23.207117       1 request.go:601] Waited for 1.196944922s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T10:32:59.745435413Z I0109 10:32:59.745394       1 request.go:601] Waited for 1.104466529s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T10:33:00.945761697Z I0109 10:33:00.945720       1 request.go:601] Waited for 1.195381403s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T10:33:01.613115765Z I0109 10:33:01.613071       1 externalloadbalancer.go:27] syncing external loadbalancer hostnames: api.sn-loggvls-jsm.qe.devcluster.openshift.com
2023-01-09T10:33:02.545492726Z I0109 10:33:02.545450       1 request.go:601] Waited for 1.114910383s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T10:33:03.152397558Z I0109 10:33:03.152329       1 servicehostname.go:40] syncing servicenetwork hostnames: [172.30.0.1 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local openshift openshift.default openshift.default.svc openshift.default.svc.cluster.local]
2023-01-09T10:33:03.744694397Z I0109 10:33:03.744653       1 request.go:601] Waited for 1.98848467s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T10:33:04.745016781Z I0109 10:33:04.744945       1 request.go:601] Waited for 1.795129667s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2023-01-09T10:33:05.945566349Z I0109 10:33:05.945526       1 request.go:601] Waited for 1.391894992s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T10:33:07.145252036Z I0109 10:33:07.145204       1 request.go:601] Waited for 1.095519984s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T10:33:08.745662766Z I0109 10:33:08.745618       1 request.go:601] Waited for 1.153570197s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T10:35:03.870342408Z E0109 10:35:03.870299       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T10:35:04.876542465Z E0109 10:35:04.876500       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T10:35:08.110503594Z I0109 10:35:08.110463       1 request.go:601] Waited for 1.083581935s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T10:35:09.110861370Z I0109 10:35:09.110813       1 request.go:601] Waited for 1.59489906s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-pod
2023-01-09T10:35:10.310160875Z I0109 10:35:10.310099       1 request.go:601] Waited for 1.196669249s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/client-ca
2023-01-09T10:35:11.310387948Z I0109 10:35:11.310346       1 request.go:601] Waited for 1.396409902s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver
2023-01-09T10:35:19.110556393Z I0109 10:35:19.110516       1 request.go:601] Waited for 1.134672838s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver
2023-01-09T10:37:56.155117136Z E0109 10:37:56.155077       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T10:37:57.161047864Z E0109 10:37:57.160984       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T10:38:00.397530078Z I0109 10:38:00.397488       1 request.go:601] Waited for 1.061164506s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T10:38:01.397983940Z I0109 10:38:01.397943       1 request.go:601] Waited for 1.584224072s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T10:40:48.329847781Z E0109 10:40:48.329800       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T10:40:49.336685707Z E0109 10:40:49.336644       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T10:40:52.620243053Z I0109 10:40:52.620201       1 request.go:601] Waited for 1.119388073s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T10:40:53.620290815Z I0109 10:40:53.620248       1 request.go:601] Waited for 1.597472939s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-8-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T10:40:55.620481820Z I0109 10:40:55.620444       1 request.go:601] Waited for 1.183306024s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T10:40:57.220333034Z I0109 10:40:57.220288       1 request.go:601] Waited for 1.065285854s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T10:40:58.620247542Z I0109 10:40:58.620204       1 request.go:601] Waited for 1.000562576s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T10:42:59.345671812Z I0109 10:42:59.345629       1 request.go:601] Waited for 1.076211469s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2023-01-09T10:43:00.345799704Z I0109 10:43:00.345762       1 request.go:601] Waited for 1.196006935s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/client-ca
2023-01-09T10:43:01.614106126Z I0109 10:43:01.614058       1 externalloadbalancer.go:27] syncing external loadbalancer hostnames: api.sn-loggvls-jsm.qe.devcluster.openshift.com
2023-01-09T10:43:02.545208711Z I0109 10:43:02.545168       1 request.go:601] Waited for 1.114068554s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T10:43:03.152462030Z I0109 10:43:03.152393       1 servicehostname.go:40] syncing servicenetwork hostnames: [172.30.0.1 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local openshift openshift.default openshift.default.svc openshift.default.svc.cluster.local]
2023-01-09T10:43:03.545884087Z I0109 10:43:03.545842       1 request.go:601] Waited for 1.929698601s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T10:43:04.745252802Z I0109 10:43:04.745209       1 request.go:601] Waited for 1.795054061s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2023-01-09T10:43:05.745737904Z I0109 10:43:05.745695       1 request.go:601] Waited for 1.494743593s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver
2023-01-09T10:43:06.946053047Z I0109 10:43:06.946013       1 request.go:601] Waited for 1.197797821s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver
2023-01-09T10:43:08.745806499Z I0109 10:43:08.745759       1 request.go:601] Waited for 1.116656827s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T10:43:40.703811088Z E0109 10:43:40.703770       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T10:43:41.711526305Z E0109 10:43:41.711481       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T10:43:44.945768388Z I0109 10:43:44.945728       1 request.go:601] Waited for 1.082661845s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2023-01-09T10:43:46.145259041Z I0109 10:43:46.145215       1 request.go:601] Waited for 1.59613876s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-8-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T10:43:48.745798622Z I0109 10:43:48.745753       1 request.go:601] Waited for 1.114429604s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T10:46:32.739555389Z E0109 10:46:32.739497       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T10:46:33.746185047Z E0109 10:46:33.746144       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T10:46:36.980781077Z I0109 10:46:36.980737       1 request.go:601] Waited for 1.073225669s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2023-01-09T10:46:37.981637398Z I0109 10:46:37.981595       1 request.go:601] Waited for 1.597395332s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-8-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T10:46:39.181667157Z I0109 10:46:39.181624       1 request.go:601] Waited for 1.195863357s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-8-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T10:49:25.028803240Z E0109 10:49:25.028742       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T10:49:26.034980442Z E0109 10:49:26.034940       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T10:49:29.193861035Z I0109 10:49:29.193814       1 request.go:601] Waited for 1.118158836s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-8-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T10:49:30.194082373Z I0109 10:49:30.194041       1 request.go:601] Waited for 1.591374597s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2023-01-09T10:49:31.194305566Z I0109 10:49:31.194256       1 request.go:601] Waited for 1.59767468s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T10:52:17.371335294Z E0109 10:52:17.371298       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T10:52:18.378376759Z E0109 10:52:18.378337       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T10:52:21.614699703Z I0109 10:52:21.614656       1 request.go:601] Waited for 1.079415745s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2023-01-09T10:52:22.614808658Z I0109 10:52:22.614766       1 request.go:601] Waited for 1.5969419s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T10:52:59.742097200Z I0109 10:52:59.742055       1 request.go:601] Waited for 1.100685654s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T10:53:00.941774624Z I0109 10:53:00.941737       1 request.go:601] Waited for 1.191964136s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T10:53:01.614475172Z I0109 10:53:01.614429       1 externalloadbalancer.go:27] syncing external loadbalancer hostnames: api.sn-loggvls-jsm.qe.devcluster.openshift.com
2023-01-09T10:53:02.542075144Z I0109 10:53:02.542034       1 request.go:601] Waited for 1.108994274s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T10:53:03.153392370Z I0109 10:53:03.153328       1 servicehostname.go:40] syncing servicenetwork hostnames: [172.30.0.1 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local openshift openshift.default openshift.default.svc openshift.default.svc.cluster.local]
2023-01-09T10:53:03.741920474Z I0109 10:53:03.741880       1 request.go:601] Waited for 1.992718019s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T10:53:04.941223100Z I0109 10:53:04.941184       1 request.go:601] Waited for 1.792702522s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver
2023-01-09T10:53:05.941872502Z I0109 10:53:05.941822       1 request.go:601] Waited for 1.583715583s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T10:55:09.501706232Z E0109 10:55:09.501666       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T10:55:10.507349099Z E0109 10:55:10.507301       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T10:55:13.745011628Z I0109 10:55:13.744948       1 request.go:601] Waited for 1.082448266s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T10:55:14.745023963Z I0109 10:55:14.744962       1 request.go:601] Waited for 1.597723896s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/client-ca
2023-01-09T10:55:15.745225878Z I0109 10:55:15.745179       1 request.go:601] Waited for 1.196197796s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T10:55:17.344955943Z I0109 10:55:17.344911       1 request.go:601] Waited for 1.180817122s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2023-01-09T10:55:18.744819897Z I0109 10:55:18.744766       1 request.go:601] Waited for 1.073205267s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T10:58:01.899142669Z E0109 10:58:01.899103       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T10:58:02.906013409Z E0109 10:58:02.905939       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T10:58:06.141270085Z I0109 10:58:06.141225       1 request.go:601] Waited for 1.082144569s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T10:58:07.341062336Z I0109 10:58:07.341002       1 request.go:601] Waited for 1.595616171s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/client-ca
2023-01-09T10:58:08.741166003Z I0109 10:58:08.741114       1 request.go:601] Waited for 1.059823136s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T10:58:09.741295273Z I0109 10:58:09.741244       1 request.go:601] Waited for 1.357822129s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T10:58:10.741372199Z I0109 10:58:10.741326       1 request.go:601] Waited for 1.393857127s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T11:00:54.226546180Z E0109 11:00:54.226504       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T11:00:55.234216684Z E0109 11:00:55.234160       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T11:00:58.474695642Z I0109 11:00:58.474650       1 request.go:601] Waited for 1.070458053s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T11:00:59.674521233Z I0109 11:00:59.674468       1 request.go:601] Waited for 1.596070056s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-8-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T11:01:00.874633531Z I0109 11:01:00.874584       1 request.go:601] Waited for 1.194975065s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-8-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T11:02:59.801052865Z I0109 11:02:59.800604       1 request.go:601] Waited for 1.15891801s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T11:03:00.994854894Z I0109 11:03:00.994807       1 request.go:601] Waited for 1.184500031s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T11:03:01.614911544Z I0109 11:03:01.614864       1 externalloadbalancer.go:27] syncing external loadbalancer hostnames: api.sn-loggvls-jsm.qe.devcluster.openshift.com
2023-01-09T11:03:02.595406778Z I0109 11:03:02.595358       1 request.go:601] Waited for 1.162095448s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T11:03:03.153478889Z I0109 11:03:03.153398       1 servicehostname.go:40] syncing servicenetwork hostnames: [172.30.0.1 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local openshift openshift.default openshift.default.svc openshift.default.svc.cluster.local]
2023-01-09T11:03:03.795649826Z I0109 11:03:03.795601       1 request.go:601] Waited for 1.989061389s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T11:03:04.795746949Z I0109 11:03:04.795702       1 request.go:601] Waited for 1.79494231s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2023-01-09T11:03:05.795772309Z I0109 11:03:05.795719       1 request.go:601] Waited for 1.338755542s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver
2023-01-09T11:03:08.795650003Z I0109 11:03:08.795597       1 request.go:601] Waited for 1.097469863s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T11:03:46.256302846Z E0109 11:03:46.256257       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T11:03:47.262698655Z E0109 11:03:47.262650       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T11:03:50.434413655Z I0109 11:03:50.434362       1 request.go:601] Waited for 1.131539227s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T11:03:51.634885186Z I0109 11:03:51.634840       1 request.go:601] Waited for 1.597664391s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T11:03:52.635082726Z I0109 11:03:52.635040       1 request.go:601] Waited for 1.19752291s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T11:03:54.634277336Z I0109 11:03:54.634222       1 request.go:601] Waited for 1.055470196s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T11:03:55.634889765Z I0109 11:03:55.634846       1 request.go:601] Waited for 1.197007306s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-8-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T11:03:56.834980702Z I0109 11:03:56.834934       1 request.go:601] Waited for 1.196618862s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-8-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T11:06:38.546676861Z E0109 11:06:38.546615       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T11:06:39.553180714Z E0109 11:06:39.553139       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T11:06:42.774094816Z I0109 11:06:42.774051       1 request.go:601] Waited for 1.063946527s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2023-01-09T11:06:43.974087065Z I0109 11:06:43.974041       1 request.go:601] Waited for 1.596419682s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-8-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T11:12:23.023313976Z E0109 11:12:23.023268       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T11:12:24.030611942Z E0109 11:12:24.030559       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T11:12:27.267132515Z I0109 11:12:27.267085       1 request.go:601] Waited for 1.058610332s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T11:12:28.467563291Z I0109 11:12:28.467515       1 request.go:601] Waited for 1.597100319s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T11:12:29.667579168Z I0109 11:12:29.667529       1 request.go:601] Waited for 1.397117253s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T11:12:30.667612515Z I0109 11:12:30.667559       1 request.go:601] Waited for 1.197144988s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-8-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T11:12:59.670930304Z I0109 11:12:59.670881       1 request.go:601] Waited for 1.029999559s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T11:13:00.870692053Z I0109 11:13:00.870644       1 request.go:601] Waited for 1.196716107s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T11:13:01.615211067Z I0109 11:13:01.615165       1 externalloadbalancer.go:27] syncing external loadbalancer hostnames: api.sn-loggvls-jsm.qe.devcluster.openshift.com
2023-01-09T11:13:02.470459308Z I0109 11:13:02.470409       1 request.go:601] Waited for 1.036763812s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T11:13:03.154580394Z I0109 11:13:03.154504       1 servicehostname.go:40] syncing servicenetwork hostnames: [172.30.0.1 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local openshift openshift.default openshift.default.svc openshift.default.svc.cluster.local]
2023-01-09T11:13:03.669883563Z I0109 11:13:03.669836       1 request.go:601] Waited for 1.99084139s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T11:13:04.670933198Z I0109 11:13:04.670890       1 request.go:601] Waited for 1.796165078s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2023-01-09T11:13:05.870030917Z I0109 11:13:05.869950       1 request.go:601] Waited for 1.344019068s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver
2023-01-09T11:13:08.870229347Z I0109 11:13:08.870178       1 request.go:601] Waited for 1.134515874s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T11:15:15.302026111Z E0109 11:15:15.301942       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T11:15:16.308295144Z E0109 11:15:16.308254       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T11:15:19.398175589Z I0109 11:15:19.398122       1 request.go:601] Waited for 1.05113675s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-8-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T11:15:20.398715862Z I0109 11:15:20.398667       1 request.go:601] Waited for 1.589961585s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T11:15:21.598948039Z I0109 11:15:21.598902       1 request.go:601] Waited for 1.793840553s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-pod
2023-01-09T11:15:22.797945435Z I0109 11:15:22.797898       1 request.go:601] Waited for 1.196325683s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/client-ca
2023-01-09T11:15:23.798406164Z I0109 11:15:23.798362       1 request.go:601] Waited for 1.195482768s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T11:15:24.798434816Z I0109 11:15:24.798393       1 request.go:601] Waited for 1.197221644s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T11:15:25.998660771Z I0109 11:15:25.998612       1 request.go:601] Waited for 1.197505799s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T11:18:07.501849324Z E0109 11:18:07.501790       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T11:18:08.508216519Z E0109 11:18:08.508174       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T11:18:11.743104196Z I0109 11:18:11.743049       1 request.go:601] Waited for 1.072816278s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T11:18:12.743175715Z I0109 11:18:12.743126       1 request.go:601] Waited for 1.596019651s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T11:18:13.743463066Z I0109 11:18:13.743412       1 request.go:601] Waited for 1.197308693s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/client-ca
2023-01-09T11:18:14.943288322Z I0109 11:18:14.943234       1 request.go:601] Waited for 1.196606722s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-server-ca
2023-01-09T11:18:15.943658136Z I0109 11:18:15.943614       1 request.go:601] Waited for 1.170645577s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2023-01-09T11:18:18.943866720Z I0109 11:18:18.943822       1 request.go:601] Waited for 1.19173389s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T11:20:59.691699618Z E0109 11:20:59.691649       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T11:21:00.698722768Z E0109 11:21:00.698683       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T11:21:03.935195210Z I0109 11:21:03.935153       1 request.go:601] Waited for 1.0686814s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2023-01-09T11:21:05.135174103Z I0109 11:21:05.135131       1 request.go:601] Waited for 1.596815046s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-8-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T11:22:59.748494902Z I0109 11:22:59.748448       1 request.go:601] Waited for 1.107028233s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T11:23:00.947835998Z I0109 11:23:00.947796       1 request.go:601] Waited for 1.195625309s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T11:23:01.616122015Z I0109 11:23:01.616078       1 externalloadbalancer.go:27] syncing external loadbalancer hostnames: api.sn-loggvls-jsm.qe.devcluster.openshift.com
2023-01-09T11:23:02.548405662Z I0109 11:23:02.548361       1 request.go:601] Waited for 1.113706015s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T11:23:03.155508896Z I0109 11:23:03.155424       1 servicehostname.go:40] syncing servicenetwork hostnames: [172.30.0.1 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local openshift openshift.default openshift.default.svc openshift.default.svc.cluster.local]
2023-01-09T11:23:03.748548456Z I0109 11:23:03.748498       1 request.go:601] Waited for 1.995605878s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T11:23:04.948352843Z I0109 11:23:04.948291       1 request.go:601] Waited for 1.797823528s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T11:23:06.148542302Z I0109 11:23:06.148492       1 request.go:601] Waited for 1.197519465s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T11:23:51.982734386Z E0109 11:23:51.982680       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T11:23:52.988963209Z E0109 11:23:52.988902       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T11:23:56.225636096Z I0109 11:23:56.225595       1 request.go:601] Waited for 1.068050002s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T11:23:57.225823868Z I0109 11:23:57.225779       1 request.go:601] Waited for 1.596929169s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-8-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T11:23:58.826090214Z I0109 11:23:58.826031       1 request.go:601] Waited for 1.052158104s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T11:23:59.826357290Z I0109 11:23:59.826308       1 request.go:601] Waited for 1.196869695s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T11:26:44.333664500Z E0109 11:26:44.331643       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T11:26:45.337808157Z E0109 11:26:45.337771       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T11:26:48.454636292Z I0109 11:26:48.454588       1 request.go:601] Waited for 1.077182942s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T11:26:49.454653572Z I0109 11:26:49.454609       1 request.go:601] Waited for 1.589116996s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2023-01-09T11:26:50.455112226Z I0109 11:26:50.455069       1 request.go:601] Waited for 1.595713499s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/localhost-recovery-client-token
2023-01-09T11:26:52.254642740Z I0109 11:26:52.254592       1 request.go:601] Waited for 1.064792098s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T11:26:53.254639905Z I0109 11:26:53.254597       1 request.go:601] Waited for 1.195292154s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T11:26:54.254834351Z I0109 11:26:54.254784       1 request.go:601] Waited for 1.196340517s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T11:29:36.588387731Z E0109 11:29:36.588339       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T11:29:37.594420857Z E0109 11:29:37.594378       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T11:29:40.832177125Z I0109 11:29:40.832134       1 request.go:601] Waited for 1.066757728s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T11:29:42.031338040Z I0109 11:29:42.031288       1 request.go:601] Waited for 1.596188308s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T11:32:29.094069379Z E0109 11:32:29.094013       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T11:32:30.100255492Z E0109 11:32:30.100215       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T11:32:33.215254498Z I0109 11:32:33.215212       1 request.go:601] Waited for 1.082662656s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T11:32:34.215761140Z I0109 11:32:34.215712       1 request.go:601] Waited for 1.597014932s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T11:32:59.748945333Z I0109 11:32:59.748898       1 request.go:601] Waited for 1.106764851s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T11:33:00.749719516Z I0109 11:33:00.749672       1 request.go:601] Waited for 1.195649208s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T11:33:01.616678027Z I0109 11:33:01.616622       1 externalloadbalancer.go:27] syncing external loadbalancer hostnames: api.sn-loggvls-jsm.qe.devcluster.openshift.com
2023-01-09T11:33:02.548868140Z I0109 11:33:02.548828       1 request.go:601] Waited for 1.113724887s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T11:33:03.156117155Z I0109 11:33:03.156045       1 servicehostname.go:40] syncing servicenetwork hostnames: [172.30.0.1 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local openshift openshift.default openshift.default.svc openshift.default.svc.cluster.local]
2023-01-09T11:33:03.549331788Z I0109 11:33:03.549286       1 request.go:601] Waited for 1.930966435s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T11:33:04.749263772Z I0109 11:33:04.749217       1 request.go:601] Waited for 1.79671411s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T11:33:05.749526167Z I0109 11:33:05.749481       1 request.go:601] Waited for 1.311815836s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver
2023-01-09T11:35:21.041435793Z E0109 11:35:21.041386       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T11:35:22.047147786Z E0109 11:35:22.047100       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T11:35:25.291131355Z I0109 11:35:25.291084       1 request.go:601] Waited for 1.050067644s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T11:35:26.291258525Z I0109 11:35:26.291216       1 request.go:601] Waited for 1.59651132s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/client-ca
2023-01-09T11:35:27.292069294Z I0109 11:35:27.292022       1 request.go:601] Waited for 1.233357804s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T11:35:28.891512361Z I0109 11:35:28.891470       1 request.go:601] Waited for 1.080154405s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T11:35:29.891738925Z I0109 11:35:29.891694       1 request.go:601] Waited for 1.191260306s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2023-01-09T11:38:13.336716342Z E0109 11:38:13.336675       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T11:38:14.343509583Z E0109 11:38:14.343466       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T11:38:17.590481516Z I0109 11:38:17.590434       1 request.go:601] Waited for 1.086585428s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T11:38:18.591293189Z I0109 11:38:18.591237       1 request.go:601] Waited for 1.597697308s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T11:38:19.790888688Z I0109 11:38:19.790843       1 request.go:601] Waited for 1.397739748s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/client-ca
2023-01-09T11:38:21.390518358Z I0109 11:38:21.390475       1 request.go:601] Waited for 1.147065272s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T11:38:22.590458865Z I0109 11:38:22.590407       1 request.go:601] Waited for 1.195485511s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T11:42:59.716943492Z I0109 11:42:59.716892       1 request.go:601] Waited for 1.074490415s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T11:43:00.917586883Z I0109 11:43:00.917534       1 request.go:601] Waited for 1.19503066s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T11:43:01.617684618Z I0109 11:43:01.617635       1 externalloadbalancer.go:27] syncing external loadbalancer hostnames: api.sn-loggvls-jsm.qe.devcluster.openshift.com
2023-01-09T11:43:02.516671931Z I0109 11:43:02.516623       1 request.go:601] Waited for 1.080611477s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T11:43:03.157127842Z I0109 11:43:03.157052       1 servicehostname.go:40] syncing servicenetwork hostnames: [172.30.0.1 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local openshift openshift.default openshift.default.svc openshift.default.svc.cluster.local]
2023-01-09T11:43:03.517489564Z I0109 11:43:03.517427       1 request.go:601] Waited for 1.899012043s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T11:43:04.525835821Z I0109 11:43:04.525784       1 request.go:601] Waited for 1.798698785s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T11:43:05.716838418Z I0109 11:43:05.716793       1 request.go:601] Waited for 1.391416295s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2023-01-09T11:43:57.818961980Z E0109 11:43:57.814726       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T11:43:58.821753054Z E0109 11:43:58.821707       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T11:44:02.059101469Z I0109 11:44:02.059055       1 request.go:601] Waited for 1.076297893s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2023-01-09T11:44:03.258388241Z I0109 11:44:03.258338       1 request.go:601] Waited for 1.596684589s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/client-ca
2023-01-09T11:46:50.129690899Z E0109 11:46:50.129648       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T11:46:51.135687610Z E0109 11:46:51.135635       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T11:46:54.370605728Z I0109 11:46:54.370562       1 request.go:601] Waited for 1.07273295s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T11:46:55.571179308Z I0109 11:46:55.571126       1 request.go:601] Waited for 1.595737991s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/client-ca
2023-01-09T11:49:42.367850260Z E0109 11:49:42.367806       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T11:49:43.374429968Z E0109 11:49:43.374384       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T11:49:46.492658616Z I0109 11:49:46.492619       1 request.go:601] Waited for 1.080618014s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T11:49:47.493348212Z I0109 11:49:47.493300       1 request.go:601] Waited for 1.593863095s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2023-01-09T11:49:48.692735004Z I0109 11:49:48.692695       1 request.go:601] Waited for 1.56836099s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2023-01-09T11:49:49.893108429Z I0109 11:49:49.893040       1 request.go:601] Waited for 1.156811448s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver
2023-01-09T11:49:52.292702582Z I0109 11:49:52.292660       1 request.go:601] Waited for 1.156851178s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T11:49:53.293082640Z I0109 11:49:53.293032       1 request.go:601] Waited for 1.192020747s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/config
2023-01-09T11:52:59.949800770Z I0109 11:52:59.949760       1 request.go:601] Waited for 1.171174663s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T11:53:00.949906679Z I0109 11:53:00.949863       1 request.go:601] Waited for 1.15027216s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver
2023-01-09T11:53:01.618628455Z I0109 11:53:01.618575       1 externalloadbalancer.go:27] syncing external loadbalancer hostnames: api.sn-loggvls-jsm.qe.devcluster.openshift.com
2023-01-09T11:53:02.549825205Z I0109 11:53:02.549781       1 request.go:601] Waited for 1.113089385s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T11:53:03.158147472Z I0109 11:53:03.158067       1 servicehostname.go:40] syncing servicenetwork hostnames: [172.30.0.1 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local openshift openshift.default openshift.default.svc openshift.default.svc.cluster.local]
2023-01-09T11:53:03.550022683Z I0109 11:53:03.549952       1 request.go:601] Waited for 1.921325931s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T11:53:04.550049418Z I0109 11:53:04.549984       1 request.go:601] Waited for 1.592653346s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver
2023-01-09T11:53:05.550614489Z I0109 11:53:05.550562       1 request.go:601] Waited for 1.377673132s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/config
2023-01-09T11:55:26.887767373Z E0109 11:55:26.887722       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T11:55:27.893803701Z E0109 11:55:27.893754       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T11:55:31.130663096Z I0109 11:55:31.130610       1 request.go:601] Waited for 1.074510368s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T11:55:32.131554858Z I0109 11:55:32.131503       1 request.go:601] Waited for 1.597936556s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T11:55:33.330683524Z I0109 11:55:33.330639       1 request.go:601] Waited for 1.195671617s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T11:58:19.266720843Z E0109 11:58:19.266672       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T11:58:20.272547558Z E0109 11:58:20.272507       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T11:58:23.492557327Z I0109 11:58:23.492493       1 request.go:601] Waited for 1.076280669s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2023-01-09T11:58:24.492654638Z I0109 11:58:24.492605       1 request.go:601] Waited for 1.593721982s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T11:58:26.293208106Z I0109 11:58:26.293148       1 request.go:601] Waited for 1.167601216s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T11:58:27.493180375Z I0109 11:58:27.493109       1 request.go:601] Waited for 1.396855337s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T12:01:11.365519846Z E0109 12:01:11.365458       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T12:01:12.371979747Z E0109 12:01:12.371941       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T12:01:15.632415988Z I0109 12:01:15.632371       1 request.go:601] Waited for 1.066186405s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2023-01-09T12:01:16.633027024Z I0109 12:01:16.632971       1 request.go:601] Waited for 1.595246878s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T12:01:17.832566945Z I0109 12:01:17.832511       1 request.go:601] Waited for 1.196951372s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T12:01:18.833102234Z I0109 12:01:18.833052       1 request.go:601] Waited for 1.19865884s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/trusted-ca-bundle
2023-01-09T12:01:20.033114220Z I0109 12:01:20.033062       1 request.go:601] Waited for 1.192242783s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2023-01-09T12:02:59.751245855Z I0109 12:02:59.751199       1 request.go:601] Waited for 1.107335846s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T12:03:00.751849283Z I0109 12:03:00.751797       1 request.go:601] Waited for 1.197023067s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T12:03:01.619345634Z I0109 12:03:01.619296       1 externalloadbalancer.go:27] syncing external loadbalancer hostnames: api.sn-loggvls-jsm.qe.devcluster.openshift.com
2023-01-09T12:03:02.551896917Z I0109 12:03:02.551843       1 request.go:601] Waited for 1.114376813s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T12:03:03.158738355Z I0109 12:03:03.158668       1 servicehostname.go:40] syncing servicenetwork hostnames: [172.30.0.1 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local openshift openshift.default openshift.default.svc openshift.default.svc.cluster.local]
2023-01-09T12:03:03.751814734Z I0109 12:03:03.751770       1 request.go:601] Waited for 1.991867531s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T12:03:04.951832612Z I0109 12:03:04.951784       1 request.go:601] Waited for 1.797133322s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T12:03:06.151064058Z I0109 12:03:06.151019       1 request.go:601] Waited for 1.196671566s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T12:09:48.178117355Z E0109 12:09:48.178070       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T12:09:49.184440404Z E0109 12:09:49.184393       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T12:09:52.405605603Z I0109 12:09:52.405567       1 request.go:601] Waited for 1.067286168s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T12:09:53.405935338Z I0109 12:09:53.405878       1 request.go:601] Waited for 1.595260064s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-pod
2023-01-09T12:12:40.343976817Z E0109 12:12:40.343930       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T12:12:41.349792070Z E0109 12:12:41.349749       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T12:12:44.585736688Z I0109 12:12:44.585693       1 request.go:601] Waited for 1.062146251s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2023-01-09T12:12:45.586043472Z I0109 12:12:45.585961       1 request.go:601] Waited for 1.596845333s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T12:12:46.586279770Z I0109 12:12:46.586226       1 request.go:601] Waited for 1.351541207s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver
2023-01-09T12:12:47.985390342Z I0109 12:12:47.985347       1 request.go:601] Waited for 1.097929485s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T12:12:48.985744162Z I0109 12:12:48.985681       1 request.go:601] Waited for 1.194813525s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T12:12:59.785544897Z I0109 12:12:59.785500       1 request.go:601] Waited for 1.141178552s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T12:13:00.785744681Z I0109 12:13:00.785686       1 request.go:601] Waited for 1.196208763s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T12:13:01.619983635Z I0109 12:13:01.619922       1 externalloadbalancer.go:27] syncing external loadbalancer hostnames: api.sn-loggvls-jsm.qe.devcluster.openshift.com
2023-01-09T12:13:02.586224593Z I0109 12:13:02.586178       1 request.go:601] Waited for 1.148599968s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T12:13:03.158805837Z I0109 12:13:03.158732       1 servicehostname.go:40] syncing servicenetwork hostnames: [172.30.0.1 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local openshift openshift.default openshift.default.svc openshift.default.svc.cluster.local]
2023-01-09T12:13:03.786039689Z I0109 12:13:03.785970       1 request.go:601] Waited for 1.990447688s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T12:13:04.786181608Z I0109 12:13:04.786137       1 request.go:601] Waited for 1.797905452s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T12:13:05.986166764Z I0109 12:13:05.986116       1 request.go:601] Waited for 1.374825778s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T12:13:10.785796765Z I0109 12:13:10.785747       1 request.go:601] Waited for 1.01437512s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/config
2023-01-09T12:15:32.616153202Z E0109 12:15:32.616115       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T12:15:33.622130658Z E0109 12:15:33.622090       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T12:15:36.858325189Z I0109 12:15:36.858281       1 request.go:601] Waited for 1.068141527s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T12:15:37.858787073Z I0109 12:15:37.858734       1 request.go:601] Waited for 1.597960962s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T12:15:39.058826054Z I0109 12:15:39.058781       1 request.go:601] Waited for 1.086966589s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T12:21:17.109442417Z E0109 12:21:17.109398       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T12:21:18.115682251Z E0109 12:21:18.115638       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T12:21:21.389704577Z I0109 12:21:21.389662       1 request.go:601] Waited for 1.109239899s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T12:21:22.589970537Z I0109 12:21:22.589917       1 request.go:601] Waited for 1.596625348s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/client-ca
2023-01-09T12:21:25.189523211Z I0109 12:21:25.189473       1 request.go:601] Waited for 1.062727349s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T12:21:26.189567826Z I0109 12:21:26.189505       1 request.go:601] Waited for 1.194483346s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T12:22:59.952056886Z I0109 12:22:59.952016       1 request.go:601] Waited for 1.180295125s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2023-01-09T12:23:00.952818031Z I0109 12:23:00.952764       1 request.go:601] Waited for 1.197332679s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/trusted-ca-bundle
2023-01-09T12:23:01.620609941Z I0109 12:23:01.620548       1 externalloadbalancer.go:27] syncing external loadbalancer hostnames: api.sn-loggvls-jsm.qe.devcluster.openshift.com
2023-01-09T12:23:02.552189372Z I0109 12:23:02.552141       1 request.go:601] Waited for 1.114429735s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T12:23:03.159259012Z I0109 12:23:03.159192       1 servicehostname.go:40] syncing servicenetwork hostnames: [172.30.0.1 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local openshift openshift.default openshift.default.svc openshift.default.svc.cluster.local]
2023-01-09T12:23:03.552642516Z I0109 12:23:03.552595       1 request.go:601] Waited for 1.930249702s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver
2023-01-09T12:23:04.552871263Z I0109 12:23:04.552820       1 request.go:601] Waited for 1.792672456s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2023-01-09T12:23:05.552934162Z I0109 12:23:05.552888       1 request.go:601] Waited for 1.333936995s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver
2023-01-09T12:23:09.352361698Z I0109 12:23:09.352306       1 request.go:601] Waited for 1.144138946s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver
2023-01-09T12:23:10.553042846Z I0109 12:23:10.552970       1 request.go:601] Waited for 1.198140364s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver
2023-01-09T12:24:09.305068316Z E0109 12:24:09.305026       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T12:24:10.311842757Z E0109 12:24:10.311804       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T12:24:13.549389915Z I0109 12:24:13.549338       1 request.go:601] Waited for 1.064415637s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T12:24:14.749182325Z I0109 12:24:14.749140       1 request.go:601] Waited for 1.594197003s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-8-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T12:24:15.949531234Z I0109 12:24:15.949486       1 request.go:601] Waited for 1.195353401s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-8-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T12:24:17.148879701Z I0109 12:24:17.148827       1 request.go:601] Waited for 1.195954372s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-8-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T12:24:18.149414050Z I0109 12:24:18.149368       1 request.go:601] Waited for 1.39492197s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/trusted-ca-bundle
2023-01-09T12:24:19.348671262Z I0109 12:24:19.348628       1 request.go:601] Waited for 1.303033692s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver
2023-01-09T12:27:01.559466040Z E0109 12:27:01.559423       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T12:27:02.565553146Z E0109 12:27:02.565509       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T12:27:05.779113149Z I0109 12:27:05.779068       1 request.go:601] Waited for 1.171352311s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T12:27:06.779492267Z I0109 12:27:06.779425       1 request.go:601] Waited for 1.593932822s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-pod
2023-01-09T12:27:07.979619601Z I0109 12:27:07.979576       1 request.go:601] Waited for 1.595205343s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver
2023-01-09T12:27:09.179315798Z I0109 12:27:09.179273       1 request.go:601] Waited for 1.169895746s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2023-01-09T12:29:53.805510462Z E0109 12:29:53.805464       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T12:29:54.811721047Z E0109 12:29:54.811666       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T12:29:58.049941614Z I0109 12:29:58.049894       1 request.go:601] Waited for 1.074345375s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T12:29:59.050476331Z I0109 12:29:59.050426       1 request.go:601] Waited for 1.595444414s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T12:30:00.250113886Z I0109 12:30:00.250065       1 request.go:601] Waited for 1.195777161s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T12:32:46.218841694Z E0109 12:32:46.218802       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T12:32:47.225179746Z E0109 12:32:47.225137       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T12:32:50.427207413Z I0109 12:32:50.427169       1 request.go:601] Waited for 1.029102635s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2023-01-09T12:32:51.627417026Z I0109 12:32:51.627377       1 request.go:601] Waited for 1.597945042s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T12:32:59.226552049Z I0109 12:32:59.226506       1 request.go:601] Waited for 1.167209117s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2023-01-09T12:33:00.227316589Z I0109 12:33:00.227272       1 request.go:601] Waited for 1.395894399s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T12:33:01.426542550Z I0109 12:33:01.426497       1 request.go:601] Waited for 1.391864892s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T12:33:01.620828933Z I0109 12:33:01.620778       1 externalloadbalancer.go:27] syncing external loadbalancer hostnames: api.sn-loggvls-jsm.qe.devcluster.openshift.com
2023-01-09T12:33:02.426747871Z I0109 12:33:02.426688       1 request.go:601] Waited for 1.193411958s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-pod
2023-01-09T12:33:03.159663405Z I0109 12:33:03.159594       1 servicehostname.go:40] syncing servicenetwork hostnames: [172.30.0.1 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local openshift openshift.default openshift.default.svc openshift.default.svc.cluster.local]
2023-01-09T12:33:03.626797637Z I0109 12:33:03.626753       1 request.go:601] Waited for 1.995366019s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2023-01-09T12:33:04.627019260Z I0109 12:33:04.626959       1 request.go:601] Waited for 1.789148079s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T12:33:05.827126125Z I0109 12:33:05.827082       1 request.go:601] Waited for 1.597401278s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T12:33:07.826964890Z I0109 12:33:07.826910       1 request.go:601] Waited for 1.193130006s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T12:33:09.227466513Z I0109 12:33:09.227423       1 request.go:601] Waited for 1.154921624s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver
2023-01-09T12:35:38.408969296Z E0109 12:35:38.408913       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T12:35:39.415637061Z E0109 12:35:39.415600       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T12:35:42.650147071Z I0109 12:35:42.650109       1 request.go:601] Waited for 1.068826983s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T12:35:43.849934893Z I0109 12:35:43.849887       1 request.go:601] Waited for 1.597620732s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/client-ca
2023-01-09T12:35:44.850659226Z I0109 12:35:44.850620       1 request.go:601] Waited for 1.397630459s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T12:35:46.250747224Z I0109 12:35:46.250704       1 request.go:601] Waited for 1.082351904s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T12:35:47.450571608Z I0109 12:35:47.450532       1 request.go:601] Waited for 1.196573045s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T12:38:30.637699600Z E0109 12:38:30.637666       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T12:38:31.643965573Z E0109 12:38:31.643929       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T12:38:34.965797940Z I0109 12:38:34.965734       1 request.go:601] Waited for 1.070913193s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T12:38:36.165568930Z I0109 12:38:36.165527       1 request.go:601] Waited for 1.596525805s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-8-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T12:41:22.874540725Z E0109 12:41:22.874502       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T12:41:23.880591176Z E0109 12:41:23.880550       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T12:41:27.114276774Z I0109 12:41:27.114234       1 request.go:601] Waited for 1.079983191s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2023-01-09T12:41:28.314435919Z I0109 12:41:28.314394       1 request.go:601] Waited for 1.594823375s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-8-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T12:41:29.314723476Z I0109 12:41:29.314681       1 request.go:601] Waited for 1.19739003s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T12:41:30.513877958Z I0109 12:41:30.513831       1 request.go:601] Waited for 1.196193607s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T12:42:59.955026185Z I0109 12:42:59.954975       1 request.go:601] Waited for 1.186985846s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2023-01-09T12:43:00.955716276Z I0109 12:43:00.955671       1 request.go:601] Waited for 1.197863328s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/trusted-ca-bundle
2023-01-09T12:43:01.621038043Z I0109 12:43:01.620980       1 externalloadbalancer.go:27] syncing external loadbalancer hostnames: api.sn-loggvls-jsm.qe.devcluster.openshift.com
2023-01-09T12:43:02.555854789Z I0109 12:43:02.555811       1 request.go:601] Waited for 1.116907298s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T12:43:03.160126318Z I0109 12:43:03.160054       1 servicehostname.go:40] syncing servicenetwork hostnames: [172.30.0.1 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local openshift openshift.default openshift.default.svc openshift.default.svc.cluster.local]
2023-01-09T12:43:03.754883757Z I0109 12:43:03.754837       1 request.go:601] Waited for 1.996419064s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/localhost-recovery-client-token
2023-01-09T12:43:04.755094282Z I0109 12:43:04.755053       1 request.go:601] Waited for 1.796214702s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T12:43:05.755615988Z I0109 12:43:05.755576       1 request.go:601] Waited for 1.393666872s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T12:43:06.755657985Z I0109 12:43:06.755602       1 request.go:601] Waited for 1.395748027s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-pod
2023-01-09T12:43:09.155017105Z I0109 12:43:09.154963       1 request.go:601] Waited for 1.090730765s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T12:43:10.155367894Z I0109 12:43:10.155326       1 request.go:601] Waited for 1.197681791s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver
2023-01-09T12:44:15.131103347Z E0109 12:44:15.131049       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T12:44:16.137258834Z E0109 12:44:16.137221       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T12:44:19.257084741Z I0109 12:44:19.257042       1 request.go:601] Waited for 1.083399781s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T12:44:20.457435565Z I0109 12:44:20.457396       1 request.go:601] Waited for 1.594613724s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-8-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T12:44:21.457521682Z I0109 12:44:21.457481       1 request.go:601] Waited for 1.595373511s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver
2023-01-09T12:44:24.257165893Z I0109 12:44:24.257122       1 request.go:601] Waited for 1.145001772s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T12:44:25.457315259Z I0109 12:44:25.457273       1 request.go:601] Waited for 1.394415317s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver
2023-01-09T12:47:07.515340670Z E0109 12:47:07.515303       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T12:47:08.521669851Z E0109 12:47:08.521628       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T12:47:11.751971941Z I0109 12:47:11.751930       1 request.go:601] Waited for 1.078499007s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2023-01-09T12:47:12.752822967Z I0109 12:47:12.752779       1 request.go:601] Waited for 1.570795562s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2023-01-09T12:47:19.152907397Z I0109 12:47:19.152868       1 request.go:601] Waited for 1.094544062s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver
2023-01-09T12:49:59.659804553Z E0109 12:49:59.659768       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T12:50:00.666342281Z E0109 12:50:00.666303       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T12:50:03.962100435Z I0109 12:50:03.962056       1 request.go:601] Waited for 1.167715354s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T12:50:04.962148664Z I0109 12:50:04.962107       1 request.go:601] Waited for 1.394254781s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T12:50:05.962332086Z I0109 12:50:05.962286       1 request.go:601] Waited for 1.59269483s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2023-01-09T12:50:06.962439398Z I0109 12:50:06.962396       1 request.go:601] Waited for 1.197481418s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-8-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T12:50:08.162936714Z I0109 12:50:08.162892       1 request.go:601] Waited for 1.196396979s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-8-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T12:50:09.162957132Z I0109 12:50:09.162912       1 request.go:601] Waited for 1.197429616s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T12:50:10.361979497Z I0109 12:50:10.361931       1 request.go:601] Waited for 1.394221416s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T12:52:59.952967245Z I0109 12:52:59.952933       1 request.go:601] Waited for 1.182904604s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2023-01-09T12:53:00.953853753Z I0109 12:53:00.953811       1 request.go:601] Waited for 1.198423445s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/trusted-ca-bundle
2023-01-09T12:53:01.621231445Z I0109 12:53:01.621182       1 externalloadbalancer.go:27] syncing external loadbalancer hostnames: api.sn-loggvls-jsm.qe.devcluster.openshift.com
2023-01-09T12:53:02.553337620Z I0109 12:53:02.553296       1 request.go:601] Waited for 1.112749977s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T12:53:03.160430263Z I0109 12:53:03.160366       1 servicehostname.go:40] syncing servicenetwork hostnames: [172.30.0.1 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local openshift openshift.default openshift.default.svc openshift.default.svc.cluster.local]
2023-01-09T12:53:03.753741697Z I0109 12:53:03.753698       1 request.go:601] Waited for 1.998442616s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/localhost-recovery-client-token
2023-01-09T12:53:04.753763394Z I0109 12:53:04.753721       1 request.go:601] Waited for 1.793577597s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver
2023-01-09T12:53:05.953685890Z I0109 12:53:05.953643       1 request.go:601] Waited for 1.73462467s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver
2023-01-09T12:55:44.171296219Z E0109 12:55:44.171255       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T12:55:45.177566188Z E0109 12:55:45.177521       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T12:55:48.370080907Z I0109 12:55:48.370040       1 request.go:601] Waited for 1.14788716s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T12:55:49.569978157Z I0109 12:55:49.569933       1 request.go:601] Waited for 1.595306076s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver
2023-01-09T12:55:50.769764753Z I0109 12:55:50.769724       1 request.go:601] Waited for 1.396276904s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T12:58:36.416951539Z E0109 12:58:36.416881       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T12:58:37.422683524Z E0109 12:58:37.422643       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T12:58:40.657203112Z I0109 12:58:40.657164       1 request.go:601] Waited for 1.077926347s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T12:58:41.856557570Z I0109 12:58:41.856510       1 request.go:601] Waited for 1.596937118s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T12:58:42.856615387Z I0109 12:58:42.856572       1 request.go:601] Waited for 1.130196382s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T12:58:43.857179610Z I0109 12:58:43.857135       1 request.go:601] Waited for 1.39680177s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-8-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T13:02:59.953704378Z I0109 13:02:59.953669       1 request.go:601] Waited for 1.181150612s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2023-01-09T13:03:00.953899228Z I0109 13:03:00.953858       1 request.go:601] Waited for 1.198386025s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-server-ca
2023-01-09T13:03:01.622289528Z I0109 13:03:01.622248       1 externalloadbalancer.go:27] syncing external loadbalancer hostnames: api.sn-loggvls-jsm.qe.devcluster.openshift.com
2023-01-09T13:03:02.553475830Z I0109 13:03:02.553435       1 request.go:601] Waited for 1.113259865s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T13:03:03.161142183Z I0109 13:03:03.161075       1 servicehostname.go:40] syncing servicenetwork hostnames: [172.30.0.1 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local openshift openshift.default openshift.default.svc openshift.default.svc.cluster.local]
2023-01-09T13:03:03.554283897Z I0109 13:03:03.554238       1 request.go:601] Waited for 1.929612994s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T13:03:04.753824459Z I0109 13:03:04.753781       1 request.go:601] Waited for 1.996630364s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T13:03:05.753884677Z I0109 13:03:05.753838       1 request.go:601] Waited for 1.997692158s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/localhost-recovery-client-token
2023-01-09T13:04:20.992662667Z E0109 13:04:20.992619       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T13:04:21.999436663Z E0109 13:04:21.999400       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T13:04:25.271757190Z I0109 13:04:25.271713       1 request.go:601] Waited for 1.111749174s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2023-01-09T13:04:26.472437677Z I0109 13:04:26.472393       1 request.go:601] Waited for 1.546526327s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2023-01-09T13:04:28.672680968Z I0109 13:04:28.672625       1 request.go:601] Waited for 1.078426561s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T13:04:29.871912532Z I0109 13:04:29.871872       1 request.go:601] Waited for 1.366501465s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2023-01-09T13:07:13.155469028Z E0109 13:07:13.155432       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T13:07:14.161696706Z E0109 13:07:14.161657       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T13:07:17.397157734Z I0109 13:07:17.397121       1 request.go:601] Waited for 1.083597319s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2023-01-09T13:07:18.596502849Z I0109 13:07:18.596462       1 request.go:601] Waited for 1.797523285s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T13:07:19.796634955Z I0109 13:07:19.796593       1 request.go:601] Waited for 1.550654666s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver
2023-01-09T13:10:05.566192070Z E0109 13:10:05.566127       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T13:10:06.573223939Z E0109 13:10:06.573178       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T13:10:09.880981752Z I0109 13:10:09.880938       1 request.go:601] Waited for 1.144713306s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2023-01-09T13:10:11.080163400Z I0109 13:10:11.080113       1 request.go:601] Waited for 1.597285164s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/client-ca
2023-01-09T13:12:57.574420111Z E0109 13:12:57.574361       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T13:12:58.580807164Z E0109 13:12:58.580767       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T13:12:59.953764945Z I0109 13:12:59.953725       1 request.go:601] Waited for 1.174400505s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2023-01-09T13:13:00.954099937Z I0109 13:13:00.954054       1 request.go:601] Waited for 1.197294519s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/trusted-ca-bundle
2023-01-09T13:13:01.623113835Z I0109 13:13:01.622505       1 externalloadbalancer.go:27] syncing external loadbalancer hostnames: api.sn-loggvls-jsm.qe.devcluster.openshift.com
2023-01-09T13:13:01.954465021Z I0109 13:13:01.954426       1 request.go:601] Waited for 1.336282347s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T13:13:03.154179267Z I0109 13:13:03.154138       1 request.go:601] Waited for 1.794883976s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T13:13:03.165417476Z I0109 13:13:03.165334       1 servicehostname.go:40] syncing servicenetwork hostnames: [172.30.0.1 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local openshift openshift.default openshift.default.svc openshift.default.svc.cluster.local]
2023-01-09T13:13:04.154508671Z I0109 13:13:04.154458       1 request.go:601] Waited for 2.19732053s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T13:13:05.353835141Z I0109 13:13:05.353766       1 request.go:601] Waited for 2.195139672s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T13:13:06.354658792Z I0109 13:13:06.354614       1 request.go:601] Waited for 1.996246962s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T13:13:07.554348862Z I0109 13:13:07.554302       1 request.go:601] Waited for 1.193971927s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T13:13:08.554761654Z I0109 13:13:08.554714       1 request.go:601] Waited for 1.198316311s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T13:13:09.754014105Z I0109 13:13:09.753962       1 request.go:601] Waited for 1.567877552s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2023-01-09T13:13:10.754231525Z I0109 13:13:10.754190       1 request.go:601] Waited for 1.59624318s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-server-ca
2023-01-09T13:15:49.894302669Z E0109 13:15:49.894265       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T13:15:50.903105609Z E0109 13:15:50.903062       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T13:15:54.138570711Z I0109 13:15:54.138530       1 request.go:601] Waited for 1.067408884s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-8-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T13:15:55.337906872Z I0109 13:15:55.337854       1 request.go:601] Waited for 1.595417419s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-pod
2023-01-09T13:18:42.350020723Z E0109 13:18:42.349976       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T13:18:43.356686354Z E0109 13:18:43.356644       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T13:18:46.593562772Z I0109 13:18:46.593519       1 request.go:601] Waited for 1.064363915s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T13:18:47.594339327Z I0109 13:18:47.594295       1 request.go:601] Waited for 1.597011431s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T13:18:48.793813881Z I0109 13:18:48.793773       1 request.go:601] Waited for 1.194549518s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T13:18:49.794160788Z I0109 13:18:49.794116       1 request.go:601] Waited for 1.197474229s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T13:21:34.608605776Z E0109 13:21:34.608562       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T13:21:35.614708630Z E0109 13:21:35.614667       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T13:21:38.853647144Z I0109 13:21:38.853602       1 request.go:601] Waited for 1.065215555s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T13:21:40.053611803Z I0109 13:21:40.053569       1 request.go:601] Waited for 1.596696718s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T13:21:41.253265690Z I0109 13:21:41.253219       1 request.go:601] Waited for 1.196065925s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T13:21:42.453583391Z I0109 13:21:42.453536       1 request.go:601] Waited for 1.397870583s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T13:22:59.954373365Z I0109 13:22:59.954335       1 request.go:601] Waited for 1.158559381s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2023-01-09T13:23:00.954584173Z I0109 13:23:00.954541       1 request.go:601] Waited for 1.197658317s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-server-ca
2023-01-09T13:23:01.623069227Z I0109 13:23:01.623027       1 externalloadbalancer.go:27] syncing external loadbalancer hostnames: api.sn-loggvls-jsm.qe.devcluster.openshift.com
2023-01-09T13:23:02.554778238Z I0109 13:23:02.554735       1 request.go:601] Waited for 1.111352905s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T13:23:03.165918585Z I0109 13:23:03.165855       1 servicehostname.go:40] syncing servicenetwork hostnames: [172.30.0.1 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local openshift openshift.default openshift.default.svc openshift.default.svc.cluster.local]
2023-01-09T13:23:03.555242587Z I0109 13:23:03.555196       1 request.go:601] Waited for 1.930838158s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2023-01-09T13:23:04.754847464Z I0109 13:23:04.754798       1 request.go:601] Waited for 1.794967912s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver
2023-01-09T13:23:05.954883598Z I0109 13:23:05.954844       1 request.go:601] Waited for 1.397464796s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T13:23:07.554717128Z I0109 13:23:07.554665       1 request.go:601] Waited for 1.042047013s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T13:23:08.555085938Z I0109 13:23:08.555045       1 request.go:601] Waited for 1.198362839s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/client-ca
2023-01-09T13:24:26.826786293Z E0109 13:24:26.826736       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T13:24:27.832850628Z E0109 13:24:27.832810       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T13:24:31.068395973Z I0109 13:24:31.068350       1 request.go:601] Waited for 1.077585651s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2023-01-09T13:24:32.068768689Z I0109 13:24:32.068724       1 request.go:601] Waited for 1.598031065s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T13:27:19.259740712Z E0109 13:27:19.259699       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T13:27:20.266196302Z E0109 13:27:20.266151       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T13:27:23.486488496Z I0109 13:27:23.486440       1 request.go:601] Waited for 1.184511094s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T13:27:24.486914176Z I0109 13:27:24.486872       1 request.go:601] Waited for 1.595047959s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2023-01-09T13:27:25.686793619Z I0109 13:27:25.686746       1 request.go:601] Waited for 1.598219387s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver
2023-01-09T13:30:11.260502362Z E0109 13:30:11.260461       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T13:30:12.267360088Z E0109 13:30:12.267320       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T13:30:15.501317574Z I0109 13:30:15.501279       1 request.go:601] Waited for 1.067500048s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T13:30:16.501746198Z I0109 13:30:16.501663       1 request.go:601] Waited for 1.595090482s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-8-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T13:30:17.701250771Z I0109 13:30:17.701211       1 request.go:601] Waited for 1.193844384s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-8-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T13:30:18.701344677Z I0109 13:30:18.701299       1 request.go:601] Waited for 1.042980245s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2023-01-09T13:30:19.701583151Z I0109 13:30:19.701536       1 request.go:601] Waited for 1.366190922s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2023-01-09T13:32:59.356111858Z I0109 13:32:59.356060       1 request.go:601] Waited for 1.073935797s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2023-01-09T13:33:00.555507788Z I0109 13:33:00.555463       1 request.go:601] Waited for 1.192115885s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2023-01-09T13:33:01.623145125Z I0109 13:33:01.623087       1 externalloadbalancer.go:27] syncing external loadbalancer hostnames: api.sn-loggvls-jsm.qe.devcluster.openshift.com
2023-01-09T13:33:02.555289893Z I0109 13:33:02.555249       1 request.go:601] Waited for 1.113061904s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T13:33:03.166208848Z I0109 13:33:03.166129       1 servicehostname.go:40] syncing servicenetwork hostnames: [172.30.0.1 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local openshift openshift.default openshift.default.svc openshift.default.svc.cluster.local]
2023-01-09T13:33:03.582815787Z E0109 13:33:03.582773       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T13:33:03.756202711Z I0109 13:33:03.756157       1 request.go:601] Waited for 1.992850858s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T13:33:04.588528469Z E0109 13:33:04.588485       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T13:33:04.955734786Z I0109 13:33:04.955696       1 request.go:601] Waited for 1.79436882s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver
2023-01-09T13:33:05.956077008Z I0109 13:33:05.956038       1 request.go:601] Waited for 1.393771707s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/config
2023-01-09T13:33:07.155980011Z I0109 13:33:07.155938       1 request.go:601] Waited for 1.193569592s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-pod
2023-01-09T13:33:08.355929178Z I0109 13:33:08.355888       1 request.go:601] Waited for 1.727997756s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T13:33:09.355973026Z I0109 13:33:09.355922       1 request.go:601] Waited for 1.797620139s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T13:33:10.555890699Z I0109 13:33:10.555843       1 request.go:601] Waited for 1.753534448s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver
2023-01-09T13:33:11.755845904Z I0109 13:33:11.755799       1 request.go:601] Waited for 1.197655231s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver
2023-01-09T13:33:12.756079420Z I0109 13:33:12.756033       1 request.go:601] Waited for 1.197235608s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T13:33:13.955496749Z I0109 13:33:13.955456       1 request.go:601] Waited for 1.195008406s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T13:35:55.993610755Z E0109 13:35:55.993572       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T13:35:57.000166361Z E0109 13:35:57.000121       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T13:36:00.237004980Z I0109 13:36:00.236950       1 request.go:601] Waited for 1.063515039s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2023-01-09T13:36:01.237355811Z I0109 13:36:01.237313       1 request.go:601] Waited for 1.569677815s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2023-01-09T13:36:02.237362432Z I0109 13:36:02.237316       1 request.go:601] Waited for 1.396752534s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T13:36:03.436907870Z I0109 13:36:03.436863       1 request.go:601] Waited for 1.196432298s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T13:36:04.636943697Z I0109 13:36:04.636897       1 request.go:601] Waited for 1.1971988s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T13:41:40.478591853Z E0109 13:41:40.478548       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T13:41:41.484795497Z E0109 13:41:41.484753       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T13:41:44.723094098Z I0109 13:41:44.723051       1 request.go:601] Waited for 1.078101773s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2023-01-09T13:41:45.923288409Z I0109 13:41:45.923243       1 request.go:601] Waited for 1.566499s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2023-01-09T13:41:46.923616201Z I0109 13:41:46.923568       1 request.go:601] Waited for 1.197408851s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-8-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T13:42:59.657378380Z I0109 13:42:59.657337       1 request.go:601] Waited for 1.007333118s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T13:43:00.663983110Z I0109 13:43:00.663939       1 request.go:601] Waited for 1.200754338s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/config
2023-01-09T13:43:01.623856739Z I0109 13:43:01.623806       1 externalloadbalancer.go:27] syncing external loadbalancer hostnames: api.sn-loggvls-jsm.qe.devcluster.openshift.com
2023-01-09T13:43:02.457353428Z I0109 13:43:02.457313       1 request.go:601] Waited for 1.015341447s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T13:43:03.166819837Z I0109 13:43:03.166742       1 servicehostname.go:40] syncing servicenetwork hostnames: [172.30.0.1 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local openshift openshift.default openshift.default.svc openshift.default.svc.cluster.local]
2023-01-09T13:43:03.457714015Z I0109 13:43:03.457668       1 request.go:601] Waited for 1.83254527s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T13:43:04.657143346Z I0109 13:43:04.657098       1 request.go:601] Waited for 1.79117221s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2023-01-09T13:43:05.657864089Z I0109 13:43:05.657822       1 request.go:601] Waited for 1.524329957s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2023-01-09T13:43:09.457306887Z I0109 13:43:09.457264       1 request.go:601] Waited for 1.181563214s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T13:43:10.457447539Z I0109 13:43:10.457397       1 request.go:601] Waited for 1.195169639s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T13:44:32.723159327Z E0109 13:44:32.723120       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T13:44:33.729841129Z E0109 13:44:33.729793       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T13:44:36.963438590Z I0109 13:44:36.963399       1 request.go:601] Waited for 1.074066494s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T13:44:37.963696717Z I0109 13:44:37.963654       1 request.go:601] Waited for 1.594327192s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-pod
2023-01-09T13:44:39.363836139Z I0109 13:44:39.363793       1 request.go:601] Waited for 1.083866936s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T13:44:40.364308243Z I0109 13:44:40.364262       1 request.go:601] Waited for 1.19766407s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T13:44:41.364379909Z I0109 13:44:41.364336       1 request.go:601] Waited for 1.396841193s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T13:47:24.896477701Z E0109 13:47:24.896434       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T13:47:25.902614199Z E0109 13:47:25.902574       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T13:47:29.137312483Z I0109 13:47:29.137269       1 request.go:601] Waited for 1.08014447s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T13:47:30.137635314Z I0109 13:47:30.137591       1 request.go:601] Waited for 1.596571174s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-8-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T13:47:31.337780216Z I0109 13:47:31.337730       1 request.go:601] Waited for 1.197297126s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-8-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T13:52:59.753291794Z I0109 13:52:59.753252       1 request.go:601] Waited for 1.102045019s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T13:53:00.953087604Z I0109 13:53:00.953053       1 request.go:601] Waited for 1.188844434s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T13:53:01.624570484Z I0109 13:53:01.624528       1 externalloadbalancer.go:27] syncing external loadbalancer hostnames: api.sn-loggvls-jsm.qe.devcluster.openshift.com
2023-01-09T13:53:02.553797418Z I0109 13:53:02.553754       1 request.go:601] Waited for 1.111140896s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T13:53:03.167320476Z I0109 13:53:03.167242       1 servicehostname.go:40] syncing servicenetwork hostnames: [172.30.0.1 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local openshift openshift.default openshift.default.svc openshift.default.svc.cluster.local]
2023-01-09T13:53:03.753564484Z I0109 13:53:03.753517       1 request.go:601] Waited for 1.992836527s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T13:53:04.953219882Z I0109 13:53:04.953182       1 request.go:601] Waited for 1.795895122s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver
2023-01-09T13:53:05.953697753Z I0109 13:53:05.953660       1 request.go:601] Waited for 1.59471942s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/client-ca
2023-01-09T13:53:09.501039755Z E0109 13:53:09.500972       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T13:53:10.507506606Z E0109 13:53:10.507467       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T13:53:13.553175280Z I0109 13:53:13.553133       1 request.go:601] Waited for 1.007310014s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T13:53:14.753049703Z I0109 13:53:14.753005       1 request.go:601] Waited for 1.597090146s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-8-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T13:53:15.753773836Z I0109 13:53:15.753722       1 request.go:601] Waited for 1.594003289s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-pod
2023-01-09T13:53:17.353729827Z I0109 13:53:17.353682       1 request.go:601] Waited for 1.078041752s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2023-01-09T13:53:18.753644397Z I0109 13:53:18.753601       1 request.go:601] Waited for 1.082438328s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2023-01-09T13:53:19.952975979Z I0109 13:53:19.952929       1 request.go:601] Waited for 1.397712027s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T13:58:53.972909510Z E0109 13:58:53.972864       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T13:58:54.979207930Z E0109 13:58:54.979163       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T13:58:58.200161588Z I0109 13:58:58.200117       1 request.go:601] Waited for 1.074040673s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2023-01-09T13:58:59.200599196Z I0109 13:58:59.200546       1 request.go:601] Waited for 1.596775217s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-8-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T13:59:00.400925440Z I0109 13:59:00.400872       1 request.go:601] Waited for 1.344127044s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver
2023-01-09T14:01:46.252339459Z E0109 14:01:46.252300       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T14:01:47.258188340Z E0109 14:01:47.258147       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T14:01:50.493446242Z I0109 14:01:50.493402       1 request.go:601] Waited for 1.049666757s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2023-01-09T14:01:51.692481597Z I0109 14:01:51.692442       1 request.go:601] Waited for 1.595951954s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-8-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T14:02:59.763465710Z I0109 14:02:59.763423       1 request.go:601] Waited for 1.111258393s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T14:03:00.963864157Z I0109 14:03:00.963824       1 request.go:601] Waited for 1.189144753s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T14:03:01.625077041Z I0109 14:03:01.625030       1 externalloadbalancer.go:27] syncing external loadbalancer hostnames: api.sn-loggvls-jsm.qe.devcluster.openshift.com
2023-01-09T14:03:02.563547905Z I0109 14:03:02.563501       1 request.go:601] Waited for 1.120885458s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T14:03:03.167765040Z I0109 14:03:03.167702       1 servicehostname.go:40] syncing servicenetwork hostnames: [172.30.0.1 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local openshift openshift.default openshift.default.svc openshift.default.svc.cluster.local]
2023-01-09T14:03:03.763119242Z I0109 14:03:03.763066       1 request.go:601] Waited for 1.992185123s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T14:03:04.963496465Z I0109 14:03:04.963453       1 request.go:601] Waited for 1.79671081s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T14:03:06.164037059Z I0109 14:03:06.163977       1 request.go:601] Waited for 1.197358558s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T14:04:38.533758578Z E0109 14:04:38.533716       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T14:04:39.540282994Z E0109 14:04:39.540239       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T14:04:42.777814080Z I0109 14:04:42.777776       1 request.go:601] Waited for 1.072642921s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2023-01-09T14:04:43.778165971Z I0109 14:04:43.778119       1 request.go:601] Waited for 1.595588878s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-pod
2023-01-09T14:04:45.577778393Z I0109 14:04:45.577737       1 request.go:601] Waited for 1.059893207s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T14:07:30.705767642Z E0109 14:07:30.705723       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T14:07:31.712315353Z E0109 14:07:31.712276       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T14:07:34.949184651Z I0109 14:07:34.949143       1 request.go:601] Waited for 1.0609132s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2023-01-09T14:07:36.148948086Z I0109 14:07:36.148899       1 request.go:601] Waited for 1.567242231s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2023-01-09T14:07:38.149209017Z I0109 14:07:38.149162       1 request.go:601] Waited for 1.006658282s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T14:07:39.548522260Z I0109 14:07:39.548482       1 request.go:601] Waited for 1.164558099s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2023-01-09T14:07:40.548626471Z I0109 14:07:40.548582       1 request.go:601] Waited for 1.194295461s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T14:10:22.993672481Z E0109 14:10:22.993629       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T14:10:24.000000883Z E0109 14:10:23.999941       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T14:10:27.235371576Z I0109 14:10:27.235327       1 request.go:601] Waited for 1.07435485s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T14:10:28.235623608Z I0109 14:10:28.235581       1 request.go:601] Waited for 1.596796713s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-8-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T14:10:29.434957716Z I0109 14:10:29.434907       1 request.go:601] Waited for 1.069055441s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T14:12:59.956717313Z I0109 14:12:59.956680       1 request.go:601] Waited for 1.192436379s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2023-01-09T14:13:00.957249881Z I0109 14:13:00.957200       1 request.go:601] Waited for 1.195495255s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/trusted-ca-bundle
2023-01-09T14:13:01.625834781Z I0109 14:13:01.625783       1 externalloadbalancer.go:27] syncing external loadbalancer hostnames: api.sn-loggvls-jsm.qe.devcluster.openshift.com
2023-01-09T14:13:02.556689081Z I0109 14:13:02.556649       1 request.go:601] Waited for 1.113125465s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T14:13:03.168398659Z I0109 14:13:03.168331       1 servicehostname.go:40] syncing servicenetwork hostnames: [172.30.0.1 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local openshift openshift.default openshift.default.svc openshift.default.svc.cluster.local]
2023-01-09T14:13:03.557545097Z I0109 14:13:03.557505       1 request.go:601] Waited for 1.930843704s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T14:13:04.757732567Z I0109 14:13:04.757687       1 request.go:601] Waited for 1.797391477s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T14:13:05.957202798Z I0109 14:13:05.957165       1 request.go:601] Waited for 1.195884353s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T14:13:15.309437053Z E0109 14:13:15.309393       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T14:13:16.316417998Z E0109 14:13:16.316379       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T14:13:19.489042299Z I0109 14:13:19.488984       1 request.go:601] Waited for 1.132558292s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-8-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T14:13:20.688938914Z I0109 14:13:20.688885       1 request.go:601] Waited for 1.398239921s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T14:13:21.888754519Z I0109 14:13:21.888713       1 request.go:601] Waited for 1.352549351s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver
2023-01-09T14:16:07.501317170Z E0109 14:16:07.501266       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T14:16:08.507424192Z E0109 14:16:08.507379       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T14:16:11.744419489Z I0109 14:16:11.744377       1 request.go:601] Waited for 1.07414967s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T14:16:12.943740281Z I0109 14:16:12.943699       1 request.go:601] Waited for 1.597031795s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver
2023-01-09T14:18:59.747492817Z E0109 14:18:59.747446       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T14:19:00.753943983Z E0109 14:19:00.753900       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T14:19:03.989406312Z I0109 14:19:03.989363       1 request.go:601] Waited for 1.074031347s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T14:19:05.189281212Z I0109 14:19:05.189241       1 request.go:601] Waited for 1.597033019s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/client-ca
2023-01-09T14:19:06.389154311Z I0109 14:19:06.389112       1 request.go:601] Waited for 1.196832567s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-server-ca
2023-01-09T14:21:52.033070600Z E0109 14:21:52.032980       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T14:21:53.039593819Z E0109 14:21:53.039552       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T14:21:56.105622102Z I0109 14:21:56.105583       1 request.go:601] Waited for 1.021750113s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/config
2023-01-09T14:21:57.105827223Z I0109 14:21:57.105784       1 request.go:601] Waited for 1.597030924s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T14:21:58.505425712Z I0109 14:21:58.505384       1 request.go:601] Waited for 1.089684236s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T14:21:59.505475810Z I0109 14:21:59.505427       1 request.go:601] Waited for 1.396407434s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T14:22:00.505847230Z I0109 14:22:00.505803       1 request.go:601] Waited for 1.197701374s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver
2023-01-09T14:22:59.760504378Z I0109 14:22:59.760459       1 request.go:601] Waited for 1.107628088s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T14:23:00.960393077Z I0109 14:23:00.960354       1 request.go:601] Waited for 1.191751036s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T14:23:01.626199961Z I0109 14:23:01.626151       1 externalloadbalancer.go:27] syncing external loadbalancer hostnames: api.sn-loggvls-jsm.qe.devcluster.openshift.com
2023-01-09T14:23:02.561028633Z I0109 14:23:02.560945       1 request.go:601] Waited for 1.116896538s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T14:23:03.169044404Z I0109 14:23:03.168955       1 servicehostname.go:40] syncing servicenetwork hostnames: [172.30.0.1 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local openshift openshift.default openshift.default.svc openshift.default.svc.cluster.local]
2023-01-09T14:23:03.760877192Z I0109 14:23:03.760835       1 request.go:601] Waited for 1.991723064s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T14:23:04.760963334Z I0109 14:23:04.760915       1 request.go:601] Waited for 1.79518692s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T14:23:05.761054744Z I0109 14:23:05.761012       1 request.go:601] Waited for 1.390685696s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2023-01-09T14:24:44.146683873Z E0109 14:24:44.146645       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T14:24:45.152837058Z E0109 14:24:45.152796       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T14:24:48.386173400Z I0109 14:24:48.386131       1 request.go:601] Waited for 1.0808654s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T14:24:49.386801179Z I0109 14:24:49.386760       1 request.go:601] Waited for 1.597003791s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T14:24:50.586335232Z I0109 14:24:50.586288       1 request.go:601] Waited for 1.196809049s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T14:27:36.531196992Z E0109 14:27:36.531160       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T14:27:37.537085854Z E0109 14:27:37.537048       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T14:27:40.861405968Z I0109 14:27:40.861358       1 request.go:601] Waited for 1.167620651s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2023-01-09T14:27:42.060727501Z I0109 14:27:42.060688       1 request.go:601] Waited for 1.594173461s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T14:27:44.661339916Z I0109 14:27:44.661291       1 request.go:601] Waited for 1.052355653s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T14:30:28.694954180Z E0109 14:30:28.694908       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T14:30:29.700756593Z E0109 14:30:29.700715       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T14:30:32.934980159Z I0109 14:30:32.934931       1 request.go:601] Waited for 1.076702494s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2023-01-09T14:30:33.935723086Z I0109 14:30:33.935673       1 request.go:601] Waited for 1.597224181s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T14:30:35.135356166Z I0109 14:30:35.135310       1 request.go:601] Waited for 1.195948922s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T14:30:38.935867340Z I0109 14:30:38.935825       1 request.go:601] Waited for 1.134957084s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T14:32:59.722766377Z I0109 14:32:59.722727       1 request.go:601] Waited for 1.069440816s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T14:33:00.922516165Z I0109 14:33:00.922470       1 request.go:601] Waited for 1.191641781s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T14:33:01.626547585Z I0109 14:33:01.626501       1 externalloadbalancer.go:27] syncing external loadbalancer hostnames: api.sn-loggvls-jsm.qe.devcluster.openshift.com
2023-01-09T14:33:02.522167932Z I0109 14:33:02.522125       1 request.go:601] Waited for 1.077434803s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T14:33:03.169880456Z I0109 14:33:03.169813       1 servicehostname.go:40] syncing servicenetwork hostnames: [172.30.0.1 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local openshift openshift.default openshift.default.svc openshift.default.svc.cluster.local]
2023-01-09T14:33:03.522782894Z I0109 14:33:03.522740       1 request.go:601] Waited for 1.895467942s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver
2023-01-09T14:33:04.722947601Z I0109 14:33:04.722906       1 request.go:601] Waited for 1.795627285s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2023-01-09T14:33:05.922550125Z I0109 14:33:05.922510       1 request.go:601] Waited for 1.389848898s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T14:33:20.953855385Z E0109 14:33:20.953802       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T14:33:21.960475726Z E0109 14:33:21.960434       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T14:33:25.122401742Z I0109 14:33:25.122361       1 request.go:601] Waited for 1.004516708s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T14:33:26.322008507Z I0109 14:33:26.321950       1 request.go:601] Waited for 1.597293954s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T14:33:29.522420648Z I0109 14:33:29.522369       1 request.go:601] Waited for 1.078188622s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T14:36:13.143550864Z E0109 14:36:13.143503       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T14:36:14.150384826Z E0109 14:36:14.150338       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T14:36:17.244167902Z I0109 14:36:17.244123       1 request.go:601] Waited for 1.057295501s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-8-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T14:36:18.444324525Z I0109 14:36:18.444281       1 request.go:601] Waited for 1.792694227s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2023-01-09T14:36:19.644272330Z I0109 14:36:19.644227       1 request.go:601] Waited for 1.797678436s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver
2023-01-09T14:36:20.844387117Z I0109 14:36:20.844341       1 request.go:601] Waited for 1.398152682s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T14:41:57.657565715Z E0109 14:41:57.657527       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T14:41:58.664066598Z E0109 14:41:58.664028       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T14:42:01.884270010Z I0109 14:42:01.884218       1 request.go:601] Waited for 1.076082925s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2023-01-09T14:42:02.884849110Z I0109 14:42:02.884806       1 request.go:601] Waited for 1.594553165s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-8-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T14:42:04.084691564Z I0109 14:42:04.084625       1 request.go:601] Waited for 1.196675514s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-8-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T14:42:59.959644957Z I0109 14:42:59.959596       1 request.go:601] Waited for 1.172270058s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2023-01-09T14:43:01.159493383Z I0109 14:43:01.159451       1 request.go:601] Waited for 1.154128092s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver
2023-01-09T14:43:01.626820411Z I0109 14:43:01.626772       1 externalloadbalancer.go:27] syncing external loadbalancer hostnames: api.sn-loggvls-jsm.qe.devcluster.openshift.com
2023-01-09T14:43:02.559612325Z I0109 14:43:02.559567       1 request.go:601] Waited for 1.114323991s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T14:43:03.170494937Z I0109 14:43:03.170422       1 servicehostname.go:40] syncing servicenetwork hostnames: [172.30.0.1 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local openshift openshift.default openshift.default.svc openshift.default.svc.cluster.local]
2023-01-09T14:43:03.760054418Z I0109 14:43:03.760012       1 request.go:601] Waited for 1.993503291s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2023-01-09T14:43:04.959528345Z I0109 14:43:04.959480       1 request.go:601] Waited for 1.594772847s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2023-01-09T14:43:13.359715612Z I0109 14:43:13.359672       1 request.go:601] Waited for 1.003454816s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/config
2023-01-09T14:44:49.960665934Z E0109 14:44:49.960629       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T14:44:50.966884090Z E0109 14:44:50.966843       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T14:44:54.192449785Z I0109 14:44:54.192410       1 request.go:601] Waited for 1.064190031s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T14:44:55.192714781Z I0109 14:44:55.192674       1 request.go:601] Waited for 1.595266898s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-8-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T14:44:57.592164952Z I0109 14:44:57.592117       1 request.go:601] Waited for 1.16786521s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T14:44:58.592297955Z I0109 14:44:58.592238       1 request.go:601] Waited for 1.395846792s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-8-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T14:47:42.224759237Z E0109 14:47:42.224718       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T14:47:43.231323909Z E0109 14:47:43.231281       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T14:47:46.466762747Z I0109 14:47:46.466723       1 request.go:601] Waited for 1.079617918s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2023-01-09T14:47:47.466942858Z I0109 14:47:47.466897       1 request.go:601] Waited for 1.597567283s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T14:47:49.667471458Z I0109 14:47:49.667428       1 request.go:601] Waited for 1.179285692s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T14:52:59.960136319Z I0109 14:52:59.960088       1 request.go:601] Waited for 1.184544566s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2023-01-09T14:53:00.960866163Z I0109 14:53:00.960824       1 request.go:601] Waited for 1.19669862s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/trusted-ca-bundle
2023-01-09T14:53:01.627302689Z I0109 14:53:01.627263       1 externalloadbalancer.go:27] syncing external loadbalancer hostnames: api.sn-loggvls-jsm.qe.devcluster.openshift.com
2023-01-09T14:53:02.560617285Z I0109 14:53:02.560569       1 request.go:601] Waited for 1.114561502s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T14:53:03.171133842Z I0109 14:53:03.171073       1 servicehostname.go:40] syncing servicenetwork hostnames: [172.30.0.1 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local openshift openshift.default openshift.default.svc openshift.default.svc.cluster.local]
2023-01-09T14:53:03.560701783Z I0109 14:53:03.560656       1 request.go:601] Waited for 1.932236055s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T14:53:04.760710441Z I0109 14:53:04.760666       1 request.go:601] Waited for 1.795675998s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver
2023-01-09T14:53:05.760881052Z I0109 14:53:05.760837       1 request.go:601] Waited for 1.38846412s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T14:53:26.833353574Z E0109 14:53:26.833314       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T14:53:27.839885890Z E0109 14:53:27.839849       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T14:53:31.075056684Z I0109 14:53:31.074984       1 request.go:601] Waited for 1.081361084s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2023-01-09T14:53:32.275415044Z I0109 14:53:32.275370       1 request.go:601] Waited for 1.59777445s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T14:53:38.075314628Z I0109 14:53:38.075272       1 request.go:601] Waited for 1.192869771s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver
2023-01-09T14:56:19.175439795Z E0109 14:56:19.175402       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T14:56:20.181736396Z E0109 14:56:20.181690       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T14:56:23.422447667Z I0109 14:56:23.422406       1 request.go:601] Waited for 1.099941336s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2023-01-09T14:56:24.422438599Z I0109 14:56:24.422399       1 request.go:601] Waited for 1.596344924s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T14:59:11.278528338Z E0109 14:59:11.278484       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T14:59:12.284804824Z E0109 14:59:12.284762       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T14:59:15.505953730Z I0109 14:59:15.505915       1 request.go:601] Waited for 1.062972839s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T14:59:16.706556664Z I0109 14:59:16.706516       1 request.go:601] Waited for 1.595160033s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/client-ca
2023-01-09T14:59:17.905734933Z I0109 14:59:17.905690       1 request.go:601] Waited for 1.589574282s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2023-01-09T14:59:18.906356647Z I0109 14:59:18.906307       1 request.go:601] Waited for 1.196842087s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T14:59:20.106435837Z I0109 14:59:20.106397       1 request.go:601] Waited for 1.368416896s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2023-01-09T15:02:03.588049180Z E0109 15:02:03.587981       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T15:02:04.594327321Z E0109 15:02:04.594275       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T15:02:07.829761106Z I0109 15:02:07.829725       1 request.go:601] Waited for 1.074115386s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T15:02:08.830164874Z I0109 15:02:08.830125       1 request.go:601] Waited for 1.596836816s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/client-ca
2023-01-09T15:02:10.030419201Z I0109 15:02:10.030370       1 request.go:601] Waited for 1.197789166s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-server-ca
2023-01-09T15:02:59.761311766Z I0109 15:02:59.761263       1 request.go:601] Waited for 1.1055767s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T15:03:00.960959232Z I0109 15:03:00.960911       1 request.go:601] Waited for 1.19132915s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T15:03:01.628035735Z I0109 15:03:01.627968       1 externalloadbalancer.go:27] syncing external loadbalancer hostnames: api.sn-loggvls-jsm.qe.devcluster.openshift.com
2023-01-09T15:03:02.560784624Z I0109 15:03:02.560733       1 request.go:601] Waited for 1.113918332s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T15:03:03.171787136Z I0109 15:03:03.171715       1 servicehostname.go:40] syncing servicenetwork hostnames: [172.30.0.1 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local openshift openshift.default openshift.default.svc openshift.default.svc.cluster.local]
2023-01-09T15:03:03.760646043Z I0109 15:03:03.760587       1 request.go:601] Waited for 1.990716371s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T15:03:04.761092014Z I0109 15:03:04.761052       1 request.go:601] Waited for 1.795756132s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2023-01-09T15:03:05.761239875Z I0109 15:03:05.761197       1 request.go:601] Waited for 1.393028573s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/config
2023-01-09T15:03:09.560467709Z I0109 15:03:09.560424       1 request.go:601] Waited for 1.013750789s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T15:03:10.560895810Z I0109 15:03:10.560852       1 request.go:601] Waited for 1.263144356s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T15:04:55.907443055Z E0109 15:04:55.907406       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T15:04:56.914235283Z E0109 15:04:56.914190       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T15:05:00.141254528Z I0109 15:05:00.141217       1 request.go:601] Waited for 1.06705769s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2023-01-09T15:05:01.341043232Z I0109 15:05:01.340986       1 request.go:601] Waited for 1.597123558s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-8-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T15:05:02.541061420Z I0109 15:05:02.541021       1 request.go:601] Waited for 1.110364993s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T15:07:48.021085284Z E0109 15:07:48.021040       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T15:07:49.027353332Z E0109 15:07:49.027316       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T15:07:52.260733780Z I0109 15:07:52.260692       1 request.go:601] Waited for 1.07192688s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T15:07:53.260866970Z I0109 15:07:53.260822       1 request.go:601] Waited for 1.597172705s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-8-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T15:07:54.460744621Z I0109 15:07:54.460705       1 request.go:601] Waited for 1.196709061s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-8-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T15:07:55.460937085Z I0109 15:07:55.460891       1 request.go:601] Waited for 1.197349693s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T15:07:56.461121149Z I0109 15:07:56.461078       1 request.go:601] Waited for 1.165142091s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2023-01-09T15:07:57.661162771Z I0109 15:07:57.661120       1 request.go:601] Waited for 1.151135174s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver
2023-01-09T15:10:40.272626773Z E0109 15:10:40.272589       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T15:10:41.278598362Z E0109 15:10:41.278556       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T15:10:44.504515656Z I0109 15:10:44.504475       1 request.go:601] Waited for 1.071681246s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T15:10:45.704883992Z I0109 15:10:45.704841       1 request.go:601] Waited for 1.597578312s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-8-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T15:13:00.162022414Z I0109 15:13:00.161971       1 request.go:601] Waited for 1.184429674s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2023-01-09T15:13:01.629086465Z I0109 15:13:01.629039       1 externalloadbalancer.go:27] syncing external loadbalancer hostnames: api.sn-loggvls-jsm.qe.devcluster.openshift.com
2023-01-09T15:13:02.561748616Z I0109 15:13:02.561705       1 request.go:601] Waited for 1.114574194s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T15:13:03.172309701Z I0109 15:13:03.172241       1 servicehostname.go:40] syncing servicenetwork hostnames: [172.30.0.1 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local openshift openshift.default openshift.default.svc openshift.default.svc.cluster.local]
2023-01-09T15:13:03.761631078Z I0109 15:13:03.761590       1 request.go:601] Waited for 1.969071257s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2023-01-09T15:13:04.761855700Z I0109 15:13:04.761811       1 request.go:601] Waited for 1.796732005s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T15:13:05.962108691Z I0109 15:13:05.962059       1 request.go:601] Waited for 1.195798982s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T15:13:08.761436241Z I0109 15:13:08.761392       1 request.go:601] Waited for 1.036820474s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T15:13:09.762166019Z I0109 15:13:09.762127       1 request.go:601] Waited for 1.397756693s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-server-ca
2023-01-09T15:13:32.492290552Z E0109 15:13:32.492251       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T15:13:33.498657303Z E0109 15:13:33.498617       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T15:13:36.536480583Z I0109 15:13:36.536442       1 request.go:601] Waited for 1.0006236s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T15:13:37.736630745Z I0109 15:13:37.736588       1 request.go:601] Waited for 1.594143239s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T15:13:38.935860705Z I0109 15:13:38.935821       1 request.go:601] Waited for 1.594610409s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T15:13:39.935867925Z I0109 15:13:39.935827       1 request.go:601] Waited for 1.196509224s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver
2023-01-09T15:16:24.748855423Z E0109 15:16:24.748817       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T15:16:25.755298859Z E0109 15:16:25.755258       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T15:16:28.994756624Z I0109 15:16:28.994719       1 request.go:601] Waited for 1.083496554s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T15:16:29.994822254Z I0109 15:16:29.994782       1 request.go:601] Waited for 1.595742079s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/client-ca
2023-01-09T15:16:31.194489284Z I0109 15:16:31.194446       1 request.go:601] Waited for 1.196467804s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-server-ca
2023-01-09T15:16:36.994104313Z I0109 15:16:36.994060       1 request.go:601] Waited for 1.106188671s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T15:22:09.255473077Z E0109 15:22:09.255423       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T15:22:10.261717630Z E0109 15:22:10.261676       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T15:22:13.497013820Z I0109 15:22:13.496945       1 request.go:601] Waited for 1.074822408s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T15:22:14.497705851Z I0109 15:22:14.497663       1 request.go:601] Waited for 1.597347234s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-8-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T15:22:15.697603141Z I0109 15:22:15.697561       1 request.go:601] Waited for 1.395793859s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T15:22:17.497499157Z I0109 15:22:17.497449       1 request.go:601] Waited for 1.166880334s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2023-01-09T15:22:19.297463683Z I0109 15:22:19.297416       1 request.go:601] Waited for 1.145299012s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver
2023-01-09T15:22:59.961951724Z I0109 15:22:59.961909       1 request.go:601] Waited for 1.185411029s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/client-ca
2023-01-09T15:23:00.962313428Z I0109 15:23:00.962272       1 request.go:601] Waited for 1.153299813s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver
2023-01-09T15:23:01.630136943Z I0109 15:23:01.630093       1 externalloadbalancer.go:27] syncing external loadbalancer hostnames: api.sn-loggvls-jsm.qe.devcluster.openshift.com
2023-01-09T15:23:02.562805186Z I0109 15:23:02.562765       1 request.go:601] Waited for 1.115567398s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T15:23:03.172663797Z I0109 15:23:03.172573       1 servicehostname.go:40] syncing servicenetwork hostnames: [172.30.0.1 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local openshift openshift.default openshift.default.svc openshift.default.svc.cluster.local]
2023-01-09T15:23:03.762758970Z I0109 15:23:03.762710       1 request.go:601] Waited for 1.97055049s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2023-01-09T15:23:04.962428090Z I0109 15:23:04.962385       1 request.go:601] Waited for 1.796875026s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T15:23:06.162365466Z I0109 15:23:06.162309       1 request.go:601] Waited for 1.196822323s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T15:23:07.362512065Z I0109 15:23:07.362468       1 request.go:601] Waited for 1.198354396s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T15:23:09.761763181Z I0109 15:23:09.761714       1 request.go:601] Waited for 1.143904297s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T15:25:01.492794471Z E0109 15:25:01.492742       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T15:25:02.498934118Z E0109 15:25:02.498890       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T15:25:05.735368839Z I0109 15:25:05.735327       1 request.go:601] Waited for 1.06974376s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2023-01-09T15:25:06.735858277Z I0109 15:25:06.735813       1 request.go:601] Waited for 1.597527863s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T15:27:53.781946137Z E0109 15:27:53.781908       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T15:27:54.788358282Z E0109 15:27:54.788321       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T15:27:58.025020224Z I0109 15:27:58.024954       1 request.go:601] Waited for 1.077288318s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T15:27:59.224823341Z I0109 15:27:59.224782       1 request.go:601] Waited for 1.595001803s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-8-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T15:28:00.225008274Z I0109 15:28:00.224947       1 request.go:601] Waited for 1.197346165s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T15:28:01.625310944Z I0109 15:28:01.625259       1 request.go:601] Waited for 1.105920686s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T15:30:46.030304428Z E0109 15:30:46.030262       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T15:30:47.036826119Z E0109 15:30:47.036785       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T15:30:50.272075407Z I0109 15:30:50.272031       1 request.go:601] Waited for 1.074065154s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T15:30:51.472058206Z I0109 15:30:51.471979       1 request.go:601] Waited for 1.581847191s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/client-ca
2023-01-09T15:32:59.673579914Z I0109 15:32:59.673538       1 request.go:601] Waited for 1.015816099s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T15:33:00.873433225Z I0109 15:33:00.873394       1 request.go:601] Waited for 1.192181044s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T15:33:01.630400382Z I0109 15:33:01.630354       1 externalloadbalancer.go:27] syncing external loadbalancer hostnames: api.sn-loggvls-jsm.qe.devcluster.openshift.com
2023-01-09T15:33:02.474102374Z I0109 15:33:02.474054       1 request.go:601] Waited for 1.025990627s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T15:33:03.173416491Z I0109 15:33:03.173346       1 servicehostname.go:40] syncing servicenetwork hostnames: [172.30.0.1 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local openshift openshift.default openshift.default.svc openshift.default.svc.cluster.local]
2023-01-09T15:33:03.674042501Z I0109 15:33:03.673964       1 request.go:601] Waited for 1.992718829s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2023-01-09T15:33:04.873708720Z I0109 15:33:04.873663       1 request.go:601] Waited for 1.797373152s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T15:33:05.874027200Z I0109 15:33:05.873960       1 request.go:601] Waited for 1.370348973s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T15:33:07.073621306Z I0109 15:33:07.073576       1 request.go:601] Waited for 1.397913617s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-server-ca
2023-01-09T15:33:09.674087416Z I0109 15:33:09.674041       1 request.go:601] Waited for 1.018548287s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T15:33:38.216370755Z E0109 15:33:38.216333       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T15:33:39.222262019Z E0109 15:33:39.222223       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T15:33:42.463717643Z I0109 15:33:42.463674       1 request.go:601] Waited for 1.079501741s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2023-01-09T15:33:43.463869396Z I0109 15:33:43.463825       1 request.go:601] Waited for 1.597045606s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T15:36:30.508201409Z E0109 15:36:30.508132       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T15:36:31.513699745Z E0109 15:36:31.513659       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T15:36:34.607868084Z I0109 15:36:34.607819       1 request.go:601] Waited for 1.073053857s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T15:36:35.608047909Z I0109 15:36:35.608001       1 request.go:601] Waited for 1.592706607s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2023-01-09T15:36:36.808088292Z I0109 15:36:36.808044       1 request.go:601] Waited for 1.570002227s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2023-01-09T15:36:39.808450639Z I0109 15:36:39.808406       1 request.go:601] Waited for 1.14116943s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T15:39:22.791748833Z E0109 15:39:22.791710       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T15:39:23.797886227Z E0109 15:39:23.797840       1 degraded_webhook.go:128] x509: certificate signed by unknown authority
2023-01-09T15:39:27.033570782Z I0109 15:39:27.033530       1 request.go:601] Waited for 1.062534058s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2023-01-09T15:39:28.233171387Z I0109 15:39:28.233112       1 request.go:601] Waited for 1.597298575s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/client-ca
2023-01-09T15:39:29.833541623Z I0109 15:39:29.833499       1 request.go:601] Waited for 1.157943292s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2023-01-09T15:39:30.833661946Z I0109 15:39:30.833617       1 request.go:601] Waited for 1.172292584s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2023-01-09T15:39:36.033458918Z I0109 15:39:36.033415       1 request.go:601] Waited for 1.079442683s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
