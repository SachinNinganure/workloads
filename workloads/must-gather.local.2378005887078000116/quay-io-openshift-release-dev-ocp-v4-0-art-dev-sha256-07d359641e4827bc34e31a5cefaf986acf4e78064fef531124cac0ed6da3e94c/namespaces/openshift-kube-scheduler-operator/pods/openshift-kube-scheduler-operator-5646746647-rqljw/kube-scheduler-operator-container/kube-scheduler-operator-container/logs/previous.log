2023-01-09T04:41:01.822467716Z W0109 04:41:01.822359       1 cmd.go:213] Using insecure, self-signed certificates
2023-01-09T04:41:01.822748689Z I0109 04:41:01.822728       1 crypto.go:600] Generating new CA for openshift-cluster-kube-scheduler-operator-signer@1673239261 cert, and key in /tmp/serving-cert-2115128/serving-signer.crt, /tmp/serving-cert-2115128/serving-signer.key
2023-01-09T04:41:03.066234585Z I0109 04:41:03.065744       1 observer_polling.go:159] Starting file observer
2023-01-09T04:41:03.085041716Z I0109 04:41:03.085005       1 builder.go:262] openshift-cluster-kube-scheduler-operator version 4.12.0-202301042354.p0.ge0b6bf9.assembly.stream-e0b6bf9-e0b6bf9c4ddb0da9268d504d23ca2ca11880d970
2023-01-09T04:41:03.086039269Z I0109 04:41:03.085983       1 dynamic_serving_content.go:113] "Loaded a new cert/key pair" name="serving-cert::/tmp/serving-cert-2115128/tls.crt::/tmp/serving-cert-2115128/tls.key"
2023-01-09T04:41:03.642609172Z I0109 04:41:03.642568       1 requestheader_controller.go:244] Loaded a new request header values for RequestHeaderAuthRequestController
2023-01-09T04:41:03.647620991Z I0109 04:41:03.647586       1 maxinflight.go:140] "Initialized nonMutatingChan" len=400
2023-01-09T04:41:03.647697990Z I0109 04:41:03.647686       1 maxinflight.go:146] "Initialized mutatingChan" len=200
2023-01-09T04:41:03.647765035Z I0109 04:41:03.647754       1 maxinflight.go:117] "Set denominator for readonly requests" limit=400
2023-01-09T04:41:03.647802101Z I0109 04:41:03.647791       1 maxinflight.go:121] "Set denominator for mutating requests" limit=200
2023-01-09T04:41:03.655569911Z W0109 04:41:03.655533       1 secure_serving.go:69] Use of insecure cipher 'TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256' detected.
2023-01-09T04:41:03.655631007Z W0109 04:41:03.655619       1 secure_serving.go:69] Use of insecure cipher 'TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256' detected.
2023-01-09T04:41:03.655945203Z I0109 04:41:03.655929       1 genericapiserver.go:480] MuxAndDiscoveryComplete has all endpoints registered and discovery information is complete
2023-01-09T04:41:03.657395695Z I0109 04:41:03.657365       1 leaderelection.go:248] attempting to acquire leader lease openshift-kube-scheduler-operator/openshift-cluster-kube-scheduler-operator-lock...
2023-01-09T04:41:03.661030620Z I0109 04:41:03.660978       1 tlsconfig.go:200] "Loaded serving cert" certName="serving-cert::/tmp/serving-cert-2115128/tls.crt::/tmp/serving-cert-2115128/tls.key" certDetail="\"localhost\" [serving] validServingFor=[localhost] issuer=\"openshift-cluster-kube-scheduler-operator-signer@1673239261\" (2023-01-09 04:41:02 +0000 UTC to 2023-02-08 04:41:03 +0000 UTC (now=2023-01-09 04:41:03.660940472 +0000 UTC))"
2023-01-09T04:41:03.661219778Z I0109 04:41:03.661205       1 named_certificates.go:53] "Loaded SNI cert" index=0 certName="self-signed loopback" certDetail="\"apiserver-loopback-client@1673239263\" [serving] validServingFor=[apiserver-loopback-client] issuer=\"apiserver-loopback-client-ca@1673239263\" (2023-01-09 03:41:03 +0000 UTC to 2024-01-09 03:41:03 +0000 UTC (now=2023-01-09 04:41:03.661180505 +0000 UTC))"
2023-01-09T04:41:03.661262775Z I0109 04:41:03.661252       1 secure_serving.go:210] Serving securely on [::]:8443
2023-01-09T04:41:03.661302920Z I0109 04:41:03.661293       1 genericapiserver.go:585] [graceful-termination] waiting for shutdown to be initiated
2023-01-09T04:41:03.661643901Z I0109 04:41:03.661628       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
2023-01-09T04:41:03.661687137Z I0109 04:41:03.661677       1 shared_informer.go:255] Waiting for caches to sync for RequestHeaderAuthRequestController
2023-01-09T04:41:03.661737704Z I0109 04:41:03.661727       1 dynamic_serving_content.go:132] "Starting controller" name="serving-cert::/tmp/serving-cert-2115128/tls.crt::/tmp/serving-cert-2115128/tls.key"
2023-01-09T04:41:03.661971937Z I0109 04:41:03.661957       1 configmap_cafile_content.go:202] "Starting controller" name="client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file"
2023-01-09T04:41:03.662023634Z I0109 04:41:03.662010       1 shared_informer.go:255] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file
2023-01-09T04:41:03.662085109Z I0109 04:41:03.662075       1 configmap_cafile_content.go:202] "Starting controller" name="client-ca::kube-system::extension-apiserver-authentication::client-ca-file"
2023-01-09T04:41:03.662109875Z I0109 04:41:03.662101       1 shared_informer.go:255] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
2023-01-09T04:41:03.662886574Z I0109 04:41:03.662866       1 tlsconfig.go:240] "Starting DynamicServingCertificateController"
2023-01-09T04:41:03.678420147Z I0109 04:41:03.677186       1 leaderelection.go:258] successfully acquired lease openshift-kube-scheduler-operator/openshift-cluster-kube-scheduler-operator-lock
2023-01-09T04:41:03.696942912Z I0109 04:41:03.694346       1 event.go:285] Event(v1.ObjectReference{Kind:"ConfigMap", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-cluster-kube-scheduler-operator-lock", UID:"bec00702-468e-4305-abac-afabc5555437", APIVersion:"v1", ResourceVersion:"4245", FieldPath:""}): type: 'Normal' reason: 'LeaderElection' openshift-kube-scheduler-operator-5646746647-rqljw_b49c6df6-0e3b-46b1-b572-4a5f788f25c6 became leader
2023-01-09T04:41:03.697781937Z I0109 04:41:03.697688       1 event.go:285] Event(v1.ObjectReference{Kind:"Lease", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-cluster-kube-scheduler-operator-lock", UID:"e3909e67-6ad2-458c-8eb2-01d1d9e8a3e8", APIVersion:"coordination.k8s.io/v1", ResourceVersion:"4248", FieldPath:""}): type: 'Normal' reason: 'LeaderElection' openshift-kube-scheduler-operator-5646746647-rqljw_b49c6df6-0e3b-46b1-b572-4a5f788f25c6 became leader
2023-01-09T04:41:03.731461763Z I0109 04:41:03.731413       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'FastControllerResync' Controller "RevisionController" resync interval is set to 0s which might lead to client request throttling
2023-01-09T04:41:03.732168458Z I0109 04:41:03.732128       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'FastControllerResync' Controller "NodeController" resync interval is set to 0s which might lead to client request throttling
2023-01-09T04:41:03.732205740Z I0109 04:41:03.732186       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'FastControllerResync' Controller "PruneController" resync interval is set to 0s which might lead to client request throttling
2023-01-09T04:41:03.733645024Z I0109 04:41:03.733582       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'FastControllerResync' Controller "LoggingSyncer" resync interval is set to 0s which might lead to client request throttling
2023-01-09T04:41:03.733645024Z I0109 04:41:03.733580       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'FastControllerResync' Controller "GuardController" resync interval is set to 0s which might lead to client request throttling
2023-01-09T04:41:03.733740714Z I0109 04:41:03.733718       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'FastControllerResync' Controller "UnsupportedConfigOverridesController" resync interval is set to 0s which might lead to client request throttling
2023-01-09T04:41:03.734139381Z I0109 04:41:03.734100       1 base_controller.go:67] Waiting for caches to sync for RemoveStaleConditionsController
2023-01-09T04:41:03.734628177Z I0109 04:41:03.734606       1 base_controller.go:67] Waiting for caches to sync for MissingStaticPodController
2023-01-09T04:41:03.734791936Z I0109 04:41:03.734774       1 base_controller.go:67] Waiting for caches to sync for KubeControllerManagerStaticResources
2023-01-09T04:41:03.734818276Z I0109 04:41:03.734798       1 base_controller.go:67] Waiting for caches to sync for ResourceSyncController
2023-01-09T04:41:03.734829660Z I0109 04:41:03.734816       1 base_controller.go:67] Waiting for caches to sync for TargetConfigController
2023-01-09T04:41:03.734839855Z I0109 04:41:03.734831       1 base_controller.go:67] Waiting for caches to sync for ConfigObserver
2023-01-09T04:41:03.734954760Z I0109 04:41:03.734938       1 base_controller.go:67] Waiting for caches to sync for StatusSyncer_kube-scheduler
2023-01-09T04:41:03.735043299Z I0109 04:41:03.735021       1 base_controller.go:67] Waiting for caches to sync for RevisionController
2023-01-09T04:41:03.735174720Z I0109 04:41:03.735163       1 base_controller.go:67] Waiting for caches to sync for InstallerController
2023-01-09T04:41:03.735213876Z I0109 04:41:03.735204       1 base_controller.go:67] Waiting for caches to sync for InstallerStateController
2023-01-09T04:41:03.735252144Z I0109 04:41:03.735243       1 base_controller.go:67] Waiting for caches to sync for StaticPodStateController
2023-01-09T04:41:03.735289683Z I0109 04:41:03.735280       1 base_controller.go:67] Waiting for caches to sync for PruneController
2023-01-09T04:41:03.735326252Z I0109 04:41:03.735317       1 base_controller.go:67] Waiting for caches to sync for NodeController
2023-01-09T04:41:03.735433957Z I0109 04:41:03.735424       1 base_controller.go:67] Waiting for caches to sync for BackingResourceController
2023-01-09T04:41:03.735886149Z I0109 04:41:03.735876       1 base_controller.go:67] Waiting for caches to sync for UnsupportedConfigOverridesController
2023-01-09T04:41:03.735928950Z I0109 04:41:03.735920       1 base_controller.go:67] Waiting for caches to sync for LoggingSyncer
2023-01-09T04:41:03.736177624Z I0109 04:41:03.736154       1 base_controller.go:67] Waiting for caches to sync for GuardController
2023-01-09T04:41:03.736461832Z I0109 04:41:03.736430       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'FastControllerResync' Controller "InstallerController" resync interval is set to 0s which might lead to client request throttling
2023-01-09T04:41:03.762205831Z I0109 04:41:03.762165       1 shared_informer.go:262] Caches are synced for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
2023-01-09T04:41:03.764321430Z I0109 04:41:03.764285       1 shared_informer.go:262] Caches are synced for client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file
2023-01-09T04:41:03.764347281Z I0109 04:41:03.764332       1 shared_informer.go:262] Caches are synced for RequestHeaderAuthRequestController
2023-01-09T04:41:03.764959589Z I0109 04:41:03.764916       1 tlsconfig.go:178] "Loaded client CA" index=0 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"admin-kubeconfig-signer\" [] issuer=\"<self>\" (2023-01-09 04:28:21 +0000 UTC to 2033-01-06 04:28:21 +0000 UTC (now=2023-01-09 04:41:03.764882239 +0000 UTC))"
2023-01-09T04:41:03.765050377Z I0109 04:41:03.764973       1 tlsconfig.go:178] "Loaded client CA" index=1 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"kubelet-signer\" [] issuer=\"<self>\" (2023-01-09 04:28:24 +0000 UTC to 2023-01-10 04:28:24 +0000 UTC (now=2023-01-09 04:41:03.764943653 +0000 UTC))"
2023-01-09T04:41:03.765129740Z I0109 04:41:03.765116       1 tlsconfig.go:178] "Loaded client CA" index=2 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"kube-control-plane-signer\" [] issuer=\"<self>\" (2023-01-09 04:28:24 +0000 UTC to 2024-01-09 04:28:24 +0000 UTC (now=2023-01-09 04:41:03.765090573 +0000 UTC))"
2023-01-09T04:41:03.765190921Z I0109 04:41:03.765179       1 tlsconfig.go:178] "Loaded client CA" index=3 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"kube-apiserver-to-kubelet-signer\" [] issuer=\"<self>\" (2023-01-09 04:28:24 +0000 UTC to 2024-01-09 04:28:24 +0000 UTC (now=2023-01-09 04:41:03.765152695 +0000 UTC))"
2023-01-09T04:41:03.765244125Z I0109 04:41:03.765233       1 tlsconfig.go:178] "Loaded client CA" index=4 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"kubelet-bootstrap-kubeconfig-signer\" [] issuer=\"<self>\" (2023-01-09 04:28:22 +0000 UTC to 2033-01-06 04:28:22 +0000 UTC (now=2023-01-09 04:41:03.765212173 +0000 UTC))"
2023-01-09T04:41:03.765498868Z I0109 04:41:03.765480       1 tlsconfig.go:200] "Loaded serving cert" certName="serving-cert::/tmp/serving-cert-2115128/tls.crt::/tmp/serving-cert-2115128/tls.key" certDetail="\"localhost\" [serving] validServingFor=[localhost] issuer=\"openshift-cluster-kube-scheduler-operator-signer@1673239261\" (2023-01-09 04:41:02 +0000 UTC to 2023-02-08 04:41:03 +0000 UTC (now=2023-01-09 04:41:03.765456177 +0000 UTC))"
2023-01-09T04:41:03.765730403Z I0109 04:41:03.765712       1 named_certificates.go:53] "Loaded SNI cert" index=0 certName="self-signed loopback" certDetail="\"apiserver-loopback-client@1673239263\" [serving] validServingFor=[apiserver-loopback-client] issuer=\"apiserver-loopback-client-ca@1673239263\" (2023-01-09 03:41:03 +0000 UTC to 2024-01-09 03:41:03 +0000 UTC (now=2023-01-09 04:41:03.765689004 +0000 UTC))"
2023-01-09T04:41:03.766024306Z I0109 04:41:03.766005       1 tlsconfig.go:178] "Loaded client CA" index=0 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"admin-kubeconfig-signer\" [] issuer=\"<self>\" (2023-01-09 04:28:21 +0000 UTC to 2033-01-06 04:28:21 +0000 UTC (now=2023-01-09 04:41:03.765961964 +0000 UTC))"
2023-01-09T04:41:03.766131117Z I0109 04:41:03.766116       1 tlsconfig.go:178] "Loaded client CA" index=1 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"kubelet-signer\" [] issuer=\"<self>\" (2023-01-09 04:28:24 +0000 UTC to 2023-01-10 04:28:24 +0000 UTC (now=2023-01-09 04:41:03.766088106 +0000 UTC))"
2023-01-09T04:41:03.766185973Z I0109 04:41:03.766175       1 tlsconfig.go:178] "Loaded client CA" index=2 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"kube-control-plane-signer\" [] issuer=\"<self>\" (2023-01-09 04:28:24 +0000 UTC to 2024-01-09 04:28:24 +0000 UTC (now=2023-01-09 04:41:03.766154543 +0000 UTC))"
2023-01-09T04:41:03.766286541Z I0109 04:41:03.766274       1 tlsconfig.go:178] "Loaded client CA" index=3 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"kube-apiserver-to-kubelet-signer\" [] issuer=\"<self>\" (2023-01-09 04:28:24 +0000 UTC to 2024-01-09 04:28:24 +0000 UTC (now=2023-01-09 04:41:03.766246627 +0000 UTC))"
2023-01-09T04:41:03.778168855Z I0109 04:41:03.778140       1 tlsconfig.go:178] "Loaded client CA" index=4 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"kubelet-bootstrap-kubeconfig-signer\" [] issuer=\"<self>\" (2023-01-09 04:28:22 +0000 UTC to 2033-01-06 04:28:22 +0000 UTC (now=2023-01-09 04:41:03.778101087 +0000 UTC))"
2023-01-09T04:41:03.778256459Z I0109 04:41:03.778241       1 tlsconfig.go:178] "Loaded client CA" index=5 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"aggregator-signer\" [] issuer=\"<self>\" (2023-01-09 04:28:22 +0000 UTC to 2023-01-10 04:28:22 +0000 UTC (now=2023-01-09 04:41:03.778216567 +0000 UTC))"
2023-01-09T04:41:03.784942642Z I0109 04:41:03.784911       1 tlsconfig.go:200] "Loaded serving cert" certName="serving-cert::/tmp/serving-cert-2115128/tls.crt::/tmp/serving-cert-2115128/tls.key" certDetail="\"localhost\" [serving] validServingFor=[localhost] issuer=\"openshift-cluster-kube-scheduler-operator-signer@1673239261\" (2023-01-09 04:41:02 +0000 UTC to 2023-02-08 04:41:03 +0000 UTC (now=2023-01-09 04:41:03.784874877 +0000 UTC))"
2023-01-09T04:41:03.785176927Z I0109 04:41:03.785158       1 named_certificates.go:53] "Loaded SNI cert" index=0 certName="self-signed loopback" certDetail="\"apiserver-loopback-client@1673239263\" [serving] validServingFor=[apiserver-loopback-client] issuer=\"apiserver-loopback-client-ca@1673239263\" (2023-01-09 03:41:03 +0000 UTC to 2024-01-09 03:41:03 +0000 UTC (now=2023-01-09 04:41:03.785133779 +0000 UTC))"
2023-01-09T04:41:03.837025059Z I0109 04:41:03.836448       1 base_controller.go:73] Caches are synced for UnsupportedConfigOverridesController 
2023-01-09T04:41:03.837025059Z I0109 04:41:03.836472       1 base_controller.go:110] Starting #1 worker of UnsupportedConfigOverridesController controller ...
2023-01-09T04:41:03.837083618Z I0109 04:41:03.837045       1 base_controller.go:73] Caches are synced for PruneController 
2023-01-09T04:41:03.837083618Z I0109 04:41:03.837065       1 base_controller.go:110] Starting #1 worker of PruneController controller ...
2023-01-09T04:41:03.837165710Z I0109 04:41:03.837128       1 base_controller.go:73] Caches are synced for BackingResourceController 
2023-01-09T04:41:03.837165710Z I0109 04:41:03.837145       1 base_controller.go:110] Starting #1 worker of BackingResourceController controller ...
2023-01-09T04:41:03.837165710Z I0109 04:41:03.837150       1 base_controller.go:73] Caches are synced for KubeControllerManagerStaticResources 
2023-01-09T04:41:03.837210483Z I0109 04:41:03.837160       1 base_controller.go:110] Starting #1 worker of KubeControllerManagerStaticResources controller ...
2023-01-09T04:41:03.837210483Z I0109 04:41:03.837129       1 base_controller.go:73] Caches are synced for RemoveStaleConditionsController 
2023-01-09T04:41:03.837210483Z I0109 04:41:03.837171       1 base_controller.go:110] Starting #1 worker of RemoveStaleConditionsController controller ...
2023-01-09T04:41:03.837226720Z I0109 04:41:03.837214       1 prune_controller.go:261] No nodes, nothing to prune
2023-01-09T04:41:03.837316959Z I0109 04:41:03.837299       1 base_controller.go:73] Caches are synced for StatusSyncer_kube-scheduler 
2023-01-09T04:41:03.837330140Z I0109 04:41:03.837313       1 base_controller.go:110] Starting #1 worker of StatusSyncer_kube-scheduler controller ...
2023-01-09T04:41:03.837748871Z I0109 04:41:03.837715       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorVersionChanged' clusteroperator/kube-scheduler version "raw-internal" changed from "" to "4.12.0-0.nightly-2023-01-08-142418"
2023-01-09T04:41:03.837765654Z I0109 04:41:03.837750       1 base_controller.go:73] Caches are synced for LoggingSyncer 
2023-01-09T04:41:03.837765654Z I0109 04:41:03.837757       1 base_controller.go:110] Starting #1 worker of LoggingSyncer controller ...
2023-01-09T04:41:03.838078551Z I0109 04:41:03.838016       1 status_controller.go:211] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:41:03Z","reason":"NoData","status":"Unknown","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:41:03Z","reason":"NoData","status":"Unknown","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:03Z","reason":"NoData","status":"Unknown","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:03Z","reason":"NoData","status":"Unknown","type":"Upgradeable"}],"relatedObjects":[{"group":"operator.openshift.io","name":"cluster","resource":"kubeschedulers"},{"group":"config.openshift.io","name":"","resource":"schedulers"},{"group":"","name":"openshift-config","resource":"namespaces"},{"group":"","name":"openshift-config-managed","resource":"namespaces"},{"group":"","name":"openshift-kube-scheduler","resource":"namespaces"},{"group":"","name":"openshift-kube-scheduler-operator","resource":"namespaces"},{"group":"controlplane.operator.openshift.io","name":"","namespace":"openshift-kube-apiserver","resource":"podnetworkconnectivitychecks"}],"versions":[{"name":"raw-internal","version":"4.12.0-0.nightly-2023-01-08-142418"}]}}
2023-01-09T04:41:03.838399253Z I0109 04:41:03.838381       1 base_controller.go:73] Caches are synced for RevisionController 
2023-01-09T04:41:03.838436800Z I0109 04:41:03.838426       1 base_controller.go:110] Starting #1 worker of RevisionController controller ...
2023-01-09T04:41:03.838822946Z I0109 04:41:03.838794       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionTriggered' new revision 1 triggered by "configmap \"kube-scheduler-pod\" not found"
2023-01-09T04:41:03.843258276Z I0109 04:41:03.843230       1 prune_controller.go:261] No nodes, nothing to prune
2023-01-09T04:41:03.845063392Z I0109 04:41:03.845031       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-scheduler changed: Degraded set to Unknown (""),Progressing set to Unknown (""),Available set to Unknown (""),Upgradeable set to Unknown (""),status.relatedObjects changed from [{"operator.openshift.io" "kubeschedulers" "" "cluster"} {"config.openshift.io" "schedulers" "" ""} {"" "namespaces" "" "openshift-config"} {"" "namespaces" "" "openshift-config-managed"} {"" "namespaces" "" "openshift-kube-scheduler-operator"} {"" "namespaces" "" "openshift-kube-scheduler"} {"controlplane.operator.openshift.io" "podnetworkconnectivitychecks" "openshift-kube-scheduler" ""}] to [{"operator.openshift.io" "kubeschedulers" "" "cluster"} {"config.openshift.io" "schedulers" "" ""} {"" "namespaces" "" "openshift-config"} {"" "namespaces" "" "openshift-config-managed"} {"" "namespaces" "" "openshift-kube-scheduler"} {"" "namespaces" "" "openshift-kube-scheduler-operator"} {"controlplane.operator.openshift.io" "podnetworkconnectivitychecks" "openshift-kube-apiserver" ""}],status.versions changed from [] to [{"raw-internal" "4.12.0-0.nightly-2023-01-08-142418"}]
2023-01-09T04:41:03.845122213Z I0109 04:41:03.845094       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorVersionChanged' clusteroperator/kube-scheduler version "raw-internal" changed from "" to "4.12.0-0.nightly-2023-01-08-142418"
2023-01-09T04:41:03.845265130Z I0109 04:41:03.845234       1 status_controller.go:211] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:41:03Z","reason":"NoData","status":"Unknown","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:41:03Z","reason":"NoData","status":"Unknown","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:03Z","reason":"NoData","status":"Unknown","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:03Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"}],"relatedObjects":[{"group":"operator.openshift.io","name":"cluster","resource":"kubeschedulers"},{"group":"config.openshift.io","name":"","resource":"schedulers"},{"group":"","name":"openshift-config","resource":"namespaces"},{"group":"","name":"openshift-config-managed","resource":"namespaces"},{"group":"","name":"openshift-kube-scheduler","resource":"namespaces"},{"group":"","name":"openshift-kube-scheduler-operator","resource":"namespaces"},{"group":"controlplane.operator.openshift.io","name":"","namespace":"openshift-kube-apiserver","resource":"podnetworkconnectivitychecks"}],"versions":[{"name":"raw-internal","version":"4.12.0-0.nightly-2023-01-08-142418"}]}}
2023-01-09T04:41:03.850192718Z E0109 04:41:03.850167       1 base_controller.go:272] StatusSyncer_kube-scheduler reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io "kube-scheduler": the object has been modified; please apply your changes to the latest version and try again
2023-01-09T04:41:03.850564334Z I0109 04:41:03.850540       1 status_controller.go:211] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:41:03Z","reason":"NoData","status":"Unknown","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:41:03Z","reason":"NoData","status":"Unknown","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:03Z","reason":"NoData","status":"Unknown","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:03Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:41:03.859545140Z I0109 04:41:03.859503       1 status_controller.go:211] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:41:03Z","reason":"NoData","status":"Unknown","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:41:03Z","reason":"NoData","status":"Unknown","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:03Z","reason":"NoData","status":"Unknown","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:03Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:41:03.861064412Z I0109 04:41:03.859711       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-scheduler changed: Upgradeable changed from Unknown to True ("All is well")
2023-01-09T04:41:03.863390301Z E0109 04:41:03.863275       1 base_controller.go:272] StatusSyncer_kube-scheduler reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io "kube-scheduler": the object has been modified; please apply your changes to the latest version and try again
2023-01-09T04:41:04.036347911Z I0109 04:41:04.036285       1 base_controller.go:73] Caches are synced for NodeController 
2023-01-09T04:41:04.036347911Z I0109 04:41:04.036317       1 base_controller.go:110] Starting #1 worker of NodeController controller ...
2023-01-09T04:41:04.036775549Z I0109 04:41:04.036713       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'MasterNodeObserved' Observed new master node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:41:04.036775549Z I0109 04:41:04.036758       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'MasterNodeObserved' Observed new master node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:41:04.036799181Z I0109 04:41:04.036770       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'MasterNodeObserved' Observed new master node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:41:04.043682597Z I0109 04:41:04.043654       1 status_controller.go:211] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"NodeControllerDegraded: All master nodes are ready","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:41:03Z","reason":"NoData","status":"Unknown","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:03Z","reason":"NoData","status":"Unknown","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:03Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:41:04.050929810Z I0109 04:41:04.050891       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-scheduler changed: Degraded changed from Unknown to False ("NodeControllerDegraded: All master nodes are ready")
2023-01-09T04:41:04.235927799Z I0109 04:41:04.235892       1 base_controller.go:73] Caches are synced for ConfigObserver 
2023-01-09T04:41:04.235927799Z I0109 04:41:04.235915       1 base_controller.go:110] Starting #1 worker of ConfigObserver controller ...
2023-01-09T04:41:04.236209770Z I0109 04:41:04.236178       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ObserveTLSSecurityProfile' minTLSVersion changed to VersionTLS12
2023-01-09T04:41:04.236229931Z I0109 04:41:04.236205       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ObserveTLSSecurityProfile' cipherSuites changed to ["TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256" "TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256" "TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384" "TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384" "TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256" "TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256"]
2023-01-09T04:41:04.236370554Z I0109 04:41:04.236343       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ObservedConfigChanged' Writing updated observed config:   map[string]interface{}{
2023-01-09T04:41:04.236370554Z + 	"servingInfo": map[string]interface{}{
2023-01-09T04:41:04.236370554Z + 		"cipherSuites": []interface{}{
2023-01-09T04:41:04.236370554Z + 			string("TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256"),
2023-01-09T04:41:04.236370554Z + 			string("TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256"),
2023-01-09T04:41:04.236370554Z + 			string("TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384"),
2023-01-09T04:41:04.236370554Z + 			string("TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384"),
2023-01-09T04:41:04.236370554Z + 			string("TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256"),
2023-01-09T04:41:04.236370554Z + 			string("TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256"),
2023-01-09T04:41:04.236370554Z + 		},
2023-01-09T04:41:04.236370554Z + 		"minTLSVersion": string("VersionTLS12"),
2023-01-09T04:41:04.236370554Z + 	},
2023-01-09T04:41:04.236370554Z   }
2023-01-09T04:41:04.635750486Z I0109 04:41:04.635705       1 base_controller.go:73] Caches are synced for TargetConfigController 
2023-01-09T04:41:04.635750486Z I0109 04:41:04.635736       1 base_controller.go:110] Starting #1 worker of TargetConfigController controller ...
2023-01-09T04:41:04.635801781Z I0109 04:41:04.635717       1 base_controller.go:73] Caches are synced for ResourceSyncController 
2023-01-09T04:41:04.635801781Z I0109 04:41:04.635766       1 base_controller.go:110] Starting #1 worker of ResourceSyncController controller ...
2023-01-09T04:41:04.736430894Z I0109 04:41:04.736391       1 base_controller.go:73] Caches are synced for GuardController 
2023-01-09T04:41:04.736430894Z I0109 04:41:04.736414       1 base_controller.go:110] Starting #1 worker of GuardController controller ...
2023-01-09T04:41:04.743723533Z E0109 04:41:04.743690       1 guard_controller.go:268] Missing operand on node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:41:04.743723533Z E0109 04:41:04.743718       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:41:04.743761931Z E0109 04:41:04.743736       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:41:04.743770528Z I0109 04:41:04.743747       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodDisruptionBudgetCreated' Created PodDisruptionBudget.policy/openshift-kube-scheduler-guard-pdb -n openshift-kube-scheduler because it was missing
2023-01-09T04:41:04.764232638Z E0109 04:41:04.764194       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:41:04.765023743Z I0109 04:41:04.764985       1 status_controller.go:211] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:41:03Z","reason":"NoData","status":"Unknown","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:03Z","reason":"NoData","status":"Unknown","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:03Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:41:04.781217286Z I0109 04:41:04.781149       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-scheduler changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready" to "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]"
2023-01-09T04:41:04.789886680Z E0109 04:41:04.789847       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:41:04.789886680Z E0109 04:41:04.789876       1 guard_controller.go:268] Missing operand on node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:41:04.789912614Z E0109 04:41:04.789891       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:41:04.812055649Z E0109 04:41:04.812020       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal]
2023-01-09T04:41:04.812822283Z I0109 04:41:04.812796       1 status_controller.go:211] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal]","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:41:03Z","reason":"NoData","status":"Unknown","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:03Z","reason":"NoData","status":"Unknown","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:03Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:41:04.826707192Z E0109 04:41:04.826673       1 guard_controller.go:268] Missing operand on node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:41:04.826763941Z E0109 04:41:04.826753       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:41:04.826801270Z E0109 04:41:04.826792       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:41:04.827570850Z I0109 04:41:04.827529       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-scheduler changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]" to "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal]"
2023-01-09T04:41:04.834860228Z I0109 04:41:04.834830       1 base_controller.go:73] Caches are synced for MissingStaticPodController 
2023-01-09T04:41:04.834860228Z I0109 04:41:04.834851       1 base_controller.go:110] Starting #1 worker of MissingStaticPodController controller ...
2023-01-09T04:41:04.835338132Z I0109 04:41:04.835309       1 base_controller.go:73] Caches are synced for StaticPodStateController 
2023-01-09T04:41:04.835338132Z I0109 04:41:04.835327       1 base_controller.go:110] Starting #1 worker of StaticPodStateController controller ...
2023-01-09T04:41:04.835366600Z I0109 04:41:04.835331       1 base_controller.go:73] Caches are synced for InstallerController 
2023-01-09T04:41:04.835366600Z I0109 04:41:04.835347       1 base_controller.go:110] Starting #1 worker of InstallerController controller ...
2023-01-09T04:41:04.835378269Z I0109 04:41:04.835336       1 base_controller.go:73] Caches are synced for InstallerStateController 
2023-01-09T04:41:04.835378269Z I0109 04:41:04.835374       1 base_controller.go:110] Starting #1 worker of InstallerStateController controller ...
2023-01-09T04:41:04.835688560Z I0109 04:41:04.835662       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: kube-scheduler-client-cert-key, configmaps: config-0,kube-scheduler-cert-syncer-kubeconfig-0,kube-scheduler-pod-0,scheduler-kubeconfig-0,serviceaccount-ca-0, secrets: localhost-recovery-client-token-0
2023-01-09T04:41:04.840448508Z I0109 04:41:04.840423       1 status_controller.go:211] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:41:03Z","reason":"NoData","status":"Unknown","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:03Z","reason":"NoData","status":"Unknown","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:03Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:41:04.844102561Z E0109 04:41:04.844079       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:41:04.859800869Z I0109 04:41:04.859765       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-scheduler changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal]" to "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]"
2023-01-09T04:41:04.867040053Z E0109 04:41:04.867008       1 guard_controller.go:268] Missing operand on node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:41:04.867076633Z E0109 04:41:04.867039       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:41:04.867076633Z E0109 04:41:04.867055       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:41:04.867174819Z E0109 04:41:04.867158       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:41:04.909666966Z E0109 04:41:04.909628       1 guard_controller.go:268] Missing operand on node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:41:04.909666966Z E0109 04:41:04.909661       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:41:04.909699048Z E0109 04:41:04.909678       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:41:04.909812555Z E0109 04:41:04.909796       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:41:04.934903483Z I0109 04:41:04.934869       1 request.go:601] Waited for 1.097431978s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/installer-sa
2023-01-09T04:41:04.944004692Z E0109 04:41:04.943959       1 base_controller.go:272] InstallerController reconciliation failed: missing required resources: [secrets: kube-scheduler-client-cert-key, configmaps: config-0,kube-scheduler-cert-syncer-kubeconfig-0,kube-scheduler-pod-0,scheduler-kubeconfig-0,serviceaccount-ca-0, secrets: localhost-recovery-client-token-0]
2023-01-09T04:41:04.944306612Z E0109 04:41:04.944277       1 base_controller.go:272] InstallerController reconciliation failed: missing required resources: [secrets: kube-scheduler-client-cert-key, configmaps: config-0,kube-scheduler-cert-syncer-kubeconfig-0,kube-scheduler-pod-0,scheduler-kubeconfig-0,serviceaccount-ca-0, secrets: localhost-recovery-client-token-0]
2023-01-09T04:41:04.944365909Z I0109 04:41:04.944344       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: kube-scheduler-client-cert-key, configmaps: config-0,kube-scheduler-cert-syncer-kubeconfig-0,kube-scheduler-pod-0,scheduler-kubeconfig-0,serviceaccount-ca-0, secrets: localhost-recovery-client-token-0
2023-01-09T04:41:04.944750867Z I0109 04:41:04.944726       1 status_controller.go:211] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]\nInstallerControllerDegraded: missing required resources: [secrets: kube-scheduler-client-cert-key, configmaps: config-0,kube-scheduler-cert-syncer-kubeconfig-0,kube-scheduler-pod-0,scheduler-kubeconfig-0,serviceaccount-ca-0, secrets: localhost-recovery-client-token-0]","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0","reason":"AsExpected","status":"False","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:03Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:41:04.945707734Z E0109 04:41:04.945683       1 base_controller.go:272] InstallerController reconciliation failed: missing required resources: [secrets: kube-scheduler-client-cert-key, configmaps: config-0,kube-scheduler-cert-syncer-kubeconfig-0,kube-scheduler-pod-0,scheduler-kubeconfig-0,serviceaccount-ca-0, secrets: localhost-recovery-client-token-0]
2023-01-09T04:41:04.945741756Z I0109 04:41:04.945674       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: kube-scheduler-client-cert-key, configmaps: config-0,kube-scheduler-cert-syncer-kubeconfig-0,kube-scheduler-pod-0,scheduler-kubeconfig-0,serviceaccount-ca-0, secrets: localhost-recovery-client-token-0
2023-01-09T04:41:04.949255817Z I0109 04:41:04.949228       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: kube-scheduler-client-cert-key, configmaps: config-0,kube-scheduler-cert-syncer-kubeconfig-0,kube-scheduler-pod-0,scheduler-kubeconfig-0,serviceaccount-ca-0, secrets: localhost-recovery-client-token-0
2023-01-09T04:41:04.949283401Z E0109 04:41:04.949268       1 base_controller.go:272] InstallerController reconciliation failed: missing required resources: [secrets: kube-scheduler-client-cert-key, configmaps: config-0,kube-scheduler-cert-syncer-kubeconfig-0,kube-scheduler-pod-0,scheduler-kubeconfig-0,serviceaccount-ca-0, secrets: localhost-recovery-client-token-0]
2023-01-09T04:41:04.954556127Z I0109 04:41:04.954200       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-scheduler changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]" to "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]\nInstallerControllerDegraded: missing required resources: [secrets: kube-scheduler-client-cert-key, configmaps: config-0,kube-scheduler-cert-syncer-kubeconfig-0,kube-scheduler-pod-0,scheduler-kubeconfig-0,serviceaccount-ca-0, secrets: localhost-recovery-client-token-0]",Progressing changed from Unknown to False ("NodeInstallerProgressing: 3 nodes are at revision 0"),Available changed from Unknown to False ("StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0")
2023-01-09T04:41:04.990506476Z I0109 04:41:04.990379       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: kube-scheduler-client-cert-key, configmaps: config-0,kube-scheduler-cert-syncer-kubeconfig-0,kube-scheduler-pod-0,scheduler-kubeconfig-0,serviceaccount-ca-0, secrets: localhost-recovery-client-token-0
2023-01-09T04:41:04.990506476Z E0109 04:41:04.990451       1 base_controller.go:272] InstallerController reconciliation failed: missing required resources: [secrets: kube-scheduler-client-cert-key, configmaps: config-0,kube-scheduler-cert-syncer-kubeconfig-0,kube-scheduler-pod-0,scheduler-kubeconfig-0,serviceaccount-ca-0, secrets: localhost-recovery-client-token-0]
2023-01-09T04:41:04.992069038Z E0109 04:41:04.992043       1 guard_controller.go:268] Missing operand on node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:41:04.992092807Z E0109 04:41:04.992066       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:41:04.992092807Z E0109 04:41:04.992081       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:41:04.992210152Z E0109 04:41:04.992193       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:41:05.070838549Z E0109 04:41:05.070803       1 base_controller.go:272] InstallerController reconciliation failed: missing required resources: [secrets: kube-scheduler-client-cert-key, configmaps: config-0,kube-scheduler-cert-syncer-kubeconfig-0,kube-scheduler-pod-0,scheduler-kubeconfig-0,serviceaccount-ca-0, secrets: localhost-recovery-client-token-0]
2023-01-09T04:41:05.070838549Z I0109 04:41:05.070785       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: kube-scheduler-client-cert-key, configmaps: config-0,kube-scheduler-cert-syncer-kubeconfig-0,kube-scheduler-pod-0,scheduler-kubeconfig-0,serviceaccount-ca-0, secrets: localhost-recovery-client-token-0
2023-01-09T04:41:05.155405477Z E0109 04:41:05.155373       1 guard_controller.go:268] Missing operand on node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:41:05.155405477Z E0109 04:41:05.155397       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:41:05.155430273Z E0109 04:41:05.155407       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:41:05.155530572Z E0109 04:41:05.155516       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:41:05.231604180Z I0109 04:41:05.231556       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: kube-scheduler-client-cert-key, configmaps: config-0,kube-scheduler-cert-syncer-kubeconfig-0,kube-scheduler-pod-0,scheduler-kubeconfig-0,serviceaccount-ca-0, secrets: localhost-recovery-client-token-0
2023-01-09T04:41:05.231604180Z E0109 04:41:05.231582       1 base_controller.go:272] InstallerController reconciliation failed: missing required resources: [secrets: kube-scheduler-client-cert-key, configmaps: config-0,kube-scheduler-cert-syncer-kubeconfig-0,kube-scheduler-pod-0,scheduler-kubeconfig-0,serviceaccount-ca-0, secrets: localhost-recovery-client-token-0]
2023-01-09T04:41:05.338422264Z I0109 04:41:05.338379       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/revision-status-1 -n openshift-kube-scheduler because it was missing
2023-01-09T04:41:05.348279163Z E0109 04:41:05.348235       1 base_controller.go:272] InstallerController reconciliation failed: missing required resources: [secrets: kube-scheduler-client-cert-key, configmaps: config-0,kube-scheduler-cert-syncer-kubeconfig-0,kube-scheduler-pod-0,scheduler-kubeconfig-0,serviceaccount-ca-0, secrets: localhost-recovery-client-token-0]
2023-01-09T04:41:05.348310826Z I0109 04:41:05.348275       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: kube-scheduler-client-cert-key, configmaps: config-0,kube-scheduler-cert-syncer-kubeconfig-0,kube-scheduler-pod-0,scheduler-kubeconfig-0,serviceaccount-ca-0, secrets: localhost-recovery-client-token-0
2023-01-09T04:41:05.348548593Z I0109 04:41:05.348527       1 status_controller.go:211] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]\nInstallerControllerDegraded: missing required resources: [secrets: kube-scheduler-client-cert-key, configmaps: config-0,kube-scheduler-cert-syncer-kubeconfig-0,kube-scheduler-pod-0,scheduler-kubeconfig-0,serviceaccount-ca-0, secrets: localhost-recovery-client-token-0]\nRevisionControllerDegraded: configmaps \"kube-scheduler-pod\" not found","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0","reason":"AsExpected","status":"False","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:03Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:41:05.357684402Z I0109 04:41:05.357639       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-scheduler changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]\nInstallerControllerDegraded: missing required resources: [secrets: kube-scheduler-client-cert-key, configmaps: config-0,kube-scheduler-cert-syncer-kubeconfig-0,kube-scheduler-pod-0,scheduler-kubeconfig-0,serviceaccount-ca-0, secrets: localhost-recovery-client-token-0]" to "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]\nInstallerControllerDegraded: missing required resources: [secrets: kube-scheduler-client-cert-key, configmaps: config-0,kube-scheduler-cert-syncer-kubeconfig-0,kube-scheduler-pod-0,scheduler-kubeconfig-0,serviceaccount-ca-0, secrets: localhost-recovery-client-token-0]\nRevisionControllerDegraded: configmaps \"kube-scheduler-pod\" not found"
2023-01-09T04:41:05.359173779Z I0109 04:41:05.359139       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionTriggered' new revision 2 triggered by "configmap \"kube-scheduler-pod\" not found"
2023-01-09T04:41:05.359266061Z I0109 04:41:05.359251       1 prune_controller.go:269] Nothing to prune
2023-01-09T04:41:05.360144629Z I0109 04:41:05.360107       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: kube-scheduler-client-cert-key, configmaps: config-1,kube-scheduler-cert-syncer-kubeconfig-1,kube-scheduler-pod-1,scheduler-kubeconfig-1,serviceaccount-ca-1, secrets: localhost-recovery-client-token-1
2023-01-09T04:41:05.366733599Z E0109 04:41:05.366706       1 base_controller.go:272] InstallerController reconciliation failed: missing required resources: [secrets: kube-scheduler-client-cert-key, configmaps: config-1,kube-scheduler-cert-syncer-kubeconfig-1,kube-scheduler-pod-1,scheduler-kubeconfig-1,serviceaccount-ca-1, secrets: localhost-recovery-client-token-1]
2023-01-09T04:41:05.367067090Z I0109 04:41:05.367035       1 prune_controller.go:269] Nothing to prune
2023-01-09T04:41:05.367151889Z I0109 04:41:05.367121       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: kube-scheduler-client-cert-key, configmaps: config-1,kube-scheduler-cert-syncer-kubeconfig-1,kube-scheduler-pod-1,scheduler-kubeconfig-1,serviceaccount-ca-1, secrets: localhost-recovery-client-token-1
2023-01-09T04:41:05.367185152Z E0109 04:41:05.367166       1 base_controller.go:272] InstallerController reconciliation failed: missing required resources: [secrets: kube-scheduler-client-cert-key, configmaps: config-1,kube-scheduler-cert-syncer-kubeconfig-1,kube-scheduler-pod-1,scheduler-kubeconfig-1,serviceaccount-ca-1, secrets: localhost-recovery-client-token-1]
2023-01-09T04:41:05.367326807Z I0109 04:41:05.367305       1 status_controller.go:211] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]\nInstallerControllerDegraded: missing required resources: [secrets: kube-scheduler-client-cert-key, configmaps: config-1,kube-scheduler-cert-syncer-kubeconfig-1,kube-scheduler-pod-1,scheduler-kubeconfig-1,serviceaccount-ca-1, secrets: localhost-recovery-client-token-1]\nRevisionControllerDegraded: configmaps \"kube-scheduler-pod\" not found","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 1","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 1","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:03Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:41:05.373565897Z I0109 04:41:05.373536       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-scheduler changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]\nInstallerControllerDegraded: missing required resources: [secrets: kube-scheduler-client-cert-key, configmaps: config-0,kube-scheduler-cert-syncer-kubeconfig-0,kube-scheduler-pod-0,scheduler-kubeconfig-0,serviceaccount-ca-0, secrets: localhost-recovery-client-token-0]\nRevisionControllerDegraded: configmaps \"kube-scheduler-pod\" not found" to "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]\nInstallerControllerDegraded: missing required resources: [secrets: kube-scheduler-client-cert-key, configmaps: config-1,kube-scheduler-cert-syncer-kubeconfig-1,kube-scheduler-pod-1,scheduler-kubeconfig-1,serviceaccount-ca-1, secrets: localhost-recovery-client-token-1]\nRevisionControllerDegraded: configmaps \"kube-scheduler-pod\" not found",Progressing changed from False to True ("NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 1"),Available message changed from "StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0" to "StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 1"
2023-01-09T04:41:05.485138727Z E0109 04:41:05.485100       1 guard_controller.go:268] Missing operand on node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:41:05.485138727Z E0109 04:41:05.485124       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:41:05.485170702Z E0109 04:41:05.485135       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:41:05.485264440Z E0109 04:41:05.485252       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:41:05.549926294Z I0109 04:41:05.549889       1 prune_controller.go:269] Nothing to prune
2023-01-09T04:41:05.550118195Z I0109 04:41:05.550093       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: kube-scheduler-client-cert-key, configmaps: config-1,kube-scheduler-cert-syncer-kubeconfig-1,kube-scheduler-pod-1,scheduler-kubeconfig-1,serviceaccount-ca-1, secrets: localhost-recovery-client-token-1
2023-01-09T04:41:05.550183056Z E0109 04:41:05.550165       1 base_controller.go:272] InstallerController reconciliation failed: missing required resources: [secrets: kube-scheduler-client-cert-key, configmaps: config-1,kube-scheduler-cert-syncer-kubeconfig-1,kube-scheduler-pod-1,scheduler-kubeconfig-1,serviceaccount-ca-1, secrets: localhost-recovery-client-token-1]
2023-01-09T04:41:05.552748951Z I0109 04:41:05.552714       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: kube-scheduler-client-cert-key, configmaps: config-1,kube-scheduler-cert-syncer-kubeconfig-1,kube-scheduler-pod-1,scheduler-kubeconfig-1,serviceaccount-ca-1, secrets: localhost-recovery-client-token-1
2023-01-09T04:41:05.552817521Z E0109 04:41:05.552798       1 base_controller.go:272] InstallerController reconciliation failed: missing required resources: [secrets: kube-scheduler-client-cert-key, configmaps: config-1,kube-scheduler-cert-syncer-kubeconfig-1,kube-scheduler-pod-1,scheduler-kubeconfig-1,serviceaccount-ca-1, secrets: localhost-recovery-client-token-1]
2023-01-09T04:41:05.934922256Z I0109 04:41:05.934878       1 request.go:601] Waited for 1.099411184s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller
2023-01-09T04:41:05.945321740Z I0109 04:41:05.945290       1 prune_controller.go:269] Nothing to prune
2023-01-09T04:41:05.945638464Z I0109 04:41:05.945599       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: kube-scheduler-client-cert-key, configmaps: config-1,kube-scheduler-cert-syncer-kubeconfig-1,kube-scheduler-pod-1,scheduler-kubeconfig-1,serviceaccount-ca-1, secrets: localhost-recovery-client-token-1
2023-01-09T04:41:05.945709486Z E0109 04:41:05.945691       1 base_controller.go:272] InstallerController reconciliation failed: missing required resources: [secrets: kube-scheduler-client-cert-key, configmaps: config-1,kube-scheduler-cert-syncer-kubeconfig-1,kube-scheduler-pod-1,scheduler-kubeconfig-1,serviceaccount-ca-1, secrets: localhost-recovery-client-token-1]
2023-01-09T04:41:06.127759243Z E0109 04:41:06.127718       1 guard_controller.go:268] Missing operand on node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:41:06.127759243Z E0109 04:41:06.127741       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:41:06.127759243Z E0109 04:41:06.127752       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:41:06.127890616Z E0109 04:41:06.127876       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:41:06.338784694Z I0109 04:41:06.338740       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ServiceAccountCreated' Created ServiceAccount/installer-sa -n openshift-kube-scheduler because it was missing
2023-01-09T04:41:06.344265458Z I0109 04:41:06.344230       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ClusterRoleBindingCreated' Created ClusterRoleBinding.rbac.authorization.k8s.io/system:openshift:operator:openshift-kube-scheduler-installer because it was missing
2023-01-09T04:41:06.353825767Z I0109 04:41:06.353798       1 prune_controller.go:269] Nothing to prune
2023-01-09T04:41:06.354147388Z I0109 04:41:06.354111       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: kube-scheduler-client-cert-key, configmaps: config-1,kube-scheduler-cert-syncer-kubeconfig-1,kube-scheduler-pod-1,scheduler-kubeconfig-1,serviceaccount-ca-1, secrets: localhost-recovery-client-token-1
2023-01-09T04:41:06.354183091Z E0109 04:41:06.354167       1 base_controller.go:272] InstallerController reconciliation failed: missing required resources: [secrets: kube-scheduler-client-cert-key, configmaps: config-1,kube-scheduler-cert-syncer-kubeconfig-1,kube-scheduler-pod-1,scheduler-kubeconfig-1,serviceaccount-ca-1, secrets: localhost-recovery-client-token-1]
2023-01-09T04:41:06.538517704Z I0109 04:41:06.538469       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NamespaceUpdated' Updated Namespace/openshift-kube-scheduler because it changed
2023-01-09T04:41:06.737864210Z I0109 04:41:06.737813       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/revision-status-2 -n openshift-kube-scheduler because it was missing
2023-01-09T04:41:06.738052920Z I0109 04:41:06.738015       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionTriggered' new revision 2 triggered by "configmap \"kube-scheduler-pod\" not found"
2023-01-09T04:41:06.758588139Z I0109 04:41:06.758538       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionTriggered' new revision 2 triggered by "configmap \"kube-scheduler-pod\" not found"
2023-01-09T04:41:06.838930118Z I0109 04:41:06.838880       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionTriggered' new revision 2 triggered by "configmap \"kube-scheduler-pod\" not found"
2023-01-09T04:41:07.000186549Z I0109 04:41:07.000126       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionTriggered' new revision 2 triggered by "configmap \"kube-scheduler-pod\" not found"
2023-01-09T04:41:07.134818623Z I0109 04:41:07.134784       1 request.go:601] Waited for 1.392473038s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/configmaps
2023-01-09T04:41:07.139865794Z I0109 04:41:07.139813       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/config -n openshift-kube-scheduler because it was missing
2023-01-09T04:41:07.140034783Z I0109 04:41:07.140007       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionTriggered' new revision 2 triggered by "configmap \"kube-scheduler-pod\" not found"
2023-01-09T04:41:07.321396287Z I0109 04:41:07.321348       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionTriggered' new revision 2 triggered by "configmap \"kube-scheduler-pod\" not found"
2023-01-09T04:41:07.411474446Z E0109 04:41:07.411437       1 guard_controller.go:268] Missing operand on node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:41:07.411474446Z E0109 04:41:07.411460       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:41:07.411526851Z E0109 04:41:07.411471       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:41:07.411615243Z E0109 04:41:07.411602       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:41:07.739210248Z I0109 04:41:07.739155       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionTriggered' new revision 2 triggered by "configmap \"kube-scheduler-pod\" not found"
2023-01-09T04:41:07.739256744Z I0109 04:41:07.739203       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-scheduler-cert-syncer-kubeconfig -n openshift-kube-scheduler because it was missing
2023-01-09T04:41:07.747384820Z I0109 04:41:07.747347       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RoleBindingCreated' Created RoleBinding.rbac.authorization.k8s.io/system:openshift:leader-locking-kube-scheduler -n kube-system because it was missing
2023-01-09T04:41:07.752532857Z I0109 04:41:07.752492       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ClusterRoleBindingCreated' Created ClusterRoleBinding.rbac.authorization.k8s.io/system:openshift:operator:kube-scheduler:public-2 because it was missing
2023-01-09T04:41:07.757380945Z I0109 04:41:07.757326       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RoleCreated' Created Role.rbac.authorization.k8s.io/system:openshift:sa-listing-configmaps -n openshift-kube-scheduler because it was missing
2023-01-09T04:41:07.763014375Z I0109 04:41:07.762976       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RoleBindingCreated' Created RoleBinding.rbac.authorization.k8s.io/system:openshift:sa-listing-configmaps -n openshift-kube-scheduler because it was missing
2023-01-09T04:41:08.332963167Z I0109 04:41:08.332922       1 request.go:601] Waited for 1.192975043s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler-operator/events
2023-01-09T04:41:08.345286814Z I0109 04:41:08.345251       1 prune_controller.go:269] Nothing to prune
2023-01-09T04:41:08.345457015Z I0109 04:41:08.345417       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionTriggered' new revision 2 triggered by "configmap \"kube-scheduler-pod\" not found"
2023-01-09T04:41:08.345509457Z I0109 04:41:08.345487       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: kube-scheduler-client-cert-key, configmaps: config-1,kube-scheduler-cert-syncer-kubeconfig-1,kube-scheduler-pod-1,scheduler-kubeconfig-1,serviceaccount-ca-1, secrets: localhost-recovery-client-token-1
2023-01-09T04:41:08.345589370Z E0109 04:41:08.345572       1 base_controller.go:272] InstallerController reconciliation failed: missing required resources: [secrets: kube-scheduler-client-cert-key, configmaps: config-1,kube-scheduler-cert-syncer-kubeconfig-1,kube-scheduler-pod-1,scheduler-kubeconfig-1,serviceaccount-ca-1, secrets: localhost-recovery-client-token-1]
2023-01-09T04:41:08.602081495Z I0109 04:41:08.602025       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionTriggered' new revision 2 triggered by "configmap \"kube-scheduler-pod\" not found"
2023-01-09T04:41:08.733776323Z E0109 04:41:08.733744       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:41:08.733776323Z E0109 04:41:08.733766       1 guard_controller.go:268] Missing operand on node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:41:08.733799258Z E0109 04:41:08.733776       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:41:08.741775155Z E0109 04:41:08.741744       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal]
2023-01-09T04:41:08.742035766Z I0109 04:41:08.742004       1 prune_controller.go:269] Nothing to prune
2023-01-09T04:41:08.742188097Z I0109 04:41:08.742152       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionTriggered' new revision 2 triggered by "configmap \"kube-scheduler-pod\" not found"
2023-01-09T04:41:08.742268900Z I0109 04:41:08.742246       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: kube-scheduler-client-cert-key, configmaps: config-1,kube-scheduler-cert-syncer-kubeconfig-1,kube-scheduler-pod-1,scheduler-kubeconfig-1,serviceaccount-ca-1, secrets: localhost-recovery-client-token-1
2023-01-09T04:41:08.742335629Z E0109 04:41:08.742319       1 base_controller.go:272] InstallerController reconciliation failed: missing required resources: [secrets: kube-scheduler-client-cert-key, configmaps: config-1,kube-scheduler-cert-syncer-kubeconfig-1,kube-scheduler-pod-1,scheduler-kubeconfig-1,serviceaccount-ca-1, secrets: localhost-recovery-client-token-1]
2023-01-09T04:41:08.742426127Z I0109 04:41:08.742410       1 status_controller.go:211] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal]\nInstallerControllerDegraded: missing required resources: [secrets: kube-scheduler-client-cert-key, configmaps: config-1,kube-scheduler-cert-syncer-kubeconfig-1,kube-scheduler-pod-1,scheduler-kubeconfig-1,serviceaccount-ca-1, secrets: localhost-recovery-client-token-1]\nRevisionControllerDegraded: configmaps \"kube-scheduler-pod\" not found","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 1","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 1","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:03Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:41:08.750049924Z I0109 04:41:08.749986       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-scheduler changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]\nInstallerControllerDegraded: missing required resources: [secrets: kube-scheduler-client-cert-key, configmaps: config-1,kube-scheduler-cert-syncer-kubeconfig-1,kube-scheduler-pod-1,scheduler-kubeconfig-1,serviceaccount-ca-1, secrets: localhost-recovery-client-token-1]\nRevisionControllerDegraded: configmaps \"kube-scheduler-pod\" not found" to "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal]\nInstallerControllerDegraded: missing required resources: [secrets: kube-scheduler-client-cert-key, configmaps: config-1,kube-scheduler-cert-syncer-kubeconfig-1,kube-scheduler-pod-1,scheduler-kubeconfig-1,serviceaccount-ca-1, secrets: localhost-recovery-client-token-1]\nRevisionControllerDegraded: configmaps \"kube-scheduler-pod\" not found"
2023-01-09T04:41:09.138799350Z I0109 04:41:09.138748       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionTriggered' new revision 2 triggered by "configmap \"kube-scheduler-pod\" not found"
2023-01-09T04:41:09.138841074Z I0109 04:41:09.138826       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/serviceaccount-ca -n openshift-kube-scheduler because it was missing
2023-01-09T04:41:09.741535840Z I0109 04:41:09.741482       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ServiceCreated' Created Service/scheduler -n openshift-kube-scheduler because it was missing
2023-01-09T04:41:09.974007492Z E0109 04:41:09.973951       1 guard_controller.go:268] Missing operand on node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:41:09.974007492Z E0109 04:41:09.973975       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:41:09.974007492Z E0109 04:41:09.973985       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:41:09.983301424Z E0109 04:41:09.983270       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:41:09.983587631Z I0109 04:41:09.983556       1 prune_controller.go:269] Nothing to prune
2023-01-09T04:41:09.983742264Z I0109 04:41:09.983708       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionTriggered' new revision 2 triggered by "configmap \"kube-scheduler-pod\" not found"
2023-01-09T04:41:09.983819030Z I0109 04:41:09.983789       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: kube-scheduler-client-cert-key, configmaps: config-1,kube-scheduler-cert-syncer-kubeconfig-1,kube-scheduler-pod-1,scheduler-kubeconfig-1,serviceaccount-ca-1, secrets: localhost-recovery-client-token-1
2023-01-09T04:41:09.983843073Z E0109 04:41:09.983827       1 base_controller.go:272] InstallerController reconciliation failed: missing required resources: [secrets: kube-scheduler-client-cert-key, configmaps: config-1,kube-scheduler-cert-syncer-kubeconfig-1,kube-scheduler-pod-1,scheduler-kubeconfig-1,serviceaccount-ca-1, secrets: localhost-recovery-client-token-1]
2023-01-09T04:41:09.983985405Z I0109 04:41:09.983968       1 status_controller.go:211] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]\nInstallerControllerDegraded: missing required resources: [secrets: kube-scheduler-client-cert-key, configmaps: config-1,kube-scheduler-cert-syncer-kubeconfig-1,kube-scheduler-pod-1,scheduler-kubeconfig-1,serviceaccount-ca-1, secrets: localhost-recovery-client-token-1]\nRevisionControllerDegraded: configmaps \"kube-scheduler-pod\" not found","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 1","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 1","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:03Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:41:09.989876075Z I0109 04:41:09.989843       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-scheduler changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal]\nInstallerControllerDegraded: missing required resources: [secrets: kube-scheduler-client-cert-key, configmaps: config-1,kube-scheduler-cert-syncer-kubeconfig-1,kube-scheduler-pod-1,scheduler-kubeconfig-1,serviceaccount-ca-1, secrets: localhost-recovery-client-token-1]\nRevisionControllerDegraded: configmaps \"kube-scheduler-pod\" not found" to "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]\nInstallerControllerDegraded: missing required resources: [secrets: kube-scheduler-client-cert-key, configmaps: config-1,kube-scheduler-cert-syncer-kubeconfig-1,kube-scheduler-pod-1,scheduler-kubeconfig-1,serviceaccount-ca-1, secrets: localhost-recovery-client-token-1]\nRevisionControllerDegraded: configmaps \"kube-scheduler-pod\" not found"
2023-01-09T04:41:11.580208938Z E0109 04:41:11.580167       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:41:11.580208938Z E0109 04:41:11.580198       1 guard_controller.go:268] Missing operand on node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:41:11.580237965Z E0109 04:41:11.580209       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:41:11.587489403Z E0109 04:41:11.587446       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal]
2023-01-09T04:41:11.587986522Z I0109 04:41:11.587955       1 prune_controller.go:269] Nothing to prune
2023-01-09T04:41:11.588099011Z I0109 04:41:11.588025       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionTriggered' new revision 2 triggered by "configmap \"kube-scheduler-pod\" not found"
2023-01-09T04:41:11.588152749Z I0109 04:41:11.588128       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: kube-scheduler-client-cert-key, configmaps: config-1,kube-scheduler-cert-syncer-kubeconfig-1,kube-scheduler-pod-1,scheduler-kubeconfig-1,serviceaccount-ca-1, secrets: localhost-recovery-client-token-1
2023-01-09T04:41:11.588203464Z E0109 04:41:11.588189       1 base_controller.go:272] InstallerController reconciliation failed: missing required resources: [secrets: kube-scheduler-client-cert-key, configmaps: config-1,kube-scheduler-cert-syncer-kubeconfig-1,kube-scheduler-pod-1,scheduler-kubeconfig-1,serviceaccount-ca-1, secrets: localhost-recovery-client-token-1]
2023-01-09T04:41:11.588349889Z I0109 04:41:11.588331       1 status_controller.go:211] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal]\nInstallerControllerDegraded: missing required resources: [secrets: kube-scheduler-client-cert-key, configmaps: config-1,kube-scheduler-cert-syncer-kubeconfig-1,kube-scheduler-pod-1,scheduler-kubeconfig-1,serviceaccount-ca-1, secrets: localhost-recovery-client-token-1]\nRevisionControllerDegraded: configmaps \"kube-scheduler-pod\" not found","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 1","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 1","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:03Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:41:11.595896467Z I0109 04:41:11.595837       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-scheduler changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]\nInstallerControllerDegraded: missing required resources: [secrets: kube-scheduler-client-cert-key, configmaps: config-1,kube-scheduler-cert-syncer-kubeconfig-1,kube-scheduler-pod-1,scheduler-kubeconfig-1,serviceaccount-ca-1, secrets: localhost-recovery-client-token-1]\nRevisionControllerDegraded: configmaps \"kube-scheduler-pod\" not found" to "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal]\nInstallerControllerDegraded: missing required resources: [secrets: kube-scheduler-client-cert-key, configmaps: config-1,kube-scheduler-cert-syncer-kubeconfig-1,kube-scheduler-pod-1,scheduler-kubeconfig-1,serviceaccount-ca-1, secrets: localhost-recovery-client-token-1]\nRevisionControllerDegraded: configmaps \"kube-scheduler-pod\" not found"
2023-01-09T04:41:11.738356958Z I0109 04:41:11.738304       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ServiceAccountCreated' Created ServiceAccount/openshift-kube-scheduler-sa -n openshift-kube-scheduler because it was missing
2023-01-09T04:41:11.743256025Z I0109 04:41:11.743216       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ClusterRoleBindingCreated' Created ClusterRoleBinding.rbac.authorization.k8s.io/system:openshift:operator:kube-scheduler-recovery because it was missing
2023-01-09T04:41:11.831796955Z I0109 04:41:11.831752       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionTriggered' new revision 2 triggered by "configmap \"kube-scheduler-pod\" not found"
2023-01-09T04:41:12.138761555Z I0109 04:41:12.138712       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionTriggered' new revision 2 triggered by "configmap \"kube-scheduler-pod\" not found"
2023-01-09T04:41:12.138809433Z I0109 04:41:12.138786       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/scheduler-kubeconfig -n openshift-kube-scheduler because it was missing
2023-01-09T04:41:13.237225504Z I0109 04:41:13.237178       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionTriggered' new revision 2 triggered by "configmap \"kube-scheduler-pod\" not found"
2023-01-09T04:41:13.737614963Z I0109 04:41:13.737569       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ServiceAccountCreated' Created ServiceAccount/localhost-recovery-client -n openshift-kube-scheduler because it was missing
2023-01-09T04:41:14.739875826Z I0109 04:41:14.739383       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionTriggered' new revision 2 triggered by "configmap \"kube-scheduler-pod\" not found"
2023-01-09T04:41:14.739952144Z I0109 04:41:14.739929       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/localhost-recovery-client-token -n openshift-kube-scheduler because it was missing
2023-01-09T04:41:14.746770162Z I0109 04:41:14.746728       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionTriggered' new revision 2 triggered by "configmap \"kube-scheduler-pod\" not found"
2023-01-09T04:41:14.749769478Z I0109 04:41:14.749732       1 prune_controller.go:269] Nothing to prune
2023-01-09T04:41:14.749848044Z I0109 04:41:14.749823       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionTriggered' new revision 2 triggered by "configmap \"kube-scheduler-pod\" not found"
2023-01-09T04:41:14.749951261Z I0109 04:41:14.749911       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: kube-scheduler-client-cert-key, configmaps: config-1,kube-scheduler-cert-syncer-kubeconfig-1,kube-scheduler-pod-1,scheduler-kubeconfig-1,serviceaccount-ca-1, secrets: localhost-recovery-client-token-1
2023-01-09T04:41:14.750067346Z E0109 04:41:14.750047       1 base_controller.go:272] InstallerController reconciliation failed: missing required resources: [secrets: kube-scheduler-client-cert-key, configmaps: config-1,kube-scheduler-cert-syncer-kubeconfig-1,kube-scheduler-pod-1,scheduler-kubeconfig-1,serviceaccount-ca-1, secrets: localhost-recovery-client-token-1]
2023-01-09T04:41:15.138666022Z I0109 04:41:15.138615       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionTriggered' new revision 2 triggered by "configmap \"kube-scheduler-pod-1\" not found"
2023-01-09T04:41:15.138834342Z I0109 04:41:15.138800       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-scheduler-pod -n openshift-kube-scheduler because it was missing
2023-01-09T04:41:15.146243653Z E0109 04:41:15.146210       1 base_controller.go:272] TargetConfigController reconciliation failed: synthetic requeue request
2023-01-09T04:41:15.146424060Z I0109 04:41:15.146397       1 prune_controller.go:269] Nothing to prune
2023-01-09T04:41:15.146507991Z I0109 04:41:15.146488       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: kube-scheduler-client-cert-key, configmaps: config-1,kube-scheduler-cert-syncer-kubeconfig-1,kube-scheduler-pod-1,scheduler-kubeconfig-1,serviceaccount-ca-1, secrets: localhost-recovery-client-token-1
2023-01-09T04:41:15.146645249Z E0109 04:41:15.146627       1 base_controller.go:272] InstallerController reconciliation failed: missing required resources: [secrets: kube-scheduler-client-cert-key, configmaps: config-1,kube-scheduler-cert-syncer-kubeconfig-1,kube-scheduler-pod-1,scheduler-kubeconfig-1,serviceaccount-ca-1, secrets: localhost-recovery-client-token-1]
2023-01-09T04:41:15.146758975Z I0109 04:41:15.146741       1 status_controller.go:211] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal]\nInstallerControllerDegraded: missing required resources: [secrets: kube-scheduler-client-cert-key, configmaps: config-1,kube-scheduler-cert-syncer-kubeconfig-1,kube-scheduler-pod-1,scheduler-kubeconfig-1,serviceaccount-ca-1, secrets: localhost-recovery-client-token-1]\nRevisionControllerDegraded: configmaps \"kube-scheduler-pod\" not found\nTargetConfigControllerDegraded: \"serviceaccount/localhost-recovery-client\": serviceaccounts \"localhost-recovery-client\" not found","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 1","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 1","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:03Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:41:15.153736907Z I0109 04:41:15.153698       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-scheduler changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal]\nInstallerControllerDegraded: missing required resources: [secrets: kube-scheduler-client-cert-key, configmaps: config-1,kube-scheduler-cert-syncer-kubeconfig-1,kube-scheduler-pod-1,scheduler-kubeconfig-1,serviceaccount-ca-1, secrets: localhost-recovery-client-token-1]\nRevisionControllerDegraded: configmaps \"kube-scheduler-pod\" not found" to "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal]\nInstallerControllerDegraded: missing required resources: [secrets: kube-scheduler-client-cert-key, configmaps: config-1,kube-scheduler-cert-syncer-kubeconfig-1,kube-scheduler-pod-1,scheduler-kubeconfig-1,serviceaccount-ca-1, secrets: localhost-recovery-client-token-1]\nRevisionControllerDegraded: configmaps \"kube-scheduler-pod\" not found\nTargetConfigControllerDegraded: \"serviceaccount/localhost-recovery-client\": serviceaccounts \"localhost-recovery-client\" not found"
2023-01-09T04:41:15.793980264Z I0109 04:41:15.793926       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: kube-scheduler-client-cert-key, configmaps: config-1,kube-scheduler-cert-syncer-kubeconfig-1,kube-scheduler-pod-1,scheduler-kubeconfig-1,serviceaccount-ca-1, secrets: localhost-recovery-client-token-1
2023-01-09T04:41:15.794048124Z E0109 04:41:15.794032       1 base_controller.go:272] InstallerController reconciliation failed: missing required resources: [secrets: kube-scheduler-client-cert-key, configmaps: config-1,kube-scheduler-cert-syncer-kubeconfig-1,kube-scheduler-pod-1,scheduler-kubeconfig-1,serviceaccount-ca-1, secrets: localhost-recovery-client-token-1]
2023-01-09T04:41:16.138422094Z I0109 04:41:16.138358       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapUpdated' Updated ConfigMap/revision-status-2 -n openshift-kube-scheduler:
2023-01-09T04:41:16.138422094Z cause by changes in data.reason
2023-01-09T04:41:16.334902996Z I0109 04:41:16.334864       1 request.go:601] Waited for 1.188201417s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/configmaps/config
2023-01-09T04:41:17.338533342Z I0109 04:41:17.338485       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-scheduler-pod-2 -n openshift-kube-scheduler because it was missing
2023-01-09T04:41:17.534038950Z I0109 04:41:17.533976       1 request.go:601] Waited for 1.197183122s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/configmaps/serviceaccount-ca
2023-01-09T04:41:17.570361013Z E0109 04:41:17.570322       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:41:17.570398601Z E0109 04:41:17.570356       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:41:17.570398601Z E0109 04:41:17.570375       1 guard_controller.go:268] Missing operand on node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:41:17.578069976Z E0109 04:41:17.578039       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal]
2023-01-09T04:41:17.578378017Z I0109 04:41:17.578323       1 prune_controller.go:269] Nothing to prune
2023-01-09T04:41:17.578647579Z E0109 04:41:17.578620       1 base_controller.go:272] InstallerController reconciliation failed: missing required resources: [secrets: kube-scheduler-client-cert-key, configmaps: config-1,kube-scheduler-cert-syncer-kubeconfig-1,kube-scheduler-pod-1,scheduler-kubeconfig-1,serviceaccount-ca-1, secrets: localhost-recovery-client-token-1]
2023-01-09T04:41:17.578668985Z I0109 04:41:17.578620       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: kube-scheduler-client-cert-key, configmaps: config-1,kube-scheduler-cert-syncer-kubeconfig-1,kube-scheduler-pod-1,scheduler-kubeconfig-1,serviceaccount-ca-1, secrets: localhost-recovery-client-token-1
2023-01-09T04:41:17.578830386Z I0109 04:41:17.578809       1 status_controller.go:211] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal]\nInstallerControllerDegraded: missing required resources: [secrets: kube-scheduler-client-cert-key, configmaps: config-1,kube-scheduler-cert-syncer-kubeconfig-1,kube-scheduler-pod-1,scheduler-kubeconfig-1,serviceaccount-ca-1, secrets: localhost-recovery-client-token-1]\nRevisionControllerDegraded: configmaps \"kube-scheduler-pod\" not found\nTargetConfigControllerDegraded: \"serviceaccount/localhost-recovery-client\": serviceaccounts \"localhost-recovery-client\" not found","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 1","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 1","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:03Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:41:17.585638630Z I0109 04:41:17.585590       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-scheduler changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal]\nInstallerControllerDegraded: missing required resources: [secrets: kube-scheduler-client-cert-key, configmaps: config-1,kube-scheduler-cert-syncer-kubeconfig-1,kube-scheduler-pod-1,scheduler-kubeconfig-1,serviceaccount-ca-1, secrets: localhost-recovery-client-token-1]\nRevisionControllerDegraded: configmaps \"kube-scheduler-pod\" not found\nTargetConfigControllerDegraded: \"serviceaccount/localhost-recovery-client\": serviceaccounts \"localhost-recovery-client\" not found" to "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal]\nInstallerControllerDegraded: missing required resources: [secrets: kube-scheduler-client-cert-key, configmaps: config-1,kube-scheduler-cert-syncer-kubeconfig-1,kube-scheduler-pod-1,scheduler-kubeconfig-1,serviceaccount-ca-1, secrets: localhost-recovery-client-token-1]\nRevisionControllerDegraded: configmaps \"kube-scheduler-pod\" not found\nTargetConfigControllerDegraded: \"serviceaccount/localhost-recovery-client\": serviceaccounts \"localhost-recovery-client\" not found"
2023-01-09T04:41:18.322835381Z E0109 04:41:18.322793       1 guard_controller.go:268] Missing operand on node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:41:18.322835381Z E0109 04:41:18.322827       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:41:18.322895237Z E0109 04:41:18.322842       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:41:18.332480376Z E0109 04:41:18.332445       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:41:18.332791618Z I0109 04:41:18.332761       1 prune_controller.go:269] Nothing to prune
2023-01-09T04:41:18.333245299Z I0109 04:41:18.333205       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: kube-scheduler-client-cert-key, configmaps: config-1,kube-scheduler-cert-syncer-kubeconfig-1,kube-scheduler-pod-1,scheduler-kubeconfig-1,serviceaccount-ca-1, secrets: localhost-recovery-client-token-1
2023-01-09T04:41:18.333324586Z E0109 04:41:18.333268       1 base_controller.go:272] InstallerController reconciliation failed: missing required resources: [secrets: kube-scheduler-client-cert-key, configmaps: config-1,kube-scheduler-cert-syncer-kubeconfig-1,kube-scheduler-pod-1,scheduler-kubeconfig-1,serviceaccount-ca-1, secrets: localhost-recovery-client-token-1]
2023-01-09T04:41:18.333518466Z I0109 04:41:18.333480       1 status_controller.go:211] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]\nInstallerControllerDegraded: missing required resources: [secrets: kube-scheduler-client-cert-key, configmaps: config-1,kube-scheduler-cert-syncer-kubeconfig-1,kube-scheduler-pod-1,scheduler-kubeconfig-1,serviceaccount-ca-1, secrets: localhost-recovery-client-token-1]\nRevisionControllerDegraded: configmaps \"kube-scheduler-pod\" not found\nTargetConfigControllerDegraded: \"serviceaccount/localhost-recovery-client\": serviceaccounts \"localhost-recovery-client\" not found","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 1","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 1","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:03Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:41:18.336292933Z E0109 04:41:18.336271       1 guard_controller.go:268] Missing operand on node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:41:18.336318796Z E0109 04:41:18.336291       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:41:18.336318796Z E0109 04:41:18.336303       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:41:18.336455993Z E0109 04:41:18.336442       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:41:18.341462782Z I0109 04:41:18.341430       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-scheduler changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal]\nInstallerControllerDegraded: missing required resources: [secrets: kube-scheduler-client-cert-key, configmaps: config-1,kube-scheduler-cert-syncer-kubeconfig-1,kube-scheduler-pod-1,scheduler-kubeconfig-1,serviceaccount-ca-1, secrets: localhost-recovery-client-token-1]\nRevisionControllerDegraded: configmaps \"kube-scheduler-pod\" not found\nTargetConfigControllerDegraded: \"serviceaccount/localhost-recovery-client\": serviceaccounts \"localhost-recovery-client\" not found" to "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]\nInstallerControllerDegraded: missing required resources: [secrets: kube-scheduler-client-cert-key, configmaps: config-1,kube-scheduler-cert-syncer-kubeconfig-1,kube-scheduler-pod-1,scheduler-kubeconfig-1,serviceaccount-ca-1, secrets: localhost-recovery-client-token-1]\nRevisionControllerDegraded: configmaps \"kube-scheduler-pod\" not found\nTargetConfigControllerDegraded: \"serviceaccount/localhost-recovery-client\": serviceaccounts \"localhost-recovery-client\" not found"
2023-01-09T04:41:18.537768729Z I0109 04:41:18.537727       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/config-2 -n openshift-kube-scheduler because it was missing
2023-01-09T04:41:18.734574928Z I0109 04:41:18.734534       1 request.go:601] Waited for 1.197260694s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/localhost-recovery-client
2023-01-09T04:41:19.739250976Z I0109 04:41:19.739030       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/serviceaccount-ca-2 -n openshift-kube-scheduler because it was missing
2023-01-09T04:41:19.934547918Z I0109 04:41:19.934358       1 request.go:601] Waited for 1.197054219s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/secrets/localhost-recovery-client-token
2023-01-09T04:41:20.226554084Z E0109 04:41:20.226514       1 guard_controller.go:268] Missing operand on node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:41:20.226554084Z E0109 04:41:20.226543       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:41:20.226606703Z E0109 04:41:20.226557       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:41:20.226741672Z E0109 04:41:20.226725       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:41:20.339571274Z E0109 04:41:20.339533       1 guard_controller.go:268] Missing operand on node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:41:20.339571274Z E0109 04:41:20.339562       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:41:20.339623314Z E0109 04:41:20.339576       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:41:20.339778778Z E0109 04:41:20.339761       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:41:20.574085739Z E0109 04:41:20.574048       1 guard_controller.go:268] Missing operand on node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:41:20.574085739Z E0109 04:41:20.574071       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:41:20.574085739Z E0109 04:41:20.574081       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:41:20.574225473Z E0109 04:41:20.574212       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:41:20.934434323Z I0109 04:41:20.934398       1 request.go:601] Waited for 1.195313971s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/configmaps
2023-01-09T04:41:20.938944388Z I0109 04:41:20.938877       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/scheduler-kubeconfig-2 -n openshift-kube-scheduler because it was missing
2023-01-09T04:41:21.329025093Z E0109 04:41:21.328971       1 guard_controller.go:268] Missing operand on node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:41:21.329104867Z E0109 04:41:21.329092       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:41:21.329142907Z E0109 04:41:21.329133       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:41:21.329447603Z E0109 04:41:21.329427       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:41:21.335388030Z E0109 04:41:21.335359       1 guard_controller.go:268] Missing operand on node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:41:21.335444417Z E0109 04:41:21.335433       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:41:21.335481447Z E0109 04:41:21.335471       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:41:21.335702073Z E0109 04:41:21.335688       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:41:21.936122662Z I0109 04:41:21.935567       1 request.go:601] Waited for 1.197202745s due to client-side throttling, not priority and fairness, request: DELETE:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/secrets/kube-scheduler-client-cert-key
2023-01-09T04:41:22.138422300Z I0109 04:41:22.138369       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-scheduler-cert-syncer-kubeconfig-2 -n openshift-kube-scheduler because it was missing
2023-01-09T04:41:22.325101532Z E0109 04:41:22.324882       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:41:22.325101532Z E0109 04:41:22.325089       1 guard_controller.go:268] Missing operand on node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:41:22.325145044Z E0109 04:41:22.325108       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:41:22.332854906Z E0109 04:41:22.332823       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal]
2023-01-09T04:41:22.332959630Z I0109 04:41:22.332937       1 prune_controller.go:269] Nothing to prune
2023-01-09T04:41:22.333270757Z E0109 04:41:22.333229       1 base_controller.go:272] InstallerController reconciliation failed: missing required resources: [secrets: kube-scheduler-client-cert-key, configmaps: config-1,kube-scheduler-cert-syncer-kubeconfig-1,kube-scheduler-pod-1,scheduler-kubeconfig-1,serviceaccount-ca-1, secrets: localhost-recovery-client-token-1]
2023-01-09T04:41:22.333322710Z I0109 04:41:22.333263       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: kube-scheduler-client-cert-key, configmaps: config-1,kube-scheduler-cert-syncer-kubeconfig-1,kube-scheduler-pod-1,scheduler-kubeconfig-1,serviceaccount-ca-1, secrets: localhost-recovery-client-token-1
2023-01-09T04:41:22.333354159Z I0109 04:41:22.333320       1 status_controller.go:211] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal]\nInstallerControllerDegraded: missing required resources: [secrets: kube-scheduler-client-cert-key, configmaps: config-1,kube-scheduler-cert-syncer-kubeconfig-1,kube-scheduler-pod-1,scheduler-kubeconfig-1,serviceaccount-ca-1, secrets: localhost-recovery-client-token-1]\nRevisionControllerDegraded: configmaps \"kube-scheduler-pod\" not found\nTargetConfigControllerDegraded: \"serviceaccount/localhost-recovery-client\": serviceaccounts \"localhost-recovery-client\" not found","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 1","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 1","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:03Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:41:22.343209461Z I0109 04:41:22.343137       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-scheduler changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]\nInstallerControllerDegraded: missing required resources: [secrets: kube-scheduler-client-cert-key, configmaps: config-1,kube-scheduler-cert-syncer-kubeconfig-1,kube-scheduler-pod-1,scheduler-kubeconfig-1,serviceaccount-ca-1, secrets: localhost-recovery-client-token-1]\nRevisionControllerDegraded: configmaps \"kube-scheduler-pod\" not found\nTargetConfigControllerDegraded: \"serviceaccount/localhost-recovery-client\": serviceaccounts \"localhost-recovery-client\" not found" to "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal]\nInstallerControllerDegraded: missing required resources: [secrets: kube-scheduler-client-cert-key, configmaps: config-1,kube-scheduler-cert-syncer-kubeconfig-1,kube-scheduler-pod-1,scheduler-kubeconfig-1,serviceaccount-ca-1, secrets: localhost-recovery-client-token-1]\nRevisionControllerDegraded: configmaps \"kube-scheduler-pod\" not found\nTargetConfigControllerDegraded: \"serviceaccount/localhost-recovery-client\": serviceaccounts \"localhost-recovery-client\" not found"
2023-01-09T04:41:22.572016863Z E0109 04:41:22.571755       1 guard_controller.go:268] Missing operand on node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:41:22.572016863Z E0109 04:41:22.571926       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:41:22.572016863Z E0109 04:41:22.571941       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:41:22.579757532Z E0109 04:41:22.579717       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:41:22.580625908Z E0109 04:41:22.580594       1 base_controller.go:272] InstallerController reconciliation failed: missing required resources: [secrets: kube-scheduler-client-cert-key, configmaps: config-1,kube-scheduler-cert-syncer-kubeconfig-1,kube-scheduler-pod-1,scheduler-kubeconfig-1,serviceaccount-ca-1, secrets: localhost-recovery-client-token-1]
2023-01-09T04:41:22.580625908Z I0109 04:41:22.580615       1 prune_controller.go:269] Nothing to prune
2023-01-09T04:41:22.580654222Z I0109 04:41:22.580636       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: kube-scheduler-client-cert-key, configmaps: config-1,kube-scheduler-cert-syncer-kubeconfig-1,kube-scheduler-pod-1,scheduler-kubeconfig-1,serviceaccount-ca-1, secrets: localhost-recovery-client-token-1
2023-01-09T04:41:22.580833969Z I0109 04:41:22.580814       1 status_controller.go:211] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]\nInstallerControllerDegraded: missing required resources: [secrets: kube-scheduler-client-cert-key, configmaps: config-1,kube-scheduler-cert-syncer-kubeconfig-1,kube-scheduler-pod-1,scheduler-kubeconfig-1,serviceaccount-ca-1, secrets: localhost-recovery-client-token-1]\nRevisionControllerDegraded: configmaps \"kube-scheduler-pod\" not found\nTargetConfigControllerDegraded: \"serviceaccount/localhost-recovery-client\": serviceaccounts \"localhost-recovery-client\" not found","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 1","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 1","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:03Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:41:22.586898558Z I0109 04:41:22.586868       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-scheduler changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal]\nInstallerControllerDegraded: missing required resources: [secrets: kube-scheduler-client-cert-key, configmaps: config-1,kube-scheduler-cert-syncer-kubeconfig-1,kube-scheduler-pod-1,scheduler-kubeconfig-1,serviceaccount-ca-1, secrets: localhost-recovery-client-token-1]\nRevisionControllerDegraded: configmaps \"kube-scheduler-pod\" not found\nTargetConfigControllerDegraded: \"serviceaccount/localhost-recovery-client\": serviceaccounts \"localhost-recovery-client\" not found" to "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]\nInstallerControllerDegraded: missing required resources: [secrets: kube-scheduler-client-cert-key, configmaps: config-1,kube-scheduler-cert-syncer-kubeconfig-1,kube-scheduler-pod-1,scheduler-kubeconfig-1,serviceaccount-ca-1, secrets: localhost-recovery-client-token-1]\nRevisionControllerDegraded: configmaps \"kube-scheduler-pod\" not found\nTargetConfigControllerDegraded: \"serviceaccount/localhost-recovery-client\": serviceaccounts \"localhost-recovery-client\" not found"
2023-01-09T04:41:23.138906545Z I0109 04:41:23.138850       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/serving-cert-2 -n openshift-kube-scheduler because it was missing
2023-01-09T04:41:23.334303574Z I0109 04:41:23.334260       1 request.go:601] Waited for 1.001329389s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/installer-sa
2023-01-09T04:41:24.334656598Z I0109 04:41:24.334606       1 request.go:601] Waited for 1.195980278s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/secrets
2023-01-09T04:41:24.340029331Z I0109 04:41:24.339967       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/localhost-recovery-client-token-2 -n openshift-kube-scheduler because it was missing
2023-01-09T04:41:24.348165739Z I0109 04:41:24.348127       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionCreate' Revision 1 created because configmap "kube-scheduler-pod-1" not found
2023-01-09T04:41:24.348618825Z I0109 04:41:24.348592       1 prune_controller.go:269] Nothing to prune
2023-01-09T04:41:24.349135197Z I0109 04:41:24.349095       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: kube-scheduler-client-cert-key
2023-01-09T04:41:24.349767895Z I0109 04:41:24.349662       1 status_controller.go:211] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]\nInstallerControllerDegraded: missing required resources: [secrets: kube-scheduler-client-cert-key, configmaps: config-1,kube-scheduler-cert-syncer-kubeconfig-1,kube-scheduler-pod-1,scheduler-kubeconfig-1,serviceaccount-ca-1, secrets: localhost-recovery-client-token-1]\nTargetConfigControllerDegraded: \"serviceaccount/localhost-recovery-client\": serviceaccounts \"localhost-recovery-client\" not found","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 1","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 1","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:03Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:41:24.356656415Z I0109 04:41:24.356622       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-scheduler changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]\nInstallerControllerDegraded: missing required resources: [secrets: kube-scheduler-client-cert-key, configmaps: config-1,kube-scheduler-cert-syncer-kubeconfig-1,kube-scheduler-pod-1,scheduler-kubeconfig-1,serviceaccount-ca-1, secrets: localhost-recovery-client-token-1]\nRevisionControllerDegraded: configmaps \"kube-scheduler-pod\" not found\nTargetConfigControllerDegraded: \"serviceaccount/localhost-recovery-client\": serviceaccounts \"localhost-recovery-client\" not found" to "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]\nInstallerControllerDegraded: missing required resources: [secrets: kube-scheduler-client-cert-key, configmaps: config-1,kube-scheduler-cert-syncer-kubeconfig-1,kube-scheduler-pod-1,scheduler-kubeconfig-1,serviceaccount-ca-1, secrets: localhost-recovery-client-token-1]\nTargetConfigControllerDegraded: \"serviceaccount/localhost-recovery-client\": serviceaccounts \"localhost-recovery-client\" not found"
2023-01-09T04:41:24.359730055Z I0109 04:41:24.359702       1 prune_controller.go:269] Nothing to prune
2023-01-09T04:41:24.360886894Z E0109 04:41:24.360070       1 base_controller.go:272] InstallerController reconciliation failed: missing required resources: secrets: kube-scheduler-client-cert-key
2023-01-09T04:41:24.361214440Z E0109 04:41:24.361195       1 base_controller.go:272] InstallerController reconciliation failed: missing required resources: secrets: kube-scheduler-client-cert-key
2023-01-09T04:41:24.361418718Z I0109 04:41:24.360838       1 status_controller.go:211] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]\nInstallerControllerDegraded: missing required resources: secrets: kube-scheduler-client-cert-key\nTargetConfigControllerDegraded: \"serviceaccount/localhost-recovery-client\": serviceaccounts \"localhost-recovery-client\" not found","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 2","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 2","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:03Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:41:24.361610308Z I0109 04:41:24.361570       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: kube-scheduler-client-cert-key
2023-01-09T04:41:24.369053841Z I0109 04:41:24.369022       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-scheduler changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]\nInstallerControllerDegraded: missing required resources: [secrets: kube-scheduler-client-cert-key, configmaps: config-1,kube-scheduler-cert-syncer-kubeconfig-1,kube-scheduler-pod-1,scheduler-kubeconfig-1,serviceaccount-ca-1, secrets: localhost-recovery-client-token-1]\nTargetConfigControllerDegraded: \"serviceaccount/localhost-recovery-client\": serviceaccounts \"localhost-recovery-client\" not found" to "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]\nInstallerControllerDegraded: missing required resources: secrets: kube-scheduler-client-cert-key\nTargetConfigControllerDegraded: \"serviceaccount/localhost-recovery-client\": serviceaccounts \"localhost-recovery-client\" not found",Progressing message changed from "NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 1" to "NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 2",Available message changed from "StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 1" to "StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 2"
2023-01-09T04:41:24.744973319Z I0109 04:41:24.744922       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapUpdated' Updated ConfigMap/kube-scheduler-pod -n openshift-kube-scheduler:
2023-01-09T04:41:24.744973319Z cause by changes in data.pod.yaml
2023-01-09T04:41:24.745293953Z I0109 04:41:24.745255       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionTriggered' new revision 3 triggered by "configmap/kube-scheduler-pod has changed"
2023-01-09T04:41:24.750607567Z I0109 04:41:24.750574       1 prune_controller.go:269] Nothing to prune
2023-01-09T04:41:24.752944996Z E0109 04:41:24.752912       1 base_controller.go:272] InstallerController reconciliation failed: missing required resources: secrets: kube-scheduler-client-cert-key
2023-01-09T04:41:24.753271498Z I0109 04:41:24.753237       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: kube-scheduler-client-cert-key
2023-01-09T04:41:24.753749105Z I0109 04:41:24.753720       1 status_controller.go:211] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]\nInstallerControllerDegraded: missing required resources: secrets: kube-scheduler-client-cert-key","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 2","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 2","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:03Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:41:24.762836610Z I0109 04:41:24.761792       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-scheduler changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]\nInstallerControllerDegraded: missing required resources: secrets: kube-scheduler-client-cert-key\nTargetConfigControllerDegraded: \"serviceaccount/localhost-recovery-client\": serviceaccounts \"localhost-recovery-client\" not found" to "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]\nInstallerControllerDegraded: missing required resources: secrets: kube-scheduler-client-cert-key"
2023-01-09T04:41:25.737561587Z I0109 04:41:25.737513       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/revision-status-3 -n openshift-kube-scheduler because it was missing
2023-01-09T04:41:25.933964309Z I0109 04:41:25.933923       1 request.go:601] Waited for 1.184123054s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/configmaps/config
2023-01-09T04:41:26.934980123Z I0109 04:41:26.934930       1 request.go:601] Waited for 1.19756831s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/configmaps
2023-01-09T04:41:26.939853833Z I0109 04:41:26.939809       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-scheduler-pod-3 -n openshift-kube-scheduler because it was missing
2023-01-09T04:41:27.937927826Z I0109 04:41:27.937875       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/config-3 -n openshift-kube-scheduler because it was missing
2023-01-09T04:41:28.937882668Z I0109 04:41:28.937598       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/serviceaccount-ca-3 -n openshift-kube-scheduler because it was missing
2023-01-09T04:41:29.738559467Z I0109 04:41:29.738502       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/scheduler-kubeconfig-3 -n openshift-kube-scheduler because it was missing
2023-01-09T04:41:30.538027312Z I0109 04:41:30.537955       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-scheduler-cert-syncer-kubeconfig-3 -n openshift-kube-scheduler because it was missing
2023-01-09T04:41:31.340295583Z I0109 04:41:31.339954       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/serving-cert-3 -n openshift-kube-scheduler because it was missing
2023-01-09T04:41:32.142426725Z I0109 04:41:32.141973       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/localhost-recovery-client-token-3 -n openshift-kube-scheduler because it was missing
2023-01-09T04:41:32.151304699Z I0109 04:41:32.151264       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionCreate' Revision 2 created because configmap/kube-scheduler-pod has changed
2023-01-09T04:41:32.151773676Z I0109 04:41:32.151741       1 prune_controller.go:269] Nothing to prune
2023-01-09T04:41:32.152034978Z I0109 04:41:32.151961       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: kube-scheduler-client-cert-key
2023-01-09T04:41:32.153067368Z I0109 04:41:32.153022       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionTriggered' new revision 3 triggered by "configmap/kube-scheduler-pod has changed"
2023-01-09T04:41:32.154497385Z W0109 04:41:32.154471       1 staticpod.go:38] revision 3 is unexpectedly already the latest available revision. This is a possible race!
2023-01-09T04:41:32.159787144Z E0109 04:41:32.159760       1 base_controller.go:272] InstallerController reconciliation failed: missing required resources: secrets: kube-scheduler-client-cert-key
2023-01-09T04:41:32.160022322Z I0109 04:41:32.159984       1 prune_controller.go:269] Nothing to prune
2023-01-09T04:41:32.160245046Z E0109 04:41:32.160222       1 base_controller.go:272] InstallerController reconciliation failed: missing required resources: secrets: kube-scheduler-client-cert-key
2023-01-09T04:41:32.160261265Z I0109 04:41:32.160242       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: kube-scheduler-client-cert-key
2023-01-09T04:41:32.160398018Z I0109 04:41:32.160372       1 status_controller.go:211] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]\nInstallerControllerDegraded: missing required resources: secrets: kube-scheduler-client-cert-key","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 3","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 3","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:03Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:41:32.166316054Z I0109 04:41:32.166284       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-scheduler changed: Progressing message changed from "NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 2" to "NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 3",Available message changed from "StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 2" to "StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 3"
2023-01-09T04:41:32.180521585Z E0109 04:41:32.180489       1 base_controller.go:272] RevisionController reconciliation failed: conflicting latestAvailableRevision 3
2023-01-09T04:41:32.181154089Z I0109 04:41:32.181126       1 prune_controller.go:269] Nothing to prune
2023-01-09T04:41:32.181569869Z E0109 04:41:32.181528       1 base_controller.go:272] InstallerController reconciliation failed: missing required resources: secrets: kube-scheduler-client-cert-key
2023-01-09T04:41:32.181592043Z I0109 04:41:32.181562       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: kube-scheduler-client-cert-key
2023-01-09T04:41:32.181616544Z I0109 04:41:32.181597       1 status_controller.go:211] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]\nInstallerControllerDegraded: missing required resources: secrets: kube-scheduler-client-cert-key\nRevisionControllerDegraded: conflicting latestAvailableRevision 3","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 3","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 3","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:03Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:41:32.188047143Z I0109 04:41:32.187980       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-scheduler changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]\nInstallerControllerDegraded: missing required resources: secrets: kube-scheduler-client-cert-key" to "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]\nInstallerControllerDegraded: missing required resources: secrets: kube-scheduler-client-cert-key\nRevisionControllerDegraded: conflicting latestAvailableRevision 3"
2023-01-09T04:41:32.190265615Z I0109 04:41:32.190235       1 status_controller.go:211] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]\nInstallerControllerDegraded: missing required resources: secrets: kube-scheduler-client-cert-key","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 3","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 3","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:03Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:41:32.190421350Z I0109 04:41:32.190404       1 prune_controller.go:269] Nothing to prune
2023-01-09T04:41:32.190736123Z I0109 04:41:32.190700       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: kube-scheduler-client-cert-key
2023-01-09T04:41:32.190792532Z E0109 04:41:32.190763       1 base_controller.go:272] InstallerController reconciliation failed: missing required resources: secrets: kube-scheduler-client-cert-key
2023-01-09T04:41:32.197726355Z I0109 04:41:32.196934       1 status_controller.go:211] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]\nInstallerControllerDegraded: missing required resources: secrets: kube-scheduler-client-cert-key","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 3","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 3","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:03Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:41:32.197726355Z I0109 04:41:32.197310       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-scheduler changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]\nInstallerControllerDegraded: missing required resources: secrets: kube-scheduler-client-cert-key\nRevisionControllerDegraded: conflicting latestAvailableRevision 3" to "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]\nInstallerControllerDegraded: missing required resources: secrets: kube-scheduler-client-cert-key"
2023-01-09T04:41:32.201383778Z E0109 04:41:32.201358       1 base_controller.go:272] StatusSyncer_kube-scheduler reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io "kube-scheduler": the object has been modified; please apply your changes to the latest version and try again
2023-01-09T04:41:35.401752592Z E0109 04:41:35.401406       1 guard_controller.go:268] Missing operand on node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:41:35.401752592Z E0109 04:41:35.401746       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:41:35.401778744Z E0109 04:41:35.401757       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:41:35.401919614Z E0109 04:41:35.401905       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:41:35.419397081Z E0109 04:41:35.419360       1 guard_controller.go:268] Missing operand on node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:41:35.419485308Z E0109 04:41:35.419449       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:41:35.419485308Z E0109 04:41:35.419474       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:41:35.419827398Z E0109 04:41:35.419799       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:41:35.597071730Z E0109 04:41:35.597033       1 guard_controller.go:268] Missing operand on node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:41:35.597071730Z E0109 04:41:35.597066       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:41:35.597105118Z E0109 04:41:35.597082       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:41:35.597302795Z E0109 04:41:35.597280       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:41:35.617293914Z E0109 04:41:35.617236       1 guard_controller.go:268] Missing operand on node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:41:35.617293914Z E0109 04:41:35.617264       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:41:35.617293914Z E0109 04:41:35.617279       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:41:35.617512272Z E0109 04:41:35.617481       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:41:38.141865073Z I0109 04:41:38.141819       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/kube-scheduler-client-cert-key -n openshift-kube-scheduler because it was missing
2023-01-09T04:41:39.682361292Z E0109 04:41:39.682312       1 guard_controller.go:268] Missing operand on node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:41:39.682361292Z E0109 04:41:39.682340       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:41:39.682361292Z E0109 04:41:39.682352       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:41:39.682516581Z E0109 04:41:39.682500       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:41:41.994561252Z E0109 04:41:41.994386       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:41:41.994561252Z E0109 04:41:41.994551       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:41:41.994596796Z E0109 04:41:41.994561       1 guard_controller.go:268] Missing operand on node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:41:42.003227779Z E0109 04:41:42.003195       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal]
2023-01-09T04:41:42.003527214Z I0109 04:41:42.003502       1 prune_controller.go:269] Nothing to prune
2023-01-09T04:41:42.003929970Z I0109 04:41:42.003904       1 status_controller.go:211] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal]\nInstallerControllerDegraded: missing required resources: secrets: kube-scheduler-client-cert-key","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 3","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 3","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:03Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:41:42.010749471Z I0109 04:41:42.010716       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-scheduler changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]\nInstallerControllerDegraded: missing required resources: secrets: kube-scheduler-client-cert-key" to "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal]\nInstallerControllerDegraded: missing required resources: secrets: kube-scheduler-client-cert-key"
2023-01-09T04:41:42.936082854Z I0109 04:41:42.936044       1 installer_controller.go:524] node ip-10-0-160-211.us-east-2.compute.internal static pod not found and needs new revision 3
2023-01-09T04:41:42.936119144Z I0109 04:41:42.936090       1 installer_controller.go:532] "ip-10-0-160-211.us-east-2.compute.internal" moving to (v1.NodeStatus) {
2023-01-09T04:41:42.936119144Z  NodeName: (string) (len=42) "ip-10-0-160-211.us-east-2.compute.internal",
2023-01-09T04:41:42.936119144Z  CurrentRevision: (int32) 0,
2023-01-09T04:41:42.936119144Z  TargetRevision: (int32) 3,
2023-01-09T04:41:42.936119144Z  LastFailedRevision: (int32) 0,
2023-01-09T04:41:42.936119144Z  LastFailedTime: (*v1.Time)(<nil>),
2023-01-09T04:41:42.936119144Z  LastFailedReason: (string) "",
2023-01-09T04:41:42.936119144Z  LastFailedCount: (int) 0,
2023-01-09T04:41:42.936119144Z  LastFallbackCount: (int) 0,
2023-01-09T04:41:42.936119144Z  LastFailedRevisionErrors: ([]string) <nil>
2023-01-09T04:41:42.936119144Z }
2023-01-09T04:41:42.943608130Z I0109 04:41:42.943562       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeTargetRevisionChanged' Updating node "ip-10-0-160-211.us-east-2.compute.internal" from revision 0 to 3 because node ip-10-0-160-211.us-east-2.compute.internal static pod not found
2023-01-09T04:41:42.944092841Z I0109 04:41:42.944065       1 prune_controller.go:269] Nothing to prune
2023-01-09T04:41:42.965918951Z I0109 04:41:42.965888       1 prune_controller.go:269] Nothing to prune
2023-01-09T04:41:42.966636018Z I0109 04:41:42.966603       1 status_controller.go:211] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal]","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 3","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 3","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:03Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:41:42.971680109Z I0109 04:41:42.971647       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-scheduler changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal]\nInstallerControllerDegraded: missing required resources: secrets: kube-scheduler-client-cert-key" to "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal]"
2023-01-09T04:41:43.425116125Z E0109 04:41:43.424823       1 guard_controller.go:268] Missing operand on node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:41:43.425161256Z E0109 04:41:43.425113       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:41:43.425161256Z E0109 04:41:43.425132       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:41:43.435055984Z E0109 04:41:43.434226       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:41:43.435599656Z I0109 04:41:43.435564       1 prune_controller.go:269] Nothing to prune
2023-01-09T04:41:43.436023321Z I0109 04:41:43.435974       1 status_controller.go:211] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 3","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 3","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:03Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:41:43.444746696Z I0109 04:41:43.444684       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-scheduler changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal]" to "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]"
2023-01-09T04:41:43.445266875Z I0109 04:41:43.445187       1 status_controller.go:211] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 3","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 3","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:03Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:41:43.448712188Z E0109 04:41:43.448684       1 base_controller.go:272] StatusSyncer_kube-scheduler reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io "kube-scheduler": the object has been modified; please apply your changes to the latest version and try again
2023-01-09T04:41:44.940427832Z I0109 04:41:44.940379       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/installer-3-ip-10-0-160-211.us-east-2.compute.internal -n openshift-kube-scheduler because it was missing
2023-01-09T04:41:44.942536530Z E0109 04:41:44.942498       1 guard_controller.go:268] Missing operand on node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:41:44.942536530Z E0109 04:41:44.942523       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:41:44.942564770Z E0109 04:41:44.942538       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:41:44.942697819Z E0109 04:41:44.942683       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:41:44.949907168Z E0109 04:41:44.949877       1 guard_controller.go:268] Missing operand on node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:41:44.949907168Z E0109 04:41:44.949900       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:41:44.949934308Z E0109 04:41:44.949917       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:41:44.950104158Z E0109 04:41:44.950087       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:41:44.954335820Z E0109 04:41:44.954309       1 guard_controller.go:268] Missing operand on node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:41:44.954374452Z E0109 04:41:44.954334       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:41:44.954374452Z E0109 04:41:44.954348       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:41:44.954502600Z E0109 04:41:44.954484       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:41:45.738091231Z I0109 04:41:45.738044       1 installer_controller.go:512] "ip-10-0-160-211.us-east-2.compute.internal" is in transition to 3, but has not made progress because installer is not finished, but in Pending phase
2023-01-09T04:41:47.736252124Z I0109 04:41:47.736215       1 installer_controller.go:512] "ip-10-0-160-211.us-east-2.compute.internal" is in transition to 3, but has not made progress because installer is not finished, but in Pending phase
2023-01-09T04:41:48.223740334Z E0109 04:41:48.223692       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:41:48.223740334Z E0109 04:41:48.223718       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:41:48.223740334Z E0109 04:41:48.223729       1 guard_controller.go:268] Missing operand on node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:41:48.233480256Z E0109 04:41:48.233444       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal]
2023-01-09T04:41:48.234004705Z I0109 04:41:48.233942       1 prune_controller.go:269] Nothing to prune
2023-01-09T04:41:48.234139648Z I0109 04:41:48.234107       1 status_controller.go:211] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal]","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 3","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 3","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:03Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:41:48.235478607Z E0109 04:41:48.235457       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:41:48.235500957Z E0109 04:41:48.235481       1 guard_controller.go:268] Missing operand on node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:41:48.235500957Z E0109 04:41:48.235496       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:41:48.241032359Z I0109 04:41:48.240974       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-scheduler changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]" to "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal]"
2023-01-09T04:41:48.244131102Z I0109 04:41:48.244100       1 prune_controller.go:269] Nothing to prune
2023-01-09T04:41:48.244436160Z E0109 04:41:48.244415       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal]
2023-01-09T04:41:48.244649914Z I0109 04:41:48.244627       1 status_controller.go:211] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal]","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 3","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 3","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:03Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:41:48.246499908Z E0109 04:41:48.246478       1 guard_controller.go:268] Missing operand on node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:41:48.246519360Z E0109 04:41:48.246498       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:41:48.246519360Z E0109 04:41:48.246508       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:41:48.252233084Z I0109 04:41:48.252198       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-scheduler changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal]" to "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal]"
2023-01-09T04:41:48.255611263Z E0109 04:41:48.255583       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:41:48.256074508Z I0109 04:41:48.256053       1 prune_controller.go:269] Nothing to prune
2023-01-09T04:41:48.256465369Z I0109 04:41:48.256444       1 status_controller.go:211] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 3","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 3","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:03Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:41:48.258247867Z E0109 04:41:48.258226       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:41:48.258269901Z E0109 04:41:48.258250       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:41:48.258269901Z E0109 04:41:48.258264       1 guard_controller.go:268] Missing operand on node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:41:48.263872307Z I0109 04:41:48.263841       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-scheduler changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal]" to "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]"
2023-01-09T04:41:48.265825959Z E0109 04:41:48.265794       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal]
2023-01-09T04:41:48.266561934Z I0109 04:41:48.266538       1 prune_controller.go:269] Nothing to prune
2023-01-09T04:41:48.266748974Z I0109 04:41:48.266729       1 status_controller.go:211] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal]","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 3","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 3","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:03Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:41:48.272354561Z I0109 04:41:48.272324       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-scheduler changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]" to "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal]"
2023-01-09T04:41:50.136385193Z I0109 04:41:50.136339       1 installer_controller.go:512] "ip-10-0-160-211.us-east-2.compute.internal" is in transition to 3, but has not made progress because installer is not finished, but in Pending phase
2023-01-09T04:41:51.736237312Z I0109 04:41:51.736172       1 installer_controller.go:512] "ip-10-0-160-211.us-east-2.compute.internal" is in transition to 3, but has not made progress because installer is not finished, but in Pending phase
2023-01-09T04:41:54.027035880Z E0109 04:41:54.026801       1 guard_controller.go:268] Missing operand on node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:41:54.027071623Z E0109 04:41:54.027043       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:41:54.027071623Z E0109 04:41:54.027063       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:41:54.035979606Z E0109 04:41:54.035940       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:41:54.039560411Z I0109 04:41:54.039516       1 status_controller.go:211] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 3","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 3","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:03Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:41:54.040899701Z I0109 04:41:54.040642       1 prune_controller.go:269] Nothing to prune
2023-01-09T04:41:54.046695794Z I0109 04:41:54.046655       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-scheduler changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal]" to "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]"
2023-01-09T04:41:54.344713125Z I0109 04:41:54.344648       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapUpdated' Updated ConfigMap/serviceaccount-ca -n openshift-kube-scheduler:
2023-01-09T04:41:54.344713125Z cause by changes in data.ca-bundle.crt
2023-01-09T04:41:54.347803547Z I0109 04:41:54.346648       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionTriggered' new revision 4 triggered by "configmap/serviceaccount-ca has changed"
2023-01-09T04:41:54.959026603Z E0109 04:41:54.958669       1 guard_controller.go:268] Missing operand on node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:41:54.959072775Z E0109 04:41:54.959030       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:41:54.959072775Z E0109 04:41:54.959046       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:41:54.959293460Z E0109 04:41:54.959272       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:41:55.534446220Z I0109 04:41:55.534116       1 request.go:601] Waited for 1.187471149s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/configmaps
2023-01-09T04:41:55.537763656Z I0109 04:41:55.537691       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/revision-status-4 -n openshift-kube-scheduler because it was missing
2023-01-09T04:41:55.936369620Z I0109 04:41:55.936195       1 installer_controller.go:512] "ip-10-0-160-211.us-east-2.compute.internal" is in transition to 3, but has not made progress because installer is not finished, but in Pending phase
2023-01-09T04:41:56.126336809Z E0109 04:41:56.126295       1 guard_controller.go:268] Missing operand on node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:41:56.126336809Z E0109 04:41:56.126329       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:41:56.126458636Z E0109 04:41:56.126348       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:41:56.126601100Z E0109 04:41:56.126583       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:41:56.534448247Z I0109 04:41:56.534394       1 request.go:601] Waited for 1.197771989s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/secrets/localhost-recovery-client-token
2023-01-09T04:41:56.738859559Z I0109 04:41:56.738802       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-scheduler-pod-4 -n openshift-kube-scheduler because it was missing
2023-01-09T04:41:57.734256726Z I0109 04:41:57.734213       1 request.go:601] Waited for 1.197426903s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/configmaps/scheduler-kubeconfig
2023-01-09T04:41:57.938017009Z I0109 04:41:57.937941       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/config-4 -n openshift-kube-scheduler because it was missing
2023-01-09T04:41:58.282395112Z E0109 04:41:58.282353       1 guard_controller.go:268] Missing operand on node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:41:58.282395112Z E0109 04:41:58.282384       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:41:58.282429292Z E0109 04:41:58.282398       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:41:58.282643662Z E0109 04:41:58.282613       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:41:58.336637296Z I0109 04:41:58.336595       1 installer_controller.go:512] "ip-10-0-160-211.us-east-2.compute.internal" is in transition to 3, but has not made progress because installer is not finished, but in Running phase
2023-01-09T04:41:58.937628948Z I0109 04:41:58.937573       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/serviceaccount-ca-4 -n openshift-kube-scheduler because it was missing
2023-01-09T04:41:59.938284625Z I0109 04:41:59.938219       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/scheduler-kubeconfig-4 -n openshift-kube-scheduler because it was missing
2023-01-09T04:42:00.336563991Z I0109 04:42:00.336521       1 installer_controller.go:512] "ip-10-0-160-211.us-east-2.compute.internal" is in transition to 3, but has not made progress because installer is not finished, but in Running phase
2023-01-09T04:42:00.938130456Z I0109 04:42:00.938057       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-scheduler-cert-syncer-kubeconfig-4 -n openshift-kube-scheduler because it was missing
2023-01-09T04:42:01.539560555Z I0109 04:42:01.539512       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/serving-cert-4 -n openshift-kube-scheduler because it was missing
2023-01-09T04:42:02.138736773Z I0109 04:42:02.138687       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/localhost-recovery-client-token-4 -n openshift-kube-scheduler because it was missing
2023-01-09T04:42:02.146809422Z I0109 04:42:02.146755       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionCreate' Revision 3 created because configmap/serviceaccount-ca has changed
2023-01-09T04:42:02.147197867Z I0109 04:42:02.147159       1 prune_controller.go:269] Nothing to prune
2023-01-09T04:42:03.571072519Z E0109 04:42:03.571036       1 guard_controller.go:268] Missing operand on node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:42:03.571097767Z E0109 04:42:03.571069       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:42:03.571097767Z E0109 04:42:03.571085       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:42:03.571341765Z E0109 04:42:03.571323       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:42:04.139060438Z I0109 04:42:04.139014       1 installer_controller.go:500] "ip-10-0-160-211.us-east-2.compute.internal" moving to (v1.NodeStatus) {
2023-01-09T04:42:04.139060438Z  NodeName: (string) (len=42) "ip-10-0-160-211.us-east-2.compute.internal",
2023-01-09T04:42:04.139060438Z  CurrentRevision: (int32) 0,
2023-01-09T04:42:04.139060438Z  TargetRevision: (int32) 4,
2023-01-09T04:42:04.139060438Z  LastFailedRevision: (int32) 0,
2023-01-09T04:42:04.139060438Z  LastFailedTime: (*v1.Time)(<nil>),
2023-01-09T04:42:04.139060438Z  LastFailedReason: (string) "",
2023-01-09T04:42:04.139060438Z  LastFailedCount: (int) 0,
2023-01-09T04:42:04.139060438Z  LastFallbackCount: (int) 0,
2023-01-09T04:42:04.139060438Z  LastFailedRevisionErrors: ([]string) <nil>
2023-01-09T04:42:04.139060438Z }
2023-01-09T04:42:04.139060438Z  because new revision pending
2023-01-09T04:42:04.141221070Z E0109 04:42:04.141192       1 guard_controller.go:268] Missing operand on node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:42:04.141221070Z E0109 04:42:04.141214       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:42:04.141249394Z E0109 04:42:04.141224       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:42:04.141358745Z E0109 04:42:04.141346       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:42:04.147021517Z I0109 04:42:04.146973       1 prune_controller.go:269] Nothing to prune
2023-01-09T04:42:04.147676760Z I0109 04:42:04.147649       1 status_controller.go:211] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 4","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 4","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:03Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:42:04.156454105Z I0109 04:42:04.156414       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-scheduler changed: Progressing message changed from "NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 3" to "NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 4",Available message changed from "StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 3" to "StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 4"
2023-01-09T04:42:05.333965282Z I0109 04:42:05.333915       1 request.go:601] Waited for 1.170536385s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/installer-4-ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:42:06.204682078Z E0109 04:42:06.204641       1 guard_controller.go:268] Missing operand on node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:42:06.204682078Z E0109 04:42:06.204673       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:42:06.204729506Z E0109 04:42:06.204689       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:42:06.204924117Z E0109 04:42:06.204893       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:42:06.334178550Z I0109 04:42:06.334142       1 request.go:601] Waited for 1.197357857s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller
2023-01-09T04:42:06.539675266Z I0109 04:42:06.539631       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/installer-4-ip-10-0-160-211.us-east-2.compute.internal -n openshift-kube-scheduler because it was missing
2023-01-09T04:42:06.542232557Z E0109 04:42:06.542209       1 guard_controller.go:268] Missing operand on node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:42:06.542253055Z E0109 04:42:06.542231       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:42:06.542253055Z E0109 04:42:06.542241       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:42:06.542398213Z E0109 04:42:06.542383       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:42:06.551399731Z E0109 04:42:06.551368       1 guard_controller.go:268] Missing operand on node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:42:06.551423658Z E0109 04:42:06.551395       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:42:06.551423658Z E0109 04:42:06.551408       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:42:06.551568899Z E0109 04:42:06.551551       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:42:06.558071566Z E0109 04:42:06.558044       1 guard_controller.go:268] Missing operand on node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:42:06.558117928Z E0109 04:42:06.558068       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:42:06.558117928Z E0109 04:42:06.558083       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:42:06.558248973Z E0109 04:42:06.558234       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:42:07.132119514Z E0109 04:42:07.132081       1 guard_controller.go:268] Missing operand on node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:42:07.132119514Z E0109 04:42:07.132109       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:42:07.132153143Z E0109 04:42:07.132123       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:42:07.132309958Z E0109 04:42:07.132293       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:42:07.339837894Z I0109 04:42:07.339800       1 installer_controller.go:512] "ip-10-0-160-211.us-east-2.compute.internal" is in transition to 4, but has not made progress because installer is not finished, but in Pending phase
2023-01-09T04:42:08.194274430Z E0109 04:42:08.194221       1 guard_controller.go:268] Missing operand on node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:42:08.194274430Z E0109 04:42:08.194247       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:42:08.194274430Z E0109 04:42:08.194258       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:42:08.194443553Z E0109 04:42:08.194417       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:42:08.590325606Z E0109 04:42:08.590281       1 guard_controller.go:268] Missing operand on node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:42:08.590415420Z E0109 04:42:08.590403       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:42:08.590455029Z E0109 04:42:08.590445       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:42:08.590720780Z E0109 04:42:08.590703       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:42:09.336649985Z I0109 04:42:09.336603       1 installer_controller.go:512] "ip-10-0-160-211.us-east-2.compute.internal" is in transition to 4, but has not made progress because installer is not finished, but in Running phase
2023-01-09T04:42:10.285722704Z E0109 04:42:10.285055       1 guard_controller.go:268] Missing operand on node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:42:10.285722704Z E0109 04:42:10.285083       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:42:10.285722704Z E0109 04:42:10.285099       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:42:10.285722704Z E0109 04:42:10.285300       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:42:11.136349575Z I0109 04:42:11.136303       1 installer_controller.go:512] "ip-10-0-160-211.us-east-2.compute.internal" is in transition to 4, but has not made progress because installer is not finished, but in Running phase
2023-01-09T04:42:12.527312794Z E0109 04:42:12.527273       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:42:12.527312794Z E0109 04:42:12.527298       1 guard_controller.go:268] Missing operand on node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:42:12.527347222Z E0109 04:42:12.527309       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:42:12.534644771Z E0109 04:42:12.534607       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal]
2023-01-09T04:42:12.535103108Z I0109 04:42:12.535068       1 prune_controller.go:269] Nothing to prune
2023-01-09T04:42:12.535721641Z I0109 04:42:12.535692       1 status_controller.go:211] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal]","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 4","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 4","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:03Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:42:12.542407581Z I0109 04:42:12.542372       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-scheduler changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]" to "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal]"
2023-01-09T04:42:14.137121472Z I0109 04:42:14.137082       1 installer_controller.go:512] "ip-10-0-160-211.us-east-2.compute.internal" is in transition to 4, but has not made progress because installer is not finished, but in Running phase
2023-01-09T04:42:14.215548857Z E0109 04:42:14.215344       1 guard_controller.go:268] Missing operand on node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:42:14.215548857Z E0109 04:42:14.215371       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:42:14.215548857Z E0109 04:42:14.215386       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:42:14.228477525Z E0109 04:42:14.228436       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:42:14.230097532Z I0109 04:42:14.230056       1 status_controller.go:211] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 4","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 4","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:03Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:42:14.233787528Z I0109 04:42:14.232922       1 prune_controller.go:269] Nothing to prune
2023-01-09T04:42:14.254960813Z I0109 04:42:14.252064       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-scheduler changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal]" to "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]"
2023-01-09T04:42:14.666020072Z E0109 04:42:14.665966       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:42:14.666091142Z E0109 04:42:14.666079       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:42:14.666159239Z E0109 04:42:14.666120       1 guard_controller.go:268] Missing operand on node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:42:14.674562990Z E0109 04:42:14.674533       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal]
2023-01-09T04:42:14.675368219Z I0109 04:42:14.675334       1 prune_controller.go:269] Nothing to prune
2023-01-09T04:42:14.675966856Z I0109 04:42:14.675942       1 status_controller.go:211] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal]","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 4","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 4","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:03Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:42:14.681984180Z I0109 04:42:14.681947       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-scheduler changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]" to "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal]"
2023-01-09T04:42:15.188686006Z E0109 04:42:15.188637       1 guard_controller.go:268] Missing operand on node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:42:15.188686006Z E0109 04:42:15.188671       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:42:15.188721364Z E0109 04:42:15.188688       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:42:15.196866957Z E0109 04:42:15.196833       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:42:15.197175758Z I0109 04:42:15.197144       1 prune_controller.go:269] Nothing to prune
2023-01-09T04:42:15.198659387Z I0109 04:42:15.198624       1 status_controller.go:211] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 4","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 4","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:03Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:42:15.210085727Z I0109 04:42:15.209481       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-scheduler changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal]" to "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]"
2023-01-09T04:42:16.136812884Z I0109 04:42:16.136768       1 installer_controller.go:512] "ip-10-0-160-211.us-east-2.compute.internal" is in transition to 4, but has not made progress because installer is not finished, but in Running phase
2023-01-09T04:42:16.219420787Z E0109 04:42:16.219371       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:42:16.219420787Z E0109 04:42:16.219405       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:42:16.219459262Z E0109 04:42:16.219419       1 guard_controller.go:268] Missing operand on node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:42:16.227600817Z E0109 04:42:16.227565       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal]
2023-01-09T04:42:16.228165877Z I0109 04:42:16.228130       1 prune_controller.go:269] Nothing to prune
2023-01-09T04:42:16.228726206Z I0109 04:42:16.228684       1 status_controller.go:211] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal]","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 4","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 4","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:03Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:42:16.236071026Z I0109 04:42:16.235518       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-scheduler changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]" to "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal]"
2023-01-09T04:42:17.151570295Z E0109 04:42:17.151531       1 guard_controller.go:268] Missing operand on node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:42:17.151665465Z E0109 04:42:17.151635       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:42:17.151665465Z E0109 04:42:17.151660       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:42:17.159288084Z E0109 04:42:17.159260       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:42:17.160657738Z I0109 04:42:17.160624       1 status_controller.go:211] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 4","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 4","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:03Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:42:17.162052691Z I0109 04:42:17.162021       1 prune_controller.go:269] Nothing to prune
2023-01-09T04:42:17.162680639Z E0109 04:42:17.162646       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:42:17.162680639Z E0109 04:42:17.162675       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:42:17.162701272Z E0109 04:42:17.162692       1 guard_controller.go:268] Missing operand on node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:42:17.167317058Z I0109 04:42:17.167283       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-scheduler changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal]" to "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]"
2023-01-09T04:42:17.169919228Z E0109 04:42:17.169881       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal]
2023-01-09T04:42:17.170545989Z I0109 04:42:17.170520       1 prune_controller.go:269] Nothing to prune
2023-01-09T04:42:17.170809157Z I0109 04:42:17.170786       1 status_controller.go:211] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal]","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 4","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 4","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:03Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:42:17.177251111Z I0109 04:42:17.177207       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-scheduler changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]" to "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal]"
2023-01-09T04:42:17.236233064Z E0109 04:42:17.236184       1 guard_controller.go:268] Missing operand on node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:42:17.236233064Z E0109 04:42:17.236223       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:42:17.236286031Z E0109 04:42:17.236239       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:42:17.245020358Z E0109 04:42:17.244971       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:42:17.246539900Z I0109 04:42:17.246504       1 status_controller.go:211] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2023-01-09T04:41:05Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 4","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2023-01-09T04:41:04Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 4","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2023-01-09T04:41:03Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2023-01-09T04:42:17.246876695Z I0109 04:42:17.246710       1 prune_controller.go:269] Nothing to prune
2023-01-09T04:42:17.253500098Z I0109 04:42:17.253441       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"d36da3ce-b8ca-4bc5-8827-829259dcf066", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-scheduler changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal, Missing operand on node ip-10-0-199-219.us-east-2.compute.internal]" to "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]"
2023-01-09T04:42:18.136804301Z I0109 04:42:18.136760       1 installer_controller.go:512] "ip-10-0-160-211.us-east-2.compute.internal" is in transition to 4, but has not made progress because installer is not finished, but in Running phase
2023-01-09T04:42:18.341271757Z E0109 04:42:18.341231       1 guard_controller.go:268] Missing operand on node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:42:18.341303747Z E0109 04:42:18.341273       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:42:18.341303747Z E0109 04:42:18.341288       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:42:18.341558718Z E0109 04:42:18.341526       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:42:19.235248663Z E0109 04:42:19.235046       1 guard_controller.go:268] Missing operand on node ip-10-0-199-219.us-east-2.compute.internal
2023-01-09T04:42:19.235248663Z E0109 04:42:19.235089       1 guard_controller.go:268] Missing operand on node ip-10-0-160-211.us-east-2.compute.internal
2023-01-09T04:42:19.235248663Z E0109 04:42:19.235105       1 guard_controller.go:268] Missing operand on node ip-10-0-145-4.us-east-2.compute.internal
2023-01-09T04:42:19.235304204Z E0109 04:42:19.235279       1 base_controller.go:272] GuardController reconciliation failed: [Missing operand on node ip-10-0-199-219.us-east-2.compute.internal, Missing operand on node ip-10-0-160-211.us-east-2.compute.internal, Missing operand on node ip-10-0-145-4.us-east-2.compute.internal]
2023-01-09T04:42:19.936337315Z I0109 04:42:19.936301       1 installer_controller.go:512] "ip-10-0-160-211.us-east-2.compute.internal" is in transition to 4, but has not made progress because installer is not finished, but in Running phase
2023-01-09T04:42:23.067242256Z I0109 04:42:23.067200       1 observer_polling.go:111] Observed file "/var/run/secrets/serving-cert/tls.key" has been created (hash="ad38f21ebc0d401a70ddc7d88326c61d4c79141a16543bddfff2e313d08d5082")
2023-01-09T04:42:23.067242256Z W0109 04:42:23.067233       1 builder.go:129] Restart triggered because of file /var/run/secrets/serving-cert/tls.key was created
2023-01-09T04:42:23.067343105Z I0109 04:42:23.067304       1 genericapiserver.go:593] "[graceful-termination] pre-shutdown hooks completed" name="PreShutdownHooksStopped"
2023-01-09T04:42:23.067343105Z I0109 04:42:23.067324       1 base_controller.go:167] Shutting down StatusSyncer_kube-scheduler ...
2023-01-09T04:42:23.067343105Z I0109 04:42:23.067326       1 observer_polling.go:111] Observed file "/var/run/secrets/serving-cert/tls.crt" has been created (hash="4772276402dcaf729e968f2287a65aacd0802e6daa385a60a1d3408715a8ddc3")
2023-01-09T04:42:23.067371580Z I0109 04:42:23.067351       1 base_controller.go:167] Shutting down RemoveStaleConditionsController ...
2023-01-09T04:42:23.067371580Z I0109 04:42:23.067364       1 base_controller.go:167] Shutting down ResourceSyncController ...
2023-01-09T04:42:23.067383463Z I0109 04:42:23.067370       1 base_controller.go:167] Shutting down KubeControllerManagerStaticResources ...
2023-01-09T04:42:23.067383463Z I0109 04:42:23.067378       1 base_controller.go:167] Shutting down TargetConfigController ...
2023-01-09T04:42:23.067428127Z I0109 04:42:23.067389       1 base_controller.go:167] Shutting down BackingResourceController ...
2023-01-09T04:42:23.067484455Z I0109 04:42:23.067404       1 base_controller.go:114] Shutting down worker of RemoveStaleConditionsController controller ...
2023-01-09T04:42:23.067509550Z I0109 04:42:23.067481       1 base_controller.go:104] All RemoveStaleConditionsController workers have been terminated
2023-01-09T04:42:23.067509550Z I0109 04:42:23.067488       1 base_controller.go:167] Shutting down RevisionController ...
2023-01-09T04:42:23.067509550Z I0109 04:42:23.067491       1 base_controller.go:167] Shutting down PruneController ...
2023-01-09T04:42:23.067509550Z I0109 04:42:23.067502       1 base_controller.go:114] Shutting down worker of BackingResourceController controller ...
2023-01-09T04:42:23.067521339Z I0109 04:42:23.067506       1 base_controller.go:167] Shutting down ConfigObserver ...
2023-01-09T04:42:23.067521339Z I0109 04:42:23.067510       1 base_controller.go:104] All BackingResourceController workers have been terminated
2023-01-09T04:42:23.067531741Z I0109 04:42:23.067519       1 controller_manager.go:54] BackingResourceController controller terminated
2023-01-09T04:42:23.067531741Z I0109 04:42:23.067522       1 base_controller.go:167] Shutting down NodeController ...
2023-01-09T04:42:23.067531741Z I0109 04:42:23.067522       1 base_controller.go:114] Shutting down worker of PruneController controller ...
2023-01-09T04:42:23.067542381Z I0109 04:42:23.067531       1 base_controller.go:114] Shutting down worker of NodeController controller ...
2023-01-09T04:42:23.067542381Z I0109 04:42:23.067538       1 base_controller.go:104] All NodeController workers have been terminated
2023-01-09T04:42:23.067552328Z I0109 04:42:23.067504       1 base_controller.go:167] Shutting down UnsupportedConfigOverridesController ...
2023-01-09T04:42:23.067552328Z I0109 04:42:23.067404       1 genericapiserver.go:493] "[graceful-termination] shutdown event" name="ShutdownInitiated"
2023-01-09T04:42:23.067552328Z I0109 04:42:23.067546       1 controller_manager.go:54] NodeController controller terminated
2023-01-09T04:42:23.067562985Z I0109 04:42:23.067538       1 base_controller.go:114] Shutting down worker of UnsupportedConfigOverridesController controller ...
2023-01-09T04:42:23.067562985Z I0109 04:42:23.067550       1 base_controller.go:114] Shutting down worker of RevisionController controller ...
2023-01-09T04:42:23.067562985Z I0109 04:42:23.067557       1 genericapiserver.go:496] "[graceful-termination] shutdown event" name="AfterShutdownDelayDuration"
2023-01-09T04:42:23.067573909Z I0109 04:42:23.067562       1 base_controller.go:104] All RevisionController workers have been terminated
2023-01-09T04:42:23.067573909Z I0109 04:42:23.067564       1 base_controller.go:167] Shutting down InstallerController ...
2023-01-09T04:42:23.067573909Z I0109 04:42:23.067569       1 controller_manager.go:54] RevisionController controller terminated
2023-01-09T04:42:23.067584398Z I0109 04:42:23.067572       1 base_controller.go:167] Shutting down GuardController ...
2023-01-09T04:42:23.067584398Z I0109 04:42:23.067532       1 base_controller.go:104] All PruneController workers have been terminated
2023-01-09T04:42:23.067594588Z I0109 04:42:23.067581       1 base_controller.go:167] Shutting down InstallerStateController ...
2023-01-09T04:42:23.067594588Z I0109 04:42:23.067581       1 base_controller.go:167] Shutting down StaticPodStateController ...
2023-01-09T04:42:23.067604369Z I0109 04:42:23.067593       1 base_controller.go:114] Shutting down worker of InstallerController controller ...
2023-01-09T04:42:23.067604369Z I0109 04:42:23.067600       1 base_controller.go:104] All InstallerController workers have been terminated
2023-01-09T04:42:23.067614448Z I0109 04:42:23.067600       1 base_controller.go:114] Shutting down worker of StaticPodStateController controller ...
2023-01-09T04:42:23.067614448Z I0109 04:42:23.067606       1 controller_manager.go:54] InstallerController controller terminated
2023-01-09T04:42:23.067614448Z I0109 04:42:23.067608       1 genericapiserver.go:583] "[graceful-termination] shutdown event" name="InFlightRequestsDrained"
2023-01-09T04:42:23.067614448Z I0109 04:42:23.067610       1 base_controller.go:114] Shutting down worker of StatusSyncer_kube-scheduler controller ...
2023-01-09T04:42:23.067629891Z I0109 04:42:23.067604       1 base_controller.go:114] Shutting down worker of LoggingSyncer controller ...
2023-01-09T04:42:23.067629891Z I0109 04:42:23.067611       1 base_controller.go:104] All StaticPodStateController workers have been terminated
2023-01-09T04:42:23.067629891Z I0109 04:42:23.067621       1 base_controller.go:114] Shutting down worker of InstallerStateController controller ...
2023-01-09T04:42:23.067629891Z I0109 04:42:23.067623       1 controller_manager.go:54] StaticPodStateController controller terminated
2023-01-09T04:42:23.067641239Z I0109 04:42:23.067532       1 base_controller.go:114] Shutting down worker of ConfigObserver controller ...
2023-01-09T04:42:23.067641239Z I0109 04:42:23.067592       1 base_controller.go:114] Shutting down worker of MissingStaticPodController controller ...
2023-01-09T04:42:23.067641239Z I0109 04:42:23.067632       1 tlsconfig.go:255] "Shutting down DynamicServingCertificateController"
2023-01-09T04:42:23.067641239Z I0109 04:42:23.067634       1 base_controller.go:104] All ConfigObserver workers have been terminated
2023-01-09T04:42:23.067651758Z I0109 04:42:23.067570       1 base_controller.go:167] Shutting down MissingStaticPodController ...
2023-01-09T04:42:23.067651758Z I0109 04:42:23.067644       1 configmap_cafile_content.go:223] "Shutting down controller" name="client-ca::kube-system::extension-apiserver-authentication::client-ca-file"
2023-01-09T04:42:23.067684626Z I0109 04:42:23.067646       1 base_controller.go:104] All MissingStaticPodController workers have been terminated
2023-01-09T04:42:23.067748999Z I0109 04:42:23.067715       1 controller_manager.go:54] MissingStaticPodController controller terminated
2023-01-09T04:42:23.067748999Z I0109 04:42:23.067585       1 controller_manager.go:54] PruneController controller terminated
2023-01-09T04:42:23.067748999Z I0109 04:42:23.067727       1 secure_serving.go:255] Stopped listening on [::]:8443
2023-01-09T04:42:23.067748999Z I0109 04:42:23.067589       1 base_controller.go:167] Shutting down LoggingSyncer ...
2023-01-09T04:42:23.067763096Z I0109 04:42:23.067737       1 base_controller.go:104] All LoggingSyncer workers have been terminated
2023-01-09T04:42:23.067763096Z I0109 04:42:23.067743       1 controller_manager.go:54] LoggingSyncer controller terminated
2023-01-09T04:42:23.067763096Z I0109 04:42:23.067591       1 object_count_tracker.go:151] "StorageObjectCountTracker pruner is exiting"
2023-01-09T04:42:23.067763096Z I0109 04:42:23.067593       1 base_controller.go:114] Shutting down worker of GuardController controller ...
2023-01-09T04:42:23.067763096Z I0109 04:42:23.067757       1 base_controller.go:104] All GuardController workers have been terminated
2023-01-09T04:42:23.067771964Z I0109 04:42:23.067411       1 base_controller.go:114] Shutting down worker of KubeControllerManagerStaticResources controller ...
2023-01-09T04:42:23.067771964Z I0109 04:42:23.067763       1 controller_manager.go:54] GuardController controller terminated
2023-01-09T04:42:23.067780684Z I0109 04:42:23.067769       1 base_controller.go:104] All KubeControllerManagerStaticResources workers have been terminated
2023-01-09T04:42:23.067780684Z I0109 04:42:23.067602       1 base_controller.go:145] All StatusSyncer_kube-scheduler post start hooks have been terminated
2023-01-09T04:42:23.067794409Z I0109 04:42:23.067779       1 base_controller.go:104] All StatusSyncer_kube-scheduler workers have been terminated
2023-01-09T04:42:23.067794409Z I0109 04:42:23.067618       1 base_controller.go:114] Shutting down worker of ResourceSyncController controller ...
2023-01-09T04:42:23.067794409Z I0109 04:42:23.067788       1 base_controller.go:104] All ResourceSyncController workers have been terminated
2023-01-09T04:42:23.067794409Z I0109 04:42:23.067627       1 base_controller.go:104] All InstallerStateController workers have been terminated
2023-01-09T04:42:23.067802685Z I0109 04:42:23.067794       1 genericapiserver.go:613] [graceful-termination] apiserver is exiting
2023-01-09T04:42:23.067802685Z I0109 04:42:23.067798       1 controller_manager.go:54] InstallerStateController controller terminated
2023-01-09T04:42:23.067810185Z I0109 04:42:23.067555       1 base_controller.go:104] All UnsupportedConfigOverridesController workers have been terminated
2023-01-09T04:42:23.067810185Z I0109 04:42:23.067803       1 builder.go:293] server exited
2023-01-09T04:42:23.067810185Z I0109 04:42:23.067806       1 controller_manager.go:54] UnsupportedConfigOverridesController controller terminated
2023-01-09T04:42:23.067817859Z I0109 04:42:23.067577       1 genericapiserver.go:560] "[graceful-termination] shutdown event" name="NotAcceptingNewRequest"
2023-01-09T04:42:23.067817859Z I0109 04:42:23.067669       1 requestheader_controller.go:183] Shutting down RequestHeaderAuthRequestController
2023-01-09T04:42:23.067825385Z I0109 04:42:23.067674       1 dynamic_serving_content.go:146] "Shutting down controller" name="serving-cert::/tmp/serving-cert-2115128/tls.crt::/tmp/serving-cert-2115128/tls.key"
2023-01-09T04:42:23.067834349Z I0109 04:42:23.067680       1 configmap_cafile_content.go:223] "Shutting down controller" name="client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file"
2023-01-09T04:42:23.067843925Z I0109 04:42:23.067757       1 genericapiserver.go:543] "[graceful-termination] shutdown event" name="HTTPServerStoppedListening"
2023-01-09T04:42:23.068743904Z E0109 04:42:23.068723       1 base_controller.go:272] TargetConfigController reconciliation failed: client rate limiter Wait returned an error: context canceled
2023-01-09T04:42:23.068762441Z I0109 04:42:23.068756       1 base_controller.go:114] Shutting down worker of TargetConfigController controller ...
2023-01-09T04:42:23.068777125Z I0109 04:42:23.068768       1 base_controller.go:104] All TargetConfigController workers have been terminated
2023-01-09T04:42:23.076495600Z W0109 04:42:23.076468       1 leaderelection.go:82] leader election lost
